{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshualevy\\Anaconda3\\envs\\ioCapture\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import traceback\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_econlit_xml(pub_code):\n",
    "    input_path = 'econ_lit_xml/' + pub_code + '_90-21.xml'\n",
    "    econlit_download = open(input_path, 'r', encoding='utf-8')\n",
    "    content = econlit_download.read()\n",
    "    econlit_content = bs(content, 'lxml')\n",
    "\n",
    "    return econlit_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def econlit_obs_counter(pubcode_econlit_bs_content, pub_code, journal_title_list):\n",
    "    candidate_article_list = pubcode_econlit_bs_content.find_all('rec')\n",
    "    pub_list = []\n",
    "    print(\"\\t\\t NUMBER OF {} CANDIDATE ARTICLES FROM ECONLIT XML: {}\".format(pub_code, len(candidate_article_list)))\n",
    "\n",
    "    for candidate in candidate_article_list:\n",
    "        try:\n",
    "            journal_title = candidate.find('jtl').text\n",
    "        except: \n",
    "            print('No \"Journal Title\" found for resultID {}, of {}'.format(candidate.get('resultid'), pub_code))\n",
    "\n",
    "        if journal_title in journal_title_list:\n",
    "            pub_list.append(candidate)\n",
    "        else:\n",
    "            print(\"'Journal Title ({}) for resultID {} of {} not as expected. Moving on.\".format(journal_title, candidate.get('resultid'), pub_code))\n",
    "\n",
    "    print(\"\\t\\t NUMBER OF {} ACTUAL ARTICLES FROM ECONLIT XML: {}\".format(pub_code, len(pub_list)))\n",
    "\n",
    "    return pub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_population(temp_df, xml_obj, nav_dict, field):\n",
    "    try:\n",
    "        # There are 2 fields that contain multiple entries: The JEL Descriptions and Authors (since we're discarding affiliations here)\n",
    "        if field in ['jel_desc', 'author']:\n",
    "            list_of = [desc.text for desc in xml_obj.find_all(nav_dict[field])]\n",
    "            temp_df.at[0, field] = list_of\n",
    "            return temp_df\n",
    "\n",
    "        value = xml_obj.find(nav_dict[field]).text\n",
    "        temp_df[field] = value\n",
    "\n",
    "        return temp_df\n",
    "\n",
    "    except:\n",
    "        value = 'ECONLIT None Found'\n",
    "        temp_df[field] = value\n",
    "        return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pub_field_pop_macro(pub_list):\n",
    "\n",
    "    xml_dict = {\n",
    "        'doi' : 'ui',\n",
    "        'title' : 'atl',\n",
    "        'volume' : 'vid',\n",
    "        'issue' : 'iid',\n",
    "        'date' : 'dt',\n",
    "        'abstract' : 'ab',\n",
    "        'pages' : 'pages',\n",
    "        'author' : 'au',\n",
    "        'jel_desc' : 'su',\n",
    "        'issn' : 'issn'\n",
    "    }\n",
    "\n",
    "    pub_df = pd.DataFrame({})\n",
    "\n",
    "    for article in pub_list:\n",
    "        temp_df = pd.DataFrame({\n",
    "            'doi' : [None],\n",
    "            'title' : [None],\n",
    "            'volume' : [None],\n",
    "            'issue' : [None],\n",
    "            'date' : [None],\n",
    "            'abstract' : [None],\n",
    "            'pages' : [None],\n",
    "            'author' : [None],\n",
    "            'jel_desc' : [None],\n",
    "            'issn' : [None]\n",
    "        })\n",
    "\n",
    "        for field in xml_dict.keys(): \n",
    "            temp_df = field_population(temp_df, article, xml_dict, field)\n",
    "\n",
    "        pub_df = pd.concat([pub_df, temp_df], ignore_index=True)\n",
    "    return pub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dash_date(string):\n",
    "    try:\n",
    "        listed = list(string)\n",
    "        listed.insert(6, '-')\n",
    "        listed.insert(4, '-')\n",
    "\n",
    "        rejoined = ''.join(listed)\n",
    "        return rejoined\n",
    "    except:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_jel_codes():\n",
    "    jel_df = pd.read_xml('aea_jel_codes.xml', xpath='classification')\n",
    "\n",
    "    return jel_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes_articles_merge(pub_df, jel_df):\n",
    "    merge_df = pub_df\n",
    "    merge_df['id'] = np.arange(len(merge_df))\n",
    "\n",
    "\n",
    "    merge_df = merge_df.explode('jel_desc')\n",
    "    merge_df = pd.merge(merge_df, jel_df,\n",
    "                        how = 'left',\n",
    "                        left_on = 'jel_desc',\n",
    "                        right_on = 'description')\n",
    "\n",
    "\n",
    "    merge_df = merge_df.groupby(by='id').agg(\n",
    "        {\n",
    "            'jel_desc' : lambda x: x.tolist(),\n",
    "            'code' : lambda x: x.tolist(),\n",
    "            'doi' : lambda x: x.unique(),\n",
    "            'title' : lambda x: x.unique(),\n",
    "            'volume' : lambda x: x.unique(),\n",
    "            'issue' : lambda x: x.unique(),\n",
    "            'date' : lambda x: x.unique(),\n",
    "            'pages' : lambda x: x.unique(),\n",
    "            'issn' : lambda x: x.unique(), \n",
    "            'author' : lambda x: list(set(x.explode())),\n",
    "            'abstract' : lambda x: ''.join(set(x.explode())),\n",
    "        }\n",
    "    ).rename({'code' : 'jel_code'}, axis=1)\n",
    "\n",
    "    merge_df = merge_df.explode('doi')\n",
    "    merge_df = merge_df.explode('title')\n",
    "    merge_df = merge_df.explode('volume')\n",
    "    merge_df = merge_df.explode('issue')\n",
    "    merge_df = merge_df.explode('date')\n",
    "    merge_df = merge_df.explode('pages')\n",
    "    merge_df = merge_df.explode('issn')\n",
    "    merge_df = merge_df.explode('date')\n",
    "\n",
    "\n",
    "\n",
    "    # return merge_df\n",
    "    merge_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    # pub_jel_df = merge_df[['volume', 'issue', 'date', 'abstract', 'author', 'jel_desc', 'jel_code', 'title']]\n",
    "\n",
    "    # pub_jel_df = merge_df\n",
    "\n",
    "    # return pub_jel_df\n",
    "    return merge_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jel_code_identification(pub_jel_df, codes_patterns_dict):\n",
    "    for jel_pattern in codes_patterns_dict.keys():\n",
    "        pub_jel_df[jel_pattern] = 0\n",
    "\n",
    "    pub_jel_df[['year', 'month', 'day']] = pub_jel_df['date'].str.split('-', expand=True)\n",
    "\n",
    "    for row in pub_jel_df.index.tolist():\n",
    "        article_codes = pub_jel_df.loc[row, 'jel_code']\n",
    "        for code in article_codes:\n",
    "            if type(code) != str:\n",
    "                continue\n",
    "            for code_col in codes_patterns_dict.keys():\n",
    "                pattern = codes_patterns_dict[code_col]\n",
    "                if re.search(pattern, code):\n",
    "                    pub_jel_df.loc[row, code_col] = 1\n",
    "\n",
    "    return pub_jel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, out_path):\n",
    "    df.to_csv(out_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "STARTING ON rje\n",
      "\t 1. ECONLIT XML OBJECT READ-IN\n",
      "\t\t NUMBER OF rje CANDIDATE ARTICLES FROM ECONLIT XML: 1288\n",
      "'Journal Title' for resultID 503 of rje not as expected. Moving on.\n",
      "\t\t NUMBER OF rje ACTUAL ARTICLES FROM ECONLIT XML: 1287\n",
      "\t 2. CONVERTED ECONLIT XML OBJECT TO LIST OF ARTICLE-XML OBJECTS\n",
      "\t 3. POPULATING A DF WITH THOSE ARTICLE-XML OBJECTS\n",
      "\t\t 3.1 REFORMATTING DF DATE FORMATS\n",
      "\t 4. MERGED JEL CODES WITH ARTICLE-LEVEL DF\n",
      "\t 5. PICKED OUT THE JEL CODES WE CARE ABOUT\n",
      "\t 6. DF OUTPUTTED AS CSV\n"
     ]
    }
   ],
   "source": [
    "instruction_dict = {\n",
    "    # 'jpe' : {\n",
    "    #     'pub_code' : 'jpe',\n",
    "    #     'journal_names' : ['Journal of Political Economy'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/jpe_econlit.csv'\n",
    "    # },\n",
    "    # 'qje' : {\n",
    "    #     'pub_code' : 'qje',\n",
    "    #     'journal_names' : ['Quarterly Journal of Economics'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/qje_econlit.csv'\n",
    "    # },\n",
    "    # 'res' : {\n",
    "    #     'pub_code' : 'res',\n",
    "    #     'journal_names' : ['Review of Economic Studies'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/res_econlit.csv'\n",
    "    # },\n",
    "    # 'eca' : {\n",
    "    #     'pub_code' : 'eca',\n",
    "    #     'journal_names' : ['Econometrica'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/eca_econlit.csv'\n",
    "    # },\n",
    "    # 'aer' : {\n",
    "    #     'pub_code' : 'aer',\n",
    "    #     'journal_names' : ['American Economic Review'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/aer_econlit.csv'\n",
    "    # },\n",
    "    # 'rje' : {\n",
    "    #     'pub_code' : 'rje',\n",
    "    #     'journal_names' : ['RAND Journal of Economics (Wiley-Blackwell)', 'RAND Journal of Economics (RAND Journal of Economics)'],\n",
    "    #     'out_path' : 'econlit_scopus_matching_out/rje_econlit.csv'\n",
    "    # },\n",
    "}\n",
    "\n",
    "# Instantiate the df of JEL codes and descriptions for matching\n",
    "jel_df = instantiate_jel_codes()\n",
    "   \n",
    "\n",
    "\n",
    "for pub in instruction_dict.keys(): \n",
    "    pub_code = instruction_dict.get(pub).get('pub_code')\n",
    "    pub_journal_names = instruction_dict.get(pub).get('journal_names')\n",
    "    pub_outpath = instruction_dict.get(pub).get('out_path')\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"STARTING ON {}\".format(pub_code))\n",
    "\n",
    "    # 1. Read in EconLit XML \n",
    "    pub_econlit_content = read_econlit_xml(pub_code)\n",
    "    print('\\t 1. ECONLIT XML OBJECT READ-IN')\n",
    "\n",
    "    # 2. Convert that XML document into a list of XML objects, each an article \n",
    "    pub_article_list = econlit_obs_counter(pub_econlit_content, pub_code, pub_journal_names)\n",
    "    print('\\t 2. CONVERTED ECONLIT XML OBJECT TO LIST OF ARTICLE-XML OBJECTS')\n",
    "\n",
    "    # 3. Instantiate a df that converts each those article-XML objects into a row of a df (This function itself calls 'field_population()')\n",
    "    pub_df = pub_field_pop_macro(pub_article_list)\n",
    "    print('\\t 3. POPULATING A DF WITH THOSE ARTICLE-XML OBJECTS')\n",
    "\n",
    "    # 3.1 Modify the \"date\" string in that df to have a certain format (for future splitting)\n",
    "    pub_df.date = pub_df.date.apply(lambda x: insert_dash_date(x))    \n",
    "    print('\\t\\t 3.1 REFORMATTING DF DATE FORMATS')\n",
    "\n",
    "    # 4. Merge the JEL codes into the pub_df which only has JEL descriptions\n",
    "    pub_jel_df = codes_articles_merge(pub_df, jel_df)\n",
    "    print('\\t 4. MERGED JEL CODES WITH ARTICLE-LEVEL DF')\n",
    "\n",
    "    #5 Output to file\n",
    "    df_to_csv(pub_jel_df, pub_outpath)\n",
    "    print('\\t 5. DF OUTPUTTED AS CSV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    'eca' : {\n",
    "        'pub_code' : 'eca',\n",
    "        'journal_names' : ['Econometrica'],\n",
    "        'out_path' : 'econlit_scopus_matching_out/eca_econlit_test.csv'\n",
    "    },\n",
    "}\n",
    "\n",
    "jel_df = instantiate_jel_codes()\n",
    "for pub in test_dict.keys():\n",
    "    pub_code = test_dict.get(pub).get('pub_code')\n",
    "    pub_journal_names = test_dict.get(pub).get('journal_names')\n",
    "    pub_outpath = test_dict.get(pub).get('out_path')\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"STARTING ON {}\".format(pub_code))\n",
    "\n",
    "    # 1. Read in EconLit XML \n",
    "    pub_econlit_content = read_econlit_xml(pub_code)\n",
    "    print('\\t 1. ECONLIT XML OBJECT READ-IN')\n",
    "\n",
    "    # 2. Convert that XML document into a list of XML objects, each an article \n",
    "    pub_article_list = econlit_obs_counter(pub_econlit_content, pub_code, pub_journal_names)\n",
    "    print('\\t 2. CONVERTED ECONLIT XML OBJECT TO LIST OF ARTICLE-XML OBJECTS')\n",
    "\n",
    "    # 3. Instantiate a df that converts each those article-XML objects into a row of a df (This function itself calls 'field_population()')\n",
    "    pub_df = pub_field_pop_macro(pub_article_list)\n",
    "    print('\\t 3. POPULATING A DF WITH THOSE ARTICLE-XML OBJECTS')\n",
    "\n",
    "    # 3.1 Modify the \"date\" string in that df to have a certain format (for future splitting)\n",
    "    pub_df.date = pub_df.date.apply(lambda x: insert_dash_date(x))    \n",
    "    print('\\t\\t 3.1 REFORMATTING DF DATE FORMATS')\n",
    "\n",
    "    # 4. Merge the JEL codes into the pub_df which only has JEL descriptions\n",
    "    pub_jel_df = codes_articles_merge(pub_df, jel_df)\n",
    "    print('\\t 4. MERGED JEL CODES WITH ARTICLE-LEVEL DF')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "301a221a682cbebc60020c6c7a0e12fb9a472db6fd70ca33686bd8433de05f70"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ioCapture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
