{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import lxml\n",
    "import traceback\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = pd.read_csv('econlit_scopus_matching_out/JPE_author_abstract_funding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aer_df = pd.read_csv('econlit_scopus_matching_out/aer_econlit.csv')\n",
    "eca_df = pd.read_csv('econlit_scopus_matching_out/eca_econlit.csv')\n",
    "jpe_df = pd.read_csv('econlit_scopus_matching_out/jpe_econlit.csv')\n",
    "qje_df = pd.read_csv('econlit_scopus_matching_out/qje_econlit.csv')\n",
    "res_df = pd.read_csv('econlit_scopus_matching_out/res_econlit.csv')\n",
    "rje_df = pd.read_csv('econlit_scopus_matching_out/rje_econlit.csv')\n",
    "\n",
    "aer_df['publication'] = 'aer'\n",
    "eca_df['publication'] = 'eca'\n",
    "jpe_df['publication'] = 'jpe'\n",
    "qje_df['publication'] = 'qje'\n",
    "res_df['publication'] = 'res'\n",
    "rje_df['publication'] = 'rje'\n",
    "\n",
    "\n",
    "econlit_df = pd.concat([aer_df, eca_df, jpe_df, qje_df, res_df, rje_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstracts_df = authors_df[['doi', 'sc_title', 'sc_abstract_text']]\n",
    "abstracts_df = econlit_df[['title', 'date', 'year', 'publication', 'abstract', 'jel_code', 'L_code', 'K_code', 'D4_code', 'O3_code', 'G34_code']]\n",
    "\n",
    "abstracts_df['anti_trust_indicator'] = 0\n",
    "abstracts_df['market_power_indicator'] = 0\n",
    "abstracts_df['L4_code'] = 0\n",
    "abstracts_df['K21_code'] = 0\n",
    "abstracts_df['J3_code'] = 0\n",
    "\n",
    "\n",
    "\n",
    "anti_trust_pattern = r'anti trust|anti-trust|antitrust'\n",
    "market_power_pattern = r'market power|market-power'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0, len(abstracts_df)):\n",
    "    # sc_abstract_text \n",
    "\n",
    "    abstract = abstracts_df.loc[row, 'abstract']\n",
    "    publication = abstracts_df.loc[row, 'publication']\n",
    "    if type(abstracts_df.loc[row, 'abstract']) !=str:\n",
    "        continue\n",
    "    if re.search(anti_trust_pattern, abstract, flags=re.I):\n",
    "        # print(\"Anti-trust: {}\".format(row))\n",
    "        abstracts_df.loc[row, 'anti_trust_indicator']=1\n",
    "        print('ANTI-TRUST--{} in abstract: {}'.format(publication, row))\n",
    "    if re.search(market_power_pattern, abstract, flags=re.I):\n",
    "        # print(\"Market power: {}\".format(row))\n",
    "        abstracts_df.loc[row, 'market_power_indicator']=1\n",
    "        print('MARKET-POWER--{} in abstract: {}'.format(publication, row))\n",
    "    # if re.search(r'merger', abstract, flags=re.I):\n",
    "    #     print('MERGER--{} in abstract: {}'.format(publication, row))\n",
    "    # if re.search(r'cartel', abstract, flags=re.I):\n",
    "    #     print('CARTEL--{} in abstract: {}'.format(publication, row))\n",
    "    # if re.search(r'monopol', abstract, flags=re.I):\n",
    "    #     print('MONOPOL--{} in abstract: {}'.format(publication, row))\n",
    "    # if re.search(r'deadweight loss|deadweight|dead-weight|dead weight', abstract, flags=re.I):\n",
    "    #     print('DEADWEIGHT LOSS--{} in abstract: {}'.format(publication, row))\n",
    "    # if re.search(r'anti compet|anti-compet|anticompet', abstract, flags=re.I):\n",
    "    #     print('ANTI-COMPET--{} in abstract: {}'.format(publication, row))\n",
    "\n",
    "    if type(abstracts_df.loc[row, 'jel_code']) != str:\n",
    "        continue\n",
    "    if re.search(r'L4', abstracts_df.loc[row, 'jel_code'], flags=re.I):\n",
    "        abstracts_df.loc[row, 'L4_code'] = 1\n",
    "\n",
    "    if re.search(r'K21', abstracts_df.loc[row, 'jel_code'], flags=re.I):\n",
    "        abstracts_df.loc[row, 'K21_code'] = 1\n",
    "    if re.search(r'J3', abstracts_df.loc[row, 'jel_code'], flags=re.I):\n",
    "        abstracts_df.loc[row, 'J3_code'] = 1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "# print('ANTI-TRUST COUNT: {}'.format(len(abstracts_df[abstracts_df.anti_trust_indicator==1])))\n",
    "# print('MARKET POWER COUNT: {}'.format(len(abstracts_df[abstracts_df.market_power_indicator==1])))\n",
    "# print('L4-AER CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='aer')])))\n",
    "# print('K21-AER CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='aer')])))\n",
    "# print('L4-ECA CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='eca')])))\n",
    "# print('K21-ECA CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='eca')])))\n",
    "# print('L4-jpe CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='jpe')])))\n",
    "# print('K21-jpe CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='jpe')])))\n",
    "# print('L4-qje CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='qje')])))\n",
    "# print('K21-qje CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='qje')])))\n",
    "# print('L4-res CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='res')])))\n",
    "# print('K21-res CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='res')])))\n",
    "# print('L4-rje CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.L4_code==1) & (abstracts_df.publication=='rje')])))\n",
    "# print('K21-rje CODE COUNT: {}'.format(len(abstracts_df[(abstracts_df.K21_code==1) & (abstracts_df.publication=='rje')])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications_year_df = abstracts_df.groupby(by=['publication', 'year']).agg(\n",
    "    {\n",
    "        'title' : lambda x: len(x)\n",
    "    }\n",
    ")\n",
    "publications_year_df.reset_index(inplace=True)\n",
    "publications_year_df.rename(columns={'title': 'count'}, inplace=True)\n",
    "publications_year_df.to_csv('../adhoc_material/Reports/04-21/publications_year.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_codes_pattern = r'C7|D11|D5|D21|D85|D86'\n",
    "\n",
    "L_papers_df = abstracts_df[abstracts_df.L_code==1]\n",
    "L_papers_df.reset_index(inplace=True)\n",
    "L_papers_df['contains_theory'] = 0\n",
    "\n",
    "for i in range(0, 10):\n",
    "    generated_key = 'L' + str(i)+ '_code'\n",
    "    L_papers_df[generated_key]=0\n",
    "\n",
    "for j in [0,1,2,3,4,9]:\n",
    "    generated_key = 'L4' + str(j) + '_code'\n",
    "    L_papers_df[generated_key] = 0\n",
    "\n",
    "for row in range(0,len(L_papers_df)):\n",
    "    if re.search(theory_codes_pattern, L_papers_df.loc[row, 'jel_code'], flags=re.I):\n",
    "        L_papers_df.loc[row, 'contains_theory'] =1\n",
    "\n",
    "    for i in range(0, 10):\n",
    "        generated_pattern = r'L'+ str(i)\n",
    "        generated_column = 'L' + str(i) + '_code'\n",
    "        if re.search(generated_pattern, L_papers_df.loc[row, 'jel_code'], flags=re.I):\n",
    "            L_papers_df.loc[row, generated_column] = 1\n",
    "\n",
    "    for j in [0,1,2,3,4,9]:\n",
    "        generated_pattern = r'L4'+str(j)\n",
    "        generated_column = 'L4' + str(j) + '_code'\n",
    "        if re.search(generated_pattern, L_papers_df.loc[row, 'jel_code'], flags=re.I):\n",
    "            L_papers_df.loc[row, generated_column] = 1\n",
    "            print(generated_pattern)\n",
    "            print(abstracts_df.loc[row, 'jel_code'])\n",
    "\n",
    "\n",
    "print(\"TOTAL IO: {}\".format(len(L_papers_df)))\n",
    "print(\"TOTAL ANTITRUST: {}\".format(len(L_papers_df[L_papers_df.L4_code ==1])))\n",
    "print(\"IO and at least one theory : {}\".format(len(L_papers_df[L_papers_df.contains_theory==1])))\n",
    "print(\"ANTITRUST AND THEORY: {}\".format(len(L_papers_df[(L_papers_df.contains_theory==1) & (L_papers_df.L4_code == 1)]))) \n",
    "## Plot these counts and shares by year\n",
    "\n",
    "L_papers_df.to_csv('../adhoc_material/Reports/04-21/L_papers_indicators.csv', index=False, encoding='utf-8')\n",
    "# L_papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(46, 49), match='nan'>\n",
      "found a dead one\n",
      "<re.Match object; span=(34, 37), match='nan'>\n",
      "found a dead one\n",
      "<re.Match object; span=(1, 4), match='nan'>\n",
      "[nan, 'E13', 'E32', 'E44', 'E52', np.nan, 'L44', np.nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'a']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_1 =\"[nan, 'E13', 'E32', 'E44', 'E52', nan, 'L44', nan]\"\n",
    "str_2 = '[nan]'\n",
    "str_3 = 'random'\n",
    "\n",
    "\n",
    "\n",
    "nan_test = re.search(r'nan', str_1)\n",
    "nan_test_iter = re.finditer(r'nan', str_1)\n",
    "modified_str = str_1\n",
    "reversing_nans = []\n",
    "\n",
    "for group in nan_test_iter:\n",
    "    reversing_nans.append(group)\n",
    "\n",
    "for group in reversed(reversing_nans):\n",
    "    print(group)\n",
    "    if (group.start(), group.end()) != (1,4):\n",
    "\n",
    "        modified_str = modified_str[:group.start()] + \"np.\" + modified_str[group.start():]\n",
    "        # print(group.start())\n",
    "        # print(group.end())\n",
    "\n",
    "        print('found a dead one')\n",
    "print(modified_str)\n",
    "\n",
    "test_list = ['a', np.nan, 'b','a', np.nan]\n",
    "if len(test_list) == 1 and test_list[0] is np.nan:\n",
    "    print('here')\n",
    "while np.nan in test_list:\n",
    "    test_list.remove(np.nan)\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_jel = abstracts_df[abstracts_df.publication != 'rje']\n",
    "top_five_jel.loc[:,'jel_list_pre'] = np.nan\n",
    "top_five_jel.loc[:, 'jel_list_elem_weight'] = np.nan\n",
    "top_five_jel.loc[:, 'first_jel'] = np.nan\n",
    "top_five_jel.loc[: , 'predom_jel'] = np.nan\n",
    "top_five_jel['jel_list_pre'] = top_five_jel['jel_list_pre'].astype('object')\n",
    "\n",
    "\n",
    "for row in range(0, len(top_five_jel)):\n",
    "    jel_list_as_string = top_five_jel.loc[row, 'jel_code']\n",
    "    nan_test_iter = re.finditer(r'nan', jel_list_as_string)\n",
    "    reversing_nans = []\n",
    "\n",
    "    # we need to collect up the matches so that we can edit in reverse\n",
    "    for group in nan_test_iter:\n",
    "        reversing_nans.append(group)\n",
    "\n",
    "    # we edit in reverse because we need to ensure we don't ruin the match locations with premature insertions\n",
    "    for group in reversed(reversing_nans):\n",
    "        jel_list_as_string = jel_list_as_string[:group.start()] + \"np.\" + jel_list_as_string[group.start():]\n",
    "        print('EDITED AN \"nan\" TO \"np.nan\" AT INDEX: {}'.format(row))\n",
    "        print(jel_list_as_string)\n",
    "\n",
    "\n",
    "    exec('jel_str = {}'.format(jel_list_as_string))\n",
    "    while np.nan in jel_str:\n",
    "        jel_str.remove(np.nan)\n",
    "\n",
    "    jel_list = []\n",
    "    for code in jel_str:\n",
    "        if str(code) == 'np.nan':\n",
    "            continue\n",
    "        jel_alpha = str(code)[0]\n",
    "        jel_list.append(jel_alpha)\n",
    "\n",
    "    \n",
    "    top_five_jel.at[row, 'jel_list_pre'] = jel_list\n",
    "    if len(jel_list) == 0:\n",
    "        top_five_jel.loc[row, 'jel_list_elem_weight'] = 0\n",
    "        top_five_jel.loc[row, 'first_jel'] = np.nan\n",
    "    else:\n",
    "        top_five_jel.loc[row, 'jel_list_elem_weight'] = 1/len(jel_list)\n",
    "        top_five_jel.loc[row, 'first_jel'] = jel_list[0]\n",
    "\n",
    "    jel_category_tuples = [(jel_alpha, jel_list.count(jel_alpha)) for jel_alpha in jel_list]\n",
    "    jel_category_tuples = list(set(jel_category_tuples))\n",
    "    jel_category_tuples.sort(key=lambda tuple: tuple[1])\n",
    "    jel_category_tuples.reverse()\n",
    "    if len(jel_category_tuples) == 0:\n",
    "        top_five_jel.loc[row, 'predom_jel'] = np.nan\n",
    "    elif len(jel_category_tuples) == 1 and jel_category_tuples[0] is np.nan:\n",
    "        top_five_jel.loc[row, 'predom_jel'] = np.nan\n",
    "    else:\n",
    "        top_five_jel.loc[row, 'predom_jel'] = jel_category_tuples[0][0]\n",
    "\n",
    "    print(\"INDEX: {}\\n\\tJEL_LIST_PRE: {}\\n\\tFIRST_JEL: {}\\n\\tPREDOM_JEL: {}\".format(\n",
    "        row, top_five_jel.loc[row, 'jel_list_pre'], top_five_jel.loc[row, 'first_jel'], top_five_jel.loc[row, 'predom_jel']\n",
    "    ))\n",
    "\n",
    "    # print(jel_list)\n",
    "    \n",
    "top_five_jel = top_five_jel[['title', 'year', 'publication', 'predom_jel', 'first_jel', 'jel_list_pre', 'jel_list_elem_weight']]\n",
    "top_five_jel.to_csv('../adhoc_material/Reports/04-21/top_five_jel_breakdown.csv', index=False, encoding='utf8')\n",
    "top_five_jel = top_five_jel[['title', 'year', 'publication', 'jel_list_pre', 'jel_list_elem_weight']]\n",
    "top_five_jel = top_five_jel.explode(column='jel_list_pre')\n",
    "top_five_jel.to_csv('../adhoc_material/Reports/04-21/top_five_jel_unnested.csv', index=False, encoding='utf8')\n",
    "top_five_jel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_pub_count = pd.DataFrame()\n",
    "year_pub_count['count'] = abstracts_df.groupby(by=['year', 'publication']).size()\n",
    "year_pub_count.reset_index(inplace=True)\n",
    "year_pub_count\n",
    "indicator_count_df = abstracts_df.groupby(by=['year', 'publication']).agg({\n",
    "    'L_code': lambda x: x.sum(),\n",
    "    'K_code': lambda x: x.sum(),\n",
    "    'L4_code': lambda x: x.sum(),\n",
    "    'K21_code': lambda x: x.sum(),\n",
    "    'D4_code': lambda x: x.sum(),\n",
    "    'O3_code': lambda x: x.sum(),\n",
    "    'G34_code': lambda x: x.sum(),\n",
    "    'J3_code': lambda x: x.sum(),\n",
    "    'anti_trust_indicator': lambda x: x.sum(),\n",
    "    'market_power_indicator': lambda x: x.sum(),\n",
    "})\n",
    "indicator_count_df.reset_index(inplace=True)\n",
    "indicator_count_df = pd.merge(indicator_count_df, year_pub_count, how='left', on=['year', 'publication'])\n",
    "indicator_count_df.to_csv('indicator_count_df.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aer_authors_df = pd.read_csv('econlit_scopus_matching_out/AER_author_abstract_funding.csv')\n",
    "eca_authors_df = pd.read_csv('econlit_scopus_matching_out/ECA_author_abstract_funding.csv')\n",
    "jpe_authors_df = pd.read_csv('econlit_scopus_matching_out/JPE_author_abstract_funding.csv')\n",
    "qje_authors_df = pd.read_csv('econlit_scopus_matching_out/QJE_author_abstract_funding.csv')\n",
    "res_authors_df = pd.read_csv('econlit_scopus_matching_out/RES_author_abstract_funding.csv')\n",
    "rje_authors_df = pd.read_csv('econlit_scopus_matching_out/RJE_author_abstract_funding.csv')\n",
    "\n",
    "authors_df = pd.concat([eca_authors_df, jpe_authors_df, qje_authors_df, res_authors_df, rje_authors_df], ignore_index=False)\n",
    "authors_df = authors_df[['doi', 'sc_title', 'sc_pub_name', 'sc_author_given_name', 'sc_author_last_name', 'sc_author_id']]\n",
    "authors_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0, len(authors_df)):\n",
    "    pub_name = authors_df.loc[row, 'sc_pub_name']\n",
    "    if type(pub_name) != str:\n",
    "        continue\n",
    "\n",
    "    if pub_name == 'Econometrica : journal of the Econometric Society':\n",
    "        authors_df.loc[row, 'sc_pub_name'] = 'Econometrica'\n",
    "    elif pub_name == 'The Rand journal of economics':\n",
    "        authors_df.loc[row, 'sc_pub_name'] = 'RAND Journal of Economics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.drop_duplicates(subset=['doi', 'sc_pub_name', 'sc_author_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = authors_df.head(100)\n",
    "coauthors_df = authors_df.head(1000).groupby(by=['doi']).apply(lambda df: unique_author_pairs(df))\n",
    "coauthors_df.reset_index(inplace=True)\n",
    "coauthors_df[['author', 'coauthor']] = pd.DataFrame(coauthors_df['pairs'].tolist(), index=coauthors_df.index)\n",
    "# coauthors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_author_pairs(sub_df):\n",
    "    author_ids_list = sub_df['sc_author_id'].unique().tolist()\n",
    "    doi = sub_df['doi'].unique()[0]\n",
    "    \n",
    "    if len(author_ids_list) ==1:\n",
    "        unique_author_pairs = pd.Series(pair for pair in combinations([author_ids_list[0], np.nan], 2))\n",
    "    else:\n",
    "        unique_author_pairs = pd.Series(pair for pair in combinations(author_ids_list,2))\n",
    "    # print(doi)\n",
    "    # print(author_ids_list)\n",
    "    # print(unique_author_pairs)\n",
    "    \n",
    "    # print('-----------------------------')\n",
    "    return pd.DataFrame({\n",
    "        # 'doi' : doi,\n",
    "        'pairs' : unique_author_pairs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(coauthors_df, 'author', 'coauthor')\n",
    "# G = nx.from_pandas_adjacency(coauthors_df[['author', 'coauthor']])\n",
    "\n",
    "G.remove_node(np.nan)\n",
    "nan_edges = [edge for edge in G.edges if np.nan in edge]\n",
    "print(nan_edges)\n",
    "# G.remove_edges_from(nan_edges)\n",
    "# for tup in G.edges:\n",
    "#     if np.nan in tup:\n",
    "#         source = tup[0]\n",
    "#         target = tup[1]\n",
    "#         print(tup)\n",
    "#         G.remove_edge(source, target)\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(20,15))\n",
    "# nx.draw_shell(G, node_size=2)\n",
    "# nx.draw_random(G, node_size=5)\n",
    "# nx.draw_networkx_edges(G)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw(G, pos=pos)  # Draw the original graph"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d024caada2c1174a84651bac8b4321c201a5c821ecf13f184567326fb13b29e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ioCapture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
