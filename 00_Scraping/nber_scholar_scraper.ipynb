{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: This is a configuration code-block. Add as many sub-dictionaries as necessary -- one for each program of interest.\n",
    "instructions_dict = {\n",
    "    # 'PERSONAL PROGRAM CODE' : {\n",
    "    #     'program_name' : 'Program name as NBER uses',\n",
    "    #     'program_api_start_url' : 'url is revealed in the way that the NBER site dynamically hydrates the page. Check the inspector and the XHR requests to see the format and substitute the program name for the program of interest.'\n",
    "    # },\n",
    "    'LABOR': {\n",
    "        'program_name' : 'Labor Studies',\n",
    "        'program_api_start_url' : 'https://www.nber.org/api/v1/scholar_listing/_/_/_/_/search?facet=user_programs%3ALabor%20Studies&page=1&perPage=100&sortBy=alpha'\n",
    "    },\n",
    "    'FINANCE' : {\n",
    "        'program_name' : 'Corporate Finance',\n",
    "        'program_api_start_url' : 'https://www.nber.org/api/v1/scholar_listing/_/_/_/_/search?facet=user_programs%3ACorporate%20Finance&page=1&perPage=100&sortBy=alpha'\n",
    "    },\n",
    "    'IO' : {\n",
    "        'program_name' : 'Industrial Organization',\n",
    "        'program_api_start_url' : 'https://www.nber.org/api/v1/scholar_listing/_/_/_/_/search?facet=user_programs%3AIndustrial%20Organization&page=1&perPage=100&sortBy=alpha'\n",
    "    },\n",
    "    'LAWECON' : {\n",
    "        'program_name' : 'Law and Economics',\n",
    "        'program_api_start_url' : 'https://www.nber.org/api/v1/scholar_listing/_/_/_/_/search?facet=user_programs%3ALaw%20and%20Economics&page=1&perPage=50&sortBy=alpha'\n",
    "    }\n",
    "}\n",
    "storage_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION: Takes in a JSON/dict (API response) and returns the 'totalResults' field as an int.\n",
    "# Note that 'totalResults' can be bigger than the number of results in this response object as the response object is capped to a max of 100 results. (Hence we iterate over subsequent pages later.)\n",
    "def get_total_expected_scholars(json_response):\n",
    "    return json_response.get('totalResults')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION: Takes in an existing df and a JSON/dict (API response). This function unpacks the JSON and reformats it as a pd.df It then concatenates the new df to the extant one. Returns the concatenated (most up-to-date) df\n",
    "def response_to_df(input_df, json_response):\n",
    "    api_results = json_response.get('results')\n",
    "    temp_df = pd.DataFrame.from_records(api_results)\n",
    "    output_df = pd.concat([input_df, temp_df], ignore_index=True)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION: Given a URL and an existing df of scholars, this function queries the URL (an API-endpoint) and returns an updated df of scholars.\n",
    "def get_scholars_by_api(url, existing_df):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        new_df = response_to_df(existing_df, response_json)\n",
    "\n",
    "        try:\n",
    "            print(\"\\tSUCCESS\")\n",
    "            return new_df\n",
    "        except Exception as e:\n",
    "            e.raiseExceptions\n",
    "    else:   \n",
    "        print('FAILING OUT JSON RESPONSE FAILED ON: {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: For each program identified in `instructions_dict`, this loop identifies the number of affiliated scholars and generates a program-level df with scholar-level observations.\n",
    "\n",
    "for program in instructions_dict.keys():\n",
    "    print('WORKING ON: {}'.format(program))\n",
    "    program_name = instructions_dict.get(program).get('program_name')\n",
    "    program_api_start_url = instructions_dict.get(program).get('program_api_start_url')\n",
    "\n",
    "    # A. Check if the API has responded correctly.\n",
    "    init_response = requests.get(program_api_start_url)\n",
    "    init_response_json = init_response.json()\n",
    "    if init_response.status_code == 200:\n",
    "        # If so, figure out if we will need to make multiple calls to collect all scholars (each call has a max. 100 scholars in the response)\n",
    "        expected_total_scholars = get_total_expected_scholars(init_response_json)\n",
    "        print('NUMBER OF SCHOLARS IDENTIFIED AS BEING AFFILIATED WITH {} PROGRAM: {}'.format(program, expected_total_scholars))\n",
    "    else:\n",
    "        # If not, throw an error. \n",
    "        print(\"FAILING OUT JSON RESPONSE FAILED ON: {}\".format(program))\n",
    "\n",
    "    # B. For each page (of length=100) format the API response and concatenate the results to the existing df of scholars. Keep doing this until we have all scholars (length of the temp_df is no less than the exepected number of scholars). Store the resulting program-level df.\n",
    "    exec('{}_df = response_to_df(pd.DataFrame(), init_response_json)'.format(program))\n",
    "    page_number = 1\n",
    "    expected_total_pages = int(math.ceil(expected_total_scholars / 100))\n",
    "    print('TOTAL PAGES TO CALL FOR {} :{}\\nSUCCESS ON CALLING PAGE 1'.format(program, expected_total_pages))\n",
    "    exec('current_df_length = len({}_df)'.format(program))\n",
    "    while current_df_length < expected_total_scholars: \n",
    "        page_number += 1 \n",
    "        new_url = re.sub(r'&page=\\d', r'&page='+str(page_number), program_api_start_url)\n",
    "        print('ATTEMPTING TO CALL ON {} PAGE {this}/{total}'.format(program, this=page_number, total=expected_total_pages))\n",
    "        exec('{}_df = get_scholars_by_api(new_url,{}_df)'.format(program, program))\n",
    "        exec('current_df_length = len({}_df)'.format(program))\n",
    "\n",
    "    exec('storage_dict[\"{}\"] = {}_df'.format(program, program))\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Do some clean up and hen concatenate each of the program-level dfs into a single, large scholar-level df with scholar-level observations to subsequent use.\n",
    "\n",
    "complete_df = pd.DataFrame()\n",
    "for program in storage_dict.keys():\n",
    "    print('CONCATENATING DF FOR {}'.format(program))\n",
    "    temp_df = storage_dict.get(program)\n",
    "    complete_df = pd.concat([complete_df, temp_df], ignore_index=True)\n",
    "\n",
    "# A. For each scholar, convert the link-formatted programs that each scholar is affiliated with, into a list of readable strings (non-link-format).\n",
    "for row in complete_df.index.tolist():\n",
    "    program_string = str(complete_df.loc[row, 'programs'])\n",
    "\n",
    "\n",
    "    matches = re.finditer(r'(?<=\\\">).*?(?=</a>)', program_string)\n",
    "    program_match_list =[]\n",
    "    for match in matches:\n",
    "        program_match_list.append(match.group())\n",
    "\n",
    "    complete_df.at[row, 'programs'] = program_match_list\n",
    "\n",
    "# B. Identify all of the programs that we want to keep. (I.e. we don't want an observation of Scholar X in Program Alpha if we are only interested in Program Beta even if Scholar X is in Programs Alpha and Beta)\n",
    "programs_of_interest_list = []\n",
    "for program in instructions_dict.keys():\n",
    "    program_name = instructions_dict.get(program).get('program_name')\n",
    "    programs_of_interest_list.append(program_name)\n",
    "\n",
    "# Filter out the scholar-program observations that are of programs that we have no interest in\n",
    "complete_df =  complete_df.explode('programs', ignore_index=True)\n",
    "complete_df.reset_index(inplace=True)\n",
    "\n",
    "complete_df = complete_df[complete_df['programs'].isin(programs_of_interest_list)]\n",
    "complete_df = complete_df.drop_duplicates(subset=['id', 'programs'])\n",
    "complete_df = complete_df.rename(columns={\n",
    "    'title' : 'name'\n",
    "})\n",
    "# C. Output to .csv\n",
    "complete_df.to_csv('nber_affiliated_scholars.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d024caada2c1174a84651bac8b4321c201a5c821ecf13f184567326fb13b29e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ioCapture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
