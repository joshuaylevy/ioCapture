{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING NECESSARY PACKAGES\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744c08b8143a77bb752f8b818fd65171\n"
     ]
    }
   ],
   "source": [
    "# Accessing secure API keys\n",
    "keys_json = json.load(open(\"env_keys.json\"))\n",
    "scopus_key = keys_json['scopus_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCOPUS HEADERS\n",
    "req_headers = {\n",
    "    'X-ELS-APIKey' : scopus_key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to construct a scopus query\n",
    "# Guide: https://dev.elsevier.com/sc_search_tips.html\n",
    "# Practice at: https://www.scopus.com/search/form.uri?display=advanced\n",
    "\n",
    "\n",
    "# Do NOT use urllib.parse.____ to pre-url-ify the url because the requests package does that for you.\n",
    "human_query = \"ISSN('00223808')\"\n",
    "\n",
    "\n",
    "### SCOPUS ARTICLE QUERY\n",
    "req_query = {\n",
    "    'httpAccept' : 'application/json',\n",
    "    'query' : human_query,\n",
    "    'date' : '1990-2022',\n",
    "    'count' : '200',\n",
    "    'start' : '1201'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r = requests.get('https://api.elsevier.com/content/search/scopus',\n",
    "    headers=req_headers,\n",
    "    params=req_query)\n",
    "print(r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()\n",
    "r.json()['search-results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that helps to fill out article-level observations from the API response without throwing too many failures or blowing up the whole process without getting at least the most important information. It is also used to collect as much author/abstract/reference information as possible without killing the whole process.\n",
    "def field_population(temp_df, json_obj, navigation_dict, field):\n",
    "    json_object = json_obj\n",
    "    # pub_name = article_obj['prism:publicationName']\n",
    "    \n",
    "    try:\n",
    "        # print(eval('article_obj{}'.format(article_obj_nav_dict[destination])))\n",
    "        exec('temp_df[\"{}\"] = json_object{}'.format(field, navigation_dict[field]))\n",
    "        # eval('print(article_obj{})'.format(article_obj_nav_dict[field]))\n",
    "        # print(temp_df)\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"SCOPUS FAILURE ON: {}\".format(field))\n",
    "        # print(e)\n",
    "        temp_df[field] = 'SCOPUS FAILURE'\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an issn and a year in which to begin, this function collects all articles from the SCOPUS Search API and returns a publication-specific df \n",
    "def publication_collect(issn:str, start_year:str, journal_name:str):\n",
    "    # INSTANTIATE AN EMPTY DATAFRAME THAT WILL CONTAIN ALL OF THE RESULTS FOR THIS PUBLICATION\n",
    "    pub_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    #### FIRST WE NEED TO SEE HOW MANY ARTICLES WE NEED TO COLLECT FROM THIS PUBLICATION\n",
    "    current_year = date.today().year - 1\n",
    "    human_query_issn = 'ISSN({issn_str})'.format(issn_str=issn)\n",
    "    human_query_date = '{start_year_str}-{current_year_str}'.format(start_year_str=start_year,\n",
    "                                                                    current_year_str=current_year)    \n",
    "    req_headers = {\n",
    "        'X-ELS-APIKey' : scopus_key\n",
    "    }\n",
    "\n",
    "    prelim_query = {\n",
    "        'httpAccept' : 'application/json',\n",
    "        'query' : human_query_issn,\n",
    "        'date' : human_query_date,\n",
    "        'count' : '1',\n",
    "        'cursor' : '*'\n",
    "    }\n",
    "\n",
    "    prelim_r = requests.get('https://api.elsevier.com/content/search/scopus',\n",
    "                            headers=req_headers,\n",
    "                            params=prelim_query)\n",
    "    print(\"PRELIM {pub_name} API STATUS CODE: {status}\".format(pub_name=journal_name, status=prelim_r.status_code))\n",
    "    prelim_json = prelim_r.json()\n",
    "    # print(prelim_json)\n",
    "    article_count = int(prelim_json['search-results']['opensearch:totalResults'])\n",
    "    print(\"PRELIM COUNT OF ARTICLES FOUND BY API: {}\".format(article_count))\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    \n",
    "\n",
    "    still_more_pages_to_call = True\n",
    "\n",
    "    nth_call_counter = 1\n",
    "    ### THE API WILL ONLY RETURN 200 ARTICLES AT TIME, SO WE NEED TO CREATE A WHILE-LOOP THAT PULLS 200 RESULTS AT A TIME AS LONG AS THE CURRENT RESPONSE LINKS TO A POTENTIAL 'next' PAGE.\n",
    "    while still_more_pages_to_call:     \n",
    "        call_df = pd.DataFrame()\n",
    "        if nth_call_counter ==1: \n",
    "            call_query = {\n",
    "                'httpAccept' : 'application/json',\n",
    "                'query' : human_query_issn,\n",
    "                'date' : human_query_date,\n",
    "                'count' : '200',\n",
    "                'cursor' : '*' \n",
    "            }\n",
    "            nth_call_counter +=1\n",
    "        else:\n",
    "            nth_call_counter +=1\n",
    "            cursor_next_hash = r_json['cursor']['@next']\n",
    "            print(\"cursor next hash value: {}\".format(cursor_next_hash))\n",
    "            call_query = {\n",
    "                'httpAccept' : 'application/json',\n",
    "                'query' : human_query_issn,\n",
    "                'date' : human_query_date,\n",
    "                'count' : '200',\n",
    "                'cursor' : cursor_next_hash\n",
    "            }\n",
    "        \n",
    "\n",
    "        # print(call_query)\n",
    "\n",
    "        # THIS IS WHERE WE CALL THE API TO GET THE LIST OF ARTICLES (200 AT A TIME BY USING 'cursor/@next')\n",
    "        r = requests.get('https://api.elsevier.com/content/search/scopus',\n",
    "                        headers=req_headers,\n",
    "                        params=call_query)\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(\"CALL {n} FOR {pub_name} AND {count} ARTICLES RETURNING STATUS CODE: {code}\".format(pub_name=journal_name,\n",
    "                                                                                    n=nth_call_counter -1,\n",
    "                                                                                    count=call_query['count'],\n",
    "                                                                                    code=r.status_code))\n",
    "        \n",
    "        # print(r.json())\n",
    "        r_json = r.json()['search-results']\n",
    "\n",
    "        if r_json['cursor']['@current'] == r_json['cursor']['@next']:\n",
    "            print(\"We have reached the end of the 'cursor-next' chain. breaking out of this pub\")\n",
    "            still_more_pages_to_call = False\n",
    "            break\n",
    "        else:\n",
    "            print(\"Going to finish collecting this page and then there still at least one more to go.\")\n",
    "\n",
    "        # NOW WE BEGIN UNPACKING EACH BATCH OF 200 TO STORE IN A TEMP DF\n",
    "        sc_query_used = r_json['link'][0]['@href']\n",
    "        r_results = r_json['entry']\n",
    "        print(\"{pub_name} CALL {n} FOR {count} ARTICLES FOUND RESULTS: {num}\".format(pub_name=journal_name,\n",
    "                                                                                    n=nth_call_counter,\n",
    "                                                                                    count=call_query['count'],\n",
    "                                                                                    num=len(r_results)))\n",
    "        \n",
    "        ## THIS DICTIONARY SHOULD BE STRUCTURED IN ORDER OF IMPORTANCE. IE. PULLING THE API ENDPOINT IS MORE IMPORTANT THAN PULLING THE DOI, WHICH IS MORE IMPORTANT THE TITLE ETC.\n",
    "        article_obj_nav_dict = {\n",
    "            'sc_abstract_api_endpoint' : '[\"link\"][0][\"@href\"]',\n",
    "            'doi' : \"['prism:doi']\",\n",
    "            'sc_title' : \"['dc:title']\",\n",
    "            'sc_issn' : \"['prism:issn']\",\n",
    "            'sc_pub_name' : \"['prism:publicationName']\",\n",
    "            'sc_pub_date' : \"['prism:coverDate']\",\n",
    "            'sc_open_access_status' : \"['openaccessFlag']\",\n",
    "            'sc_vol' : \"['prism:volume']\",\n",
    "            'sc_issue' : \"['prism:issueIdentifier']\",\n",
    "            'sc_page_range' : \"['prism:pageRange']\",\n",
    "            'sc_human_url' : \"['link'][3]['@href']\"\n",
    "        }\n",
    "\n",
    "        for article_obj in r_results:\n",
    "            # CONSTRUCT A TEMP_DF THAT CONTAINS A SINGLE ARTICLE THAT WILL BE APPENDED TO call_df\n",
    "            temp_df = pd.DataFrame({\n",
    "                'doi' : [None],\n",
    "                'sc_title' : [None],\n",
    "                'sc_issn' : [None],\n",
    "                'sc_pub_name' : [None],\n",
    "                'sc_vol' : [None],\n",
    "                'sc_issue' : [None],\n",
    "                'sc_page_range' : [None],\n",
    "                'sc_abstract_api_endpoint' : [None],\n",
    "                'sc_human_url' : [None]\n",
    "            })\n",
    "            for field in article_obj_nav_dict:\n",
    "                # FOR EACH OF THE FIELDS IDENTIFIED ABOVE (article_obj_nav_dict), EXECUTE THE field population FUNCTION THAT WILL TRY TO ACCESS THAT FIELD ACCORDING TO THE GIVEN SUBSCRIPT. IF UNAVAILABLE, CONTINUE WITH NOTATION OF FAILURE\n",
    "                temp_df = field_population(temp_df, article_obj, article_obj_nav_dict, field)\n",
    "\n",
    "            # ADD THE ARTICLE TO call_df\n",
    "            # print(temp_df)\n",
    "            call_df = pd.concat([call_df, temp_df], ignore_index=True)\n",
    "\n",
    "        #ADD TO THE call_df THE CONSTRUCTED API-ENDPOINT QUERY THAT WAS USED TO GENERATE ALL OF THE RESULTS (ARTICLES) FOR THIS call_df\n",
    "        call_df['sc_query_used'] = sc_query_used\n",
    "\n",
    "        # ADD THE 200-BATCH OF ARTICLES TO pub_df\n",
    "        pub_df = pd.concat([pub_df, call_df], ignore_index=True)\n",
    "\n",
    "        ### TIMER HERE TO ENSURE WE DON'T EXCEED THE SCOPUS API'S QUERY THROTTLE\n",
    "        time.sleep(0.15)\n",
    "\n",
    "\n",
    "    return pub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MASTER RUN BLOCK HERE. BE CAREFUL\n",
    "collection_dict = {\n",
    "    'JPE' : {\n",
    "        'issn' : '00223808',\n",
    "        'start_year' : '1990',\n",
    "        'print_name' : 'Journal of Political Economy'\n",
    "    },\n",
    "    # 'QJE' : {\n",
    "    #     'issn' : '00335533',\n",
    "    #     'start_year' : '1990',\n",
    "    #     'print_name' : 'Quarterly Journal of Economics'\n",
    "    # }, \n",
    "    # 'AER' : {\n",
    "    #     'issn' : '00028282',\n",
    "    #     'start_year' : '1990',\n",
    "    #     'print_name' : 'American Economic Review'\n",
    "    # },\n",
    "    # 'RST' : {\n",
    "    #     'issn' : '00346527',\n",
    "    #     'start_year' : '1990',\n",
    "    #     'print_name' : 'Review of Economic Studies' \n",
    "    # },\n",
    "    # 'ECN' : {\n",
    "    #     'issn' : '00129682',\n",
    "    #     'start_year' : '1990',\n",
    "    #     'print_name' : 'Econometrica'\n",
    "    # }\n",
    "}\n",
    "\n",
    "# This is the dictionary that we are going to use to access the publication-specific dfs\n",
    "pub_dict = {}\n",
    "\n",
    "for pub in collection_dict.keys():\n",
    "    pub_code = pub\n",
    "    pub_issn = collection_dict.get(pub).get('issn')\n",
    "    pub_start_year = collection_dict.get(pub).get('start_year')\n",
    "    pub_name = collection_dict.get(pub).get('print_name')\n",
    "\n",
    "    exec('{}_df = publication_collect(\"{}\", \"{}\",\"{}\")'.format(pub_code, pub_issn, pub_start_year, pub_name))\n",
    "    exec('pub_dict[\"{}\"] = {}_df'.format(pub_code,pub_code))\n",
    "\n",
    "\n",
    "# pub_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a pub_code (see 'collection_dict' keys), this function identifies the publication-specific df generated by 'publication_collect', and generates two new dfs: 1) authors and abstract; and 2) the citations that the article of interest makes. It then merges these back on to the pub_df (1:m) and returns that updated pub_df. We ALWAYS merge on 'doi' because it is universal (so we can merge with other datasets later).\n",
    "def abstract_references_collect(pub_code):\n",
    "    pub_df = pub_dict.get(pub_code)\n",
    "\n",
    "    abstract_query = {\n",
    "        'httpAccept' : 'application/json'\n",
    "    }\n",
    "\n",
    "    articles = pub_df.head(10)[['doi', 'sc_abstract_api_endpoint']]\n",
    "\n",
    "    authors_abstracts_df = pd.DataFrame()\n",
    "    article_cites_df = pd.DataFrame()\n",
    "\n",
    "    # WE ARE GOING TO GO THROUGH EVERY ARTICLE IN THIS PUBLICATION \n",
    "    for row in range(0, len(articles)):\n",
    "        doi = articles.loc[row, 'doi']\n",
    "        url = articles.loc[row, 'sc_abstract_api_endpoint']\n",
    "\n",
    "        # CLEAR TEMP DFS\n",
    "        aa_df_temp = pd.DataFrame()\n",
    "        article_cites_df_temp = pd.DataFrame()\n",
    "    \n",
    "\n",
    "        abstract_r = requests.get(url, headers=req_headers, params=abstract_query)\n",
    "        if abstract_r.status_code != 200:\n",
    "            continue\n",
    "\n",
    "        abstract_r_json = abstract_r.json()\n",
    "\n",
    "        ###################################\n",
    "        # WE DO AUTHORS AND ABSTRACTS FIRST\n",
    "        ###################################\n",
    "\n",
    "        authors_object = abstract_r_json['abstracts-retrieval-response']['item']['bibrecord']['head']['author-group']\n",
    "        abstract_text = abstract_r_json['abstracts-retrieval-response']['item']['bibrecord']['head']['abstracts']\n",
    "\n",
    "        sc_author_id_list = []\n",
    "        sc_author_given_name_list = []\n",
    "        sc_author_last_name_list = []\n",
    "        sc_author_indexed_name_list = []\n",
    "        sc_author_affil_id_list = []\n",
    "        sc_author_affil_indexed_list =[]\n",
    "        sc_funding_inst_id_list = []\n",
    "        sc_funding_inst_name_list = []\n",
    "        sc_funding_text_list = []\n",
    "\n",
    "        # IF there is only a single author then this is a json/dict...\n",
    "        if type(authors_object) == dict:\n",
    "            aa_json = authors_object\n",
    "\n",
    "\n",
    "            sc_author_id = aa_json['author'][0]['@auid']\n",
    "            sc_author_given_name = aa_json['author'][0]['preferred-name']['ce:given-name']\n",
    "            sc_author_last_name = aa_json['author'][0]['preferred-name']['ce:surname']\n",
    "            sc_author_indexed_name = aa_json['author'][0]['preferred-name']['ce:indexed-name']\n",
    "\n",
    "            sc_author_id_list.append(sc_author_id)\n",
    "            sc_author_given_name_list.append(sc_author_given_name)\n",
    "            sc_author_last_name_list.append(sc_author_last_name)\n",
    "            sc_author_indexed_name_list.append(sc_author_indexed_name)\n",
    "\n",
    "            # SOMETIMES AN AUTHOR HAS MULTIPLE AFFILIATIONS (EG NBER AND HARVARD). IN THIS CASE, WE CONCATENATE ALL OF THE AFFILIATIONS, DELIMITED BY '+' SYMBOLS AND STORE THEM AS A STRING (TO BE UNNESTED LATER)\n",
    "            if type(aa_json['affiliation']['affiliation-id']) == list:\n",
    "                multi_affil_list = []\n",
    "                for obj in aa_json['affiliation']['affiliation-id']:\n",
    "                    multi_affil_list.append(obj['@afid'])\n",
    "                '+'.join(multi_affil_list)\n",
    "            else:\n",
    "                sc_author_affil_id = aa_json['affiliation']['affiliation-id']['@afid']\n",
    "            sc_author_affil_indexed = aa_json['affiliation']['ce:source-text']\n",
    "\n",
    "            sc_author_affil_id_list.append(sc_author_affil_id)\n",
    "            sc_author_affil_indexed_list.append(sc_author_affil_indexed)\n",
    "        #... but if there are multiple authors this is a list of jsons/dicts\n",
    "        else:\n",
    "            for author_affil in authors_object:\n",
    "                aa_json = author_affil\n",
    "\n",
    "                sc_author_id = aa_json['author'][0]['@auid']\n",
    "                sc_author_given_name = aa_json['author'][0]['preferred-name']['ce:given-name']\n",
    "                sc_author_last_name = aa_json['author'][0]['preferred-name']['ce:surname']\n",
    "                sc_author_indexed_name = aa_json['author'][0]['preferred-name']['ce:indexed-name']\n",
    "\n",
    "                sc_author_id_list.append(sc_author_id)\n",
    "                sc_author_given_name_list.append(sc_author_given_name)\n",
    "                sc_author_last_name_list.append(sc_author_last_name)\n",
    "                sc_author_indexed_name_list.append(sc_author_indexed_name)\n",
    "\n",
    "                if type(aa_json['affiliation']['affiliation-id']) == list:\n",
    "                    multi_affil_list = []\n",
    "                    for obj in aa_json['affiliation']['affiliation-id']:\n",
    "                        multi_affil_list.append(obj['@afid'])\n",
    "                    '+'.join(multi_affil_list)\n",
    "                else:\n",
    "                    sc_author_affil_id = aa_json['affiliation']['affiliation-id']['@afid']\n",
    "                sc_author_affil_indexed = aa_json['affiliation']['ce:source-text']\n",
    "\n",
    "                sc_author_affil_id_list.append(sc_author_affil_id)\n",
    "                sc_author_affil_indexed_list.append(sc_author_affil_indexed)\n",
    "\n",
    "\n",
    "        aa_df_temp = pd.DataFrame({\n",
    "            'doi' : doi,\n",
    "            'abstract' : abstract_text,\n",
    "            'sc_author_id' : sc_author_id_list,\n",
    "            'sc_author_given_name' : sc_author_given_name_list,\n",
    "            'sc_author_last_name' : sc_author_last_name_list,\n",
    "            'sc_author_indexed_name' : sc_author_indexed_name_list,\n",
    "            'sc_author_affil_id' : sc_author_affil_id_list,\n",
    "            'sc_author_affil_indexed' : sc_author_affil_indexed,\n",
    "            'sc_funding_inst_id' : sc_funding_inst_id_list,\n",
    "            'sc_funding_inst_name' : sc_funding_inst_name_list,\n",
    "            'sc_funding_text'  : sc_funding_text_list \n",
    "        })\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # WE DO REFERENCES AND CITES NEXT\n",
    "        #################################\n",
    "\n",
    "        references_object = abstract_r_json['abstracts-retrieval-response']['item']['bibrecord']['tail']['bibliography']\n",
    "\n",
    "        print(references_object['@refcount'])\n",
    "        references_list = references_object['reference']\n",
    "\n",
    "        sc_article_cites_scopus_group_id_list = []\n",
    "        sc_article_cites_api_endpoint_list = []\n",
    "\n",
    "        for ref in references_list:\n",
    "            # The bibliography returns itemids of scopus-group id types rather than scopus id type. I don't think it should matter long-run because the articles can still be accessed by the 'https://api.elsevier.com/content/abstract/scopus_id/{scopus_id}' API. For more info see: https://silo.tips/download/sciverse-scopus-custom-data-documentation page 59.\n",
    "\n",
    "            sc_article_cites_scopus_group_id = ref['ref-info']['refd-itemidlist']['itemid']['$']\n",
    "            sc_article_cites_api_endpoint = 'https://api.elsevier.com/content/abstract/scopus_id/{}'.format(sc_article_cites_scopus_group_id)\n",
    "\n",
    "            sc_article_cites_scopus_group_id_list.append(sc_article_cites_scopus_group_id)\n",
    "            sc_article_cites_api_endpoint_list.append(sc_article_cites_api_endpoint)\n",
    "\n",
    "        article_cites_df_temp = pd.DataFrame({\n",
    "            'doi' : doi,\n",
    "            'sc_article_cites_scopus_group_id' : sc_article_cites_scopus_group_id_list,\n",
    "            'sc_article_cites_api_endpoint_list' : sc_article_cites_api_endpoint\n",
    "        })\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # CONCATENATE THE ARTICLES AUTHORS/ABSTRACTS AND REFERENCES TO THE PUBLICATION-LEVEL DFS, RESPECTIVELY\n",
    "        authors_abstracts_df = pd.concat([authors_abstracts_df, aa_df_temp], ignore_index=True)\n",
    "        article_cites_df = pd.concat([article_cites_df, article_cites_df_temp], ignore_index=True)\n",
    "\n",
    "\n",
    "        time.sleep(0.15)\n",
    "    \n",
    "    # print(authors_abstracts_df)\n",
    "    # print(article_cites_df)\n",
    "    \n",
    "    # MERGE THE AUTHORS/ABSTRACTS AND REFERENCES DATA ONTO THE THE CORE ARTICLE DATA (AT THE pub_df LEVEL)\n",
    "    author_abstract_funding_df = pd.merge(pub_df, authors_abstracts_df, how='left', on='doi')\n",
    "    cites_df = pd.merge(pub_df, article_cites_df, how='left', on='doi')\n",
    "\n",
    "    return author_abstract_funding_df, cites_df\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "jpe_author_abstract_funding_df, jpe_cites_df = abstract_references_collect(\"JPE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstracts-retrieval-response': {'coredata': {'dc:description': '© 2022 The University of Chicago. All rights reserved.The vast majority of the pay inequality in organizations comes from differences in pay between employees and their bosses. But are employees aware of these pay disparities? Are employees demotivated by this inequality? To address these questions, we conducted a natural field experiment with a sample of 2,060 employees from a multibillion-dollar corporation in Southeast Asia. We document large misperceptions among employees about the salaries of their managers and smaller but still significant misperceptions of the salaries of their peers, and we show that these perceptions have a significant causal effect on the employees’ own behavior.',\n",
       "   'dc:title': 'How Much Does Your Boss Make? The Effects of Salary Comparisons',\n",
       "   'prism:doi': '10.1086/717891'},\n",
       "  'authors': {'author': [{'ce:given-name': 'Zoë',\n",
       "     'preferred-name': {'ce:given-name': 'Zoë',\n",
       "      'ce:initials': 'Z.',\n",
       "      'ce:surname': 'Cullen',\n",
       "      'ce:indexed-name': 'Cullen Z.'},\n",
       "     '@seq': '1',\n",
       "     'ce:initials': 'Z.',\n",
       "     '@_fa': 'true',\n",
       "     'affiliation': {'@id': '60019666',\n",
       "      '@href': 'https://api.elsevier.com/content/affiliation/affiliation_id/60019666'},\n",
       "     'ce:surname': 'Cullen',\n",
       "     '@auid': '57225214289',\n",
       "     'author-url': 'https://api.elsevier.com/content/author/author_id/57225214289',\n",
       "     'ce:indexed-name': 'Cullen Z.'},\n",
       "    {'ce:given-name': 'Ricardo',\n",
       "     'preferred-name': {'ce:given-name': 'Ricardo',\n",
       "      'ce:initials': 'R.',\n",
       "      'ce:surname': 'Perez-Truglia',\n",
       "      'ce:indexed-name': 'Perez-Truglia R.'},\n",
       "     '@seq': '2',\n",
       "     'ce:initials': 'R.',\n",
       "     '@_fa': 'true',\n",
       "     'affiliation': {'@id': '60025038',\n",
       "      '@href': 'https://api.elsevier.com/content/affiliation/affiliation_id/60025038'},\n",
       "     'ce:surname': 'Perez-Truglia',\n",
       "     '@auid': '36997372700',\n",
       "     'author-url': 'https://api.elsevier.com/content/author/author_id/36997372700',\n",
       "     'ce:indexed-name': 'Perez-Truglia R.'}]}}}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://api.elsevier.com/content/search/scopus?cursor=AoJR%2FoJNMjItczIuMC04NTA2NDEzMTMxNg%3D%3D&count=200&query=ISSN%2800223808%29&date=1990-2021\n",
    "# https://api.elsevier.com/content/abstract/scopus_id/85117518428\n",
    "\n",
    "# test_hash = 'AoJV7PRLMTItczIuMC0wMDI1NTg2MTMy'\n",
    "\n",
    "# human_query_issn = 'ISSN({issn_str})'.format(issn_str='00223808')\n",
    "# human_query_date = '{start_year_str}-{current_year_str}'.format(start_year_str=1990,\n",
    "#                                                                     current_year_str=2021)\n",
    "\n",
    "\n",
    "# call_query = {\n",
    "#                 'httpAccept' : 'application/json',\n",
    "#                 'query' : human_query_issn,\n",
    "#                 'date' : human_query_date,\n",
    "#                 'count' : '10',\n",
    "#                 'cursor' : '*',\n",
    "#                 'view' : 'COMPLETE'\n",
    "#             }\n",
    "        \n",
    "## Grants? : https://api.elsevier.com/content/abstract/doi/10.1086/708815\n",
    "## Funds? : https://api.elsevier.com/content/abstract/scopus_id/85117518428\n",
    "\n",
    "\n",
    "# THIS IS WHERE WE CALL THE API TO GET THE LIST OF ARTICLES (200 AT A TIME BY USING 'cursor/@next')\n",
    "test = requests.get('https://api.elsevier.com/content/abstract/doi/10.1086/717891',\n",
    "                headers=req_headers,\n",
    "                params= {\n",
    "                    'httpAccept' : 'application/json',\n",
    "                    'view' : 'FULL',\n",
    "                    'field' : 'dc:title,item,prism:doi,authors,xocs:meta,dc:description'\n",
    "                },\n",
    "                # params=call_query\n",
    "                )\n",
    "\n",
    "\n",
    "# test.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['author-group']\n",
    "test.json()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d024caada2c1174a84651bac8b4321c201a5c821ecf13f184567326fb13b29e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ioCapture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
