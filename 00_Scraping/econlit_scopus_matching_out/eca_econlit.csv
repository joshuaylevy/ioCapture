volume,issue,date,abstract,author,jel_desc,jel_code,title,L_code,K_code,D4_code,O3_code,G34_code,year,month,day
89,2,2021-03-01,ECONLIT None Found,[nan],[nan],[nan],2020 Election of Fellows to the Econometric Society.,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We prove that local projections (LPs) and Vector Autoregressions (VARs) estimate the same impulse responses. This nonparametric result only requires unrestricted lag structures. We discuss several implications: (i) LP and VAR estimators are not conceptually separate procedures; instead, they are simply two dimension reduction techniques with common estimand but different finite-sample properties. (ii) VAR-based structural identification--including short-run, long-run, or sign restrictions--can equivalently be performed using LPs, and vice versa. (iii) Structural estimation with an instrument (proxy) can be carried out by ordering the instrument first in a recursive VAR, even under noninvertibility. (iv) Linear VARs are as robust to nonlinearities as linear LPs.","['Plagborg-Moller, Mikkel', 'Wolf, Christian K.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Local Projections and VARs Estimate the Same Impulse Responses,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"Are the highest sample realizations selected from a larger presample more or less informative than the same amount of random data? Developing multivariate accuracy for interval dominance ordered preferences, we show that sample selection always benefits (or always harms) a decision maker if the reverse hazard rate of the data distribution is log-supermodular (or log-submodular), as in location experiments with normal noise. We find nonpathological conditions under which the information contained in the winning bids of a symmetric auction decreases in the number of bidders. Exploiting extreme value theory, we quantify the limit amount of information revealed when the presample size (number of bidders) goes to infinity. In a model of equilibrium persuasion with costly information, we derive implications for the optimal design of selected experiments when selection is made by an examinee, a biased researcher, or contending sides with the peremptory challenge right to eliminate a number of jurors.","['Sorensen, Peter Norman', 'Di Tillio, Alfredo', 'Ottaviani, Marco']","['Survey Methods; Sampling Methods', 'Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Litigation Process']","['C83', 'D44', 'D83', 'K41']",Strategic Sample Selection,0,1,1,0,0,2021,03,01
89,2,2021-03-01,"Quantile factor models (QFM) represent a new class of factor models for high-dimensional panel data. Unlike approximate factor models (AFM), which only extract mean factors, QFM also allow unobserved factors to shift other relevant parts of the distributions of observables. We propose a quantile regression approach, labeled Quantile Factor Analysis (QFA), to consistently estimate all the quantile-dependent factors and loadings. Their asymptotic distributions are established using a kernel-smoothed version of the QFA estimators. Two consistent model selection criteria, based on information criteria and rank minimization, are developed to determine the number of factors at each quantile. QFA estimation remains valid even when the idiosyncratic errors exhibit heavy-tailed distributions. An empirical application illustrates the usefulness of QFA by highlighting the role of extra factors in the forecasts of U.S. GDP growth and inflation rates using a large set of predictors.","['Gonzalo, Jesus', 'Dolado, Juan J.', 'Chen, Liang']","['Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models', 'Forecasting Models; Simulation Methods', 'Macroeconomics: Production', 'Macroeconomics: Consumption, Saving, Production, Employment, and Investment: Forecasting and Simulation: Models and Applications']","['C38', 'C53', 'E23', 'E27']",Quantile Factor Models,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We study the consequences of measurement error in the dependent variable of random-coefficients models, focusing on the particular case of quantile regression. The popular quantile regression estimator of Koenker and Bassett (1978) is biased if there is an additive error term. Approaching this problem as an errors-in-variables problem where the dependent variable suffers from classical measurement error, we present a sieve maximum likelihood approach that is robust to left-hand-side measurement error. After providing sufficient conditions for identification, we demonstrate that when the number of knots in the quantile grid is chosen to grow at an adequate speed, the sieve-maximum-likelihood estimator is consistent and asymptotically normal, permitting inference via bootstrapping. Monte Carlo evidence verifies our method outperforms quantile regression in mean bias and MSE. Finally, we illustrate our estimator with an application to the returns to education highlighting changes over time in the returns to education that have previously been masked by measurement-error bias.","['Liu, Haoyang', 'Luo, Ye', 'Hausman, Jerry', 'Palmer, Christopher']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Returns to Education', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C14', 'C21', 'I26', 'J24', 'J31']",Errors in the Dependent Variable of Quantile Regression Models,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"This paper studies a penalized statistical decision rule for the treatment assignment problem. Consider the setting of a utilitarian policy maker who must use sample data to allocate a binary treatment to members of a population, based on their observable characteristics. We model this problem as a statistical decision problem where the policy maker must choose a subset of the covariate space to assign to treatment, out of a class of potential subsets. We focus on settings in which the policy maker may want to select amongst a collection of constrained subset classes: examples include choosing the number of covariates over which to perform best-subset selection, and model selection when approximating a complicated class via a sieve. We adapt and extend results from statistical learning to develop the Penalized Welfare Maximization (PWM) rule. We establish an oracle inequality for the regret of the PWM rule which shows that it is able to perform model selection over the collection of available classes. We then use this oracle inequality to derive relevant bounds on maximum regret for PWM. An important consequence of our results is that we are able to formalize model-selection using a ""holdout"" procedure, where the policy maker would first estimate various policies using half of the data, and then select the policy which performs the best when evaluated on the other half of the data.","['Mbakop, Eric', 'Tabord-Meehan, Max']","['Operations Research; Statistical Decision Theory', 'Model Evaluation, Validation, and Selection']","['C44', 'C52']",Model Selection for Treatment Choice: Penalized Welfare Maximization,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We study contracts between naive present-biased consumers and risk-neutral firms. We show that the welfare loss from present bias vanishes as the contracting horizon grows. This is true both when bargaining power is on the consumers' and on the firms' side, when consumers cannot commit to long-term contracts, and when firms do not know the consumers' naivete. However, the welfare loss from present bias does not vanish when firms do not know the consumers' present bias or when they cannot offer exclusive contracts.","['Zhang, Xingtan', 'Gottlieb, Daniel']","['Consumer Economics: Theory', 'Firm Behavior: Theory', 'Economics of Contract: Theory', 'Labor Contracts']","['D11', 'D21', 'D86', 'J41']",Long-Term Contracting with Time-Inconsistent Agents,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"This paper develops methods for detecting discrimination by individual employers using correspondence experiments that send fictitious resumes to real job openings. We establish identification of higher moments of the distribution of job-level callback rates as a function of the number of resumes sent to each job and propose shape-constrained estimators of these moments. Applying our methods to three experimental data sets, we find striking job-level heterogeneity in the extent to which callback probabilities differ by race or sex. Estimates of higher moments reveal that while most jobs barely discriminate, a few discriminate heavily. These moment estimates are then used to bound the share of jobs that discriminate and the posterior probability that each individual job is engaged in discrimination. In a recent experiment manipulating racially distinctive names, we find that at least 85% of jobs that contact both of two white applications and neither of two black applications are engaged in discrimination. To assess the potential value of our methods for regulators, we consider the accuracy of decision rules for investigating suspicious callback behavior in various experimental designs under a simple two-type model that rationalizes the experimental data. Though we estimate that only 17% of employers discriminate on the basis of race, we find that an experiment sending 10 applications to each job would enable detection of 7-10% of discriminatory jobs while yielding Type I error rates below 0.2%. A minimax decision rule acknowledging partial identification of the distribution of callback rates yields only slightly fewer investigations than a Bayes decision rule based on the two-type model. These findings suggest illegal labor market discrimination can be reliably monitored with relatively small modifications to existing correspondence designs.","['Walters, Christopher', 'Kline, Patrick']","['Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Economics of Gender; Non-labor Discrimination', 'Labor Demand', 'Labor Discrimination', 'Personnel Economics: Firm Employment Decisions; Promotions']","['J15', 'J16', 'J23', 'J71', 'M51']",Reasonable Doubt: Experimental Detection of Job-Level Employment Discrimination,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We provide general formulation of weak identification in semiparametric models and an efficiency concept. Weak identification occurs when a parameter is weakly regular, that is, when it is locally homogeneous of degree zero. When this happens, consistent or equivariant estimation is shown to be impossible. We then show that there exists an underlying regular parameter that fully characterizes the weakly regular parameter. While this parameter is not unique, concepts of sufficiency and minimality help pin down a desirable one. If estimation of minimal sufficient underlying parameters is inefficient, it introduces noise in the corresponding estimation of weakly regular parameters, whence we can improve the estimators by local asymptotic Rao-Blackwellization. We call an estimator weakly efficient if it does not admit such improvement. New weakly efficient estimators are presented in linear IV and nonlinear regression models. Simulation of a linear IV model demonstrates how 2SLS and optimal IV estimators are improved.","['Kaji, Tetsuya']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C13', 'C14', 'C26']",Theory of Weak Identification in Semiparametric Models,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We develop a framework to estimate the aggregate capital-labor elasticity of substitution by aggregating the actions of individual plants. The aggregate elasticity reflects substitution within plants and reallocation across plants; the extent of heterogeneity in capital intensities determines their relative importance. We use micro data on the cross-section of plants to build up to the aggregate elasticity at a point in time. Interpreting our econometric estimates through the lens of several different models, we find that the aggregate elasticity for the U.S. manufacturing sector is in the range of 0.5-0.7, and has declined slightly since 1970. We use our estimates to measure the bias of technical change and assess the decline in labor's share of income in the U.S. manufacturing sector. Mechanisms that rely on changes in the relative supply of factors, such as an acceleration of capital accumulation, cannot account for the decline.","['Raval, Devesh', 'Oberfield, Ezra']","['Firm Behavior: Empirical Analysis', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Factor Income Distribution', 'Aggregate Factor Income Distribution', 'Industry Studies: Manufacturing: General', 'Technological Change: Choices and Consequences; Diffusion Processes']","['D22', 'D24', 'D33', 'E25', 'L60', 'O33']",Micro Data and Macro Technology,1,0,0,1,0,2021,03,01
89,2,2021-03-01,Standard models of hierarchy assume that agents and middle managers are better informed than principals. We estimate the value of the informational advantage held by supervisors--middle managers--when ministerial leadership--the principal--introduced a new monitoring technology aimed at improving the performance of agricultural extension agents (AEAs) in rural Paraguay. Our approach employs a novel experimental design that elicited treatment-priority rankings from supervisors before randomization of treatment. We find that supervisors have valuable information--they prioritize AEAs who would be more responsive to the monitoring treatment. We develop a model of monitoring under different scales of treatment roll-out and different treatment allocation rules. We semiparametrically estimate marginal treatment effects (MTEs) to demonstrate that the value of information and the benefits to decentralizing treatment decisions depend crucially on the sophistication of the principal and on the scale of roll-out.,"['Li, Nicholas Y.', 'Schechter, Laura', 'Finan, Frederico', 'Dal Bo, Ernesto']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Agricultural Labor Markets', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Agricultural R&D; Agricultural Technology; Biofuels; Agricultural Extension Services']","['D82', 'D83', 'J43', 'O13', 'O18', 'Q16']",Information Technology and Government Decentralization: Experimental Evidence from Paraguay,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"We investigate learning at the workplace. To do so, we use German administrative data that contain information on the entire workforce of a sample of establishments. We document that having more-highly-paid coworkers is strongly associated with future wage growth, particularly if those workers earn more. Motivated by this fact, we propose a dynamic theory of a competitive labor market where firms produce using teams of heterogeneous workers that learn from each other. We develop a methodology to structurally estimate knowledge flows using the full-richness of the German employer-employee matched data. The methodology builds on the observation that a competitive labor market prices coworker learning. Our quantitative approach imposes minimal restrictions on firms' production functions, can be implemented on a very short panel, and allows for potentially rich and flexible coworker learning functions. In line with our reduced-form results, learning from coworkers is significant, particularly from more knowledgeable coworkers. We show that between 4 and 9% of total worker compensation is in the form of learning and that inequality in total compensation is significantly lower than inequality in wages.","['Oberfield, Ezra', 'Jarosch, Gregor', 'Rossi-Hansberg, Esteban']","['Firm Behavior: Empirical Analysis', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Wage Level and Structure; Wage Differentials', 'Personnel Economics: Compensation and Compensation Methods and Their Effects', 'Personnel Economics: Labor Management']","['D22', 'D83', 'J31', 'M52', 'M54']",Learning from Coworkers,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"A firm selects applicants to hire based on hard information, such as a test result, and soft information, such as a manager's evaluation of an interview. The contract that the firm offers to the manager can be thought of as a restriction on acceptance rates as a function of test results. I characterize optimal acceptance rate functions both when the firm knows the manager's mix of information and biases and when the firm is uncertain. These contracts may admit a simple implementation in which the manager can accept any set of applicants with a sufficiently high average test score.","['Frankel, Alex']","['Firm Behavior: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economics of Contract: Theory', 'Labor Contracts', 'Personnel Economics: Firm Employment Decisions; Promotions']","['D21', 'D83', 'D86', 'J41', 'M51']",Selecting Applicants,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"This paper draws parallels between the principal components analysis of factorless high-dimensional nonstationary data and the classical spurious regression. We show that a few of the principal components of such data absorb nearly all the data variation. The corresponding scree plot suggests that the data contain a few factors, which is corroborated by the standard panel information criteria. Furthermore, the Dickey-Fuller tests of the unit root hypothesis applied to the estimated ""idiosyncratic terms"" often reject, creating an impression that a few factors are responsible for most of the nonstationarity in the data. We warn empirical researchers of these peculiar effects and suggest to always compare the analysis in levels with that in differences.","['Onatski, Alexei', 'Wang, Chen']","['Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models', 'Large Data Sets: Modeling and Analysis']","['C38', 'C55']",Spurious Factor Analysis,0,0,0,0,0,2021,03,01
89,2,2021-03-01,"May's theorem (1952), a celebrated result in social choice, provides the foundation for majority rule. May's crucial assumption of symmetry, often thought of as a procedural equity requirement, is violated by many choice procedures that grant voters identical roles. We show that a weakening of May's symmetry assumption allows for a far richer set of rules that still treat voters equally. We show that such rules can have minimal winning coalitions comprising a vanishing fraction of the population, but not less than the square root of the population size. Methodologically, we introduce techniques from group theory and illustrate their usefulness for the analysis of social choice questions.","['Yariv, Leeat', 'Tamuz, Omer', 'Josyula, Maya', 'Bartholdi, Laurent', 'Hann-Caruthers, Wade']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Equitable Voting Rules,0,0,0,0,0,2021,03,01
89,2,2021-03-01,ECONLIT None Found,"['Wilson, Robert B.']","['History of Economic Thought: Quantitative and Mathematical', 'History of Economic Thought: Individuals', 'Auctions']","['B23', 'B31', 'D44']",Strategic Analysis of Auctions,0,0,1,0,0,2021,03,01
89,6,2021-11-01,"This paper develops a general framework to study how misinterpreting information impacts learning. Our main result is a simple criterion to characterize long-run beliefs based on the underlying form of misspecification. We present this characterization in the context of social learning, then highlight how it applies to other learning environments, including individual learning. A key contribution is that our characterization applies to settings with model heterogeneity and provides conditions for entrenched disagreement. Our characterization can be used to determine whether a representative agent approach is valid in the face of heterogeneity, study how differing levels of bias or unawareness of others' biases impact learning, and explore whether the impact of a bias is sensitive to parametric specification or the source of information. This unified framework synthesizes insights gleaned from previously studied forms of misspecification and provides novel insights in specific applications, as we demonstrate in settings with partisan bias, overreaction, naive learning, and level-k reasoning.","['Bohren, J. Aislinn', 'Hauser, Daniel N.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'General Aggregative Models: Neoclassical']","['D83', 'E13']",Learning with Heterogeneous Misspecified Models: Characterization and Robustness,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"We develop a model of banking industry dynamics to study the quantitative impact of regulatory policies on bank risk-taking and market structure. Since our model is matched to U.S. data, we propose a market structure where big banks with market power interact with small, competitive fringe banks as well as non-bank lenders. Banks face idiosyncratic funding shocks in addition to aggregate shocks which affect the fraction of performing loans in their portfolio. A nontrivial bank size distribution arises out of endogenous entry and exit, as well as banks' buffer stock of capital. We show that the model predictions are consistent with untargeted business cycle properties, the bank lending channel, and empirical studies of the role of concentration on financial stability. We find that regulatory policies can have an important impact on banking market structure, which, along with selection effects, can generate changes in allocative efficiency and stability.","[""D'Erasmo, Pablo"", 'Corbae, Dean']","['Business Fluctuations; Cycles', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financial Institutions and Services: Government Policy and Regulation', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Oligopoly and Other Imperfect Markets', 'Firm Performance: Size, Diversification, and Scope']","['E32', 'G21', 'G28', 'G32', 'L13', 'L25']",Capital Buffers in a Quantitative Model of Banking Industry Dynamics,1,0,0,0,0,2021,11,01
89,6,2021-11-01,"We formulate a stability notion for two-sided pairwise matching problems with individually insignificant agents in distributional form. Matchings are formulated as joint distributions over the characteristics of the populations to be matched. Spaces of characteristics can be high-dimensional and need not be compact. Stable matchings exist with and without transfers, and stable matchings correspond precisely to limits of stable matchings for finite-agent models. We can embed existing continuum matching models and stability notions with transferable utility as special cases of our model and stability notion. In contrast to finite-agent matching models, stable matchings exist under a general class of externalities.","['Greinecker, Michael', 'Kah, Christopher']","['Bargaining Theory; Matching Theory', 'Externalities']","['C78', 'D62']",Pairwise Stable Matching in Large Economies,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"Most assets clear independently rather than jointly. This paper presents a model based on the uniform-price double auction which accommodates arbitrary restrictions on market clearing, including independent clearing across assets (allowed when demand for each asset is contingent only on the price of that asset) and joint market clearing for all assets (required when demand for each asset is contingent on the prices of all assets). Additional trading protocols for traded assets--neutral when the market clears jointly--are generally not redundant innovations, even if all traders participate in all protocols. Multiple trading protocols that clear independently can be designed to be at least as efficient as joint market clearing for all assets. The change in price impact brought by independence in market clearing can overcome the loss of information, and enhance diversification and risk sharing. Except when the market is competitive, market characteristics should guide innovation in trading technology.","['Rostek, Marzena', 'Yoon, Ji Hee']","['Auctions', 'Equities; Fixed Income Securities', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D44', 'G12', 'G14']",Exchange Design and Efficiency,0,0,1,0,0,2021,11,01
89,6,2021-11-01,"I show that the zero lower bound (ZLB) on interest rates can be used to identify the causal effects of monetary policy. Identification depends on the extent to which the ZLB limits the efficacy of monetary policy. I propose a simple way to test the efficacy of unconventional policies, modeled via a ""shadow rate."" I apply this method to U.S. monetary policy using a three-equation structural vector autoregressive model of inflation, unemployment, and the Federal Funds rate. I reject the null hypothesis that unconventional monetary policy has no effect at the ZLB, but find some evidence that it is not as effective as conventional monetary policy.","['Mavroeidis, Sophocles']","['Price Level; Inflation; Deflation', 'Interest Rates: Determination, Term Structure, and Effects', 'Monetary Policy']","['E31', 'E43', 'E52']",Identification at the Zero Lower Bound,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"Haavelmo (1944) proposed a probabilistic structure for econometric modeling, aiming to make econometrics useful for decision making. His fundamental contribution has become thoroughly embedded in econometric research, yet it could not answer all the deep issues that the author raised. Notably, Haavelmo struggled to formalize the implications for decision making of the fact that models can at most approximate actuality. In the same period, Wald (1939, 1945) initiated his own seminal development of statistical decision theory. Haavelmo favorably cited Wald, but econometrics did not embrace statistical decision theory. Instead, it focused on study of identification, estimation, and statistical inference. This paper proposes use of statistical decision theory to evaluate the performance of models in decision making. I consider the common practice of as-if optimization: specification of a model, point estimation of its parameters, and use of the point estimate to make a decision that would be optimal if the estimate were accurate. A central theme is that one should evaluate as-if optimization or any other model-based decision rule by its performance across the state space, listing all states of nature that one believes feasible, not across the model space. I apply the theme to prediction and treatment choice. Statistical decision theory is conceptually simple, but application is often challenging. Advancing computation is the primary task to complete the foundations sketched by Haavelmo and Wald.","['Manski, Charles F.']","['History of Economic Thought: Quantitative and Mathematical', 'History of Economic Thought: Individuals', 'Econometrics', 'Operations Research; Statistical Decision Theory', 'Econometric Modeling: General']","['B23', 'B31', 'C01', 'C44', 'C50']",Econometrics for Decision Making: Building Foundations Sketched by Haavelmo and Wald,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"We conduct inference on volatility with noisy high-frequency data. We assume the observed transaction price follows a continuous-time Ito-semimartingale, contaminated by a discrete-time moving-average noise process associated with the arrival of trades. We estimate volatility, defined as the quadratic variation of the semimartingale, by maximizing the likelihood of a misspecified moving-average model, with its order selected based on an information criterion. Our inference is uniformly valid over a large class of noise processes whose magnitude and dependence structure vary with sample size. We show that the convergence rate of our estimator dominates n^{1/4} as noise vanishes, and is determined by the selected order of noise dependence when noise is sufficiently small. Our implementation guarantees positive estimates in finite samples.","['Xiu, Dacheng', 'Da, Rui']","['Large Data Sets: Modeling and Analysis', 'Equities; Fixed Income Securities']","['C55', 'G12']",When Moving-Average Models Meet High-Frequency Data: Uniform Inference on Volatility,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"We study the joint evolution of the sectoral composition and the investment rate of developing economies. Using panel data for several countries in different stages of development, we document three novel facts: (a) the share of industry and the investment rate are strongly correlated and follow a hump-shaped profile with development, (b) investment goods contain more domestic value added from industry and less from services than consumption goods do, and (c) the evolution of the sectoral composition of investment and consumption goods differs from the one of GDP. We build a multi-sector growth model to fit these patterns and provide two important results. First, the hump-shaped evolution of investment demand explains half of the hump in industry with development. Second, asymmetric sectoral productivity growth helps explain the decline in the relative price of investment goods along the development path, which in turn increases capital accumulation and promotes growth.","['Pijoan-Mas, Josep', 'Villacorta, Lucciano', 'Garcia-Santana, Manuel']","['Macroeconomics: Consumption; Saving; Wealth', 'Investment; Capital; Intangible Capital; Capacity', 'Macroeconomics: Production', 'One, Two, and Multisector Growth Models']","['E21', 'E22', 'E23', 'O41']",Investment Demand and Structural Change,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"The prevailing neo-Wicksellian view holds that the central bank's objective is to track the natural rate of interest (r^{*}), which itself is largely exogenous to monetary policy. We challenge this view using a fixed-cost model of durable consumption demand, in which expansionary monetary policy prompts households to accelerate purchases of durable goods. This yields an intertemporal trade-off in aggregate demand as encouraging households to increase durable holdings today leaves fewer households acquiring durables going forward. Interest rates must be kept low to support demand going forward, so accommodative monetary policy today reduces r^{*} in the future. We show that this mechanism is quantitatively important in explaining the persistently low level of real interest rates and r^{*} after the Great Recession.","['McKay, Alisdair', 'Wieland, Johannes F.']","['Consumer Economics: Theory', 'Macroeconomics: Consumption; Saving; Wealth', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Monetary Policy']","['D11', 'E21', 'E32', 'E43', 'E52']",Lumpy Durable Consumption Demand and the Limited Ammunition of Monetary Policy,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"This paper shows that the products and prices offered in markets are correlated with local income-specific tastes. To quantify the welfare impact of this variation, I calculate local price indexes micro-founded by a model of non-homothetic demand over thousands of grocery products. These indexes reveal large differences in how wealthy and poor households perceive the choice sets available in wealthy and poor cities. Relative to low-income households, high-income households enjoy 40 percent higher utility per dollar expenditure in wealthy cities, relative to poor cities. Similar patterns are observed across stores in different neighborhoods. Most of this variation is explained by differences in the product assortment offered, rather than the relative prices charged, by chains that operate in different markets.","['Handbury, Jessie']","['Consumer Economics: Empirical Analysis', 'Personal Income, Wealth, and Their Distributions', 'Price Level; Inflation; Deflation', 'General Welfare; Well-Being', 'Retail and Wholesale Trade; e-Commerce', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Other Demand']","['D12', 'D31', 'E31', 'I31', 'L81', 'R22']",Are Poor Cities Cheap for Everyone? Non-homotheticity and the Cost of Living across U.S. Cities,1,0,0,0,0,2021,11,01
89,6,2021-11-01,"Few want to do business with a partner who has a bad reputation. Consequently, once a bad reputation is established, it can be difficult to get rid of. This leads on the one hand to the intuitive idea that a good reputation is easy to lose and hard to gain. On the other hand, it can lead to a strong form of history dependence in which a single beneficial or adverse event can cast a shadow over a very long period of time. It gives rise to a reputational trap where an agent rationally chooses not to invest in a good reputation because the chances others will find out is too low. Nevertheless, the same agent with a good reputation will make every effort to maintain it. Here, a simple reputational model is constructed and the conditions for there to be a unique equilibrium that constitutes a reputation trap are characterized.","['Levine, David K.']","['Consumer Economics: Theory', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making']","['D11', 'D91']",The Reputation Trap,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"Most jobs require teamwork. Are some people good team players? In this paper, we design and test a new method for identifying individual contributions to team production. We randomly assign people to multiple teams and predict team performance based on previously assessed individual skills. Some people consistently cause their team to exceed its predicted performance. We call these individuals ""team players."" Team players score significantly higher on a well-established measure of social intelligence, but do not differ across a variety of other dimensions, including IQ, personality, education, and gender. Social skills--defined as a single latent factor that combines social intelligence scores with the team player effect--improve team performance about as much as IQ. We find suggestive evidence that team players increase effort among teammates.","['Deming, David J.', 'Weidmann, Ben']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Personnel Management; Executives; Executive Compensation', 'Personnel Economics: Labor Management']","['J24', 'M12', 'M54']",Team Players: How Social Skills Improve Team Performance,0,0,0,0,0,2021,11,01
89,6,2021-11-01,"This paper proposes a tractable model of Bayesian learning on large random networks where agents choose whether to adopt an innovation. We study the impact of the network structure on learning dynamics and product diffusion. In directed networks, all direct and indirect links contribute to agents' learning. In comparison, learning and welfare are lower in undirected networks and networks with cliques. In a rich class of networks, behavior is described by a small number of differential equations, making the model useful for empirical work.","['Meyer-ter-Vehn, Moritz', 'Board, Simon']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D83', 'D85', 'O33', 'Z13']",Learning Dynamics in Social Networks,0,0,0,1,0,2021,11,01
89,6,2021-11-01,"We study optimal monetary and fiscal policies in a New Keynesian model with heterogeneous agents, incomplete markets, and nominal rigidities. Our approach uses small-noise expansions and Frechet derivatives to approximate equilibria quickly and efficiently. Responses of optimal policies to aggregate shocks differ qualitatively from what they would be in a corresponding representative agent economy and are an order of magnitude larger. A motive to provide insurance that arises from heterogeneity and incomplete markets outweighs price stabilization motives.","['Golosov, Mikhail', 'Bhandari, Anmol', 'Sargent, Thomas J.', 'Evans, David']","['Incomplete Markets', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian; Modern Monetary Theory', 'Business Fluctuations; Cycles', 'Monetary Policy', 'Fiscal Policy', 'Comparative or Joint Analysis of Fiscal and Monetary Policy; Stabilization; Treasury Policy']","['D52', 'D63', 'E12', 'E32', 'E52', 'E62', 'E63']","Inequality, Business Cycles, and Monetary-Fiscal Policy",0,0,0,0,0,2021,11,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2019–2020.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2019–2020.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"We study repeated independent Blackwell experiments; standard examples include drawing multiple samples from a population, or performing a measurement in different locations. In the baseline setting of a binary state of nature, we compare experiments in terms of their informativeness in large samples. Addressing a question due to Blackwell (1951), we show that generically an experiment is more informative than another in large samples if and only if it has higher Renyi divergences. We apply our analysis to the problem of measuring the degree of dissimilarity between distributions by means of divergences. A useful property of Renyi divergences is their additivity with respect to product distributions. Our characterization of Blackwell dominance in large samples implies that every additive divergence that satisfies the data processing inequality is an integral of Renyi divergences.","['Strack, Philipp', 'Tamuz, Omer', 'Pomatto, Luciano', 'Mu, Xiaosheng']","['Survey Methods; Sampling Methods', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C83', 'D83']",From Blackwell Dominance in Large Samples to Renyi Divergences and Back Again,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"An important goal of empirical demand analysis is choice and welfare prediction on counterfactual budget sets arising from potential policy interventions. Such predictions are more credible when made without arbitrary functional-form/distributional assumptions, and instead based solely on economic rationality, that is, that choice is consistent with utility maximization by a heterogeneous population. This paper investigates nonparametric economic rationality in the empirically important context of binary choice. We show that under general unobserved heterogeneity, economic rationality is equivalent to a pair of Slutsky-like shape restrictions on choice-probability functions. The forms of these restrictions differ from Slutsky inequalities for continuous goods. Unlike McFadden-Richter's stochastic revealed preference, our shape restrictions (a) are global, that is, their forms do not depend on which and how many budget sets are observed, (b) are closed form, hence easy to impose on parametric/semi/nonparametric models in practical applications, and (c) provide computationally simple, theory-consistent bounds on demand and welfare predictions on counterfactual budge sets.","['Bhattacharya, Debopam']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C14', 'C25']",The Empirical Content of Binary Choice Models,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"Kitamura and Stoye (2018) recently proposed a nonparametric statistical test for random utility models of consumer behavior. The test is formulated in terms of linear inequality constraints and a quadratic objective function. While the nonparametric test is conceptually appealing, its practical implementation is computationally challenging. In this paper, we develop a column generation approach to operationalize the test. These novel computational tools generate considerable computational gains in practice, which substantially increases the empirical usefulness of Kitamura and Stoye's statistical test.","['Smeulders, Bart', 'De Rock, Bram', 'Cherchye, Laurens']","['Semiparametric and Nonparametric Methods: General', 'Consumer Economics: Empirical Analysis']","['C14', 'D12']",Nonparametric Analysis of Random Utility Models: Computational Tools for Statistical Testing,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"We often make high stakes choices based on complex information that we have no way to verify. Careful Bayesian reasoning--assessing every reason why a claim could be false or misleading--is not feasible, so we necessarily act on faith: we trust certain sources and treat claims as if they were direct observations of payoff relevant events. This creates a challenge when trusted sources conflict: Practically speaking, is there a principled way to update beliefs in response to contradictory claims? I propose a model of belief formation along with several updating axioms. An impossibility theorem shows there is no obvious best answer, while a representation theorem delineates the boundary of what is possible.","['Sadler, Evan']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],A Practical Guide to Updating Beliefs from Contradictory Evidence,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"At an initial time, an individual forms a belief about a future random outcome. As time passes, the individual may obtain, privately or subjectively, further information, until the outcome is eventually revealed. How can a protocol be devised that induces the individual, as a strict best response, to reveal at the outset his prior assessment of both the final outcome and the information flows he anticipates and, subsequently, what information he privately receives? The protocol can provide the individual with payoffs that depend only on the outcome realization and his reports. We develop a framework to design such protocols, and apply it to construct simple elicitation mechanisms for common dynamic environments. The framework is general: we show that strategyproof protocols exist for any number of periods and large outcome sets. For these more general settings, we build a family of strategyproof protocols based on a hierarchy of choice menus, and show that any strategyproof protocol can be approximated by a protocol of this family.","['Chambers, Christopher P.', 'Lambert, Nicolas S.']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Dynamic Belief Elicitation,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"We present a new multi-sector growth model that features nonhomothetic, constant elasticity of substitution preferences, and accommodates long-run demand and supply drivers of structural change for an arbitrary number of sectors. The model is consistent with the decline in agriculture, the hump-shaped evolution of manufacturing, and the rise of services over time. We estimate the demand system derived from the model using household-level data from the United States and India, as well as historical aggregate-level panel data for 39 countries during the postwar period. The estimated model parsimoniously accounts for the broad patterns of sectoral reallocation observed among rich, miracle, and developing economies. Our estimates support the presence of strong nonhomotheticity across time, income levels, and countries. We find that income effects account for the bulk of the within-country evolution of sectoral reallocation.","['Comin, Diego', 'Lashkari, Danial', 'Mestieri, Marti']","['Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Macroeconomic Analyses of Economic Development', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Industrialization; Manufacturing and Service Industries; Choice of Technology', 'One, Two, and Multisector Growth Models', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['L16', 'O11', 'O12', 'O13', 'O14', 'O41', 'O47']",Structural Change with Long-Run Income and Price Effects,1,0,0,0,0,2021,01,01
89,1,2021-01-01,"We use data from Hungary to establish two results about the relationship between the government and the media. (i) We document large advertising favors from the government to connected media, and large corruption coverage favors from connected media to the government. Our empirical strategy exploits sharp reallocations around changes in media ownership and other events to rule out market-based explanations. (ii) Under the assumptions of a structural model, we distinguish between owner ideology and favor exchange as the mechanism driving favors. We estimate our model exploiting within-owner changes in coverage for identification and find that both mechanisms are important. These results imply that targeted government advertising can meaningfully influence content. Counterfactuals show that targeted advertising can also influence owner ideology, by making media ownership more profitable to pro-government connected investors. Our results are consistent with qualitative evidence from many democracies and suggest that government advertising affects media content worldwide.","['Szucs, Ferenc', 'Szeidl, Adam']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Entertainment; Media', 'Marketing', 'Advertising']","['D72', 'G32', 'L82', 'M31', 'M37']",Media Capture through Favor Exchange,1,0,0,0,0,2021,01,01
89,1,2021-01-01,"This paper models the evolution of organizations that allow free entry and exit of members, such as cities and trade unions. In each period, current members choose a policy for the organization. Policy changes attract newcomers and drive away dissatisfied members, altering the set of future policymakers. The resulting feedback effects take the organization down a ""slippery slope"" that converges to a myopically stable policy, even if the agents are forward-looking, but convergence becomes slower the more patient they are. The model yields a tractable characterization of the steady state and the transition dynamics. The analysis is also extended to situations in which the organization can exclude members, such as enfranchisement and immigration.","['Gieczewski, German']","['Microeconomic Policy: Formulation, Implementation, and Evaluation', 'Organizational Behavior; Transaction Costs; Property Rights', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination']","['D04', 'D23', 'J15']",Policy Persistence and Drift in Organizations,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"What incentives do governments have to negotiate trade agreements that constrain their domestic regulatory policies? We study a model in which firms design products to appeal to local consumer tastes, but their fixed costs increase with the difference between versions of their product destined for different markets. In this setting, firms' profit-maximizing choices of product attributes are globally optimal in the absence of consumption externalities, but national governments have unilateral incentives to invoke regulatory protectionism to induce firm delocation. An efficient trade agreement requires commitments not to engage in such opportunistic behavior. A rule requiring mutual recognition of standards can be used to achieve efficiency, but one that requires only national treatment falls short. When product attributes confer local consumption externalities, an efficient trade agreement must coordinate the fine details of countries' regulatory policies.","['Grossman, Gene M.', 'Staiger, Robert W.', 'McCalman, Phillip']","['Firm Behavior: Theory', 'Externalities', 'Models of Trade with Imperfect Competition and Scale Economies; Fragmentation', 'Trade Policy; International Trade Organizations', 'Economics of Regulation']","['D21', 'D62', 'F12', 'F13', 'L51']",The 'New' Economics of Trade Agreements: From Trade Liberalization to Regulatory Convergence?,1,0,0,0,0,2021,01,01
89,1,2021-01-01,"We study deep neural networks and their use in semiparametric inference. We establish novel nonasymptotic high probability bounds for deep feedforward neural nets. These deliver rates of convergence that are sufficiently fast (in some cases minimax optimal) to allow us to establish valid second-step inference after first-step estimation with deep learning, a result also new to the literature. Our nonasymptotic high probability bounds, and the subsequent semiparametric inference, treat the current standard architecture: fully connected feedforward neural networks (multilayer perceptrons), with the now-common rectified linear unit activation function, unbounded weights, and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish the nonasymptotic bounds for these deep nets for a general class of nonparametric regression-type loss functions, which includes as special cases least squares, logistic regression, and other generalized linear models. We then apply our theory to develop semiparametric inference, focusing on causal parameters for concreteness, and demonstrate the effectiveness of deep learning with an empirical application to direct mail marketing.","['Misra, Sanjog', 'Farrell, Max H.', 'Liang, Tengyuan']","['Semiparametric and Nonparametric Methods: General', 'Neural Networks and Related Topics', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory', 'Marketing']","['C14', 'C45', 'D83', 'D85', 'M31']",Deep Neural Networks for Estimation and Inference,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"Centralized markets reduce search for buyers and sellers. Their ""thickness"" increases the chance of order execution at nearly competitive prices. In spite of the incentives to consolidate, some markets, securities markets and on-line advertising being the most notable, are fragmented into multiple trading venues. We argue that fragmentation is an inevitable feature of any centralized market except in special circumstances.","['Peivandi, Ahmad', 'Vohra, Rakesh V.']","['Market Structure, Pricing, and Design: General', 'Asset Markets and Pricing', 'Advertising']","['D40', 'G10', 'M37']",Instability of Centralized Markets,0,0,1,0,0,2021,01,01
89,1,2021-01-01,"In many areas, practitioners seek to use observational data to learn a treatment assignment policy that satisfies application-specific constraints, such as budget, fairness, simplicity, or other functional form constraints. For example, policies may be restricted to take the form of decision trees based on a limited set of easily observable individual characteristics. We propose a new approach to this problem motivated by the theory of semiparametrically efficient estimation. Our method can be used to optimize either binary treatments or infinitesimal nudges to continuous treatments, and can leverage observational data where causal effects are identified using a variety of strategies, including selection on observables and instrumental variables. Given a doubly robust estimator of the causal effect of assigning everyone to treatment, we develop an algorithm for choosing whom to treat, and establish strong guarantees for the asymptotic utilitarian regret of the resulting policy.","['Athey, Susan', 'Wager, Stefan']","['Microeconomic Policy: Formulation, Implementation, and Evaluation', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making', 'Policy Objectives; Policy Designs and Consistency; Policy Coordination', 'National Budget; Budget Systems']","['D04', 'D63', 'D91', 'E61', 'H61']",Policy Learning with Observational Data,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"Standard experimental designs are geared toward point estimation and hypothesis testing, while bandit algorithms are geared toward in-sample outcomes. Here, we instead consider treatment assignment in an experiment with several waves for choosing the best among a set of possible policies (treatments) at the end of the experiment. We propose a computationally tractable assignment algorithm that we call ""exploration sampling,"" where assignment probabilities in each wave are an increasing concave function of the posterior probabilities that each treatment is optimal. We prove an asymptotic optimality result for this algorithm and demonstrate improvements in welfare in calibrated simulations over both non-adaptive designs and bandit algorithms. An application to selecting between six different recruitment strategies for an agricultural extension service in India demonstrates practical feasibility.","['Kasy, Maximilian', 'Sautmann, Anja']","['Hypothesis Testing: General', 'Estimation: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Agricultural R&D; Agricultural Technology; Biofuels; Agricultural Extension Services', 'Agricultural Policy; Food Policy']","['C12', 'C13', 'C21', 'O13', 'Q16', 'Q18']",Adaptive Treatment Assignment in Experiments for Policy Choice,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"We model the term structure of interest rates that results from the interaction between investors with preferences for specific maturities and risk-averse arbitrageurs. Shocks to the short rate are transmitted to long rates through arbitrageurs' carry trades. Arbitrageurs earn rents from transmitting the shocks through bond risk premia that relate positively to the slope of the term structure. When the short rate is the only risk factor, changes in investor demand have the same relative effect on interest rates across maturities regardless of the maturities where they originate. When investor demand is also stochastic, demand effects become more localized. A calibration indicates that long rates underreact to forward-guidance announcements about short rates. Large-scale asset purchases can be more effective in moving long rates, especially if they are concentrated at long maturities.","['Vila, Jean-Luc', 'Vayanos, Dimitri']","['Interest Rates: Determination, Term Structure, and Effects', 'Equities; Fixed Income Securities', 'Behavioral Finance: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making in Financial Markets']","['E43', 'G12', 'G41']",A Preferred-Habitat Model of the Term Structure of Interest Rates,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"Waitlists are often used to ration scarce resources, but the trade-offs in designing these mechanisms depend on agents' preferences. We study equilibrium allocations under alternative designs for the deceased donor kidney waitlist. We model the decision to accept an organ or wait for a preferable one as an optimal stopping problem and estimate preferences using administrative data from the New York City area. Our estimates show that while some kidney types are desirable for all patients, there is substantial match-specific heterogeneity in values. We then develop methods to evaluate alternative mechanisms, comparing their effects on patient welfare to an equivalent change in donor supply. Past reforms to the kidney waitlist primarily resulted in redistribution, with similar welfare and organ discard rates to the benchmark first-come, first-served mechanism. These mechanisms and other commonly studied theoretical benchmarks remain far from optimal. We design a mechanism that increases patient welfare by the equivalent of an 18.2% increase in donor supply.","['Agarwal, Nikhil', 'Somaini, Paulo', 'Ashlagi, Itai', 'Waldinger, Daniel', 'Rees, Michael A.']","['Asymmetric and Private Information; Mechanism Design', 'Analysis of Health Care Markets', 'Health Behavior']","['D82', 'I11', 'I12']",Equilibrium Allocations under Alternative Waitlist Designs: Evidence from Decreased Donor Kidneys,0,0,0,0,0,2021,01,01
89,1,2021-01-01,"We examine intergenerational mobility (IM) in educational attainment in Africa since independence using census data. First, we map IM across 27 countries and more than 2800 regions, documenting wide cross-country and especially within-country heterogeneity. Inertia looms large as differences in the literacy of the old generation explain about half of the observed spatial disparities in IM. The rural-urban divide is substantial. Though conspicuous in some countries, there is no evidence of systematic gender gaps in IM. Second, we characterize the geography of IM, finding that colonial investments in railroads and Christian missions, as well as proximity to capitals and the coastline are the strongest correlates. Third, we ask whether the regional differences in mobility reflect spatial sorting or their independent role. To isolate the two, we focus on children whose families moved when they were young. Comparing siblings, looking at moves triggered by displacement shocks, and using historical migrations to predict moving-families' destinations, we establish that, while selection is considerable, regional exposure effects are at play. An extra year spent in a high-mobility region before the age of 12 (and after 5) significantly raises the likelihood for children of uneducated parents to complete primary school. Overall, the evidence suggests that geographic and historical factors laid the seeds for spatial disparities in IM that are cemented by sorting and the independent impact of regions.","['Michalopoulos, Stelios', 'Papaioannou, Elias', 'Alesina, Alberto', 'Hohmann, Sebastian']","['Economics of Gender; Non-labor Discrimination', 'Job, Occupational, and Intergenerational Mobility; Promotion', 'Railroads and Other Surface Transportation', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics', 'Cultural Economics: Religion']","['J16', 'J62', 'L92', 'O15', 'O18', 'R23', 'Z12']",Intergenerational Mobility in Africa,1,0,0,0,0,2021,01,01
88,6,2020-11-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society 2019 Annual Report of the President.,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"The empirical observation that ""large firms tend to export, whereas small firms do not"" has transformed the way economists think about the determinants of international trade. Yet, it has had surprisingly little impact on how economists think about trade policy. Under very general conditions, we show that from the point of view of a country that unilaterally imposes trade taxes to maximize domestic welfare, the self-selection of heterogeneous firms into exports calls for import subsidies on the least profitable foreign firms. In contrast, our analysis does not provide any rationale for export subsidies or taxes on the least profitable domestic firms.","['Werning, Ivan', 'Rodriguez-Clare, Andres', 'Costinot, Arnaud']","['Firm Behavior: Theory', 'Neoclassical Models of Trade', 'Trade Policy; International Trade Organizations', 'Empirical Studies of Trade', 'Firm Performance: Size, Diversification, and Scope']","['D21', 'F11', 'F13', 'F14', 'L25']",Micro to Macro: Optimal Trade Policy with Firm Heterogeneity,1,0,0,0,0,2020,11,01
88,6,2020-11-01,"We study equilibria in multi-asset and multi-agent continuous-time economies with asymmetric information and bounded rational noise traders. We establish the existence of two equilibria. First, a full communication equilibrium where the informed agents' signal is disclosed to the market and static policies are optimal. Second, a partial communication equilibrium where the signal disclosed is affine in the informed and noise traders' signals, and dynamic policies are optimal. Here, information asymmetry creates demand for two public funds, as well as a dark pool where private information trades can be implemented. Markets are endogenously complete and equilibrium returns have a three factor structure with stochastic factors and loadings. Results are valid for constant absolute risk averse investors, general vector diffusions for fundamentals, nonlinear terminal payoffs, and non-Gaussian noise trading. Asset price dynamics and public information flows are endogenous, and rational expectations equilibria are special cases of the general results.","['Rindisbacher, Marcel', 'Robertson, Scott', 'Detemple, Jerome']","['Asymmetric and Private Information; Mechanism Design', 'Expectations; Speculations', 'General Aggregative Models: Neoclassical']","['D82', 'D84', 'E13']",Dynamic Noisy Rational Expectations Equilibrium with Insider Information,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"In a cheap-talk setting where the conflict of interest between sender and receiver is determined endogenously by the choice of parameters theta_{i} for each agent i, conditions are provided that determine the sign of each agent's inverse demand for theta without assuming that the most informative equilibrium will necessarily be played in the cheap talk game. For two popular functional forms of payoffs, we derive analytically tractable approximations for agent i's demand for theta. In an application where the theta_{i}'s are purchased on a competitive market, we provide conditions for a competitive equilibrium to feature maximal information transmission. In a principal-agent application where the agent's theta is set by the principal, our results show that information transmission will be partial. We consider extensions where: (1) the thetas are acquired covertly rather than overtly and (2) the thetas are traded after the sender has received the information.","['Persico, Nicola', 'Antic, Nemanja']","['Game Theory and Bargaining Theory: General', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D82', 'D83']",Cheap Talk with Endogenous Conflict of Interest,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"I study a mechanism design problem in which a designer allocates a single good to one of several agents, and the mechanism is followed by an aftermarket--a post-mechanism game played between the agent who acquired the good and third-party market participants. The designer has preferences over final outcomes, but she cannot design the aftermarket. However, she can influence its information structure by publicly disclosing information elicited from the agents by the mechanism. I introduce a class of allocation and disclosure rules, called cutoff rules, that disclose information about the buyer's type only by revealing information about the realization of a random threshold (cutoff) that she had to outbid to win the object. When there is a single agent in the mechanism, I show that the optimal cutoff mechanism offers full privacy to the agent. In contrast, when there are multiple agents, the optimal cutoff mechanism may disclose information about the winner's type; I provide sufficient conditions for optimality of simple designs. I also characterize aftermarkets for which restricting attention to cutoff mechanisms is without loss of generality in a subclass of all feasible mechanisms satisfying additional conditions.","['Dworczak, Piotr']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Mechanism Design with Aftermarkets: Cutoff Mechanisms,0,0,0,0,0,2020,11,01
88,6,2020-11-01,We study the behavior of the U.S. labor share over the past 90 years. We find that the observed decline of the labor share is entirely explained by the capitalization of intellectual property products in the national income and product accounts.,"['Koh, Dongya', 'Santaeulalia-Llopis, Raul', 'Zheng, Yu']","['Measurement and Data on National Income and Product Accounts and Wealth; Environmental Accounts', 'Aggregate Factor Income Distribution']","['E01', 'E25']",Labor Share Decline and Intellectual Property Products Capital,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"We study games of incomplete information as both the information structure and the extensive form vary. An analyst may know the payoff-relevant data but not the players' private information, nor the extensive form that governs their play. Alternatively, a designer may be able to build a mechanism from these ingredients. We characterize all outcomes that can arise in an equilibrium of some extensive form with some information structure. We show how to specialize our main concept to capture the additional restrictions implied by extensive-form refinements.","['Doval, Laura', 'Ely, Jeffrey C.']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Sequential Information Design,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"Asymptotic bootstrap validity is usually understood as consistency of the distribution of a bootstrap statistic, conditional on the data, for the unconditional limit distribution of a statistic of interest. From this perspective, randomness of the limit bootstrap measure is regarded as a failure of the bootstrap. We show that such limiting randomness does not necessarily invalidate bootstrap inference if validity is understood as control over the frequency of correct inferences in large samples. We first establish sufficient conditions for asymptotic bootstrap validity in cases where the unconditional limit distribution of a statistic can be obtained by averaging a (random) limiting bootstrap distribution. Further, we provide results ensuring the asymptotic validity of the bootstrap as a tool for conditional inference, the leading case being that where a bootstrap distribution estimates consistently a conditional (and thus, random) limit distribution of a statistic. We apply our framework to several inference problems in econometrics, including linear models with possibly nonstationary regressors, CUSUM statistics, conditional Kolmogorov-Smirnov specification tests and tests for constancy of parameters in dynamic econometric models.","['Georgiev, Iliyan', 'Cavaliere, Giuseppe']","['Statistical Simulation Methods: General', 'Single Equation Models; Single Variables: General']","['C15', 'C20']",Inference under Random Limit Bootstrap Measures,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"Differences in regulated pharmaceutical prices within the European Economic Area create arbitrage opportunities that pharmacy retailers can access through parallel imports. For prescription drugs under patent, parallel trade affects the sharing of profits among an innovating pharmaceutical company, retailers, and parallel traders. We develop a structural model of demand and supply in which retailers can choose the set of goods to sell, thus foreclosing consumers' access to less profitable drugs. This allows retailers to bargain and obtain lower wholesale prices from the manufacturer and parallel trader. With detailed transaction data from Norway, we identify a demand model with unobserved choice sets using retail-side conditions for optimal assortment decisions of pharmacies. We find that retailer incentives play a significant role in fostering parallel trade penetration and that banning parallel imports would benefit manufacturers as well as prevent pharmacies from foreclosing the manufacturer's product. Finally, in the case of the statin market in Norway, we show that it would be possible to decrease spending and increase profits of the original manufacturer through lump sum transfers associated with a lower reimbursement price, thus decreasing price differentiation across countries.","['Dubois, Pierre', 'Saethre, Morten']","['Empirical Studies of Trade', 'Firm Performance: Size, Diversification, and Scope', 'Chemicals; Rubber; Drugs; Biotechnology; Plastics', 'Retail and Wholesale Trade; e-Commerce']","['F14', 'L25', 'L65', 'L81']",On the Effect of Parallel Trade on Manufacturers' and Retailers' Profits in the Pharmaceutical Sector,1,0,0,0,0,2020,11,01
88,6,2020-11-01,"We study the role of financial frictions and firm heterogeneity in determining the investment channel of monetary policy. Empirically, we find that firms with low default risk--those with low debt burdens and high ""distance to default""--are the most responsive to monetary shocks. We interpret these findings using a heterogeneous firm New Keynesian model with default risk. In our model, low-risk firms are more responsive to monetary shocks because they face a flatter marginal cost curve for financing investment. The aggregate effect of monetary policy may therefore depend on the distribution of default risk, which varies over time.","['Winberry, Thomas', 'Ottonello, Pablo']","['Firm Behavior: Theory', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian; Modern Monetary Theory', 'Monetary Policy', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['D21', 'E12', 'E52', 'G31']",Financial Heterogeneity and the Investment Channel of Monetary Policy,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"We study games in which a network mediates strategic spillovers and externalities among the players. How does a planner optimally target interventions that change individuals' private returns to investment? We analyze this question by decomposing any intervention into orthogonal principal components, which are determined by the network and are ordered according to their associated eigenvalues. There is a close connection between the nature of spillovers and the representation of various principal components in the optimal intervention. In games of strategic complements (substitutes), interventions place more weight on the top (bottom) principal components, which reflect more global (local) network structure. For large budgets, optimal interventions are simple--they essentially involve only a single principal component.","['Galeotti, Andrea', 'Goyal, Sanjeev', 'Golub, Benjamin']","['Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models', 'Game Theory and Bargaining Theory: General', 'Externalities', 'Network Formation and Analysis: Theory']","['C38', 'C70', 'D62', 'D85']",Targeting Interventions in Networks,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"The correlation between productivity and competition is an oft observed but incompletely understood result. Some suggest that there is a treatment effect of competition on measured productivity, for example, through a reduction of managerial slack. Others argue that greater competition makes unproductive establishments exit by reallocating demand to their productive rivals, raising observed average productivity via selection. I study the ready-mix concrete industry and offer three perspectives on this ambivalence. First, using a standard decomposition approach, I look for evidence of greater reallocation of demand to productive plants in more competitive markets. Second, I model the establishment exit decision and construct a semiparametric selection correction to quantify the empirical significance of treatment and selection. Finally, I use a grouped instrumental variable quantile regression to test the distributional predictions of the selection hypothesis. I find no evidence for greater selection or reallocation in more competitive markets; instead, all three results suggest that measured productivity responds directly to competition. Potential channels include specialization and managerial inputs.","['Backus, Matthew']","['Semiparametric and Nonparametric Methods: General', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Metals and Metal Products; Cement; Glass; Ceramics']","['C14', 'D24', 'L61']",Why Is Productivity Correlated with Competition?,1,0,0,0,0,2020,11,01
88,6,2020-11-01,"We design a labor market experiment to compare demand- and supply-side policies to tackle youth unemployment, a key issue in low-income countries. The experiment tracks 1700 workers and 1500 firms over four years to compare the effect of offering workers either vocational training (VT) or firm-provided training (FT) for six months in a common setting where youth unemployment is above 60%. Relative to control workers, we find that, averaged over three post-intervention years, FT and VT workers: (i) enjoy large and similar upticks in sector-specific skills, (ii) significantly improve their employment rates, and (iii) experience marked improvements in an index of labor market outcomes. These averages, however, mask differences in dynamics: FT gains materialize quickly but fade over time, while VT gains emerge slowly but are long-lasting, leading VT worker employment and earning profiles to rise above those of FT workers. Estimating a job ladder model of worker search reveals the key reason for this: VT workers receive significantly higher rates of job offers when unemployed, thus hastening their movement back into work. This likely stems from the fact that the skills of VT workers are certified and therefore can be demonstrated to potential employers. Tackling youth unemployment by skilling youth using vocational training pre-labor market entry therefore appears to be more effective than incentivizing firms through wage subsidies to hire and train young labor market entrants.","['Bandiera, Oriana', 'Bassi, Vittorio', 'Burgess, Robin', 'Sulaiman, Munshi', 'Alfonsi, Livia', 'Rasul, Imran']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Fertility; Family Planning; Child Care; Children; Youth', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Wages, Compensation, and Labor Costs: Public Policy', 'Mobility, Unemployment, and Vacancies: Public Policy', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration']","['E24', 'J13', 'J24', 'J31', 'J38', 'J68', 'O15']",Tackling Youth Unemployment: Evidence from a Labor Market Experiment in Uganda,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"The presence of a westward-moving frontier of settlement shaped early U.S. history. In 1893, the historian Frederick Jackson Turner famously argued that the American frontier fostered individualism. We investigate the ""frontier thesis"" and identify its long-run implications for culture and politics. We track the frontier throughout the 1790-1890 period and construct a novel, county-level measure of total frontier experience (TFE). Historically, frontier locations had distinctive demographics and greater individualism. Long after the closing of the frontier, counties with greater TFE exhibit more pervasive individualism and opposition to redistribution. This pattern cuts across known divides in the United States, including urban-rural and north-south. We provide evidence on the roots of frontier culture, identifying both selective migration and a causal effect of frontier exposure on individualism. Overall, our findings shed new light on the frontier's persistent legacy of rugged individualism.","['Bazzi, Samuel', 'Fiszbein, Martin', 'Gebresilasse, Mesay']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S.; Canada: Pre-1913', 'Economic History: Government, War, Law, International Relations, and Regulation: U.S.; Canada: Pre-1913', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D72', 'H23', 'N31', 'N41', 'Z13']",Frontier Culture: The Roots and Persistence of 'Rugged Individualism' in the United States,0,0,0,0,0,2020,11,01
88,6,2020-11-01,"We exhibit a natural environment, social learning among heterogeneous agents, where even slight misperceptions can have a large negative impact on long-run learning outcomes. We consider a population of agents who obtain information about the state of the world both from initial private signals and by observing a random sample of other agents' actions over time, where agents' actions depend not only on their beliefs about the state but also on their idiosyncratic types (e.g., tastes or risk attitudes). When agents are correct about the type distribution in the population, they learn the true state in the long run. By contrast, we show, first, that even arbitrarily small amounts of misperception about the type distribution can generate extreme breakdowns of information aggregation, where in the long run all agents incorrectly assign probability 1 to some fixed state of the world, regardless of the true underlying state. Second, any misperception of the type distribution leads long-run beliefs and behavior to vary only coarsely with the state, and we provide systematic predictions for how the nature of misperception shapes these coarse long-run outcomes. Third, we show that how fragile information aggregation is against misperception depends on the richness of agents' payoff-relevant uncertainty; a design implication is that information aggregation can be improved by simplifying agents' learning environment. The key feature behind our findings is that agents' belief-updating becomes ""decoupled"" from the true state over time. We point to other environments where this feature is present and leads to similar fragility results.","['Iijima, Ryota', 'Frick, Mira', 'Ishii, Yuhta']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D82', 'D83']",Misinterpreting Others and the Fragility of Social Learning,0,0,0,0,0,2020,11,01
88,6,2020-11-01,ECONLIT None Found,"['Santos, Andres']","['Estimation: General', 'Model Construction and Estimation']","['C13', 'C51']","A Comment on: 'On the Informativeness of Descriptive Statistics for Structural Estimates' by Isaiah Andrews, Matthew Gentzkow, and Jesse M. Shapiro",0,0,0,0,0,2020,11,01
88,6,2020-11-01,ECONLIT None Found,"['Kitamura, Yuichi']","['Estimation: General', 'Model Construction and Estimation']","['C13', 'C51']","A Comment on: 'On the Informativeness of Descriptive Statistics for Structural Estimates' by Isaiah Andrews, Matthew Gentzkow, and Jesse M. Shapiro",0,0,0,0,0,2020,11,01
88,6,2020-11-01,ECONLIT None Found,"['Bonhomme, Stephane']","['Estimation: General', 'Model Construction and Estimation']","['C13', 'C51']","A Comment on: 'On the Informativeness of Descriptive Statistics for Structural Estimates' by Isaiah Andrews, Matthew Gentzkow, and Jesse M. Shapiro",0,0,0,0,0,2020,11,01
88,6,2020-11-01,"We propose a way to formalize the relationship between descriptive analysis and structural estimation. A researcher reports an estimate ^ of a structural quantity of interest c that is exactly or asymptotically unbiased under some base model. The researcher also reports descriptive statistics gamma^ that estimate features gamma of the distribution of the data that are related to c under the base model. A reader entertains a less restrictive model that is local to the base model, under which the estimate c^ may be biased. We study the reduction in worst-case bias from a restriction that requires the reader's model to respect the relationship between c and gamma specified by the base model. Our main result shows that the proportional reduction in worst-case bias depends only on a quantity we call the informativeness of gamma^ for c^. Informativeness can be easily estimated even for complex models. We recommend that researchers report estimated informativeness alongside their descriptive analyses, and we illustrate with applications to three recent papers.","['Andrews, Isaiah', 'Shapiro, Jesse M.', 'Gentzkow, Matthew']","['Estimation: General', 'Model Construction and Estimation']","['C13', 'C51']",On the Informativeness of Descriptive Statistics for Structural Estimates,0,0,0,0,0,2020,11,01
88,5,2020-09-01,ECONLIT None Found,"['Babus, Ana', 'Kondor, Peter', 'Wang, Yilin']","['Asymmetric and Private Information; Mechanism Design', 'Equities; Fixed Income Securities', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Investment Banking; Venture Capital; Brokerage; Ratings and Ratings Agencies']","['D82', 'G12', 'G14', 'G24']",Corrigendum to 'Trading and Information Diffusion in Over-the-Counter Markets',0,0,0,0,0,2020,09,01
88,5,2020-09-01,"This paper proposes a valid bootstrap-based distributional approximation for M-estimators exhibiting a Chernoff (1964)-type limiting distribution. For estimators of this kind, the standard nonparametric bootstrap is inconsistent. The method proposed herein is based on the nonparametric bootstrap, but restores consistency by altering the shape of the criterion function defining the estimator whose distribution we seek to approximate. This modification leads to a generic and easy-to-implement resampling method for inference that is conceptually distinct from other available distributional approximations. We illustrate the applicability of our results with four examples in econometrics and machine learning.","['Cattaneo, Matias D.', 'Jansson, Michael', 'Nagasawa, Kenichi']","['Semiparametric and Nonparametric Methods: General', 'Statistical Simulation Methods: General', 'Neural Networks and Related Topics']","['C14', 'C15', 'C45']",Bootstrap-Based Inference for Cube Root Asymptotics,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"A patient player privately observes a persistent state and interacts with an infinite sequence of myopic uninformed players. The patient player is either a strategic type who maximizes his payoff or one of several commitment types who mechanically play the same action in every period. I focus on situations in which the uninformed player's best reply to a commitment action depends on the state and where the total probability of commitment types is sufficiently small. I show that the patient player's equilibrium payoff is bounded below his commitment payoff in some equilibria under some of his payoff functions. This is because he faces a trade-off between building his reputation for commitment and signaling favorable information about the state. When players' stage-game payoff functions are monotone-supermodular, the patient player receives high payoffs in all states and in all equilibria. Under an additional condition on the state distribution, my reputation model yields a unique prediction on the patient player's equilibrium payoff and on-path behavior.","['Pei, Harry']","['Game Theory and Bargaining Theory: General', 'Asymmetric and Private Information; Mechanism Design']","['C70', 'D82']",Reputation Effects under Interdependent Values,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"This paper analyzes a procedure called Testing-Based Forward Model Selection (TBFMS) in linear regression problems. This procedure inductively selects covariates that add predictive power into a working statistical model before estimating a final regression. The criterion for deciding which covariate to include next and when to stop including covariates is derived from a profile of traditional statistical hypothesis tests. This paper proves probabilistic bounds, which depend on the quality of the tests, for prediction error and the number of selected covariates. As an example, the bounds are then specialized to a case with heteroscedastic data, with tests constructed with the help of Huber-Eicker-White standard errors. Under the assumed regularity conditions, these tests lead to estimation convergence rates matching other common high-dimensional estimators including Lasso.","['Kozbur, Damian']","['Hypothesis Testing: General', 'Model Evaluation, Validation, and Selection']","['C12', 'C52']",Analysis of Testing-Based Forward Model Selection,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"This paper considers a class of generalized methods of moments (GMM) estimators for general dynamic panel models, allowing for weakly exogenous covariates and cross-sectional dependence due to spatial lags, unspecified common shocks, and time-varying interactive effects. We significantly expand the scope of the existing literature by allowing for endogenous time-varying spatial weight matrices without imposing explicit structural assumptions on how the weights are formed. An important area of application is in social interaction and network models where our specification can accommodate data dependent network formation. We consider an exemplary social interaction model and show how identification of the interaction parameters is achieved through a combination of linear and quadratic moment conditions. For the general setup we develop an orthogonal forward differencing transformation to aid in the estimation of factor components while maintaining orthogonality of moment conditions. This is an important ingredient to a tractable asymptotic distribution of our estimators. In general, the asymptotic distribution of our estimators is found to be mixed normal due to random norming. However, the asymptotic distribution of our test statistics is still chi-square.","['Prucha, Ingmar R.', 'Kuersteiner, Guido M.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Specific Distributions; Specific Statistics', 'Network Formation and Analysis: Theory']","['C23', 'C33', 'C46', 'D85']","Dynamic Spatial Panel Models: Networks, Common Shocks, and Sequential Exogeneity",0,0,0,0,0,2020,09,01
88,5,2020-09-01,"This paper considers a Principal-Agent model with hidden action in which the Principal can monitor the Agent by acquiring independent signals conditional on effort at a constant marginal cost. The Principal aims to implement a target effort level at minimal cost. The main result of the paper is that the optimal information-acquisition strategy is a two-threshold policy and, consequently, the equilibrium contract specifies two possible wages for the Agent. This result provides a rationale for the frequently observed single-bonus wage contracts.","['Szentes, Balazs', 'Georgiadis, George']","['Asymmetric and Private Information; Mechanism Design', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts']","['D82', 'J31', 'J41']",Optimal Monitoring Design,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"Markups vary systematically across firms and are a source of misallocation. This paper develops a tractable model of firm dynamics where firms' market power is endogenous and the distribution of markups emerges as an equilibrium outcome. Monopoly power is the result of a process of forward-looking, risky accumulation: firms invest in productivity growth to increase markups in their existing products but are stochastically replaced by more efficient competitors. Creative destruction therefore has pro-competitive effects because faster churn gives firms less time to accumulate market power. In an application to firm-level data from Indonesia, the model predicts that, relative to the United States, misallocation is more severe and firms are substantially smaller. To explain these patterns, the model suggests an important role for frictions that prevent existing firms from entering new markets. Differences in entry costs for new firms are less important.","['Peters, Michael']","['Firm Behavior: Theory', 'Firm Behavior: Empirical Analysis', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Oligopoly and Other Imperfect Markets', 'Firm Performance: Size, Diversification, and Scope', 'Industrialization; Manufacturing and Service Industries; Choice of Technology']","['D21', 'D22', 'D24', 'L13', 'L25', 'O14']","Heterogeneous Markups, Growth, and Endogenous Misallocation",1,0,0,0,0,2020,09,01
88,5,2020-09-01,"We test the longstanding hypothesis that ethnic groups organized around ""segmentary lineages"" are more prone to conflict. Ethnographic accounts suggest that in such societies, which are characterized by strong allegiances to distant relatives, individuals are obligated to come to the aid of fellow lineage members when they become involved in conflicts. As a consequence, small disagreements often escalate into larger-scale conflicts involving many individuals. We test for a link between segmentary lineage organization and conflict across ethnic groups in sub-Saharan Africa. Using a number of estimation strategies, including a regression discontinuity design at ethnic boundaries, we find that segmentary lineage societies experience more conflicts, and particularly ones that are retaliatory, long in duration, and large in scale.","['Robinson, James A.', 'Nunn, Nathan', 'Moscona, Jacob']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Microeconomic Analyses of Economic Development', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D74', 'J12', 'J15', 'O12', 'O17']",Segmentary Lineage Organization and Conflict in Sub-Saharan Africa,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"We measure the impact of increasing integration between rural villages and outside labor markets. Seasonal flash floods cause exogenous and unpredictable loss of market access. We study the impact of new bridges that eliminate this risk. Identification exploits variation in riverbank characteristics that preclude bridge construction in some villages, despite similar need. We collect detailed annual household surveys over three years, and weekly telephone followups to study contemporaneous effects of flooding. Floods decrease labor market income by 18 percent when no bridge is present. Bridges eliminate this effect. The indirect effects on labor market choice, farm investment, and savings are quantitatively important and consistent with the predictions of a general equilibrium model in which farm investment is risky, and households manage labor market risk and agricultural risk simultaneously. In the calibrated model, the increase in consumption-equivalent welfare is substantially larger than the increase in income due to the ability to mitigate risk.","['Donovan, Kevin', 'Brooks, Wyatt']","['State and Local Government: Other Expenditure Categories', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Micro Analysis of Farm Firms, Farm Households, and Farm Input Markets', 'Climate; Natural Disasters and Their Management; Global Warming', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['H76', 'O12', 'O13', 'O18', 'Q12', 'Q54', 'R23']",Eliminating Uncertainty in Market Access: The Impact of New Bridges in Rural Nicaragua,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"We introduce a new family of dynamic mechanisms that restricts sellers from using future distributional knowledge. Since the allocation and pricing of each auction period do not depend on the type distributions of future periods, we call this family of dynamic mechanisms non-clairvoyant. We develop a framework (bank account mechanisms) for characterizing, designing, and proving lower bounds for dynamic mechanisms (clairvoyant or non-clairvoyant). We use the same methods to compare the revenue extraction power of clairvoyant and non-clairvoyant dynamic mechanisms.","['Tang, Pingzhong', 'Zuo, Song', 'Leme, Renato Paes', 'Mirrokni, Vahab']","['Asymmetric and Private Information; Mechanism Design', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages']","['D82', 'G21']",Non-clairvoyant Dynamic Mechanism Design,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"We propose a new theory of price rigidity based on firms' Knightian uncertainty about their competitive environment. This uncertainty has two key implications. First, firms learn about the shape of their demand function from past observations of quantities sold. This learning gives rise to kinks in the expected profit function at previously observed prices, making those prices both sticky and more likely to reoccur. Second, uncertainty about the relationship between aggregate and industry-level inflation generates nominal rigidity. We prove the main insights analytically and quantify the effects of our mechanism. Our estimated quantitative model is consistent with a wide range of micro-level pricing facts that are typically challenging to match jointly. It also implies significantly more persistent monetary non-neutrality than in standard models, allowing it to generate large real effects from nominal shocks.","['Vincent, Nicolas', 'Ilut, Cosmin', 'Valchev, Rosen']","['Firm Behavior: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Price Level; Inflation; Deflation', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['D22', 'D81', 'E31', 'L11']",Paralyzed by Fear: Rigid and Discrete Pricing under Demand Uncertainty,1,0,0,0,0,2020,09,01
88,5,2020-09-01,"We propose leave-out estimators of quadratic forms designed for the study of linear models with unrestricted heteroscedasticity. Applications include analysis of variance and tests of linear restrictions in models with many regressors. An approximation algorithm is provided that enables accurate computation of the estimator in very large data sets. We study the large sample properties of our estimator allowing the number of regressors to grow in proportion to the number of observations. Consistency is established in a variety of settings where plug-in methods and estimators predicated on homoscedasticity exhibit first-order biases. For quadratic forms of increasing rank, the limiting distribution can be represented by a linear combination of normal and non-central X2 random variables, with normality ensuing under strong identification. Standard error estimators are proposed that enable tests of linear restrictions and the construction of uniformly valid confidence intervals for quadratic forms of interest. We find in Italian social security records that leave-out estimates of a variance decomposition in a two-way fixed effects model of wage determination yield substantially different conclusions regarding the relative contribution of workers, firms, and worker-firm sorting to wage inequality than conventional methods. Monte Carlo exercises corroborate the accuracy of our asymptotic approximations, with clear evidence of non-normality emerging when worker mobility between blocks of firms is limited.","['Solvsten, Mikkel', 'Kline, Patrick', 'Saggio, Raffaele']","['Estimation: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Large Data Sets: Modeling and Analysis', 'Wage Level and Structure; Wage Differentials']","['C13', 'C21', 'C55', 'J31']",Leave-Out Estimation of Variance Components,0,0,0,0,0,2020,09,01
88,5,2020-09-01,"The objective of this paper is to identify and estimate network formation models using observed data on network structure. We characterize network formation as a simultaneous-move game, where the utility from forming a link depends on the structure of the network, thereby generating strategic interactions between links. With the prevalence of multiple equilibria, the parameters are not necessarily point identified. We leave the equilibrium selection unrestricted and propose a partial identification approach. We derive bounds on the probability of observing a subnetwork, where a subnetwork is the restriction of a network to a subset of the individuals. Unlike the standard bounds as in Ciliberto and Tamer (2009), these subnetwork bounds are computationally tractable in large networks provided we consider small subnetworks. We provide Monte Carlo evidence that bounds from small subnetworks are informative in large networks.","['Sheng, Shuyang']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Network Formation and Analysis: Theory', 'Transactional Relationships; Contracts and Reputation; Networks']","['C73', 'D85', 'L14']",A Structural Econometric Analysis of Network Formation Games through Subnetworks,1,0,0,0,0,2020,09,01
88,5,2020-09-01,"In this paper, we show that stable outcomes exist in matching environments with complementarities, such as social media platforms or markets for patent licenses. Our results apply to both nontransferable and transferable utility settings, and allow for multilateral agreements and those with externalities. In particular, we show that stable outcomes in these settings are characterized by the largest fixed point of a monotone operator, and so can be found using an algorithm; in the nontransferable utility case, this is a one-sided deferred acceptance algorithm, rather than a Gale-Shapley algorithm. We also give a monotone comparative statics result as well as a comparative static on the effect of bundling contracts together. These illustrate the impact of design decisions, such as increased privacy protections on social media, or the use of antitrust law to disallow patent pools, on stable outcomes.","['Rostek, Marzena', 'Yoder, Nathan']","['Bargaining Theory; Matching Theory', 'Economics of Contract: Theory', 'Antitrust Law', 'Contracting Out; Joint Ventures; Technology Licensing', 'Entertainment; Media', 'Intellectual Property and Intellectual Capital']","['C78', 'D86', 'K21', 'L24', 'L82', 'O34']",Matching with Complementary Contracts,1,1,0,1,0,2020,09,01
89,5,2021-09-01,"We revisit the causes, welfare consequences, and policy implications of the dispersion in households' labor market outcomes using a model with uninsurable risk, incomplete asset markets, and home production. Allowing households to be heterogeneous in both their disutility of home work and their home production efficiency, we find that home production amplifies welfare-based differences, meaning that inequality in standards of living is larger than we thought. We infer significant home production efficiency differences across households because hours working at home do not covary with consumption and wages in the cross section of households. Heterogeneity in home production efficiency is essential for inequality, as home production would not amplify inequality if differences at home only reflected heterogeneity in disutility of work.","['Boerma, Job', 'Karabarbounis, Loukas']","['Household Production and Intrahousehold Allocation', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Criteria for Decision-Making under Risk and Uncertainty', 'General Welfare; Well-Being', 'Time Allocation and Labor Supply']","['D13', 'D63', 'D81', 'I31', 'J22']",Inferring Inequality with Home Production,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"Heteroskedasticity- and autocorrelation-robust (HAR) inference in time series regression typically involves kernel estimation of the long-run variance. Conventional wisdom holds that, for a given kernel, the choice of truncation parameter trades off a test's null rejection rate and power, and that this tradeoff differs across kernels. We formalize this intuition: using higher-order expansions, we provide a unified size-power frontier for both kernel and weighted orthonormal series tests using nonstandard ""fixed-b"" critical values. We also provide a frontier for the subset of these tests for which the fixed-b distribution is t or F. These frontiers are respectively achieved by the QS kernel and equal-weighted periodogram. The frontiers have simple closed-form expressions, which show that the price paid for restricting attention to tests with t and F critical values is small. The frontiers are derived for the Gaussian multivariate location model, but simulations suggest the qualitative findings extend to stochastic regressors.","['Lewis, Daniel J.', 'Stock, James H.', 'Lazarus, Eben']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",The Size-Power Tradeoff in HAR Inference,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"The location of individuals determines their job and schooling opportunities, amenities, and housing costs. We conceptualize the location choice of individuals as a decision to invest in a ""location asset."" This asset has a current cost equal to the location's rent, and a future payoff through better job and schooling opportunities. As with any asset, savers in the location asset transfer resources into the future by going to expensive locations with high future returns. In contrast, borrowers transfer resources to the present by going to cheap locations that offer few other advantages. Holdings of the location asset depend on its comparison to other assets, with the distinction that the location asset is not subject to borrowing constraints. We propose a dynamic location model and derive an agent's mobility choices after experiencing income shocks. We document the investment dimension of location and confirm the core predictions of our theory using French individual panel data from tax returns.","['Rossi-Hansberg, Esteban', 'Bilal, Adrien']","['Consumer Economics: Empirical Analysis', 'Household Saving, Borrowing, Debt, and Wealth', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['D12', 'G51', 'H24', 'R23']",Location as an Asset,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"This paper develops a uniformly valid and asymptotically nonconservative test based on projection for a class of shape restrictions. The key insight we exploit is that these restrictions form convex cones, a simple and yet elegant structure that has been barely harnessed in the literature. Based on a monotonicity property afforded by such a geometric structure, we construct a bootstrap procedure that, unlike many studies in nonstandard settings, dispenses with estimation of local parameter spaces, and the critical values are obtained in a way as simple as computing the test statistic. Moreover, by appealing to strong approximations, our framework accommodates nonparametric regression models as well as distributional/density-related and structural settings. Since the test entails a tuning parameter (due to the nonstandard nature of the problem), we propose a data-driven choice and prove its validity. Monte Carlo simulations confirm that our test works well.","['Seo, Juwon', 'Fang, Zheng']","['Semiparametric and Nonparametric Methods: General', 'Statistical Simulation Methods: General']","['C14', 'C15']",A Projection Framework for Testing Shape Restrictions That Form Convex Cones,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"We compare sparse and dense representations of predictive models in macroeconomics, microeconomics, and finance. To deal with a large number of possible predictors, we specify a prior that allows for both variable selection and shrinkage. The posterior distribution does not typically concentrate on a single sparse model, but on a wide set of models that often include many predictors.","['Primiceri, Giorgio E.', 'Giannone, Domenico', 'Lenza, Michele']","['Forecasting Models; Simulation Methods', 'Large Data Sets: Modeling and Analysis', 'General Aggregative Models: Forecasting and Simulation: Models and Applications']","['C53', 'C55', 'E17']",Economic Predictions with Big Data: The Illusion of Sparsity,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"We propose a general and highly efficient method for solving and estimating general equilibrium heterogeneous-agent models with aggregate shocks in discrete time. Our approach relies on the rapid computation of sequence-space Jacobians--the derivatives of perfect-foresight equilibrium mappings between aggregate sequences around the steady state. Our main contribution is a fast algorithm for calculating Jacobians for a large class of heterogeneous-agent problems. We combine this algorithm with a systematic approach to composing and inverting Jacobians to solve for general equilibrium impulse responses. We obtain a rapid procedure for likelihood-based estimation and computation of nonlinear perfect-foresight transitions. We apply our methods to three canonical heterogeneous-agent models: a neoclassical model, a New Keynesian model with one asset, and a New Keynesian model with two assets.","['Rognlie, Matthew', 'Auclert, Adrien', 'Bardoczy, Bence', 'Straub, Ludwig']","['Model Construction and Estimation', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian; Modern Monetary Theory', 'General Aggregative Models: Neoclassical']","['C51', 'E12', 'E13']",Using the Sequence-Space Jacobian to Solve and Estimate Heterogeneous-Agent Models,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"To measure the benefits of formal contract enforcement for society, I create a market with merchants and buyers, in which buyers can choose whether to buy, and whether to pay. A set of multiple ""state-favored"" ethnic groups control the state. I experimentally vary whether formal contracts are required and the composition of buyer-merchant pairs. The design separately identifies the effect of the contracts on the buyers' incentive to pay and on their incentive to buy. I document two ways in which society limits the benefits of contracts. First, contracts reduce buyer cheating, thus increasing merchants' profits, if, and only if, the merchant is state-favored. Buyers' beliefs suggest that the merchants can enforce the contracts if, and only if, the merchant is state-favored. Second, holding constant whether the pair is state-favored, contracts only influence buyer choices when the buyer and the merchant belong to two, different, state-favored ethnic groups. Buyers' choices and beliefs confirm that, in that case, the contracts are expected to be enforceable, but they have no effect on buyers' choices because reputation already governs the incentives to cheat within groups. The findings temper the view of the state as independent from society, offer a rationale for why contracts are not adopted, and nuance the notion of state weakness.","['Sanchez de la Sierra, Raul']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economics of Contract: Theory', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Contract Law']","['D83', 'D86', 'J15', 'K12']",Whither Formal Contracts?,0,1,0,0,0,2021,09,01
89,5,2021-09-01,"We study individual male earnings dynamics over the life cycle using panel data on millions of U.S. workers. Using nonparametric methods, we first show that the distribution of earnings changes exhibits substantial deviations from lognormality, such as negative skewness and very high kurtosis. Further, the extent of these nonnormalities varies significantly with age and earnings level, peaking around age 50 and between the 70th and 90th percentiles of the earnings distribution. Second, we estimate nonparametric impulse response functions and find important asymmetries: Positive changes for high-income individuals are quite transitory, whereas negative ones are very persistent; the opposite is true for low-income individuals. Third, we turn to long-run outcomes and find substantial heterogeneity in the cumulative growth rates of earnings and the total number of years individuals spend nonemployed between ages 25 and 55. Finally, by targeting these rich sets of moments, we estimate stochastic processes for earnings that range from the simple to the complex. Our preferred specification features normal mixture innovations to both persistent and transitory components and includes state-dependent long-term nonemployment shocks with a realization probability that varies with age and earnings.","['Ozkan, Serdar', 'Karahan, Fatih', 'Song, Jae', 'Guvenen, Fatih']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Wage Level and Structure; Wage Differentials']","['D15', 'J31']",What Do Data on Millions of U.S. Workers Reveal about Lifecycle Earnings Dynamics?,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"We study how endogenous innovation and technology diffusion interact to determine the shape of the productivity distribution and generate aggregate growth. We model firms that choose to innovate, adopt technology, or produce with their existing technology. Costly adoption creates a spread between the best and worst technologies concurrently used to produce similar goods. The balance of adoption and innovation determines the shape of the distribution; innovation stretches the distribution, while adoption compresses it. On the balanced growth path, the aggregate growth rate equals the maximum growth rate of innovators. While innovation drives long-run growth, changes in the adoption environment can influence growth by affecting innovation incentives, either directly, through licensing of excludable technologies, or indirectly, via the option value of adoption.","['Benhabib, Jess', 'Perla, Jesse', 'Tonetti, Christopher']","['Firm Behavior: Theory', 'Rationing; Licensing', 'Innovation and Invention: Processes and Incentives', 'Management of Technological Innovation and R&D']","['D21', 'D45', 'O31', 'O32']",Reconciling Models of Diffusion and Innovation: A Theory of the Productivity Distribution and Technology Frontier,0,0,1,1,0,2021,09,01
89,5,2021-09-01,"We introduce random evolving lotteries to study preference for non-instrumental information. Each period, the agent enjoys a flow payoff from holding a lottery that will resolve at the terminal date. We provide a representation theorem for non-separable risk consumption preferences and use it to characterize agents' attitude to non-instrumental information. To address applications, we characterize peak-trough utilities that aggregate trajectories of flow utilities linearly but, in addition, put weight on the best (peak) and worst (trough) lotteries along each path. We show that the model is consistent with recent experimental evidence on attitudes to information, including a preference for gradual arrival of good news and the ostrich effect, that is, decision makers' tendency to prefer information after good news to information after bad news.","['Pesendorfer, Wolfgang', 'Natenzon, Paulo', 'Gul, Faruk']","['Consumer Economics: Theory', 'Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D44', 'D83']",Random Evolving Lotteries and Intrinsic Preference for Information,0,0,1,0,0,2021,09,01
89,5,2021-09-01,"Firms and governments often use R&D contests to incentivize suppliers to develop and deliver innovative products. The optimal design of such contests depends on empirical primitives: the cost of research, the uncertainty in outcomes, and the surplus participants capture. Can R&D contests in real-world settings be redesigned to increase social surplus? I ask this question in the context of the Department of Defense's Small Business Innovation Research program, a multistage R&D contest. I develop a structural model to estimate the primitives from data on R&D and procurement contracts. I find that the optimal design substantially increases social surplus, and simple design changes in isolation (e.g., inviting more contestants) can capture up to half these gains; however, these changes reduce the DOD's own welfare. These results suggest there is substantial scope for improving the design of real-world contests but that a designer must balance competing objectives.","['Bhattacharya, Vivek']","['Asymmetric and Private Information; Mechanism Design', 'National Security and War', 'National Government Expenditures and Related Policies: Procurement', 'Transactional Relationships; Contracts and Reputation; Networks', 'Firm Performance: Size, Diversification, and Scope', 'Innovation and Invention: Processes and Incentives']","['D82', 'H56', 'H57', 'L14', 'L25', 'O31']",An Empirical Model of R&D Procurement Contests: An Analysis of the DOD SBIR Program,1,0,0,1,0,2021,09,01
89,5,2021-09-01,"We propose a bootstrap procedure for data that may exhibit cluster-dependence in two or more dimensions. The asymptotic distribution of the sample mean or other statistics may be non-Gaussian if observations are dependent but uncorrelated within clusters. We show that there exists no procedure for estimating the limiting distribution of the sample mean under two-way clustering that achieves uniform consistency. However, we propose bootstrap procedures that achieve adaptivity with respect to different uniformity criteria. Important cases and extensions discussed in the paper include regression inference, U- and V-statistics, subgraph counts for network data, and non-exhaustive samples of matched data.","['Menzel, Konrad']","['Statistical Simulation Methods: General', 'Specific Distributions; Specific Statistics']","['C15', 'C46']",Bootstrap with Cluster-Dependence in Two or More Dimensions,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"We propose a positive model of empirical science in which an analyst makes a report to an audience after observing some data. Agents in the audience may differ in their beliefs or objectives, and may therefore update or act differently following a given report. We contrast the proposed model with a classical model of statistics in which the report directly determines the payoff. We identify settings in which the predictions of the proposed model differ from those of the classical model, and seem to better match practice.","['Andrews, Isaiah', 'Shapiro, Jesse M.']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making']","['D11', 'D83', 'D91']",A Model of Scientific Communication,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"A sender ranks information structures knowing that a receiver processes the information before choosing an action affecting them both. The sender and receiver may differ in their utility functions and/or prior beliefs, yielding a model of dynamic inconsistency when they represent the same individual at two points in time. I take as primitive (i) a collection of preference orderings over all information structures, indexed by menus of acts (the sender's ex ante preferences for information), and (ii) a collection of correspondences over menus of acts, indexed by signals (the receiver's signal-contingent choice(s) from menus). I provide axiomatic representation theorems characterizing the sender as a sophisticated planner and the receiver as a Bayesian information processor, and show that all parameters can be uniquely identified from the sender's preferences for information. I also establish a series of results characterizing common priors, common utility functions, and intuitive measures of disagreement for these parameters--all in terms of the sender's preferences for information.","['Jakobsen, Alexander M.']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making']","['D11', 'D83', 'D91']",An Axiomatic Model of Persuasion,0,0,0,0,0,2021,09,01
89,5,2021-09-01,"We study information aggregation when n bidders choose, based on their private information, between two concurrent common-value auctions. There are k_{s} identical objects on sale through a uniform-price auction in market s and there are an additional k_{r} objects on auction in market r, which is identical to market s except for a positive reserve price. The reserve price in market r implies that information is not aggregated in this market. Moreover, if the object-to-bidder ratio in market s exceeds a certain cutoff, then information is not aggregated in market s either. Conversely, if the object-to-bidder ratio is less than this cutoff, then information is aggregated in market s as the market grows arbitrarily large. Our results demonstrate how frictions in one market can disrupt information aggregation in a linked, frictionless market because of the pattern of market selection by imperfectly informed bidders.","['Atakan, Alp E.', 'Ekmekci, Mehmet']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Market Selection and the Information Content of Prices,0,0,1,0,0,2021,09,01
89,5,2021-09-01,"We propose a robust method of discrete choice analysis when agents' choice sets are unobserved. Our core model assumes nothing about agents' choice sets apart from their minimum size. Importantly, it leaves unrestricted the dependence, conditional on observables, between choice sets and preferences. We first characterize the sharp identification region of the model's parameters by a finite set of conditional moment inequalities. We then apply our theoretical findings to learn about households' risk preferences and choice sets from data on their deductible choices in auto collision insurance. We find that the data can be explained by expected utility theory with low levels of risk aversion and heterogeneous non-singleton choice sets, and that more than three in four households require limited choice sets to explain their deductible choices. We also provide simulation evidence on the computational tractability of our method in applications with larger feasible sets or higher-dimensional unobserved heterogeneity.","['Teitelbaum, Joshua C.', 'Molinari, Francesca', 'Barseghyan, Levon', 'Coughlin, Maura']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty', 'Insurance; Insurance Companies; Actuarial Studies', 'Household Finance: Insurance']","['D11', 'D81', 'G22', 'G52']",Heterogeneous Choice Sets and Preferences,0,0,0,0,0,2021,09,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],"Fellows of the Econometric Society July, 2020.",0,0,0,0,0,2020,07,01
88,4,2020-07-01,"In Giglio, Maggiori, and Stroebel (2016), we propose and implement a new test for classic rational bubbles. Such bubbles derive their value from each agent's rational expectation of being able to resell the bubble claims to the next agent. Backward induction ensures that classic rational bubbles can only exist on infinite-maturity assets. Our empirical exercise shows that infinite-maturity claims and 999-year claims for otherwise identical housing assets trade at the same price, and thus rules out the presence of classic rational bubbles. Domeij and Ellingsen (DE) informally propose an alternative equilibrium of a bubble that they claim is consistent with our empirical findings. DE's bubble relies on information frictions such that market participants are unaware of the bubble. Our paper clearly excluded this type of bubble from the scope of our test, and DE's note thus has no implications for the validity of our test. Instead, DE's bubble simply represents one of many possible examples of bubbles on which our test was explicitly silent.","['Maggiori, Matteo', 'Stroebel, Johannes', 'Giglio, Stefano']","['Equities; Fixed Income Securities', 'Housing Supply and Markets']","['G12', 'R31']",Reply to 'Rational Bubbles in UK Housing Markets' [No-Bubble Condition: Model-Free Tests in Housing Markets],0,0,0,0,0,2020,07,01
88,4,2020-07-01,"Giglio, Maggiori, and Stroebel (2016) show that there is no significant price difference between freeholds and ultra-long leaseholds in the UK housing market. They claim that this finding precludes the presence of large rational bubbles, as these can only attach to the price of freeholds. But the conclusion presumes that leaseholders cannot acquire bubbles through enfranchisement at favorable prices. We find that the presumption is violated. Enfranchisement rights are comprehensive and cheap to exercise. We also dispute the counter-argument that cheap enfranchisement proves that market participants, if they have rational expectations, must have explicitly concluded that freehold prices are bubbleless.","['Domeij, David', 'Ellingsen, Tore']","['Equities; Fixed Income Securities', 'Housing Supply and Markets']","['G12', 'R31']",Rational Bubbles in UK Housing Markets: Comment on 'No-Bubble Condition: Model-Free Tests in Housing Markets',0,0,0,0,0,2020,07,01
88,4,2020-07-01,"We consider statistical inference in games. Each player obtains a small random sample of other players' actions, uses statistical inference to estimate their actions, and chooses an optimal action based on the estimate. In a sampling equilibrium with statistical inference (SESI), the sample is drawn from the distribution of players' actions based on this process. We characterize the set of SESIs in large two-action games, and compare their predictions to those of Nash equilibrium, and for different sample sizes and statistical inference procedures. We then study applications to competitive markets, markets with network effects, monopoly pricing, and search and matching markets.","['Salant, Yuval', 'Cherry, Josh']","['Game Theory and Bargaining Theory: General', 'Market Structure, Pricing, and Design: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D40', 'D83']",Statistical Inference in Games,0,0,1,0,0,2020,07,01
88,4,2020-07-01,"Equilibrium payoff bounds from reputation effects are derived for repeated games with imperfect public monitoring in which a long-run player interacts frequently with a population of short-run players and the monitoring technology scales with the length of the period of interaction. The bounds depend on the monitoring technology through the flow of information, a measure of signal informativeness per unit of time based on relative entropy. Examples are shown where, under complete information, the set of equilibrium payoffs of the long-run player converges, as the period length tends to zero, to the set of static equilibrium payoffs, whereas when the game is perturbed by a small ex ante probability on commitment types, reputation effects remain powerful in the high-frequency limit.","['Faingold, Eduardo']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D82', 'D83']",Reputation and the Flow of Information in Repeated Games,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"We study the pure-strategy subgame-perfect Nash equilibria of stochastic games with perfect monitoring, geometric discounting, and public randomization. We develop novel algorithms for computing equilibrium payoffs, in which we combine policy iteration when incentive constraints are slack with value iteration when incentive constraints bind. We also provide software implementations of our algorithms. Preliminary simulations indicate that they are significantly more efficient than existing methods. The theoretical results that underlie the algorithms also imply bounds on the computational complexity of equilibrium payoffs when there are two players. When there are more than two players, we show by example that the number of extreme equilibrium payoffs may be countably infinite.","['Brooks, Benjamin', 'Abreu, Dilip', 'Sannikov, Yuliy']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",Algorithms for Stochastic Games with Perfect Monitoring,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"We study a model of cheap talk with one substantive assumption: The sender's preferences are state independent. Our main observation is that such a sender gains credibility by degrading self-serving information. Using this observation, we examine the sender's benefits from communication, assess the value of commitment, and explicitly solve for sender-optimal equilibria in three examples. A key result is a geometric characterization of the value of cheap talk, described by the quasiconcave envelope of the sender's value function.","['Lipnowski, Elliot', 'Ravid, Doron']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Cheap Talk with Transparent Motives,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"This paper proposes a class of games called revision games. In a revision game, players start with initially prepared actions, followed by a sequence of random revision opportunities until a predetermined deadline. In the course of revisions, players monitor each other's behavior. It is shown that players can cooperate and that their behavior under the optimal equilibrium is described by a simple differential equation. We present the necessary and sufficient conditions for cooperation to be sustained in revision games. We also present applications to the preopening activities in the stock exchange and to an electoral campaign.","['Kandori, Michihiro', 'Kamada, Yuichiro']","['Game Theory and Bargaining Theory: General', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Portfolio Choice; Investment Decisions']","['C70', 'D72', 'G11']",Revision Games,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"This paper develops a multi-stage general-equilibrium model of global value chains (GVCs) and studies the specialization of countries within GVCs in a world with barriers to international trade. With costly trade, the optimal location of production of a given stage in a GVC is not only a function of the marginal cost at which that stage can be produced in a given country, but is also shaped by the proximity of that location to the precedent and the subsequent desired locations of production. We show that, other things equal, it is optimal to locate relatively downstream stages of production in relatively central locations. We also develop and estimate a tractable, quantifiable version of our model that illustrates how changes in trade costs affect the extent to which various countries participate in domestic, regional, or global value chains, and traces the real income consequences of these changes.","['de Gortari, Alonso', 'Antras, Pol']","['Trade Policy; International Trade Organizations', 'Empirical Studies of Trade', 'Transactional Relationships; Contracts and Reputation; Networks']","['F13', 'F14', 'L14']",On the Geography of Global Value Chains,1,0,0,0,0,2020,07,01
88,4,2020-07-01,"We propose a decomposition of the realized covariance matrix into components based on the signs of the underlying high-frequency returns, and we derive the asymptotic properties of the resulting realized semicovariance measures as the sampling interval goes to zero. The first-order asymptotic results highlight how the same-sign and mixed-sign components load differently on economic information related to stochastic correlation and jumps. The second-order asymptotic results reveal the structure underlying the same-sign semicovariances, as manifested in the form of co-drifting and dynamic ""leverage"" effects. In line with this anatomy, we use data on a large cross-section of individual stocks to empirically document distinct dynamic dependencies in the different realized semicovariance components. We show that the accuracy of portfolio return variance forecasts may be significantly improved by exploiting the information in realized semicovariances.","['Li, Jia', 'Bollerslev, Tim', 'Quaedvlieg, Rogier', 'Patton, Andrew J.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Equities; Fixed Income Securities', 'Financial Forecasting and Simulation']","['D83', 'G11', 'G12', 'G17']",Realized Semicovariances,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"Do new communication technologies, such as social media, alleviate the collective action problem? This paper provides evidence that penetration of VK, the dominant Russian online social network, led to more protest activity during a wave of protests in Russia in 2011. As a source of exogenous variation in network penetration, we use the information on the city of origin of the students who studied with the founder of VK, controlling for the city of origin of the students who studied at the same university several years earlier or later. We find that a 10% increase in VK penetration increased the probability of a protest by 4.6% and the number of protesters by 19%. Additional results suggest that social media induced protest activity by reducing the costs of coordination rather than by spreading information critical of the government. We observe that VK penetration increased pro-governmental support, with no evidence of increased polarization. We also find that cities with higher fractionalization of network users between VK and Facebook experienced fewer protests, and the effect of VK on protests exhibits threshold behavior.","['Makarin, Alexey', 'Enikolopov, Ruben', 'Petrova, Maria']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Sports; Gambling; Restaurants; Recreation; Tourism', 'Socialist Systems and Transitional Economies: Political Economy; Property Rights', 'Socialist Institutions and Their Transitions: Consumer Economics; Health; Education and Training: Welfare, Income, Wealth, and Poverty', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D72', 'L83', 'P26', 'P36', 'Z13']",Social Media and Protest Participation: Evidence from Russia,1,0,0,0,0,2020,07,01
88,4,2020-07-01,"Oversubscribed treatments are often allocated using randomized waiting lists. Applicants are ranked randomly, and treatment offers are made following that ranking until all seats are filled. To estimate causal effects, researchers often compare applicants getting and not getting an offer. We show that those two groups are not statistically comparable. Therefore, the estimator arising from that comparison is inconsistent when the number of waitlists goes to infinity. We propose a new estimator, and show that it is consistent, provided the waitlists have at least two seats. Finally, we revisit an application, and we show that using our estimator can lead to a statistically significant difference with respect to the results obtained using the commonly used estimator.","['de Chaisemartin, Clement', 'Behaghel, Luc']","['Analysis of Education', 'Returns to Education', 'Education: Government Policy', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['I21', 'I26', 'I28', 'J24']",Estimating the Effect of Treatments Allocated by Randomized Waiting Lists,0,0,0,0,0,2020,07,01
88,4,2020-07-01,"We study optimal transport networks in spatial equilibrium. We develop a framework consisting of a neoclassical trade model with labor mobility in which locations are arranged on a graph. Goods must be shipped through linked locations, and transport costs depend on congestion and on the infrastructure in each link, giving rise to an optimal transport problem in general equilibrium. The optimal transport network is the solution to a social planner's problem of building infrastructure in each link. We provide conditions such that this problem is globally convex, guaranteeing its numerical tractability. We also study cases with increasing returns to transport technologies in which global convexity fails. We apply the framework to assess optimal investments and inefficiencies in the road networks of European countries.","['Schaal, Edouard', 'Fajgelbaum, Pablo D.']","['Neoclassical Models of Trade', 'Transportation: General', 'Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise', 'Transportation Economics: Government and Private Investment Analysis; Road Maintenance, Transportation Planning', 'Public Facility Location Analysis; Public Investment and Capital Stock']","['F11', 'L91', 'R41', 'R42', 'R53']",Optimal Transport Networks in Spatial Equilibrium,1,0,0,0,0,2020,07,01
88,4,2020-07-01,"Cumulative Prospect Theory (CPT), the leading behavioral account of decisionmaking under uncertainty, avoids the dominance violations implicit in Prospect Theory (PT) by assuming that the probability weight applied to a given outcome depends on its ranking. We devise a simple and direct nonparametric method for measuring the change in relative probability weights resulting from a change in payoff ranks. We find no evidence that these weights are even modestly sensitive to ranks. Conventional calibrations of CPT preferences imply that the percentage change in probability weights should be an order of magnitude larger than we observe. It follows either that probability weighting is not rank-dependent, or that the weighting function is nearly linear. Nonparametric measurement of the change in relative probability weights resulting from changes in probabilities rules out the second possibility. Additional tests nevertheless indicate that the dominance patterns predicted by PT do not arise. We reconcile these findings by positing a form of complexity aversion that generalizes the well-known certainty effect.","['Bernheim, B. Douglas', 'Sprenger, Charles']","['Semiparametric and Nonparametric Methods: General', 'Criteria for Decision-Making under Risk and Uncertainty']","['C14', 'D81']",On the Empirical Validity of Cumulative Prospect Theory: Experimental Evidence of Rank-Independent Probability Weighting,0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,"['Besley, Timothy']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance', 'Public Goods']","['D72', 'E62', 'H24', 'H26', 'H41']","Reply to: Comments on 'State Capacity, Reciprocity, and the Social Contract'",0,0,0,0,0,2020,07,01
88,4,2020-07-01,"In this note, I discuss avenues for future research stemming from Besley's (this issue) theoretical approach on the interconnections between civicness, institutions, and state-fiscal capacity. First, I lay down some ideas on how one could extend the framework to model fragility traps that characterize many low-income countries and study issues related to nation-building, conflict, and heterogeneity across space and ethnic lines in the provision of public goods. Second, I discuss the relevance of the approach for the analysis of authoritarian populism that is spreading in developed countries and emerging markets.","['Papaioannou, Elias']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance', 'Public Goods']","['D72', 'E62', 'H24', 'H26', 'H41']","A Comment on: 'State Capacity, Reciprocity, and the Social Contract' by Timothy Besley",0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,"['Bisin, Alberto']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance', 'Public Goods']","['D72', 'E62', 'H24', 'H26', 'H41']","A Comment on: 'State Capacity, Reciprocity, and the Social Contract' by Timothy Besley",0,0,0,0,0,2020,07,01
88,4,2020-07-01,"Treating civic preferences as endogenous and government policies and tax capacities as both an influence on and a consequence of their evolution is an important new strand of thinking to which Besley has contributed. I ask: Does his model provide a convincing explanation of the way that civic cultures and the expansion of the state evolved as a matter of historical fact? And I suggest a number of alternative modeling approaches that both would recognize that policy makers take account of the effects of their policy choices on preferences and, consistent with empirical observations, would support equilibria with culturally heterogeneous rather than homogeneous populations.","['Bowles, Samuel']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance', 'Public Goods']","['D72', 'E62', 'H24', 'H26', 'H41']","A Comment on: 'State Capacity, Reciprocity, and the Social Contract' by Timothy Besley",0,0,0,0,0,2020,07,01
88,4,2020-07-01,This paper explores the role of civic culture in expanding fiscal capacity by developing a model based on reciprocal obligations: citizens pay their taxes and the state provides public goods. Civic culture evolves over time according to the relative payoff of civic-minded and materialist citizens. A strong civic culture manifests itself as high tax revenues sustained by high levels of voluntary tax compliance and provision of public goods. This captures the idea of government as a reciprocal social contract between the state and its citizens. The paper highlights the role of political institutions and common interests in the emergence of civic culture.,"['Besley, Timothy']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance', 'Public Goods']","['D72', 'E62', 'H24', 'H26', 'H41']","State Capacity, Reciprocity, and the Social Contract",0,0,0,0,0,2020,07,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],2019 Election of Fellows to the Econometric Society.,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"Theories of bounded rationality often assume a rich dataset of choices from many overlapping menus, limiting their practical applicability. In contrast, we study the problem of identifying the distribution of cognitive characteristics in a population of agents from a minimal dataset that consists of aggregate choice shares from a single menu, and includes no observable covariates of any kind. With homogeneous preferences, we find that ""consideration capacity"" and ""consideration probability"" distributions can both be recovered effectively if the menu is sufficiently large. This remains true generically when tastes are heterogeneous with a known distribution. When the taste distribution is unknown, we show that joint choice share data from three ""occasions"" are generically sufficient for full identification of the cognitive distribution, and also provide substantial information about tastes.","['Tyson, Christopher J.', 'Mariotti, Marco', 'Manzini, Paola', 'Dardanoni, Valentino']","['Consumer Economics: Theory', 'Social Choice; Clubs; Committees; Associations', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D71', 'D83']",Inferring Cognitive Heterogeneity from Aggregate Choices,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"We consider a large class of social learning models in which a group of agents face uncertainty regarding a state of the world, share the same utility function, observe private signals, and interact in a general dynamic setting. We introduce social learning equilibria, a static equilibrium concept that abstracts away from the details of the given extensive form, but nevertheless captures the corresponding asymptotic equilibrium behavior. We establish general conditions for agreement, herding, and information aggregation in equilibrium, highlighting a connection between agreement and information aggregation.","['Mossel, Elchanan', 'Sly, Allan', 'Tamuz, Omer', 'Mueller-Frank, Manuel']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Social Learning Equilibria,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"This paper investigates the determinants of political polarization, a phenomenon of increasing relevance in Western democracies. How much of polarization is driven by divergence in the ideologies of politicians? How much is instead the result of changes in the capacity of parties to control their members? We use detailed internal information on party discipline in the context of the U.S. Congress--whip count data for 1977-1986--to identify and structurally estimate an economic model of legislative activity in which agenda selection, party discipline, and member votes are endogenous. The model delivers estimates of the ideological preferences of politicians, the extent of party control, and allows us to assess the effects of polarization through agenda setting (i.e., which alternatives to a status quo are strategically pursued). We find that parties account for approximately 40% of the political polarization in legislative voting over this time period, a critical inflection point in U.S. polarization. We also show that, absent party control, historically significant economic policies would have not passed or lost substantial support. Counterfactual exercises establish that party control is highly relevant for the probability of success of a given bill and that polarization in ideological preferences is more consequential for policy selection, resulting in different bills being pursued.","['Trebbi, Francesco', 'Kendall, Chad', 'Canen, Nathan']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D72', 'D83']",Unbundling Polarization,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"We propose a model of preferences in which the effect of randomization on ambiguity depends on how the unknown probability law is determined. We adopt the framework of Anscombe and Aumann (1963) and relax the axioms. In the resulting representation of the individual's preference, the individual has a collection of sets of priors M. She believes that before she moves, nature has chosen an unknown scenario (a set of priors) from M, and from that scenario, nature will choose a prior after she moves. The representation illustrates how randomization may partially eliminate the effect of ambiguity.","['Ke, Shaowei', 'Zhang, Qi']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Randomization and Ambiguity Aversion,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"Using an analytically tractable heterogeneous agent New Keynesian model, we show that whether incomplete markets resolve New Keynesian ""paradoxes"" depends on the cyclicality of income risk. Incomplete markets reduce the effectiveness of forward guidance and multipliers in a liquidity trap only with procyclical risk. Countercyclical risk amplifies these ""puzzles."" Procyclical risk permits determinacy under a peg; countercyclical risk may generate indeterminacy even under the Taylor principle. By affecting the cyclicality of risk, even ""passive"" fiscal policy influences the effects of monetary policy.","['Dogra, Keshav', 'Acharya, Sushant']","['Incomplete Markets', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian; Modern Monetary Theory', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Monetary Policy', 'Fiscal Policy']","['D52', 'E12', 'E32', 'E43', 'E52', 'E62']",Understanding HANK: Insights from a PRANK,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"In this paper, we study how occupation (or industry) tradability shapes local labor-market adjustment to immigration. Theoretically, we derive a simple condition under which the arrival of foreign-born labor into a region crowds native-born workers out of (or into) immigrant-intensive jobs, thus lowering (or raising) relative wages in these occupations, and we explain why this process differs within tradable versus within nontradable activities. Using data for U.S. commuting zones over the period 1980-2012, we find--consistent with our theory--that a local influx of immigrants crowds out employment of native-born workers in more relative to less immigrant-intensive nontradable jobs, but has no such effect across tradable occupations. Further analysis of occupation labor payments is consistent with adjustment to immigration within tradables occurring more through changes in output (versus changes in prices) when compared to adjustment within nontradables, thereby confirming our model's theoretical mechanism. We then use the model to explore the quantitative consequences of counterfactual changes in U.S. immigration on real wages at the occupation and region level.","['Tian, Lin', 'Hanson, Gordon', 'Vogel, Jonathan', 'Burstein, Ariel']","['Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Wage Level and Structure; Wage Differentials', 'Geographic Labor Mobility; Immigrant Workers']","['J15', 'J31', 'J61']",Tradability and the Labor-Market Impact of Immigration: Theory and Evidence from the United States,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"In this paper, we develop a model that captures key components of the Roy model, a search model, compensating differentials, and human capital accumulation on-the-job. We establish which components of the model can be non-parametrically identified and which ones cannot. We estimate the model and use it to assess the relative contribution of the different factors for overall wage inequality. We find that variation in premarket skills (the key feature of the Roy model) is the most important component to account for the majority of wage variation. We also demonstrate that there is substantial interaction between the other components, most notably, that the importance of the job match obtained by search frictions varies from around 4% to around 29%, depending on how we account for other components. Inequality due to preferences for non-pecuniary aspects of the job (which leads to compensating differentials) and search are both very important for explaining other features of the data. Search is important for turnover, but so are preferences for non-pecuniary aspects of jobs as one-third of all choices between two jobs would have resulted in a different outcome if the worker only cared about wages.","['Taber, Christopher', 'Vejlin, Rune']","['Model Construction and Estimation', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts']","['C51', 'J24', 'J31', 'J41']",Estimation of a Roy/Search/Compensating Differential Model of the Labor Market,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"It is well understood that classical sample selection models are not semiparametrically identified without exclusion restrictions. Lee (2009) developed bounds for the parameters in a model that nests the semiparametric sample selection model. These bounds can be wide. In this paper, we investigate bounds that impose the full structure of a sample selection model with errors that are independent of the explanatory variables but have unknown distribution. The additional structure can significantly reduce the identified set for the parameters of interest. Specifically, we construct the identified set for the parameter vector of interest. It is a one-dimensional line segment in the parameter space, and we demonstrate that this line segment can be short in practice. We show that the identified set is sharp when the model is correct and empty when there exist no parameter values that make the sample selection model consistent with the data. We also provide non-sharp bounds under the assumption that the model is correct. These are easier to compute and associated with lower statistical uncertainty than the sharp bounds. Throughout the paper, we illustrate our approach by estimating a standard sample selection model for wages.","['Honore, Bo E.', 'Hu, Luojia']","['Semiparametric and Nonparametric Methods: General', 'Model Evaluation, Validation, and Selection', 'Wage Level and Structure; Wage Differentials']","['C14', 'C52', 'J31']",Selection without Exclusion,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"Liver exchange has been practiced in small numbers, mainly to overcome blood-type incompatibility between patients and their living donors. A donor can donate either his smaller left lobe or the larger right lobe, although the former option is safer. Despite its elevated risk, right-lobe transplantation is often utilized due to size-compatibility requirement with the patient. We model liver exchange as a market-design problem, focusing on logistically simpler two-way exchanges, and introduce an individually rational, Pareto-efficient, and incentive-compatible mechanism. Construction of this mechanism requires novel technical tools regarding bilateral exchanges under partial-order-induced preferences. Through simulations we show that not only can liver exchange increase the number of transplants by more than 30%, it can also increase the share of the safer left-lobe transplants.","['Ergin, Haluk', 'Sonmez, Tayfun', 'Unver, M. Utku']","['Market Design', 'Asymmetric and Private Information; Mechanism Design', 'Analysis of Health Care Markets']","['D47', 'D82', 'I11']",Efficient and Incentive-Compatible Liver Exchange,0,0,1,0,0,2020,05,01
88,3,2020-05-01,"We prove the folk theorem for discounted repeated games with anonymous random matching. We allow non-uniform matching, include asymmetric payoffs, and place no restrictions on the stage game other than full dimensionality. No record-keeping or communication devices--including cheap talk communication and public randomization--are necessary.","['Deb, Joyee', 'Wolitzky, Alexander', 'Sugaya, Takuo']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory']","['C73', 'C78']",The Folk Theorem in Repeated Games with Anonymous Random Matching,0,0,0,0,0,2020,05,01
88,3,2020-05-01,"We study how aggregate economic conditions affect the timing of marriage, and particularly child marriage, in Sub-Saharan Africa and in India. In both regions, substantial monetary or in-kind transfers occur with marriage: bride price across Sub-Saharan Africa and dowry in India. In a simple equilibrium model of the marriage market in which parents choose when their children marry, income shocks affect the age of marriage because marriage payments are a source of consumption smoothing, particularly for a woman's family. As predicted by our model, we show that droughts, which reduce annual crop yields by 10 to 15% and aggregate income by 4 to 5%, have opposite effects on the marriage behavior of a sample of 400,000 women in the two regions: in Sub-Saharan Africa they increase the annual hazard into child marriage by 3%, while in India droughts reduce such a hazard by 4%. Changes in the age of marriage due to droughts are associated with changes in fertility, especially in Sub-Saharan Africa, and with declines in observed marriage payments. Our results indicate that the age of marriage responds to short-term changes in aggregate economic conditions and that marriage payments determine the sign of this response. This suggests that, in order to design successful policies to combat child marriage and improve investments in daughters' human capital, it is crucial to understand the economic role of marriage market institutions.","['Voena, Alessandra', 'Hildebrandt, Nicole', 'Corno, Lucia']","['Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Gender; Non-labor Discrimination', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Climate; Natural Disasters and Their Management; Global Warming']","['J12', 'J13', 'J16', 'O13', 'O15', 'Q54']","Age of Marriage, Weather Shocks, and the Direction of Marriage Payments",0,0,0,0,0,2020,05,01
88,3,2020-05-01,"Treatment for depression is complex, requiring decisions that may involve trade-offs between exploiting treatments with the highest expected value and experimenting with treatments with higher possible payoffs. Using patient claims data, we show that among skilled doctors, using a broader portfolio of drugs predicts better patient outcomes, except in cases where doctors' decisions violate loose professional guidelines. We introduce a behavioral model of decision making guided by our empirical observations. The model's novel feature is that the trade-off between exploitation and experimentation depends on the doctor's diagnostic skill. The model predicts that higher diagnostic skill leads to greater diversity in drug choice and better matching of drugs to patients even among doctors with the same initial beliefs regarding drug effectiveness. Consistent with the finding that guideline violations predict poorer patient outcomes, simulations of the model suggest that increasing the number of possible drug choices can lower performance.","['Currie, Janet M.', 'MacLeod, W. Bentley']","['Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making', 'Analysis of Health Care Markets', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Professional Labor Markets; Occupational Licensing']","['D91', 'I11', 'J24', 'J44']",Understanding Doctor Decision Making: The Case of Depression Treatment,0,0,0,0,0,2020,05,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2021,01,01
88,6,2020-11-01,ECONLIT None Found,"['Andrews, Isaiah', 'Shapiro, Jesse M.', 'Gentzkow, Matthew']","['Estimation: General', 'Model Construction and Estimation']","['C13', 'C51']",Reply to: Comments on 'On the Informativeness of Descriptive Statistics for Structural Estimates',0,0,0,0,0,2020,11,01
88,2,2020-03-01,"We consider social welfare functions that satisfy Arrow's classic axioms of independence of irrelevant alternatives and Pareto optimality when the outcome space is the convex hull of some finite set of alternatives. Individual and collective preferences are assumed to be continuous and convex, which guarantees the existence of maximal elements and the consistency of choice functions that return these elements, even without insisting on transitivity. We provide characterizations of both the domains of preferences and the social welfare functions that allow for anonymous Arrovian aggregation. The domains admit arbitrary preferences over alternatives, which completely determine an agent's preferences over all mixed outcomes. On these domains, Arrow's impossibility turns into a complete characterization of a unique social welfare function, which can be readily applied in settings involving divisible resources such as probability, time, or money.","['Brandl, Florian', 'Brandt, Felix']","['Consumer Economics: Theory', 'Allocative Efficiency; Cost-Benefit Analysis']","['D11', 'D61']",Arrovian Aggregation of Convex Preferences,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"This research advances the hypothesis and establishes empirically that interpersonal population diversity, rather than fractionalization or polarization across ethnic groups, has been pivotal to the emergence, prevalence, recurrence, and severity of intrasocietal conflicts. Exploiting an exogenous source of variations in population diversity across nations and ethnic groups, as determined predominantly during the exodus of humans from Africa tens of thousands of years ago, the study demonstrates that population diversity, and its impact on the degree of diversity within ethnic groups, has contributed significantly to the risk and intensity of historical and contemporary civil conflicts. The findings arguably reflect the contribution of population diversity to the non-cohesiveness of society, as reflected partly in the prevalence of mistrust, the divergence in preferences for public goods and redistributive policies, and the degree of fractionalization and polarization across ethnic, linguistic, and religious groups.","['Arbatli, Cemal Eren', 'Galor, Oded', 'Ashraf, Quamrul H.', 'Klemp, Marc']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D74', 'Z13']",Diversity and Conflict,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"This paper studies the robustness of an equilibrium to incomplete information in binary-action supermodular games. Using a generalized version of belief operator, we explore the restrictions that prior beliefs impose on higher order beliefs. In particular, we obtain a nontrivial lower bound on the probability of a common belief event, uniform over type spaces, when the underlying game has a monotone potential. Conversely, when the game has no monotone potential, we construct a type space with an arbitrarily high probability event in which players never have common belief about that event. As an implication of these results, we show for generic binary-action supermodular games that an action profile is robust to incomplete information if and only if it is a monotone potential maximizer. Our study offers new methodology and insight to the analysis of global game equilibrium selection.","['Oyama, Daisuke', 'Takahashi, Satoru']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']",Generalized Belief Operator and Robustness in Binary-Action Supermodular Games,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"In this paper, we study the role of the transportation sector in world trade. We build a spatial model that centers on the interaction of the market for (oceanic) transportation services and the market for world trade in goods. The model delivers equilibrium trade flows, as well as equilibrium trade costs (shipping prices). Using detailed data on vessel movements and shipping prices, we document novel facts about shipping patterns; we then flexibly estimate our model. We use this setup to demonstrate that the transportation sector (i) attenuates differences in the comparative advantage across countries; (ii) generates network effects in trade costs; and (iii) dampens the impact of shocks on trade flows. These three mechanisms reveal a new role for geography in international trade that was previously concealed by the frequently-used assumption of exogenous trade costs. Finally, we illustrate how our setup can be used for policy analysis by evaluating the impact of future and existing infrastructure projects (e.g., Northwest Passage, Panama Canal).","['Kalouptsidi, Myrto', 'Papageorgiou, Theodore', 'Brancaccio, Giulia']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Empirical Studies of Trade', 'Railroads and Other Surface Transportation', 'Size and Spatial Distributions of Regional Economic Activity', 'Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise', 'Transportation Economics: Government and Private Investment Analysis; Road Maintenance, Transportation Planning']","['D24', 'F14', 'L92', 'R12', 'R41', 'R42']","Geography, Transportation, and Endogenous Trade Costs",1,0,0,0,0,2020,03,01
88,2,2020-03-01,"We study preferences over lotteries in which both the prize and the payment date are uncertain. In particular, a time lottery is one in which the prize is fixed but the date is random. With Expected Discounted Utility, individuals must be risk seeking over time lotteries (RSTL). In an incentivized experiment, however, we find that almost all subjects violate this property. Our main contributions are theoretical. We first show that within a very broad class of models, which includes many forms of nonexpected utility and time discounting, it is impossible to accommodate even a single violation of RSTL without also violating a property we termed Stochastic Impatience, a risky counterpart of standard Impatience. We then present two positive results. If one wishes to maintain Stochastic Impatience, violations of RSTL can be accommodated by keeping Independence within periods while relaxing it across periods. If, instead, one is willing to forego Stochastic Impatience, violations of RSTL can be accommodated with a simple generalization of Expected Discounted Utility, obtained by imposing only the behavioral postulates of Discounted Utility and Expected Utility.","['Dillenberger, David', 'Ortoleva, Pietro', 'Gottlieb, Daniel', 'DeJarnette, Patrick']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Time Lotteries and Stochastic Impatience,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"New ways of doing things often get started through the actions of a few innovators, then diffuse rapidly as more and more people come into contact with prior adopters in their social network. Much of the literature focuses on the speed of diffusion as a function of the network topology. In practice, the topology may not be known with any precision, and it is constantly in flux as links are formed and severed. Here, we establish an upper bound on the expected waiting time until a given proportion of the population has adopted that holds independently of the network structure. Kreindler and Young (2014) demonstrated such a bound for regular networks when agents choose between two options: the innovation and the status quo. Our bound holds for directed and undirected networks of arbitrary size and degree distribution, and for multiple competing innovations with different payoffs.","['Babichenko, Yakov', 'Peretz, Ron', 'Arieli, Itai', 'Young, H. Peyton']","['Innovation and Invention: Processes and Incentives', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['O31', 'Z13']",The Speed of Innovation Diffusion in Social Networks,0,0,0,1,0,2020,03,01
88,2,2020-03-01,"Can digital information and communication technology foster mass political mobilization? We use a novel georeferenced data set for the entire African continent between 1998 and 2012 on the coverage of mobile phone signal together with georeferenced data from multiple sources on the occurrence of protests and on individual participation in protests to bring this argument to empirical scrutiny. We find that while mobile phones are instrumental to mass mobilization, this only happens during economic downturns, when reasons for grievance emerge and the cost of participation falls. The results are in line with insights from a network model with imperfect information and strategic complementarities in protest occurrence. Mobile phones make individuals more responsive to both changes in economic conditions--a mechanism that we ascribe to enhanced information--and to their neighbors' participation--a mechanism that we ascribe to enhanced coordination.","['Manacorda, Marco', 'Tesei, Andrea']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Telecommunications', 'Industrialization; Manufacturing and Service Industries; Choice of Technology', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Technological Change: Choices and Consequences; Diffusion Processes']","['D72', 'L96', 'O14', 'O17', 'O33']",Liberation Technology: Mobile Phones and Political Mobilization in Africa,1,0,0,1,0,2020,03,01
88,2,2020-03-01,"We extend Kreps and Wilson's concept of sequential equilibrium to games with infinite sets of signals and actions. A strategy profile is a conditional Epsilon-equilibrium if, for any of a player's positive probability signal events, his conditional expected utility is within Epsilon of the best that he can achieve by deviating. With topologies on action sets, a conditional Epsilon-equilibrium is full if strategies give every open set of actions positive probability. Such full conditional Epsilon-equilibria need not be subgame perfect, so we consider a non-topological approach. Perfect conditional Epsilon-equilibria are defined by testing conditional Epsilon-rationality along nets of small perturbations of the players' strategies and of nature's probability function that, for any action and for almost any state, make this action and state eventually (in the net) always have positive probability. Every perfect conditional Epsilon-equilibrium is a subgame perfect Epsilon-equilibrium, and, in finite games, limits of perfect conditional Epsilon-equilibria as Epsilon approaches 0 are sequential equilibrium strategy profiles. But limit strategies need not exist in infinite games so we consider instead the limit distributions over outcomes. We call such outcome distributions perfect conditional equilibrium distributions and establish their existence for a large class of regular projective games. Nature's perturbations can produce equilibria that seem unintuitive and so we augment the game with a net of permissible perturbations.","['Reny, Philip J.', 'Myerson, Roger B.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'D82']",Perfect Conditional Epsilon-Equilibria of Multi-stage Games with Infinite Sets of Signals and Actions,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"We study the incidence of nonlinear labor income taxes in an economy with a continuum of endogenous wages. We derive in closed form the effects of reforming nonlinearly an arbitrary tax system, by showing that this problem can be formalized as an integral equation. Our tax incidence formulas are valid both when the underlying assignment of skills to tasks is fixed or endogenous. We show qualitatively and quantitatively that contrary to conventional wisdom, if the tax system is initially suboptimal and progressive, the general-equilibrium ""trickle-down"" forces may raise the benefits of increasing the marginal tax rates on high incomes. We finally derive a parsimonious characterization of optimal taxes.","['Werquin, Nicolas', 'Tsyvinski, Aleh', 'Sachs, Dominik']","['General Equilibrium and Disequilibrium: General', 'Taxation and Subsidies: Efficiency; Optimal Taxation']","['D50', 'H21']",Nonlinear Tax Incidence and Optimal Taxation in General Equilibrium,0,0,0,0,0,2020,03,01
88,2,2020-03-01,"Consider an extensive-form mechanism, run by an auctioneer who communicates sequentially and privately with bidders. Suppose the auctioneer can deviate from the rules provided that no single bidder detects the deviation. A mechanism is credible if it is incentive-compatible for the auctioneer to follow the rules. We study the optimal auctions in which only winners pay, under symmetric independent private values. The first-price auction is the unique credible static mechanism. The ascending auction is the unique credible strategy-proof mechanism.","['Li, Shengwu', 'Akbarpour, Mohammad']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Credible Auctions: A Trilemma,0,0,1,0,0,2020,03,01
88,2,2020-03-01,"Weak contract enforcement may reduce the efficiency of production in developing countries. I study how contract enforcement affects efficiency in procurement auctions for the largest power projects in India. I gather data on bidding and ex post contract renegotiation and find that the renegotiation of contracts in response to cost shocks is widespread, despite that bidders are allowed to index their bids to future costs like the price of coal. To study heterogeneity in bidding strategies, I construct a new measure of firm connectedness, based on whether a firm has been awarded coal concessions by the Government. Connected firms choose to index less of the value of their bids to coal prices and, through this strategy, expose themselves to cost shocks to induce renegotiation. I use a structural model of bidding in a scoring auction to characterize equilibrium bidding when bidders are heterogeneous both in cost and in the payments they expect after renegotiation. The model estimates show that bidders offer power below cost due to the expected value of later renegotiation. The model is used to simulate bidding and efficiency with strict contract enforcement. Contract enforcement is found to be pro-competitive. With no renegotiation, equilibrium bids would rise to cover cost, but markups relative to total contract value fall sharply. Production costs decline, due to projects being allocated to lower-cost bidders over those who expect larger payments in renegotiation.","['Ryan, Nicholas']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Auctions', 'Economics of Contract: Theory', 'Transactional Relationships; Contracts and Reputation; Networks', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Industrialization; Manufacturing and Service Industries; Choice of Technology', 'Hydrocarbon Resources']","['D24', 'D44', 'D86', 'L14', 'O13', 'O14', 'Q35']",Contract Enforcement and Productive Efficiency: Evidence from the Bidding and Renegotiation of Power Contracts in India,1,0,1,0,0,2020,03,01
88,2,2020-03-01,"Most of the literature that studies frictional search-and-matching models with heterogeneous agents and random search investigates steady state equilibria. Steady state equilibrium requires, in particular, that the flows of agents into and out of the population of unmatched agents balance. We investigate the structure of this balance condition, taking agents' matching behavior as given. Building on the ""fundamental matching lemma"" for quadratic search technologies in Shimer and Smith (2000), we establish existence, uniqueness, and comparative statics properties of the solution to the balance condition for any search technology satisfying minimal regularity conditions. Implications for the existence and structure of steady state equilibria in the Shimer-Smith model and extensions thereof are noted. These reinforce the point that much of the structure of search-and-matching models with quadratic search technologies carries over to more general search technologies.","['Troger, Thomas', 'Lauermann, Stephan', 'Noldeke, Georg']","['Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'D83']",The Balance Condition in Search-and-Matching Models,0,0,0,0,0,2020,03,01
89,4,2021-07-01,"This paper presents a continuous-time model of sovereign debt. In it, a relatively impatient sovereign government's hidden type switches back and forth between a commitment type, which cannot default, and an opportunistic type, which can, and where we assume outside lenders have particular beliefs regarding how a commitment type should borrow for any given level of debt and bond price. In any Markov equilibrium, the opportunistic type mimics the commitment type when borrowing, revealing its type only by defaulting on its debt at random times. The equilibrium features a ""graduation date"": a finite amount of time since the last default, after which time reputation reaches its highest level and is unaffected by not defaulting. Before such date, not defaulting always increases the country's reputation. For countries that have recently defaulted, bond prices and the total amount of debt are increasing functions of the amount of time since the country's last default. For countries that have not recently defaulted (i.e., those that have graduated), bond prices are constant.","['Phelan, Christopher', 'Amador, Manuel']","['International Lending and Debt Problems', 'National Debt; Debt Management; Sovereign Debt']","['F34', 'H63']",Reputation and Sovereign Default,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"Asymptotic justification of the bootstrap often takes the form of weak convergence of the bootstrap distribution to some limit distribution. Theoretical literature recognized that the weak convergence does not imply consistency of the bootstrap second moment or the bootstrap variance as an estimator of the asymptotic variance, but such concern is not always reflected in the applied practice. We bridge the gap between the theory and practice by showing that such common bootstrap based standard error in fact leads to a potentially conservative inference.","['Liao, Zhipeng', 'Hahn, Jinyong']","['Statistical Simulation Methods: General', 'Specific Distributions; Specific Statistics']","['C15', 'C46']",Bootstrap Standard Error Estimates and Inference,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"Present bias is the inclination to prefer a smaller present reward to a larger later reward, but reversing this preference when both rewards are equally delayed. Such behavior violates stationarity of temporal choices, and hence exponential discounting. This paper provides a weakening of the stationarity axiom that can accommodate present-biased choice reversals. We call this new behavioral postulate Weak Present Bias and characterize the general class of utility functions that is consistent with it. We show that present-biased preferences can be represented as those of a decision maker who makes her choices according to conservative present-equivalents, in the face of uncertainty about future tastes.","['Chakraborty, Anujit']","['Consumer Economics: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making']","['D11', 'D15', 'D91']",Present Bias,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"A ruler who does not identify with a social group, whether on religious, ethnic, cultural, or socioeconomic grounds, is confronted with a trade-off between taking advantage of the out-group population's eagerness to maintain its identity and inducing it to ""comply"" (conversion, quitting, exodus, or any other way to accommodate the ruler's own identity). This paper first nests economists' extraction model, in which rulers are revenue-maximizers, within a more general identity-based model, in which rulers care also about inducing people to lose their identity, both in a static and an evolving environment. This paper then constructs novel data sources to test the implications of both models in the context of Egypt's conversion to Islam between 641 and 1170. The evidence supports the identity-based model.","['Tirole, Jean', 'Saleh, Mohamed']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Africa; Oceania', 'Economic History: Government, War, Law, International Relations, and Regulation: Africa; Oceania', 'Cultural Economics: Religion', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D72', 'J15', 'N37', 'N47', 'Z12', 'Z13']",Taxing Identity: Theory and Evidence from Early Islam,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"We estimate the distribution of television advertising elasticities and the distribution of the advertising return on investment (ROI) for a large number of products in many categories. Our results reveal substantially smaller advertising elasticities compared to the results documented in the literature, as well as a sizable percentage of statistically insignificant or negative estimates. The results are robust to functional form assumptions and are not driven by insufficient statistical power or measurement error. The ROI analysis shows negative ROIs at the margin for more than 80% of brands, implying over-investment in advertising by most firms. Further, the overall ROI of the observed advertising schedule is only positive for one third of all brands.","['Tuchman, Anna E.', 'Hitsch, Gunter J.', 'Shapiro, Bradley T.']","['Firm Behavior: Empirical Analysis', 'Firm Performance: Size, Diversification, and Scope', 'Entertainment; Media', 'Marketing', 'Advertising']","['D22', 'L25', 'L82', 'M31', 'M37']",TV Advertising Effectiveness and Profitability: Generalizable Results from 288 Brands,1,0,0,0,0,2021,07,01
89,4,2021-07-01,"We introduce a generalization of the popular local-to-unity model of time series persistence by allowing for p autoregressive (AR) roots and p - 1 moving average (MA) roots close to unity. This generalized local-to-unity model, GLTU(p), induces convergence of the suitably scaled time series to a continuous time Gaussian ARMA(p, p - 1) process on the unit interval. Our main theoretical result establishes the richness of this model class, in the sense that it can well approximate a large class of processes with stationary Gaussian limits that are not entirely distinct from the unit root benchmark. We show that Campbell and Yogo's (2006) popular inference method for predictive regressions fails to control size in the GLTU(2) model with empirically plausible parameter values, and we propose a limited-information Bayesian framework for inference in the GLTU(p) model and apply it to quantify the uncertainty about the half-life of deviations from purchasing power parity.","['Dou, Liyu', 'Muller, Ulrich K.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Generalized Local-to-Unity Models,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"Applied macroeconomists often compute confidence intervals for impulse responses using local projections, that is, direct linear regressions of future outcomes on current covariates. This paper proves that local projection inference robustly handles two issues that commonly arise in applications: highly persistent data and the estimation of impulse responses at long horizons. We consider local projections that control for lags of the variables in the regression. We show that lag-augmented local projections with normal critical values are asymptotically valid uniformly over (i) both stationary and non-stationary data, and also over (ii) a wide range of response horizons. Moreover, lag augmentation obviates the need to correct standard errors for serial correlation in the regression residuals. Hence, local projection inference is arguably both simpler than previously thought and more robust than standard autoregressive inference, whose validity is known to depend sensitively on the persistence of the data and on the length of the horizon.","['Montiel Olea, Jose Luis', 'Plagborg-Moller, Mikkel']",['Estimation: General'],['C13'],Local Projection Inference Is Simpler and More Robust Than You Think,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"We characterize the relationship between the distributions of two variables linked by a structural model. We then show that, in models of heterogeneous firms in monopolistic competition, this relationship implies a new demand function that we call ""CREMR"" (Constant Revenue Elasticity of Marginal Revenue). This demand function is the only one that is consistent with productivity and sales distributions having the same form (whether Pareto, lognormal, or Frechet) in the cross section, and it is necessary and sufficient for Gibrat's Law to hold over time. Among the applications we consider, we use our methodology to characterize misallocation across firms; we derive the distribution of markups implied by any assumptions on demand and productivity; and we show empirically that CREMR-based markup distributions provide an excellent parsimonious fit to Indian firm-level data, which in turn allows us to calculate the proportion of firms that are of suboptimal size in the market equilibrium.","['Neary, J. Peter', 'Mrazova, Monika', 'Parenti, Mathieu']","['Firm Behavior: Theory', 'Firm Behavior: Empirical Analysis', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Firm Performance: Size, Diversification, and Scope', 'Industrialization; Manufacturing and Service Industries; Choice of Technology']","['D21', 'D22', 'D24', 'L25', 'O14']",Sales and Markup Dispersion: Theory and Empirics,1,0,0,0,0,2021,07,01
89,4,2021-07-01,"We study the impact of manipulating the attention of a decision-maker who learns sequentially about a number of items before making a choice. Under natural assumptions on the decision-maker's strategy, directing attention toward one item increases its likelihood of being chosen regardless of its value. This result applies when the decision-maker can reject all items in favor of an outside option with known value; if no outside option is available, the direction of the effect of manipulation depends on the value of the item. A similar result applies to manipulation of choices in bandit problems.","['Gossner, Olivier', 'Stewart, Colin', 'Steiner, Jakub']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D83']",Attention Please!,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"We introduce a novel parametrization of the correlation matrix. The reparametrization facilitates modeling of correlation and covariance matrices by an unrestricted vector, where positive definiteness is an innate property. This parametrization can be viewed as a generalization of Fisher's Z-transformation to higher dimensions and has a wide range of potential applications. An algorithm for reconstructing the unique n x n correlation matrix from any vector in R^{n(n-1)/2} is provided, and we derive its numerical complexity.","['Archakov, Ilya', 'Hansen, Peter Reinhard']",['Miscellaneous Mathematical Tools'],['C65'],A New Parametrization of Correlation Matrices,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"Policymakers frequently use price regulations as a response to inequality in the markets they control. In this paper, we examine the optimal structure of such policies from the perspective of mechanism design. We study a buyer-seller market in which agents have private information about both their valuations for an indivisible object and their marginal utilities for money. The planner seeks a mechanism that maximizes agents' total utilities, subject to incentive and market-clearing constraints. We uncover the constrained Pareto frontier by identifying the optimal trade-off between allocative efficiency and redistribution. We find that competitive-equilibrium allocation is not always optimal. Instead, when there is inequality across sides of the market, the optimal design uses a tax-like mechanism, introducing a wedge between the buyer and seller prices, and redistributing the resulting surplus to the poorer side of the market via lump-sum payments. When there is significant same-side inequality that can be uncovered by market behavior, it may be optimal to impose price controls even though doing so induces rationing.","['Dworczak, Piotr', 'Akbarpour, Mohammad', 'Kominers, Scott Duke']","['Rationing; Licensing', 'Allocative Efficiency; Cost-Benefit Analysis', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies']","['D45', 'D61', 'D63', 'D83', 'H23']",Redistribution through Markets,0,0,1,0,0,2021,07,01
89,4,2021-07-01,"We study preferences estimated from finite choice experiments and provide sufficient conditions for convergence to a unique underlying ""true"" preference. Our conditions are weak and, therefore, valid in a wide range of economic environments. We develop applications to expected utility theory, choice over consumption bundles, and menu choice. Our framework unifies the revealed preference tradition with models that allow for errors.","['Echenique, Federico', 'Chambers, Christopher P.', 'Lambert, Nicolas S.']","['Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis', 'Micro-Based Behavioral Economics: General']","['D11', 'D12', 'D90']",Recovering Preferences from Finite Data,0,0,0,0,0,2021,07,01
89,4,2021-07-01,"We develop a model of international tariff negotiations to study the design of the institutional rules of the GATT/WTO. A key principle of the GATT/WTO is its most-favored-nation (MFN) requirement of nondiscrimination, a principle that has long been criticized for inviting free-riding behavior. We embed a multisector model of international trade into a model of interconnected bilateral negotiations over tariffs and assess the value of the MFN principle. Using 1990 trade flows and tariff outcomes from the Uruguay Round of GATT/WTO negotiations, we estimate the model and use it to simulate what would happen if the MFN requirement were abandoned and countries negotiated over discriminatory tariffs. We find that if tariff bargaining in the Uruguay Round had proceeded without the MFN requirement, it would have wiped out the world real income gains that MFN tariff bargaining in the Uruguay Round produced and would have instead led to a small reduction in world real income relative to the 1990 status quo.","['Bagwell, Kyle', 'Yurukoglu, Ali', 'Staiger, Robert W.']","['Trade Policy; International Trade Organizations', 'Empirical Studies of Trade', 'International Law']","['F13', 'F14', 'K33']",Quantitative Analysis of Multiparty Tariff Negotiations,0,1,0,0,0,2021,07,01
89,4,2021-07-01,"We characterize the set of extreme points of monotonic functions that are either majorized by a given function f or themselves majorize f and show that these extreme points play a crucial role in many economic design problems. Our main results show that each extreme point is uniquely characterized by a countable collection of intervals. Outside these intervals the extreme point equals the original function f and inside the function is constant. Further consistency conditions need to be satisfied pinning down the value of an extreme point in each interval where it is constant. We apply these insights to a varied set of economic problems: equivalence and optimality of mechanisms for auctions and (matching) contests, Bayesian persuasion, optimal delegation, and decision making under uncertainty.","['Kleiner, Andreas', 'Strack, Philipp', 'Moldovanu, Benny']","['Bargaining Theory; Matching Theory', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D44', 'D81', 'D82']",Extreme Points and Majorization: Economic Applications,0,0,1,0,0,2021,07,01
89,4,2021-07-01,"This paper reconciles the asymptotic disagreement between Bayesian and frequentist inference in set-identified models by adopting a multiple-prior (robust) Bayesian approach. We propose new tools for Bayesian inference in set-identified models and show that they have a well-defined posterior interpretation in finite samples and are asymptotically valid from the frequentist perspective. The main idea is to construct a prior class that removes the source of the disagreement: the need to specify an unrevisable prior for the structural parameter given the reduced-form parameter. The corresponding class of posteriors can be summarized by reporting the 'posterior lower and upper probabilities' of a given event and/or the 'set of posterior means' and the associated 'robust credible region'. We show that the set of posterior means is a consistent estimator of the true identified set and the robust credible region has the correct frequentist asymptotic coverage for the true identified set if it is convex. Otherwise, the method provides posterior inference about the convex hull of the identified set. For impulse-response analysis in set-identified Structural Vector Autoregressions, the new tools can be used to overcome or quantify the sensitivity of standard Bayesian inference to the choice of an unrevisable prior.","['Giacomini, Raffaella', 'Kitagawa, Toru']","['Bayesian Analysis: General', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C11', 'C32']",Robust Bayesian Inference for Set-Identified Models,0,0,0,0,0,2021,07,01
89,3,2021-05-01,"This paper studies asset pricing and labor market dynamics when idiosyncratic risk to human capital is not fully insurable. Firms use long-term contracts to provide insurance to workers, but neither side can fully commit; furthermore, owing to costly and unobservable retention effort, worker-firm relationships have endogenous durations. Uninsured tail risk in labor earnings arises as a part of an optimal risk-sharing scheme. In equilibrium, exposure to the tail risk generates higher aggregate risk premia and higher return volatility. Consistent with data, firm-level labor share predicts both future returns and pass-throughs of firm-level shocks to labor compensation.","['Ai, Hengjie', 'Bhandari, Anmol']","['Firm Behavior: Theory', 'Factor Income Distribution', 'Equities; Fixed Income Securities', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['D21', 'D33', 'G12', 'J24', 'J31']",Asset Pricing with Endogenously Uninsurable Tail Risk,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"What should researchers do when their baseline model is falsified? We recommend reporting the set of parameters that are consistent with minimally nonfalsified models. We call this the falsification adaptive set (FAS). This set generalizes the standard baseline estimand to account for possible falsification. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. In the classical linear IV model with multiple instruments, we show that the FAS has a simple closed-form expression that only depends on a few 2SLS coefficients. We apply our results to an empirical study of roads and trade. We show how the FAS complements traditional overidentification tests by summarizing the variation in estimates obtained from alternative nonfalsified models.","['Poirier, Alexandre', 'Masten, Matthew A.']",['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation'],['C26'],Salvaging Falsified Instrumental Variable Models,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"This paper develops inference methods for the iterated overidentified Generalized Method of Moments (GMM) estimator. We provide conditions for the existence of the iterated estimator and an asymptotic distribution theory, which allows for mild misspecification. Moment misspecification causes bias in conventional GMM variance estimators, which can lead to severely oversized hypothesis tests. We show how to consistently estimate the correct asymptotic variance matrix. Our simulation results show that our methods are properly sized under both correct specification and mild to moderate misspecification. We illustrate the method with an application to the model of Acemoglu, Johnson, Robinson, and Yared (2008).","['Hansen, Bruce E.', 'Lee, Seojeong']","['Estimation: General', 'Model Construction and Estimation', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Macroeconomics: Production', 'Institutions and Growth']","['C13', 'C51', 'D72', 'E23', 'O43']",Inference for Iterated GMM under Misspecification,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"How much capital should financial intermediaries hold? We propose a general equilibrium model with a financial sector that makes risky long-term loans to firms, funded by deposits from savers. Government guarantees create a role for bank capital regulation. The model captures the sharp and persistent drop in macro-economic aggregates and credit provision as well as the sharp change in credit spreads observed during financial crises. Policies requiring intermediaries to hold more capital reduce financial fragility, reduce the size of the financial and non-financial sectors, and lower intermediary profits. They redistribute wealth from savers to the owners of banks and non-financial firms. Pre-crisis capital requirements are close to optimal. Counter-cyclical capital requirements increase welfare.","['Elenev, Vadim', 'Van Nieuwerburgh, Stijn', 'Landvoigt, Tim']","['Firm Behavior: Theory', 'Business Fluctuations; Cycles', 'Financial Crises', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financial Institutions and Services: Government Policy and Regulation', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['D21', 'E32', 'G01', 'G21', 'G28', 'G32']",A Macroeconomic Model with Financially Constrained Producers and Intermediaries,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"A profit-maximizing seller has a single unit of a good to sell. The bidders have a pure common value that is drawn from a distribution that is commonly known. The seller does not know the bidders' beliefs about the value and thinks that beliefs are designed adversarially by Nature to minimize profit. We construct a strong maxmin solution to this joint mechanism design and information design problem, consisting of a mechanism, an information structure, and an equilibrium, such that neither the seller nor Nature can move profit in their respective preferred directions, even if the deviator can select the new equilibrium. The mechanism and information structure solve a family of maxmin mechanism design and minmax information design problems, regardless of how an equilibrium is selected. The maxmin mechanism takes the form of a proportional auction: each bidder submits a one-dimensional bid, the aggregate allocation and aggregate payment depend on the aggregate bid, and individual allocations and payments are proportional to bids. We report a number of additional properties of the maxmin mechanisms, including what happens as the number of bidders grows large and robustness with respect to the prior over the value.","['Brooks, Benjamin', 'Du, Songzi']","['Auctions', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D82', 'D83']",Optimal Auction Design with Common Values: An Informationally Robust Approach,0,0,1,0,0,2021,05,01
89,3,2021-05-01,"A finite number of vertically differentiated firms simultaneously compete for and screen agents with private information about their payoffs. In equilibrium, higher firms serve higher types. Each firm distorts the allocation downward from the efficient level on types below a threshold, but upward above. While payoffs in this game are neither quasi-concave nor continuous, if firms are sufficiently differentiated, then any strategy profile that satisfies a simple set of necessary conditions is a pure-strategy equilibrium, and an equilibrium exists. A mixed-strategy equilibrium exists even when firms are less differentiated. The welfare effects of private information are drastically different than under monopoly. The equilibrium approaches the competitive limit quickly as entry costs grow small. We solve the problem of a multi-plant firm facing a type-dependent outside option and use this to study the effect of mergers.","['Swinkels, Jeroen', 'Chade, Hector']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Monopoly', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Asymmetric and Private Information; Mechanism Design', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance']","['D21', 'D42', 'D43', 'D82', 'G34']",Screening in Vertical Oligopolies,0,0,1,0,1,2021,05,01
89,3,2021-05-01,How does an economy's capital respond to aggregate productivity shocks when firms make lumpy investments? We show that capital's transitional dynamics are structurally linked to two steady-state moments: the dispersion of capital to productivity ratios--an indicator of capital misallocation--and the covariance of capital to productivity ratios with the time elapsed since their last adjustment--an indicator of asymmetric costs of upsizing and downsizing the capital stock. We compute these two sufficient statistics using data on the size and frequency of investment of Chilean plants. The empirical values indicate significant effects of aggregate productivity shocks and favor investment models with a strong downsizing rigidity and random opportunities for free adjustments.,"['Blanco, Andres', 'Baley, Isaac']","['Firm Behavior: Empirical Analysis', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Investment; Capital; Intangible Capital; Capacity', 'Macroeconomics: Production', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['D22', 'D24', 'E22', 'E23', 'G31', 'O16']",Aggregate Dynamics in Lumpy Economies,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"We reconsider the microeconomic foundations of financial economics. Motivated by the importance of Knightian uncertainty in markets, we present a model that does not carry any probabilistic structure ex ante, yet is based on a common order. We derive the fundamental equivalence of economic viability of asset prices and absence of arbitrage. We also obtain a modified version of the fundamental theorem of asset pricing using the notion of sublinear pricing measures. Different versions of the efficient market hypothesis are related to the assumptions one is willing to impose on the common order.","['Riedel, Frank', 'Soner, H. Mete', 'Burzoni, Matteo']","['Criteria for Decision-Making under Risk and Uncertainty', 'Equities; Fixed Income Securities']","['D81', 'G12']",Viability and Arbitrage under Knightian Uncertainty,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"In response to a change, individuals may choose to follow the responses of their friends or, alternatively, to change their friends. To model these decisions, consider a game where players choose their behaviors and friendships. In equilibrium, players internalize the need for consensus in forming friendships and choose their optimal strategies on subsets of k players--a form of bounded rationality. The k-player consensual dynamic delivers a probabilistic ranking of a game's equilibria, and via a varying k, facilitates estimation of such games. Applying the model to adolescents' smoking suggests that: (a) the response of the friendship network to changes in tobacco price amplifies the intended effect of price changes on smoking, (b) racial desegregation of high schools decreases the overall smoking prevalence, (c) peer effect complementarities are substantially stronger between smokers compared to between nonsmokers.","['Badev, Anton']","['Noncooperative Games', 'Consumer Economics: Theory', 'Analysis of Education', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Food; Beverages; Cosmetics; Tobacco; Wine and Spirits', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['C72', 'D11', 'I21', 'J13', 'J15', 'L66', 'Z13']",Nash Equilibria on (Un)stable Networks,1,0,0,0,0,2021,05,01
89,3,2021-05-01,"We consider estimation and inference on average treatment effects under unconfoundedness conditional on the realizations of the treatment variable and covariates. Given nonparametric smoothness and/or shape restrictions on the conditional mean of the outcome variable, we derive estimators and confidence intervals (CIs) that are optimal in finite samples when the regression errors are normal with known variance. In contrast to conventional CIs, our CIs use a larger critical value that explicitly takes into account the potential bias of the estimator. When the error distribution is unknown, feasible versions of our CIs are valid asymptotically, even when the square root of n-inference is not possible due to lack of overlap, or low smoothness of the conditional mean. We also derive the minimum smoothness conditions on the conditional mean that are necessary for the square root of n-inference. When the conditional mean is restricted to be Lipschitz with a large enough bound on the Lipschitz constant, the optimal estimator reduces to a matching estimator with the number of matches set to one. We illustrate our methods in an application to the National Supported Work Demonstration.","['Kolesar, Michal', 'Armstrong, Timothy B.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Model Construction and Estimation', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Mobility, Unemployment, and Vacancies: Public Policy']","['C21', 'C51', 'I38', 'J68']",Finite-Sample Optimal Estimation and Inference on Average Treatment Effects under Unconfoundedness,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"We characterize optimal asset management contracts in a classic portfolio-investment setting. When the agent has access to hidden savings, his incentives to misbehave depend on his precautionary saving motive. The contract dynamically distorts the agent's access to capital to manipulate his precautionary saving motive and reduce incentives for misbehavior. We provide a sufficient condition for the validity of the first-order approach, which holds in the optimal contract: global incentive compatibility is ensured if the agent's precautionary saving motive weakens after bad outcomes. We extend our results to incorporate market risk, hidden investment, and renegotiation.","['Sannikov, Yuliy', 'Di Tella, Sebastian']","['Economics of Contract: Theory', 'Portfolio Choice; Investment Decisions', 'Behavioral Finance: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making in Financial Markets', 'Household Saving, Borrowing, Debt, and Wealth']","['D86', 'G11', 'G41', 'G51']",Optimal Asset Management Contracts with Hidden Savings,0,0,0,0,0,2021,05,01
89,3,2021-05-01,"We study how an agent learns from endogenous data when their prior belief is misspecified. We show that only uniform Berk-Nash equilibria can be long-run outcomes, and that all uniformly strict Berk-Nash equilibria have an arbitrarily high probability of being the long-run outcome for some initial beliefs. When the agent believes the outcome distribution is exogenous, every uniformly strict Berk-Nash equilibrium has positive probability of being the long-run outcome for any initial belief. We generalize these results to settings where the agent observes a signal before acting.","['Lanzani, Giacomo', 'Fudenberg, Drew', 'Strack, Philipp']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D82', 'D83']",Limit Points of Endogenous Misspecified Learning,0,0,0,0,0,2021,05,01
89,3,2021-05-01,ECONLIT None Found,"['Philippon, Thomas']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'General Equilibrium and Disequilibrium: General', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Aggregate Factor Income Distribution', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Antitrust Law']","['D21', 'D43', 'D50', 'E24', 'E25', 'G32', 'K21']",A Comment on: 'General Equilibrium Oligopoly and Ownership Structure' by Jose Azar and Xavier Vives,0,1,1,0,0,2021,05,01
89,3,2021-05-01,ECONLIT None Found,"['Eeckhout, Jan']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'General Equilibrium and Disequilibrium: General', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Aggregate Factor Income Distribution', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Antitrust Law']","['D21', 'D43', 'D50', 'E24', 'E25', 'G32', 'K21']",A Comment on: 'General Equilibrium Oligopoly and Ownership Structure' by Jose Azar and Xavier Vives,0,1,1,0,0,2021,05,01
89,3,2021-05-01,"We develop a tractable general equilibrium framework in which firms are large and have market power with respect to both products and labor, and in which a firm's decisions are affected by its ownership structure. We characterize the Cournot-Walras equilibrium of an economy where each firm maximizes a share-weighted average of shareholder utilities--rendering the equilibrium independent of price normalization. In a one-sector economy, if returns to scale are non-increasing, then an increase in ""effective"" market concentration (which accounts for common ownership) leads to declines in employment, real wages, and the labor share. Yet when there are multiple sectors, due to an intersectoral pecuniary externality, an increase in common ownership could stimulate the economy when the elasticity of labor supply is high relative to the elasticity of substitution in product markets. We characterize for which ownership structures the monopolistically competitive limit or an oligopolistic one is attained as the number of sectors in the economy increases. When firms have heterogeneous constant returns to scale technologies, we find that an increase in common ownership leads to markets that are more concentrated.","['Vives, Xavier', 'Azar, Jose']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'General Equilibrium and Disequilibrium: General', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Aggregate Factor Income Distribution', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Antitrust Law']","['D21', 'D43', 'D50', 'E24', 'E25', 'G32', 'K21']",General Equilibrium Oligopoly and Ownership Structure,0,1,1,0,0,2021,05,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2018–2019.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2018–2019.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,"Two main classes of channels are studied as informational sources of financial contagion. One is a fundamental channel that is based on real and financial links between economies, and the second is a social learning channel that arises when agents base their decisions on noisy observations about the actions of others in foreign markets. Using global games, I present a two-country model of financial contagion in which both channels can operate and I test its predictions experimentally. The experimental results show that subjects do not extract information optimally, which leads to two systematic biases that affect these channels directly. Base-rate neglect leads subjects to underweight their prior, and thus weakens the fundamental channel. An overreaction bias strengthens the social learning channel, since subjects rely on information about the behavior of others, even when this information is irrelevant. These results have significant welfare effects rooted in the specific way in which these biases alter behavior.","['Trevino, Isabel']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Macroeconomics: Production', 'Financial Markets and the Macroeconomy', 'International Business Cycles']","['D83', 'E23', 'E44', 'F44']",Informational Channels of Financial Contagion,0,0,0,0,0,2020,01,01
88,1,2020-01-01,"Consider a researcher estimating the parameters of a regression function based on data for all 50 states in the United States or on data for all visits to a website. What is the interpretation of the estimated parameters and the standard errors? In practice, researchers typically assume that the sample is randomly drawn from a large population of interest and report standard errors that are designed to capture sampling variation. This is common even in applications where it is difficult to articulate what that population of interest is, and how it differs from the sample. In this article, we explore an alternative approach to inference, which is partly design-based. In a design-based setting, the values of some of the regressors can be manipulated, perhaps through a policy intervention. Design-based uncertainty emanates from lack of knowledge about the values that the regression outcome would have taken under alternative interventions. We derive standard errors that account for design-based uncertainty instead of, or in addition to, sampling-based uncertainty. We show that our standard errors in general are smaller than the usual infinite-population sampling-based standard errors and provide conditions under which they coincide.","['Wooldridge, Jeffrey M.', 'Athey, Susan', 'Abadie, Alberto', 'Imbens, Guido W.']","['Model Construction and Estimation', 'Survey Methods; Sampling Methods']","['C51', 'C83']",Sampling-Based versus Design-Based Uncertainty in Regression Analysis,0,0,0,0,0,2020,01,01
88,1,2020-01-01,"This paper examines the prices of basic staples in rural Mexico. We document that nonlinear pricing in the form of quantity discounts is common, that quantity discounts are sizable for basic staples, and that the well-known conditional cash transfer program Progresa has significantly increased quantity discounts, although the program, as documented in previous studies, has not affected unit prices on average. To account for these patterns, we propose a model of price discrimination that nests those of Maskin and Riley (1984) and Jullien (2000), in which consumers differ in their tastes and, because of subsistence constraints, in their ability to pay for a good. We show that under mild conditions, a model in which consumers face heterogeneous subsistence or budget constraints is equivalent to one in which consumers have access to heterogeneous outside options. We rely on known results to characterize the equilibrium price schedule, which is nonlinear in quantity. We analyze the effect of nonlinear pricing on market participation as well as the impact of a market-wide transfer, analogous to the Progresa one, when consumers are differentially constrained. We show that the model is structurally identified from data on prices and quantities from a single market under common assumptions. We estimate the model using data on three commonly consumed commodities from municipalities and localities in Mexico. Interestingly, we find that relative to linear pricing, nonlinear pricing is beneficial to a large number of households, including those consuming small quantities, mostly because of the higher degree of market participation that nonlinear pricing induces. We also show that the Progresa transfer has affected the slopes of the price schedules of the three commodities we study, which have become steeper as consistent with our model, leading to an increase in the intensity of price discrimination. Finally, we find that a reduced form of our model, in which the size of quantity discounts depends on the hazard rate of the distribution of quantities purchased in a village, accounts for the shift in price schedules induced by the program.","['Attanasio, Orazio', 'Pastorino, Elena']","['Consumer Economics: Empirical Analysis', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Agriculture: Aggregate Supply and Demand Analysis; Prices']","['D12', 'I38', 'L11', 'O12', 'O13', 'Q11']",Nonlinear Pricing in Village Economies,1,0,0,0,0,2020,01,01
88,1,2020-01-01,"This paper considers the problem of forecasting a collection of short time series using cross-sectional information in panel data. We construct point predictors using Tweedie's formula for the posterior mean of heterogeneous coefficients under a correlated random effects distribution. This formula utilizes cross-sectional information to transform the unit-specific (quasi) maximum likelihood estimator into an approximation of the posterior mean under a prior distribution that equals the population distribution of the random coefficients. We show that the risk of a predictor based on a nonparametric kernel estimate of the Tweedie correction is asymptotically equivalent to the risk of a predictor that treats the correlated random effects distribution as known (ratio optimality). Our empirical Bayes predictor performs well compared to various competitors in a Monte Carlo study. In an empirical application, we use the predictor to forecast revenues for a large panel of bank holding companies and compare forecasts that condition on actual and severely adverse macroeconomic conditions.","['Liu, Laura', 'Schorfheide, Frank', 'Moon, Hyungsik Roger']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Forecasting Models; Simulation Methods', 'Business Fluctuations; Cycles', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Firm Performance: Size, Diversification, and Scope']","['C23', 'C53', 'E32', 'G21', 'L25']",Forecasting with Dynamic Panel Data Models,1,0,0,0,0,2020,01,01
88,1,2020-01-01,"We provide a systematic analysis of the properties of individual returns to wealth using 12 years of population data from Norway's administrative tax records. We document a number of novel results. First, individuals earn markedly different average returns on their net worth (a standard deviation of 22.1 percent) and on its components. Second, heterogeneity in returns does not arise merely from differences in the allocation of wealth between safe and risky assets: returns are heterogeneous even within narrow asset classes. Third, returns are positively correlated with wealth: moving from the 10th to the 90th percentile of the net worth distribution increases the return by 18 percentage points (and 10 percentage points if looking at net-of-tax returns). Fourth, individual wealth returns exhibit substantial persistence over time. We argue that while this persistence partly arises from stable differences in risk exposure and assets scale, it also reflects heterogeneity in sophistication and financial information, as well as entrepreneurial talent. Finally, wealth returns are correlated across generations. We discuss the implications of these findings for several strands of the wealth inequality debate.","['Fagereng, Andreas', 'Guiso, Luigi', 'Malacrino, Davide', 'Pistaferri, Luigi']","['Personal Income, Wealth, and Their Distributions', 'Household Saving, Borrowing, Debt, and Wealth', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['D31', 'G51', 'H24']",Heterogeneity and Persistence in Returns to Wealth,0,0,0,0,0,2020,01,01
88,1,2020-01-01,"We provide a tractable, quantitatively-oriented theory of innovation and technology diffusion to explore the role of international trade in the process of development. We model innovation and diffusion as a process involving the combination of new ideas with insights from other industries or countries. We provide conditions under which each country's equilibrium frontier of knowledge converges to a Frechet distribution, and derive a system of differential equations describing the evolution of the scale parameters of these distributions, that is, countries' stocks of knowledge. The model remains tractable with many asymmetric countries and generates a rich set of predictions about how the level and composition of trade affect countries' frontiers of knowledge. We use the framework to quantify the contribution of bilateral trade costs to long-run changes in TFP and individual post-war growth miracles. For our preferred calibration, we find that both gains from trade and the fraction of variation of TFP growth accounted for by changes in trade more than double relative to a model without diffusion.","['Buera, Francisco J.', 'Oberfield, Ezra']","['Neoclassical Models of Trade', 'International Linkages to Development; Role of International Organizations', 'Innovation and Invention: Processes and Incentives', 'Technological Change: Choices and Consequences; Diffusion Processes']","['F11', 'O19', 'O31', 'O33']",The Global Diffusion of Ideas,0,0,0,1,0,2020,01,01
88,1,2020-01-01,"We develop a tractable model of endogenous production networks. Each one of a number of products can be produced by combining labor and an endogenous subset of the other products as inputs. Different combinations of inputs generate (prespecified) levels of productivity and various distortions may affect costs and prices. We establish the existence and uniqueness of an equilibrium and provide comparative static results on how prices and endogenous technology/input choices (and thus the production network) respond to changes in parameters. These results show that improvements in technology (or reductions in distortions) spread throughout the economy via input-output linkages and reduce all prices, and under reasonable restrictions on the menu of production technologies, also lead to a denser production network. Using a dynamic version of the model, we establish that the endogenous evolution of the production network could be a powerful force towards sustained economic growth. At the root of this result is the fact that the arrival of a few new products expands the set of technological possibilities of all existing industries by a large amount--that is, if there are n products, the arrival of one more new product increases the combinations of inputs that each existing product can use from 2^{n-1} to 2^{n}, thus enabling significantly more pronounced cost reductions from choice of input combinations. These cost reductions then spread to other industries via lower input prices and incentivize them to also adopt additional inputs.","['Acemoglu, Daron', 'Azar, Pablo D.']","['Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Network Formation and Analysis: Theory', 'Organization of Production', 'Production Management']","['D21', 'D24', 'D85', 'L23', 'M11']",Endogenous Production Networks,1,0,0,0,0,2020,01,01
88,1,2020-01-01,"We theoretically and empirically study an incomplete information model of social learning. Agents initially guess the binary state of the world after observing a private signal. In subsequent rounds, agents observe their network neighbors' previous guesses before guessing again. Agents are drawn from a mixture of learning types--Bayesian, who face incomplete information about others' types, and DeGroot, who average their neighbors' previous period guesses and follow the majority. We study (1) learning features of both types of agents in our incomplete information model; (2) what network structures lead to failures of asymptotic learning; (3) whether realistic networks exhibit such structures. We conducted lab experiments with 665 subjects in Indian villages and 350 students from ITAM in Mexico. We perform a reduced-form analysis and then structurally estimate the mixing parameter, finding the share of Bayesian agents to be 10 percent and 50 percent in the Indian-villager and Mexican-student samples, respectively.","['Larreguy, Horacio', 'Xandri, Juan Pablo', 'Chandrasekhar, Arun G.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration']","['D83', 'O15']",Testing Models of Social Learning on Networks: Evidence from Two Experiments,0,0,0,0,0,2020,01,01
87,6,2019-11-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society 2018 Annual Report of the President.,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"We revisit prominent learning models in which a sequence of agents make a binary decision on the basis of both a private signal and information related to past choices. We analyze the efficiency of learning in these models, measured in terms of the expected welfare. We show that, irrespective of the distribution of private signals, learning efficiency is the same whether each agent observes the entire sequence of earlier decisions or only the previous decision. In addition, we provide a simple condition on the signal distributions that is necessary and sufficient for learning efficiency. This condition fails to hold in many cases of interest. We discuss a number of extensions and variants.","['Rosenberg, Dinah', 'Vieille, Nicolas']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",On the Efficiency of Social Learning,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"I develop a search-and-bargaining model of endogenous intermediation in over-the-counter markets. Unlike the existing work, my model allows for rich investor heterogeneity in three simultaneous dimensions: preferences, inventories, and meeting rates. By comparing trading-volume patterns that arise in my model and are observed in practice, I argue that the heterogeneity in meeting rates is the main driver of intermediation patterns. I find that investors with higher meeting rates (i.e., fast investors) are less averse to holding inventories and more attracted to cash earnings, which makes the model corroborate a number of stylized facts that do not emerge from existing models: (i) fast investors provide intermediation by charging a speed premium , and (ii) fast investors hold more extreme inventories. Then, I use the model to study the effect of trading frictions on the supply and price of liquidity. On social welfare, I show that the interaction of meeting rate heterogeneity with optimal inventory management makes the equilibrium inefficient. I provide a financial transaction tax/subsidy scheme that corrects this inefficiency, in which fast investors cross-subsidize slow investors.","['Uslu, Semih']","['Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Equities; Fixed Income Securities', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['C78', 'D83', 'G11', 'G12', 'G31']",Pricing and Liquidity in Decentralized Asset Markets,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"How should a society choose between two social alternatives if participation in the decision process is voluntary and costly, and monetary transfers are not feasible? Assuming symmetric independent private values, we show that it is utilitarian-optimal to use a linear voting rule: votes get alternative-dependent weights, and a default obtains if the weighted sum of votes stays below some threshold. Any combination of weights and threshold can be optimal. A standard quorum rule can be optimal only when it yields the same outcome as a linear rule. A linear rule is called upper linear if the default is upset at every election result that meets the threshold exactly. We develop a perturbation method to characterize equilibria of voting rules in the case of small participation costs and show that leaving participation voluntary increases welfare for any two-sided upper linear rule that is optimal under compulsory participation.","['Troger, Thomas', 'Gruner, Hans Peter']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Linear Voting Rules,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"We define and investigate a property of mechanisms that we call ""strategic simplicity,"" and that is meant to capture the idea that, in strategically simple mechanisms, strategic choices require limited strategic sophistication. We define a mechanism to be strategically simple if choices can be based on first-order beliefs about the other agents' preferences and first-order certainty about the other agents' rationality alone, and there is no need for agents to form higher-order beliefs, because such beliefs are irrelevant to the optimal strategies. All dominant strategy mechanisms are strategically simple. But many more mechanisms are strategically simple. In particular, strategically simple mechanisms may be more flexible than dominant strategy mechanisms in the bilateral trade problem and the voting problem.","['Borgers, Tilman', 'Li, Jiangtao']","['Consumer Economics: Theory', 'Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D71', 'D82', 'D83']",Strategically Simple Mechanisms,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"We provide an axiomatic analysis of dynamic random utility, characterizing the stochastic choice behavior of agents who solve dynamic decision problems by maximizing some stochastic process (U_{t}) of utilities. We show first that even when (U_{t}) is arbitrary, dynamic random utility imposes new testable across-period restrictions on behavior, over and above period-by-period analogs of the static random utility axioms. An important feature of dynamic random utility is that behavior may appear history-dependent , because period-t choices reveal information about U_{t}, which may be serially correlated; however, our key new axioms highlight that the model entails specific limits on the form of history dependence that can arise. Second, we show that imposing natural Bayesian rationality axioms restricts the form of randomness that (U_{t}) can display. By contrast, a specification of utility shocks that is widely used in empirical work violates these restrictions, leading to behavior that may display a negative option value and can produce biased parameter estimates. Finally, dynamic stochastic choice data allow us to characterize important special cases of random utility--in particular, learning and taste persistence--that on static domains are indistinguishable from the general model.","['Iijima, Ryota', 'Frick, Mira', 'Strzalecki, Tomasz']","['Household Behavior: General', 'Consumer Economics: Theory']","['D10', 'D11']",Dynamic Random Utility,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"This paper develops a dynamic model of rational behavior under uncertainty, in which the agent maximizes the stream of future tau-quantile utilities, for tau belongs to (0,1). That is, the agent has a quantile utility preference instead of the standard expected utility. Quantile preferences have useful advantages, including the ability to capture heterogeneity and allowing the separation between risk aversion and elasticity of intertemporal substitution. Although quantiles do not share some of the helpful properties of expectations, such as linearity and the law of iterated expectations, we are able to establish all the standard results in dynamic models. Namely, we show that the quantile preferences are dynamically consistent, the corresponding dynamic problem yields a value function, via a fixed point argument, this value function is concave and differentiable, and the principle of optimality holds. Additionally, we derive the corresponding Euler equation, which is well suited for using well-known quantile regression methods for estimating and testing the economic model. In this way, the parameters of the model can be interpreted as structural objects. Therefore, the proposed methods provide microeconomic foundations for quantile regression methods. To illustrate the developments, we construct an intertemporal consumption model and estimate the discount factor and elasticity of intertemporal substitution parameters across the quantiles. The results provide evidence of heterogeneity in these parameters.","['de Castro, Luciano', 'Galvao, Antonio F.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Criteria for Decision-Making under Risk and Uncertainty']","['C22', 'C51', 'D12', 'D15', 'D81']",Dynamic Quantile Models of Rational Behavior,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"A receiver wants to learn multidimensional information from a sender, and she has the capacity to verify just one dimension. The sender's payoff depends on the belief he induces, via an exogenously given monotone function. We show that by using a randomized verification strategy, the receiver can learn the sender's information fully in many cases. We characterize exactly when it is possible to do so. In particular, when the exogenous payoff function is submodular, we can explicitly describe a full-learning mechanism; when it is (strictly) supermodular, full learning is not possible. In leading cases where full learning is possible, it can be attained using an indirect mechanism in which the sender chooses the probability of verifying each dimension.","['Egorov, Georgy', 'Carroll, Gabriel']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Strategic Communication with Minimal Verification,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"This paper shows that bargainers may reach delayed agreements even in environments where there is no uncertainty about payoffs or feasible actions. Under such conditions, delay may arise when bargainers face direct forms of strategic uncertainty--that is, uncertainty about the opponent's play. The paper restricts the nature of this uncertainty in two important ways. First, it assumes on-path strategic certainty: Bargainers face uncertainty only after surprise moves. Second, it assumes Battigalli and Siniscalchi's (2002) rationality and common strong belief of rationality (RCSBR)--a requirement that bargainers are ""strategically sophisticated."" The main result characterizes the set of outcomes consistent with on-path strategic certainty and RCSBR. It shows that these assumptions allow for delayed agreement, despite the fact that the bargaining environment is one of complete information. The source of delay is second-order optimism: Bargainers do not put forward ""good"" offers early in the negotiation process because they fear that doing so will cause the other party to become more optimistic about her future prospects.","['Friedenberg, Amanda']","['Bargaining Theory; Matching Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['C78', 'D81']",Bargaining under Strategic Uncertainty: The Role of Second-Order Optimism,0,0,0,0,0,2019,11,01
87,6,2019-11-01,"Making inferences about aggregate business cycles from regional variation alone is difficult because of economic channels and shocks that differ between regional and aggregate economies. However, we argue that regional business cycles contain valuable information that can help discipline models of aggregate fluctuations. We begin by documenting a strong relationship across U.S. states between local employment and wage growth during the Great Recession. This relationship is much weaker in U.S. aggregates. Then, we present a methodology that combines such regional and aggregate data in order to estimate a medium-scale New Keynesian DSGE model. We find that aggregate demand shocks were important drivers of aggregate employment during the Great Recession, but the wage stickiness necessary for them to account for the slow employment recovery and the modest fall in aggregate wages is inconsistent with the flexibility of wages we observe across U.S. states. Finally, we show that our methodology yields different conclusions about the causes of aggregate employment and wage dynamics between 2007 and 2014 than either estimating our model with aggregate data alone or performing back-of-the-envelope calculations that directly extrapolate from well-identified regional elasticities.","['Hurst, Erik', 'Beraja, Martin', 'Ospina, Juan']","['General Aggregative Models: Keynes; Keynesian; Post-Keynesian; Modern Monetary Theory', 'Macroeconomics: Production', 'Business Fluctuations; Cycles', 'Regional Economic Activity: Growth, Development, Environmental Issues, and Changes']","['E12', 'E23', 'E32', 'R11']",The Aggregate Implications of Regional Business Cycles,0,0,0,0,0,2019,11,01
87,5,2019-09-01,ECONLIT None Found,"['Chen, Songnian', 'Tang, Xun', 'Khan, Shakeeb']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Exclusion Restrictions in Dynamic Binary Choice Panel Data Models: Comment on 'Semiparametric Binary Choice Panel Data Models without Strictly Exogenous Regressors',0,0,0,0,0,2019,09,01
87,5,2019-09-01,"Harsanyi (1974) and Ray and Vohra (2015) extended the stable set of von Neumann and Morgenstern to impose farsighted credibility on coalitional deviations. But the resulting farsighted stable set suffers from a conceptual drawback: while coalitional moves improve on existing outcomes, coalitions might do even better by moving elsewhere. Or other coalitions might intervene to impose their favored moves. We show that every farsighted stable set satisfying some reasonable and easily verifiable properties is unaffected by the imposition of these stringent maximality constraints. The properties we describe are satisfied by many, but not all, farsighted stable sets.","['Ray, Debraj', 'Vohra, Rajiv']",['Game Theory and Bargaining Theory: General'],['C70'],Maximality in the Farsighted Stable Set,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"We analyze financial markets in which agents face differential constraints on the set of assets in which they can trade. In particular, the assets available to each agent span a partition of the state space that can be strictly coarser than the partition spanned by the assets available in the market. We first show that the existence of differential constraints has an impact on prices and allocations as compared to a complete financial market with unconstrained agents. We consider the implications for survival, taking the work of Blume and Easley (2006) as a starting point. We show that whenever agents have identical correct beliefs and equal discount factors, and their partitions are nested, all agents survive. When agents have heterogeneous beliefs, differential constraints may allow agents with wrong beliefs to survive. Provided constraints are relevant (in a sense we define more precisely), the condition for an agent to survive is that his survival index is at least as large as that of the agents with finer partitions. We also study the impact of deregulation (an increase in the set of assets available to some agents). Unless the agent can adopt beliefs that are closer to the truth on the newly refined partition than those of less constrained agents, increasing his opportunities for trade might harm his chances for survival.","['Guerdjikova, Ani', 'Quiggin, John']","['Equities; Fixed Income Securities', 'Information and Market Efficiency; Event Studies; Insider Trading']","['G12', 'G14']",Market Selection with Differential Financial Constraints,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"We propose a new solution for discrete exchange economies and resource-allocation problems, the exclusion core. The exclusion core rests upon a foundational idea in the legal understanding of property, the right to exclude others. By reinterpreting endowments as a distribution of exclusion rights, rather than as bundles of goods, our analysis extends to economies with qualified property rights, joint ownership, and social hierarchies. The exclusion core is characterized by a generalized top trading cycle algorithm in a large class of economies, including those featuring private, public, and mixed ownership. It is neither weaker nor stronger than the strong core.","['Kotowski, Maciej H.', 'Balbuzanov, Ivan']","['Exchange and Production Economies', 'Property Law', 'Capitalist Systems: Property Rights']","['D51', 'K11', 'P14']","Endowments, Exclusion, and Exchange",0,1,0,0,0,2019,09,01
87,5,2019-09-01,"We show how frictions and continuous transfers jointly affect equilibria in a model of matching in trading networks. Our model incorporates distortionary frictions such as transaction taxes and commissions. When contracts are fully substitutable for firms, competitive equilibria exist and coincide with outcomes that satisfy a cooperative solution concept called trail stability. However, competitive equilibria are generally neither stable nor Pareto-efficient.","['Fleiner, Tamas', 'Jagadeesan, Ravi', 'Janko, Zsuzsanna', 'Teytelboym, Alexander']","['Bargaining Theory; Matching Theory', 'Network Formation and Analysis: Theory']","['C78', 'D85']",Trading Networks with Frictions,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"We obtain a recursive formulation for a general class of optimization problems with forward-looking constraints which often arise in economic dynamic models, for example, in contracting problems with incentive constraints or in models of optimal policy. In this case, the solution does not satisfy the Bellman equation. Our approach consists of studying a recursive Lagrangian. Under standard general conditions, there is a recursive saddle-point functional equation (analogous to a Bellman equation) that characterizes a recursive solution to the planner's problem. The recursive formulation is obtained after adding a co-state variable mu","['Marcet, Albert', 'Marimon, Ramon']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'Economics of Contract: Theory']","['C61', 'D86']",Recursive Contracts,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"Can participation in financial markets lead individuals to reevaluate the costs of conflict, change their political attitudes, and even their votes? Prior to the 2015 Israeli elections, we randomly assigned Palestinian and Israeli financial assets to likely voters and incentivized them to actively trade for up to 7 weeks. No political messages or nonfinancial information were included. The treatment systematically shifted vote choices toward parties more supportive of the peace process. This effect is not due to a direct material incentive to vote a particular way. Rather, the treatment reduces opposition to concessions for peace and changes awareness of the broader economic risks of conflict. While participants who were assigned Palestinian assets are more likely to associate their assets' performance with peace, they are less engaged in the experiment. Combined with the superior performance of Israeli stocks during the study period, the ultimate effects of Israeli and Palestinian assets are similar.","['Shayo, Moses', 'Jha, Saumitra']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Equities; Fixed Income Securities', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Household Saving, Borrowing, Debt, and Wealth']","['D72', 'G12', 'G14', 'G51']",Valuing Peace: The Effects of Financial Market Exposure on Votes and Political Attitudes,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"This paper considers inference on fixed effects in a linear regression model estimated from network data. An important special case of our setup is the two-way regression model. This is a workhorse technique in the analysis of matched data sets, such as employer-employee or student-teacher panel data. We formalize how the structure of the network affects the accuracy with which the fixed effects can be estimated. This allows us to derive sufficient conditions on the network for consistent estimation and asymptotically valid inference to be possible. Estimation of moments is also considered. We allow for general networks and our setup covers both the dense and the sparse case. We provide numerical results for the estimation of teacher value-added models and regressions with occupational dummies.","['Jochmans, Koen', 'Weidner, Martin']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Education', 'Time Allocation and Labor Supply', 'Public Sector Labor Markets']","['C23', 'H75', 'I21', 'J22', 'J45']",Fixed-Effect Regressions on Network Data,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"Entrants and incumbents can create new products and displace the products of competitors. Incumbents can also improve their existing products. How much of aggregate productivity growth occurs through each of these channels? Using data from the U.S. Longitudinal Business Database on all nonfarm private businesses from 1983 to 2013, we arrive at three main conclusions: First, most growth appears to come from incumbents. We infer this from the modest employment share of entering firms (defined as those less than 5 years old). Second, most growth seems to occur through improvements of existing varieties rather than creation of brand new varieties. Third, own-product improvements by incumbents appear to be more important than creative destruction. We infer this because the distribution of job creation and destruction has thinner tails than implied by a model with a dominant role for creative destruction.","['Klenow, Peter J.', 'Garcia-Macia, Daniel', 'Hsieh, Chang-Tai']","['Macroeconomics: Production', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Innovation and Invention: Processes and Incentives']","['E23', 'E24', 'L11', 'O31']",How Destructive Is Innovation?,1,0,0,1,0,2019,09,01
87,5,2019-09-01,"This paper is about measuring state dependence in dynamic discrete outcomes. I develop a nonparametric dynamic potential outcomes (DPO) model and propose an array of parameters and identifying assumptions that can be considered in this model. I show how to construct sharp identified sets under combinations of identifying assumptions by using a flexible linear programming procedure. I apply the analysis to study state dependence in unemployment for working age high school educated men using an extract from the 2008 Survey of Income and Program Participation (SIPP). Using only nonparametric assumptions, I estimate that state dependence accounts for at least 30-40 percent of the four-month persistence in unemployment among high school educated men.","['Torgovitsky, Alexander']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Unemployment: Models, Duration, Incidence, and Job Search']","['C23', 'E24', 'J22', 'J24', 'J64']",Nonparametric Inference on State Dependence in Unemployment,0,0,0,0,0,2019,09,01
87,5,2019-09-01,"In 1960, 94 percent of doctors and lawyers were white men. By 2010, the fraction was just 62 percent. Similar changes in other highly-skilled occupations have occurred throughout the U.S. economy during the last 50 years. Given that the innate talent for these professions is unlikely to have changed differently across groups, the change in the occupational distribution since 1960 suggests that a substantial pool of innately talented women and black men in 1960 were not pursuing their comparative advantage. We examine the effect on aggregate productivity of the convergence in the occupational distribution between 1960 and 2010 through the prism of a Roy model. Across our various specifications, between 20 percent and 40 percent of growth in aggregate market output per person can be explained by the improved allocation of talent.","['Jones, Charles I.', 'Hurst, Erik', 'Hsieh, Chang-Tai', 'Klenow, Peter J.']","['Macroeconomics: Production', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Professional Labor Markets; Occupational Licensing']","['E23', 'J15', 'J24', 'J44']",The Allocation of Talent and U.S. Economic Growth,0,0,0,0,0,2019,09,01
87,4,2019-07-01,"We propose a bootstrap-based calibrated projection procedure to build confidence intervals for single components and for smooth functions of a partially identified parameter vector in moment (in)equality models. The method controls asymptotic coverage uniformly over a large class of data generating processes. The extreme points of the calibrated projection confidence interval are obtained by extremizing the value of the function of interest subject to a proper relaxation of studentized sample analogs of the moment (in)equality conditions. The degree of relaxation, or critical level, is calibrated so that the function of theta, not theta itself, is uniformly asymptotically covered with prespecified probability. This calibration is based on repeatedly checking feasibility of linear programming problems, rendering it computationally attractive.","['Stoye, Jorg', 'Molinari, Francesca', 'Kaido, Hiroaki']","['Estimation: General', 'Air Transportation']","['C13', 'L93']",Confidence Intervals for Projections of Partially Identified Parameters,1,0,0,0,0,2019,07,01
87,4,2019-07-01,"The main result in Daskalakis, Deckelbaum, and Tzamos (2017) establishes strong duality in the monopoly problem with an argument based on transportation theory. We provide a short, alternative proof using linear programming.","['Manelli, Alejandro', 'Kleiner, Andreas']","['Market Structure, Pricing, and Design: Monopoly', 'Monopoly; Monopolization Strategies']","['D42', 'L12']",Strong Duality in Monopoly Pricing,1,0,1,0,0,2019,07,01
87,4,2019-07-01,"We consider a general social choice environment that has multiple agents, a finite set of alternatives, independent types, and atomless type distribution. We show that for any Bayesian incentive compatible mechanism, there exists an equivalent deterministic mechanism that (1) is Bayesian incentive compatible; (2) delivers the same interim expected allocation probabilities and the same interim expected utilities for all agents; and (3) delivers the same ex ante expected social surplus. This result holds in settings with a rich class of utility functions, multidimensional types, interdependent valuations, and in settings without monetary transfers. To prove our result, we develop a novel methodology of mutual purification, and establish its link with the mechanism design literature.","['Sun, Yeneng', 'Li, Jiangtao', 'He, Wei', 'Chen, Yi-Chun']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Equivalence of Stochastic and Deterministic Mechanisms,0,0,1,0,0,2019,07,01
87,4,2019-07-01,"Many decision situations involve two or more of the following divergences from subjective expected utility: imprecision of beliefs (or ambiguity), imprecision of tastes (or multi-utility), and state dependence of utility. This paper proposes and characterizes a model of uncertainty averse preferences that can simultaneously incorporate all three phenomena. The representation supports a principled separation of (imprecise) beliefs and (potentially state-dependent, imprecise) tastes. Moreover, the representation permits comparative statics separating the roles of beliefs and tastes, and is modular: it easily delivers special cases involving various combinations of the phenomena, as well as state-dependent multi-utility generalizations covering popular ambiguity models.","['Hill, Brian']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D83']",A Non-Bayesian Theory of State-Dependent Utility,0,0,0,0,0,2019,07,01
87,4,2019-07-01,"We study the problem of measuring group differences in choices when the dimensionality of the choice set is large. We show that standard approaches suffer from a severe finite-sample bias, and we propose an estimator that applies recent advances in machine learning to address this bias. We apply this method to measure trends in the partisanship of congressional speech from 1873 to 2016, defining partisanship to be the ease with which an observer could infer a congressperson's party from a single utterance. Our estimates imply that partisanship is far greater in recent years than in the past, and that it increased sharply in the early 1990s after remaining low and relatively constant over the preceding century.","['Taddy, Matt', 'Shapiro, Jesse M.', 'Gentzkow, Matthew']","['Model Construction and Estimation', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Economic History: Government, War, Law, International Relations, and Regulation: U.S.; Canada: Pre-1913', 'Economic History: Government, War, Law, International Relations, and Regulation: U.S.; Canada: 1913-']","['C51', 'D72', 'N41', 'N42']",Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech,0,0,0,0,0,2019,07,01
87,4,2019-07-01,"We derive asymptotic properties of estimators and test statistics to determine--in a grouped data setting--common versus group-specific factors. Despite the fact that our test statistic for the number of common factors, under the null, involves a parameter at the boundary (related to unit canonical correlations), we derive a parameter-free asymptotic Gaussian distribution. We show how the group factor setting applies to mixed-frequency data. As an empirical illustration, we address the question whether Industrial Production (IP) is still the dominant factor driving the U.S. economy using a mixed-frequency data panel of IP and non-IP sectors. We find that a single common factor explains 89% of IP output growth and 61% of total GDP growth despite the diminishing role of manufacturing.","['Ghysels, E.', 'Rubin, M.', 'Gagliardini, P.', 'Andreou, E.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Macroeconomics: Production', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Industry Studies: Manufacturing: General']","['C23', 'E23', 'L16', 'L60']",Inference in Group Factor Models with an Application to Mixed-Frequency Data,1,0,0,0,0,2019,07,01
87,4,2019-07-01,"We study Pareto optimal policy reforms aimed at overhauling retirement financing as an integral part of the tax and transfer system. Our framework for policy analysis is a heterogeneous-agent overlapping-generations model that performs well in matching the aggregate and distributional features of the U.S. economy. We present a test of Pareto optimality that identifies the main source of inefficiency in the status quo policies. Our test suggests that lack of asset subsidies late in life is the main source of inefficiency when annuity markets are incomplete. We solve for Pareto optimal policy reforms and show that progressive asset subsidies provide a powerful tool for Pareto optimal reforms. On the other hand, earnings tax reforms do not always yield efficiency gains. We implement our Pareto optimal policy reform in an economy that features demographic change. The reform reduces the present discounted value of net resources consumed by each generation by about 7 to 11 percent in the steady state. These gains amount to a one-time lump-sum transfer to the initial generation equal to 10.5 percent of GDP.","['Shourideh, Ali', 'Hosseini, Roozbeh']","['Household Saving; Personal Finance', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Macroeconomics: Production', 'Taxation and Subsidies: Efficiency; Optimal Taxation', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Social Security and Public Pensions', 'Retirement; Retirement Policies']","['D14', 'D15', 'E23', 'H21', 'H24', 'H55', 'J26']",Retirement Financing: An Optimal Reform Approach,0,0,0,0,0,2019,07,01
87,4,2019-07-01,"We provide a nonlinear characterization of the macroeconomic impact of microeconomic productivity shocks in terms of reduced-form nonparametric elasticities for efficient economies. We also show how microeconomic parameters are mapped to these reduced-form general equilibrium elasticities. In this sense, we extend the foundational theorem of Hulten (1978) beyond the first order to capture nonlinearities. Key features ignored by first-order approximations that play a crucial role are: structural microeconomic elasticities of substitution, network linkages, structural microeconomic returns to scale, and the extent of factor reallocation. In a business-cycle calibration with sectoral shocks, nonlinearities magnify negative shocks and attenuate positive shocks, resulting in an aggregate output distribution that is asymmetric (negative skewness), fat-tailed (excess kurtosis), and has a negative mean, even when shocks are symmetric and thin-tailed. Average output losses due to short-run sectoral shocks are an order of magnitude larger than the welfare cost of business cycles calculated by Lucas (1987). Nonlinearities can also cause shocks to critical sectors to have disproportionate macroeconomic effects, almost tripling the estimated impact of the 1970s oil shocks on world aggregate output. Finally, in a long-run growth context, nonlinearities, which underpin Baumol's cost disease via the increase over time in the sales shares of low-growth bottleneck sectors, account for a 20 percentage point reduction in aggregate TFP growth over the period 1948-2014 in the United States.","['Baqaee, David Rezza', 'Farhi, Emmanuel']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Macroeconomics: Production', 'Business Fluctuations; Cycles']","['D24', 'E23', 'E32']",The Macroeconomic Impact of Microeconomic Shocks: Beyond Hulten's Theorem,0,0,0,0,0,2019,07,01
87,4,2019-07-01,"Private information is at the heart of many economic activities. For decades, economists have assumed that individuals are willing to misreport private information if this maximizes their material payoff. We combine data from 90 experimental studies in economics, psychology, and sociology, and show that, in fact, people lie surprisingly little. We then formalize a wide range of potential explanations for the observed behavior, identify testable predictions that can distinguish between the models, and conduct new experiments to do so. Our empirical evidence suggests that a preference for being seen as honest and a preference for being honest are the main motivations for truth-telling.","['Abeler, Johannes', 'Nosenzo, Daniele', 'Raymond, Collin']","['Asymmetric and Private Information; Mechanism Design', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D82', 'Z13']",Preferences for Truth-Telling,0,0,0,0,0,2019,07,01
87,4,2019-07-01,"Twelve percent of the Malawian population is HIV infected. Eighteen percent of sexual encounters are casual. A condom is used a third of the time. To analyze the Malawian epidemic, a choice-theoretic general equilibrium search model is constructed. In the developed framework, people select between different sexual practices while knowing the inherent risk. The calibrated model is used to study several policy interventions, namely, ART, circumcision, better condoms, and the treatment of other STDs. The efficacy of public policy depends upon the induced behavioral changes and equilibrium effects. The framework complements the insights from epidemiological studies and small-scale field experiments.","['Kircher, Philipp', 'Greenwood, Jeremy', 'Tertilt, Michele', 'Santos, Cezar']","['Model Construction and Estimation', 'Field Experiments', 'National Government Expenditures and Health', 'Health Behavior', 'Health: Government Policy; Regulation; Public Health', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration']","['C51', 'C93', 'H51', 'I12', 'I18', 'O15']",An Equilibrium Model of the African HIV/AIDS Epidemic,0,0,0,0,0,2019,07,01
87,3,2019-05-01,ECONLIT None Found,[nan],[nan],[nan],2018 Election of Fellows to the Econometric Society.,0,0,0,0,0,2019,05,01
87,3,2019-05-01,"Fan, Liao, and Yao (2015) recently introduced a remarkable method for increasing the asymptotic power of tests in high-dimensional testing problems. If applicable to a given test, their power enhancement principle leads to an improved test that has the same asymptotic size, has uniformly non-inferior asymptotic power, and is consistent against a strictly broader range of alternatives than the initially given test. We study under which conditions this method can be applied and show the following: In asymptotic regimes where the dimensionality of the parameter space is fixed as sample size increases, there often exist tests that cannot be further improved with the power enhancement principle. However, when the dimensionality of the parameter space increases sufficiently slowly with sample size and a marginal local asymptotic normality (LAN) condition is satisfied, every test with asymptotic size smaller than 1 can be improved with the power enhancement principle. While the marginal LAN condition alone does not allow one to extend the latter statement to all rates at which the dimensionality increases with sample size, we give sufficient conditions under which this is the case.","['Kock, Anders Bredahl', 'Preinerstorfer, David']","['Hypothesis Testing: General', 'Large Data Sets: Modeling and Analysis']","['C12', 'C55']",Notes and Comments: Power in High-Dimensional Testing Problems,0,0,0,0,0,2019,05,01
87,3,2019-05-01,"This paper provides nonparametric identification results for a class of latent utility models with additively separable unobservable heterogeneity. These results apply to existing models of discrete choice, bundles, decisions under uncertainty, and matching. Under an independence assumption, such models admit a representative agent. As a result, we can identify how regressors alter the desirability of goods using only average demands. Moreover, average indirect utility (""welfare"") is identified without needing to specify or identify the distribution of unobservable heterogeneity.","['Rehbeck, John', 'Allen, Roy']","['Semiparametric and Nonparametric Methods: General', 'Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['C14', 'D11', 'D81']",Identification with Additively Separable Heterogeneity,0,0,0,0,0,2019,05,01
87,3,2019-05-01,"Half of U.S. 50-year-olds will experience a nursing home stay before they die, and one in ten will incur out-of-pocket long-term care expenses in excess of $200,000. Surprisingly, only about 10% of individuals over age 62 have private long-term care insurance (LTCI) and LTCI takeup rates are low at all wealth levels. We analyze the contributions of Medicaid, administrative costs, and asymmetric information about nursing home entry risk to low LTCI takeup rates in a quantitative equilibrium contracting model. As in practice, the insurer in the model assigns individuals to risk groups based on noisy indicators of their nursing home entry risk. All individuals in frail and/or low-income risk groups are denied coverage because the cost of insuring any individual in these groups exceeds that individual's willingness-to-pay. Individuals in insurable risk groups are offered a menu of contracts whose terms vary across risk groups. We find that Medicaid accounts for low LTCI takeup rates of poorer individuals. However, administrative costs and adverse selection are responsible for low takeup rates of the rich. The model reproduces other empirical features of the LTCI market including the fact that owners of LTCI have about the same nursing home entry rates as non-owners.","['Kopecky, Karen A.', 'Braun, R. Anton', 'Koreshkova, Tatyana']","['Insurance; Insurance Companies; Actuarial Studies', 'National Government Expenditures and Health', 'Analysis of Health Care Markets', 'Health Insurance, Public and Private', 'Health: Government Policy; Regulation; Public Health', 'Economics of the Elderly; Economics of the Handicapped; Non-labor Market Discrimination']","['G22', 'H51', 'I11', 'I13', 'I18', 'J14']","Old, Frail, and Uninsured: Accounting for Features of the U.S. Long-Term Care Insurance Market",0,0,0,0,0,2019,05,01
87,3,2019-05-01,"This paper begins by observing that any reflexive binary (preference) relation (over risky prospects) that satisfies the independence axiom admits a form of expected utility representation. We refer to this representation notion as the coalitional minmax expected utility representation. By adding the remaining properties of the expected utility theorem, namely, continuity, completeness, and transitivity, one by one, we find how this representation gets sharper and sharper, thereby deducing the versions of this classical theorem in which any combination of these properties is dropped from its statement. This approach also allows us to weaken transitivity in this theorem, rather than eliminate it entirely, say, to quasitransitivity or acyclicity. Apart from providing a unified dissection of the expected utility theorem, these results are relevant for the growing literature on boundedly rational choice in which revealed preference relations often lack the properties of completeness and/or transitivity (but often satisfy the independence axiom). They are also especially suitable for the (yet overlooked) case in which the decision-maker is made up of distinct individuals and, consequently, transitivity is routinely violated. Finally, and perhaps more importantly, we show that our representation theorems allow us to answer many economic questions that are posed in terms of nontransitive/incomplete preferences, say, about the maximization of preferences, the existence of Nash equilibrium, the preference for portfolio diversification, and the possibility of the preference reversal phenomenon.","['Ok, Efe A.', 'Riella, Gil', 'Hara, Kazuhiro']","['Noncooperative Games', 'Consumer Economics: Theory', 'Household Saving; Personal Finance', 'Portfolio Choice; Investment Decisions']","['C72', 'D11', 'D14', 'G11']",Coalitional Expected Multi-utility Theory,0,0,0,0,0,2019,05,01
87,3,2019-05-01,"An Equivalence Theorem between geometric structures and utility functions allows new methods for understanding preferences. Our classification of valuations into ""Demand Types"" incorporates existing definitions (substitutes, complements, ""strong substitutes,"" etc.) and permits new ones. Our Unimodularity Theorem generalizes previous results about when competitive equilibrium exists for any set of agents whose valuations are all of a ""demand type."" Contrary to popular belief, equilibrium is guaranteed for more classes of purely-complements than of purely-substitutes, preferences. Our Intersection Count Theorem checks equilibrium existence for combinations of agents with specific valuations by counting the intersection points of geometric objects. Applications include matching and coalition-formation, and the ""Product-Mix Auction"" introduced by the Bank of England in response to the financial crisis.","['Baldwin, Elizabeth', 'Klemperer, Paul']","['Bargaining Theory; Matching Theory', 'Consumer Economics: Theory', 'Auctions', 'Central Banks and Their Policies']","['C78', 'D11', 'D44', 'E58']","Understanding Preferences: 'Demand Types', and the Existence of Equilibrium with Indivisibilities",0,0,1,0,0,2019,05,01
87,3,2019-05-01,"We revisit the Nash bargaining model and axiomatize a procedural solution that maximizes the probability of successful bargaining. Our characterization spans several known solution concepts, including the special cases of the Nash, egalitarian, and utilitarian solutions. Using a probability-based language, we offer a natural interpretation for the product operator underlying the Nash solution: when the bargainers' individual acceptance probabilities are independent, their product recovers the joint acceptance probability.","['Bastianello, Lorenzo', 'LiCalzi, Marco']","['Noncooperative Games', 'Bargaining Theory; Matching Theory']","['C72', 'C78']",The Probability to Reach an Agreement as a Foundation for Axiomatic Bargaining,0,0,0,0,0,2019,05,01
87,3,2019-05-01,"We develop a dynamic trade model with spatially distinct labor markets facing varying exposure to international trade. The model captures the role of labor mobility frictions, goods mobility frictions, geographic factors, and input-output linkages in determining equilibrium allocations. We show how to solve the equilibrium of the model and take the model to the data without assuming that the economy is at a steady state and without estimating productivities, migration frictions, or trade costs, which can be difficult to identify. We calibrate the model to 22 sectors, 38 countries, and 50 U.S. states. We study how the rise in China's trade for the period 2000 to 2007 impacted U.S. households across more than a thousand U.S. labor markets distinguished by sector and state. We find that the China trade shock resulted in a reduction of about 0.55 million U.S. manufacturing jobs, about 16% of the observed decline in manufacturing employment from 2000 to 2007. The U.S. gains in the aggregate, but due to trade and migration frictions, the welfare and employment effects vary across U.S. labor markets. Estimated transition costs to the new long-run equilibrium are also heterogeneous and reflect the importance of accounting for labor dynamics.","['Parro, Fernando', 'Dvorkin, Maximiliano', 'Caliendo, Lorenzo']","['Model Construction and Estimation', 'Empirical Studies of Trade', 'Trade and Labor Market Interactions', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Industry Studies: Manufacturing: General', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['C51', 'F14', 'F16', 'L16', 'L60', 'R23']",Trade and Labor Market Dynamics: General Equilibrium Analysis of the China Trade Shock,1,0,0,0,0,2019,05,01
87,3,2019-05-01,"We propose a framework to identify and estimate earnings distributions and worker composition on matched panel data, allowing for two-sided worker-firm unobserved heterogeneity and complementarities in earnings. We introduce two models: a static model that allows for nonlinear interactions between workers and firms, and a dynamic model that allows, in addition, for Markovian earnings dynamics and endogenous mobility. We show that this framework nests a number of structural models of wages and worker mobility. We establish identification in short panels, and develop tractable two-step estimators where firms are classified in a first step. Applying our method to Swedish administrative data, we find that log-earnings are approximately additive in worker and firm heterogeneity. Our estimates imply the presence of strong sorting patterns between workers and firms, and a small contribution of firms-net of worker composition-to earnings dispersion. In addition, we document that wages have a direct effect on mobility, and that, beyond their dependence on the current firm, earnings after a job move also depend on the previous employer.","['Manresa, Elena', 'Lamadon, Thibaut', 'Bonhomme, Stephane']","['Model Construction and Estimation', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Job, Occupational, and Intergenerational Mobility; Promotion']","['C51', 'J31', 'J41', 'J62']",A Distributional Framework for Matched Employer Employee Data,0,0,0,0,0,2019,05,01
89,3,2021-05-01,ECONLIT None Found,"['Vives, Xavier', 'Azar, Jose']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'General Equilibrium and Disequilibrium: General', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Aggregate Factor Income Distribution', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Antitrust Law']","['D21', 'D43', 'D50', 'E24', 'E25', 'G32', 'K21']",Reply to: Comments on 'General Equilibrium Oligopoly and Ownership Structure',0,1,1,0,0,2021,05,01
87,2,2019-03-01,"Structural econometric methods are often criticized for being sensitive to functional form assumptions. We study parametric estimators of the local average treatment effect (LATE) derived from a widely used class of latent threshold crossing models and show they yield LATE estimates algebraically equivalent to the instrumental variables (IV) estimator. Our leading example is Heckman's (1979) two-step (""Heckit"") control function estimator which, with two-sided non-compliance, can be used to compute estimates of a variety of causal parameters. Equivalence with IV is established for a semiparametric family of control function estimators and shown to hold at interior solutions for a class of maximum likelihood estimators. Our results suggest differences between structural and IV estimates often stem from disagreements about the target parameter rather than from functional form assumptions per se. In cases where equivalence fails, reporting structural estimates of LATE alongside IV provides a simple means of assessing the credibility of structural extrapolation exercises.","['Walters, Christopher R.', 'Kline, Patrick']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C21', 'C26']","On Heckits, Late, and Numerical Equivalence",0,0,0,0,0,2019,03,01
87,2,2019-03-01,"A sender persuades a receiver to accept a project by disclosing information about a payoff-relevant quality. The receiver has private information about the quality, referred to as his type. We show that the sender-optimal mechanism takes the form of nested intervals: each type accepts on an interval of qualities and a more optimistic type's interval contains a less optimistic type's interval. This nested-interval structure offers a simple algorithm to solve for the optimal disclosure and connects our problem to the monopoly screening problem. The mechanism is optimal even if the sender conditions the disclosure mechanism on the receiver's reported type.","['Guo, Yingni', 'Shmaya, Eran']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",The Interval Structure of Optimal Disclosure,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"We develop a framework to study the dynamics of vote trading over multiple binary issues. We prove that there always exists a stable allocation of votes that is reachable in a finite number of trades, for any number of voters and issues, any separable preference profile, and any restrictions on the coalitions that may form. If at every step all blocking trades are chosen with positive probability, convergence to a stable allocation occurs in finite time with probability 1. If coalitions are unrestricted, the outcome of vote trading must be Pareto optimal, but unless there are three voters or two issues, it need not correspond to the Condorcet winner.","['Casella, Alessandra', 'Palfrey, Thomas']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Trading Votes for Votes: A Dynamic Theory,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"A general selection theorem is presented constructing a measurable mapping from a state space to a parameter space under the assumption that the state space can be decomposed as a collection of countable equivalence classes under a smooth equivalence relation. It is then shown how this selection theorem can be used as a general purpose tool for proving the existence of measurable equilibria in broad classes of several branches of games when an appropriate smoothness condition holds, including Bayesian games with atomic knowledge spaces, stochastic games with countable orbits, and graphical games of countable degree--examples of a subclass of games with uncountable state spaces that we term purely atomic games. Applications to repeated games with symmetric incomplete information and acceptable bets are also presented.","['Hellman, Ziv', 'Levy, Yehuda John']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Measurable Selection for Purely Atomic Games,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"We can often predict the behavior of those closest to us more accurately than that of complete strangers, yet we routinely engage in strategic situations with both: our social network impacts our strategic knowledge. Peer-confirming equilibrium describes the behavioral consequences of this intuition in a noncooperative game. We augment a game with a network to represent strategic information: if two players are linked in the network, they have correct conjectures about each others' strategies. In peer-confirming equilibrium, there is common belief that players (i) behave rationally and (ii) correctly anticipate neighbors' play. In simultaneous-move games, adding links to the network always restricts the set of outcomes. In dynamic games, the outcome set may vary non-monotonically with the network because the actions of well-connected players help poorly-connected players coordinate. This solution concept provides a useful language for studying public good provision, highlights a new channel through which central individuals facilitate coordination, and delineates possible sources of miscoordination in protests and coups.","['Lipnowski, Elliot', 'Sadler, Evan']","['Noncooperative Games', 'Network Formation and Analysis: Theory']","['C72', 'D85']",Peer-Confirming Equilibrium,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"We show that in a class of I-agent mechanism design problems with evidence, commitment is unnecessary, randomization has no value, and robust incentive compatibility has no cost. In particular, for each agent i, we construct a simple disclosure game between the principal and agent i where the equilibrium strategies of the agents in these disclosure games give their equilibrium strategies in the game corresponding to the mechanism but where the principal is not committed to his response. In this equilibrium, the principal obtains the same payoff as in the optimal mechanism with commitment. As an application, we show that certain costly verification models can be characterized using equilibrium analysis of an associated model of evidence.","['Lipman, Barton L.', 'Ben-Porath, Elchanan', 'Dekel, Eddie']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Mechanisms with Evidence: Commitment and Robustness,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"Endogenous demand composition across sectors due to income elasticity differences, or Engel's Law for brevity, affects (i) sectoral compositions in employment and in value-added, (ii) variations in innovation rates and in productivity change across sectors, (iii) intersectoral patterns of trade across countries, and (iv) product cycles from rich to poor countries. Using a two-country model of directed technical change with a continuum of sectors under nonhomothetic preferences, which is rich enough to capture all these effects as well as their interactions, this paper offers a unifying perspective on how economic growth and globalization affect the patterns of structural change, innovation, and trade across countries and across sectors in the presence of Engel's Law. Among the main messages is that globalization amplifies, instead of reducing, the power of endogenous domestic demand composition differences as a driver of structural change.","['Matsuyama, Kiminori']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Neoclassical Models of Trade', 'Economic Impacts of Globalization: Macroeconomic Impacts', 'Technological Change: Choices and Consequences; Diffusion Processes', 'One, Two, and Multisector Growth Models']","['E24', 'F11', 'F62', 'O33', 'O41']","Engel's Law in the Global Economy: Demand-Induced Patterns of Structural Change, Innovation, and Trade",0,0,0,1,0,2019,03,01
87,2,2019-03-01,"Insurgency and guerrilla warfare impose enormous socio-economic costs and often persist for decades. The opacity of such forms of conflict is an obstacle to effective international humanitarian intervention and development programs. To shed light on the internal organization of otherwise unknown insurgent groups, this paper proposes two methodologies for the detection of unobserved coalitions of militants in conflict areas. These approaches are based on daily geocoded incident-level data on insurgent attacks. We provide applications to the Afghan conflict during the 2004-2009 period and to Pakistan during the 2008-2011 period, identifying systematically different coalition structures. Applications to global terrorism data and identification of new groups or shifting coalitions are discussed.","['Weese, Eric', 'Trebbi, Francesco']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D74', 'O17']",Insurgency and Small Wars: Estimation of Unobserved Coalition Structures,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"We study the interactions between sovereign debt default and maturity choice in a setting with limited commitment for repayment as well as future debt issuances. Our main finding is that, under a wide range of conditions, the sovereign should, as long as default is not preferable, remain passive in long-term bond markets, making payments and retiring long-term bonds as they mature but never actively issuing or buying back such bonds. The only active debt-management margin is the short-term bond market. We show that any attempt to manipulate the existing maturity profile of outstanding long-term bonds generates losses, as bond prices move against the sovereign. Our results hold regardless of the shape of the yield curve. The yield curve captures the average costs of financing at different maturities but is misleading regarding the marginal costs.","['Werning, Ivan', 'Hopenhayn, Hugo', 'Aguiar, Mark', 'Amador, Manuel']","['Interest Rates: Determination, Term Structure, and Effects', 'International Lending and Debt Problems', 'National Debt; Debt Management; Sovereign Debt']","['E43', 'F34', 'H63']",Take the Short Route: Equilibrium Default and Debt Maturity,0,0,0,0,0,2019,03,01
87,2,2019-03-01,"We study the optimal design of subsidies in an equilibrium setting, where the decisions of individual recipients impose externalities on one another. We apply the model to the case of post-Katrina rebuilding in New Orleans under the Louisiana Road Home rebuilding grant program (RH). We estimate the structural model via indirect inference, exploiting a discontinuity in the formula for determining the size of grants, which helps isolate the causal effect of neighbors' rebuilding on one's own rebuilding choices. We find that the additional rebuilding induced by RH generated positive externalities equivalent to $4950 to each inframarginal household whose rebuilding choice was not affected by the program. Counterfactual policy experiments find that optimal subsidy policies bias grant offers against relocation, with an inverse-U-shaped relationship between the degree of bias and the severity of damages from the disaster.","['Fu, Chao', 'Gregory, Jesse']","['Model Construction and Estimation', 'Externalities', 'Climate; Natural Disasters and Their Management; Global Warming', 'Housing Supply and Markets', 'Production Analysis and Firm Location: Government Policy']","['C51', 'D62', 'Q54', 'R31', 'R38']",Estimation of an Equilibrium Model with Externalities: Post-disaster Neighborhood Rebuilding,0,0,0,0,0,2019,03,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2017–2018.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"In a transformation model y_{t} = c[a(x_{t}, beta), u_{t}], where the errors u_{t} are i.i.d. and independent of the explanatory variables , the parameters can be estimated by a pseudo-maximum likelihood (PML) method, that is, by using a misspecified distribution of the errors, but the PML estimator of beta is in general not consistent. We explain in this paper how to nest the initial model in an identified augmented model with more parameters in order to derive consistent PML estimators of appropriate functions of parameter beta. The usefulness of the consistency result is illustrated by examples of systems of nonlinear equations, conditionally heteroscedastic models, stochastic volatility, or models with spatial interactions.","['Zakoian, J-M.', 'Monfort, A.', 'Gourieroux, C.']","['Estimation: General', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C13', 'C32']",Consistent Pseudo-maximum Likelihood Estimators and Groups of Transformations,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"An empirical approach to optimal income taxation design is developed within an equilibrium collective marriage market model with imperfectly transferable utility. Taxes distort time allocation decisions, as well as marriage market outcomes, and the within household decision process. Using data from the American Community Survey and American Time Use Survey, we structurally estimate our model and explore empirical design problems. We allow taxes to depend upon marital status, with the form of tax jointness for married couples unrestricted. We find that the optimal tax system for married couples is characterized by negative jointness, although the welfare gains from jointness are modest. These welfare gains are then shown to be increasing in the gender wage gap, with taxes here, as in the case of gender based taxation, providing an instrument to address within household inequality.","['Gayle, George-Levi', 'Shephard, Andrew']","['Household Production and Intrahousehold Allocation', 'Taxation and Subsidies: Efficiency; Optimal Taxation', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['D13', 'H21', 'H24', 'J12', 'J16', 'J22']","Optimal Taxation, Marriage, Home Production, and Family Labor Supply",0,0,0,0,0,2019,01,01
87,1,2019-01-01,"Households face large income uncertainty that varies substantially over the business cycle. We examine the macroeconomic consequences of these variations in a model with incomplete markets, liquid and illiquid assets, and a nominal rigidity. Heightened uncertainty depresses aggregate demand as households respond by hoarding liquid ""paper"" assets for precautionary motives, thereby reducing both illiquid physical investment and consumption demand. We document the empirical response of portfolio liquidity and aggregate activity to surprise changes in idiosyncratic income uncertainty and find both to be quantitatively in line with our model. The welfare consequences of uncertainty shocks and of the policy response thereto depend crucially on a household's asset position.","['Pham-Dao, Lien', 'Tjaden, Volker', 'Bayer, Christian', 'Luetticke, Ralph']","['Household Saving; Personal Finance', 'Incomplete Markets', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Macroeconomics: Consumption; Saving; Wealth', 'Business Fluctuations; Cycles']","['D14', 'D52', nan, 'E21', 'E32']","Precautionary Savings, Illiquid Assets, and the Aggregate Consequences of Shocks to Household Income Risk",0,0,0,0,0,2019,01,01
87,1,2019-01-01,"Comparing the 1935 and 1975 U.S. birth cohorts, wages of married women grew twice as fast as for married men, and the wage gap between married and single women turned from negative to positive. The employment rate of married women also increased sharply, while that of other groups remained quite stable. To better understand these diverse patterns, we develop a life-cycle model incorporating individual and household decisions about education, employment, marriage/divorce, and fertility. The model provides an excellent fit to wage and employment patterns, along with changes in education, marriage/divorce rates, and fertility. We assume fixed preferences, but allow for four exogenously changing factors: (i) mother's education, health, and taxes/transfers; (ii) marriage market opportunities and divorce costs; (iii) the wage structure and job offers; (iv) contraception technology. We quantify how each factor contributed to changes across cohorts. We find that factor (iii) was the most important force driving the increase in relative wages of married women, but that all four factors are important for explaining the many socio-economic changes that occurred in the past 50 years. Finally, we use the model to simulate a shift from joint to individual taxation. In a revenue-neutral simulation, we predict this would increase employment of married women by 9% and the marriage rate by 8.1%.","['Lifshitz, Osnat', 'Keane, Michael', 'Eckstein, Zvi']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Returns to Education', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Gender; Non-labor Discrimination', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['D15', 'H24', 'I26', 'J13', 'J16', 'J24', 'J31']",Career and Family Decisions: Cohorts Born 1935-1975,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"We conduct an experiment to study whether individuals save more when information about the progress toward their self-set savings goal is shared with another village member (a ""monitor""). We develop a reputational framework to explore how a monitor's effectiveness depends on her network position. Savers who care about whether others perceive them as responsible should save more with central monitors, who more widely disseminate information, and proximate monitors, who pass information to individuals with whom the saver interacts frequently. We randomly assign monitors to savers and find that monitors on average increase savings by 36%. Consistent with the framework, more central and proximate monitors lead to larger increases in savings. Moreover, information flows through the network, with 63% of monitors telling others about the saver's progress. Fifteen months after the conclusion of the experiment, other villagers have updated their beliefs about the saver's responsibility in response to the intervention.","['Chandrasekhar, Arun G.', 'Breza, Emily']","['Field Experiments', 'Household Saving; Personal Finance', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Microeconomic Analyses of Economic Development', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['C93', 'D14', 'G21', 'O12', 'O16', 'Z13']","Social Networks, Reputation, and Commitment: Evidence from a Savings Monitors Experiment",0,0,0,0,0,2019,01,01
87,1,2019-01-01,"Is there a role for governments in emerging countries to accelerate economic development by intervening in product and factor markets? To address this question, we study optimal dynamic Ramsey policies in a standard growth model with financial frictions. The optimal policy intervention involves pro-business policies like suppressed wages in early stages of the transition, resulting in higher entrepreneurial profits and faster wealth accumulation. This, in turn, relaxes borrowing constraints in the future, leading to higher labor productivity and wages. In the long run, optimal policy reverses sign and becomes pro-worker. In a multi-sector extension, optimal policy subsidizes sectors with a latent comparative advantage and, under certain circumstances, involves a depreciated real exchange rate. Our results provide an efficiency rationale, but also identify caveats, for many of the development policies actively pursued by dynamic emerging economies.","['Itskhoki, Oleg', 'Moll, Benjamin']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Industrial Policy; Sectoral Planning Methods', 'Industrial Policy', 'One, Two, and Multisector Growth Models']","['E24', 'L52', 'O25', 'O41']",Optimal Development Policies with Financial Frictions,1,0,0,0,0,2019,01,01
87,1,2019-01-01,"We introduce a new solution concept for models of coalition formation, called the myopic stable set (MSS). The MSS is defined for a general class of social environments and allows for an infinite state space. An MSS exists and, under minor continuity assumptions, it is also unique. The MSS generalizes and unifies various results from more specific applications. It coincides with the coalition structure core in coalition function form games when this set is nonempty; with the set of stable matchings in the Gale-Shapley matching model; with the set of pairwise stable networks and closed cycles in models of network formation; and with the set of pure strategy Nash equilibria in pseudo-potential games and finite supermodular games. We also characterize the MSS for the class of proper simple games.","['Herings, P. Jean-Jacques', 'Demuynck, Thomas', 'Seel, Christian', 'Saulle, Riccardo D.']","['Game Theory and Bargaining Theory: General', 'Bargaining Theory; Matching Theory', 'Social Choice; Clubs; Committees; Associations']","['C70', 'C78', 'D71']",The Myopic Stable Set for Social Environments,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"We study stability of two-sided many-to-one matching in which firms' preferences for workers may exhibit complementarities. Although such preferences are known to jeopardize stability in a finite market, we show that a stable matching exists in a large market with a continuum of workers, provided that each firm's choice is convex and changes continuously as the set of available workers changes. We also study the existence and structure of stable matchings under preferences exhibiting substitutability and indifferences in a large market. Building on these results, we show that an approximately stable matching exists in large finite economies. We extend our framework to ensure a stable matching with desirable incentive and fairness properties in the presence of indifferences in firms' preferences.","['Kim, Jinwoo', 'Che, Yeon-Koo', 'Kojima, Fuhito']",['Bargaining Theory; Matching Theory'],['C78'],Stable Matching in Large Economies,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"We study economies with Knightian uncertainty about state prices. We introduce an equilibrium concept with sublinear prices and prove that equilibria exist under weak conditions. In general, such equilibria lead to inefficient allocations; they coincide with Arrow-Debreu equilibria if and only if the values of net trades are ambiguity-free in mean. In economies without aggregate uncertainty, inefficiencies are generic. Equilibrium allocations under price uncertainty are efficient in a constrained sense that we call uncertainty-neutral efficient. Arrow-Debreu equilibria turn out to be non-robust with respect to the introduction of Knightian uncertainty.","['Riedel, Frank', 'Beissner, Patrick']","['General Equilibrium and Disequilibrium: General', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D50', 'D81', 'D83']",Equilibria under Knightian Price Uncertainty,0,0,0,0,0,2019,01,01
87,1,2019-01-01,"We show that even in the absence of data on individual decisions, the distribution of individual attitudes towards risk can be identified from the aggregate conditions that characterize equilibrium on markets for risky assets. Taking parimutuel horse races as a textbook model of contingent markets, we allow for heterogeneous bettors with very general risk preferences, including non-expected utility. Under a standard single-crossing condition on preferences, we identify the distribution of preferences among the population of bettors and we derive testable implications. We estimate the model on data from U.S. races. Specifications based on expected utility fit the data very poorly. Our results stress the crucial importance of nonlinear probability weighting. They also suggest that several dimensions of heterogeneity may be at work.","['Salanie, Francois', 'Gandhi, Amit', 'Salanie, Bernard', 'Chiappori, Pierre-Andre']","['Criteria for Decision-Making under Risk and Uncertainty', 'Sports; Gambling; Restaurants; Recreation; Tourism', 'Sports Economics: Industry Studies']","['D81', 'L83', 'Z21']",From Aggregate Betting Data to Individual Risk Preferences,1,0,0,0,0,2019,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,"Savage (1954) provided the first axiomatic characterization of expected utility without relying on any given probabilities or utilities. It is the most famous preference axiomatization existing. This note shows that Savage's axiom P3 is implied by the other axioms, which reveals its redundancy. It is remarkable that this was not noticed before as Savage's axiomatization has been studied and taught by hundreds of researchers for more than six decades.","['Hartmann, Lorenz']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Savage's P3 Is Redundant,0,0,0,0,0,2020,01,01
86,6,2018-11-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society 2017 Annual Report of the President.,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"Many time series exhibit ""long memory"": Their autocorrelation function decays slowly with lag. This behavior has traditionally been modeled via unit roots or fractional Brownian motion and explained via aggregation of heterogeneous processes, nonlinearity, learning dynamics, regime switching, or structural breaks. This paper identifies a different and complementary mechanism for long-memory generation by showing that it can naturally arise when a large number of simple linear homogeneous economic subsystems with short memory are interconnected to form a network such that the outputs of the subsystems are fed into the inputs of others. This networking picture yields a type of aggregation that is not merely additive, resulting in a collective behavior that is richer than that of individual subsystems. Interestingly, the long-memory behavior is found to be almost entirely determined by the geometry of the network, while being relatively insensitive to the specific behavior of individual agents.","['Schennach, Susanne M.']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory']","['C32', 'D83', 'D85']",Long Memory via Networking,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"We study the design of provider incentives in the post-acute care setting--a high-stakes but under-studied segment of the healthcare system. We focus on long-term care hospitals (LTCHs) and the large (approximately $13,500) jump in Medicare payments they receive when a patient's stay reaches a threshold number of days. Discharges increase substantially after the threshold, with the marginal discharged patient in relatively better health. Despite the large financial incentives and behavioral response in a high mortality population, we are unable to detect any compelling evidence of an impact on patient mortality. To assess provider behavior under counterfactual payment schedules, we estimate a simple dynamic discrete choice model of LTCH discharge decisions. When we conservatively limit ourselves to alternative contracts that hold the LTCH harmless, we find that an alternative contract can generate Medicare savings of about $2,100 per admission, or about 5% of total payments. More aggressive payment reforms can generate substantially greater savings, but the accompanying reduction in LTCH profits has potential out-of-sample consequences. Our results highlight how improved financial incentives may be able to reduce healthcare spending, without negative consequences for industry profits or patient health.","['Mahoney, Neale', 'Finkelstein, Amy', 'Einav, Liran']","['Economics of Contract: Theory', 'National Government Expenditures and Health', 'Analysis of Health Care Markets', 'Health Behavior', 'Health: Government Policy; Regulation; Public Health']","['D86', 'H51', 'I11', 'I12', 'I18']",Provider Incentives and Healthcare Costs: Evidence from Long-Term Care Hospitals,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"High pollution persists in many developing countries despite strict environmental rules. We use a field experiment and a structural model to study how plant emission standards are enforced. In collaboration with an Indian environmental regulator, we experimentally doubled the rate of inspection for treatment plants and required that the extra inspections be assigned randomly. We find that treatment plants only slightly increased compliance. We hypothesize that this weak effect is due to poor targeting, since the random inspections in the treatment found fewer extreme violators than the regulator's own discretionary inspections. To unbundle the roles of extra inspections and the removal of discretion over what plants to target, we set out a model of environmental regulation where the regulator targets inspections, based on a signal of pollution, to maximize plant abatement. Using the experiment to identify key parameters of the model, we find that the regulator aggressively targets its discretionary inspections, to the degree that half of the plants receive fewer than one inspection per year, while plants expected to be the dirtiest may receive ten. Counterfactual simulations show that discretion in targeting helps enforcement: inspections that the regulator assigns cause three times more abatement than would the same number of randomly assigned inspections. Nonetheless, we find that the regulator's information on plant pollution is poor, and improvements in monitoring would reduce emissions.","['Greenstone, Michael', 'Ryan, Nicholas', 'Pande, Rohini', 'Duflo, Esther']","['Field Experiments', 'Economics of Regulation', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Industrialization; Manufacturing and Service Industries; Choice of Technology', 'Pollution Control Adoption and Costs; Distributional Effects; Employment Effects', 'Air Pollution; Water Pollution; Noise; Hazardous Waste; Solid Waste; Recycling']","['C93', 'L51', 'O13', 'O14', 'Q52', 'Q53']",The Value of Regulatory Discretion: Estimates from Environmental Inspections in India,1,0,0,0,0,2018,11,01
86,6,2018-11-01,"This study examines how the historical state conditions long-run development, using Vietnam as a laboratory. Northern Vietnam (Dai Viet) was ruled by a strong, centralized state in which the village was the fundamental administrative unit. Southern Vietnam was a peripheral tributary of the Khmer (Cambodian) Empire, which followed a patron-client model with more informal, personalized power relations and no village intermediation. Using a regression discontinuity design, the study shows that areas exposed to Dai Viet administrative institutions for a longer period prior to French colonization have experienced better economic outcomes over the past 150 years. Rich historical data document that in Dai Viet villages, citizens have been better able to organize for public goods and redistribution through civil society and local government. We argue that institutionalized village governance crowded in local cooperation and that these norms persisted long after the original institutions disappeared.","['Lane, Nathan', 'Querubin, Pablo', 'Dell, Melissa']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Colonialism; Imperialism; Postcolonialism', 'Public Goods', 'Economic History: Macroeconomics and Monetary Economics; Industrial Structure; Growth; Fluctuations: Asia including Middle East', 'Economic History: Government, War, Law, International Relations, and Regulation: Asia including Middle East', 'Regional and Urban History: Asia including Middle East', 'Size and Spatial Distributions of Regional Economic Activity']","['D72', 'F54', 'H41', 'N15', 'N45', 'N95', 'R12']","The Historical State, Local Collective Action, and Economic Development in Vietnam",0,0,0,0,0,2018,11,01
86,6,2018-11-01,"We show that there is substantial heterogeneity in women's labor supply elasticities at the micro level and highlight the implications for aggregate behavior. We consider both intertemporal and intratemporal choices, and identify intensive and extensive responses in a consistent life-cycle framework, using US CEX data. Heterogeneity is due to observables, such as age, wealth, hours worked, and the wage level, as well as to unobservable tastes for leisure: the median Marshallian elasticity for hours worked is 0.18, with corresponding Hicksian elasticity of 0.54 and Frisch elasticity of 0.87. At the 90th percentile, these values are 0.79, 1.16, and 1.92. Responses at the extensive margin explain about 54% of the total labor supply response for women under 30, although this declines with age. Aggregate elasticities are higher in recessions, and increase with the length of the recession. The heterogeneity at the micro level means that the aggregate labor supply elasticity is not a structural parameter: any aggregate elasticity will depend on the demographic structure of the economy as well as the distribution of wealth and the particular point in the business cycle.","['Attanasio, Orazio', 'Levell, Peter', 'Sanchez-Marcos, Virginia', 'Low, Hamish']","['Model Construction and Estimation', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Business Fluctuations; Cycles', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials']","['C51', 'D15', 'E32', 'J16', 'J22', 'J31']",Aggregating Elasticities: Intensive and Extensive Margins of Women's Labor Supply,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"We prove that a subtle but substantial bias exists in a common measure of the conditional dependence of present outcomes on streaks of past outcomes in sequential data. The magnitude of this streak selection bias generally decreases as the sequence gets longer, but increases in streak length, and remains substantial for a range of sequence lengths often used in empirical work. We observe that the canonical study in the influential hot hand fallacy literature, along with replications, are vulnerable to the bias. Upon correcting for the bias, we find that the longstanding conclusions of the canonical study are reversed.","['Sanjurjo, Adam', 'Miller, Joshua B.']",['Econometric and Statistical Methods and Methodology: General'],['C10'],Surprised by the Hot Hand Fallacy? A Truth in the Law of Small Numbers,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"It is generally difficult to know whether the parameters in nonlinear econometric models are point-identified. We provide computationally attractive procedures to construct confidence sets (CSs) for identified sets of the full parameter vector and of subvectors in models defined through a likelihood or a vector of moment equalities or inequalities. The CSs are based on level sets of ""optimal"" criterion functions (such as likelihoods, optimally-weighted or continuously-updated GMM criterions). The level sets are constructed using cutoffs that are computed via Monte Carlo (MC) simulations from the quasi-posterior distribution of the criterion. We establish new Bernstein-von Mises (or Bayesian Wilks) type theorems for the quasi-posterior distributions of the quasi-likelihood ratio (QLR) and profile QLR in partially-identified models. These results imply that our MC CSs have exact asymptotic frequentist coverage for identified sets of full parameters and of subvectors in partially-identified regular models, and have valid but potentially conservative coverage in models whose local tangent spaces are convex cones. Further, our MC CSs for identified sets of subvectors are shown to have exact asymptotic coverage in models with singularities. We provide local power properties and uniform validity of our CSs over classes of DGPs that include point- and partially-identified models. Finally, we present two simulation experiments and two empirical examples: an airline entry game and a model of trade flows.","['Tamer, Elie', 'Chen, Xiaohong', 'Christensen, Timothy M.']","['Single Equation Models; Single Variables: General', 'Empirical Studies of Trade', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Air Transportation']","['C20', 'F14', 'L11', 'L93']",Monte Carlo Confidence Sets for Identified Sets,1,0,0,0,0,2018,11,01
86,6,2018-11-01,"Multivalued treatment models have typically been studied under restrictive assumptions: ordered choice, and more recently, unordered monotonicity. We show how treatment effects can be identified in a more general class of models that allows for multidimensional unobserved heterogeneity. Our results rely on two main assumptions: treatment assignment must be a measurable function of threshold-crossing rules, and enough continuous instruments must be available. We illustrate our approach for several classes of models.","['Lee, Sokbae', 'Salanie, Bernard']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C21', 'C31']",Identifying Effects of Multivalued Treatments,0,0,0,0,0,2018,11,01
86,6,2018-11-01,"The partial (ceteris paribus) effects of interest in nonlinear and interactive linear models are heterogeneous as they can vary dramatically with the underlying observed or unobserved covariates. Despite the apparent importance of heterogeneity, a common practice in modern empirical work is to largely ignore it by reporting average partial effects (or, at best, average effects for some groups). While average effects provide very convenient scalar summaries of typical effects, by definition they fail to reflect the entire variety of the heterogeneous effects. In order to discover these effects much more fully, we propose to estimate and report sorted effects--a collection of estimated partial effects sorted in increasing order and indexed by percentiles. By construction, the sorted effect curves completely represent and help visualize the range of the heterogeneous effects in one plot. They are as convenient and easy to report in practice as the conventional average partial effects. They also serve as a basis for classification analysis, where we divide the observational units into most or least affected groups and summarize their characteristics. We provide a quantification of uncertainty (standard errors and confidence bands) for the estimated sorted effects and related classification analysis, and provide confidence sets for the most and least affected groups. The derived statistical results rely on establishing key, new mathematical results on Hadamard differentiability of a multivariate sorting operator and a related classification operator, which are of independent interest. We apply the sorted effects method and classification analysis to demonstrate several striking patterns in the gender wage gap. We find that this gap is particularly strong for married women, ranging from -60% to 0% between the 2% and 98% percentiles, as a function of observed and unobserved characteristics; while the gap for never married women ranges from -40% to +20%. The most adversely affected women tend to be married, do not have college degrees, work in sales, and have high levels of potential experience.","['Chernozhukov, Victor', 'Luo, Ye', 'Fernandez-Val, Ivan']","['Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models', 'Economics of Gender; Non-labor Discrimination', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C38', 'J16', 'J24', 'J31']",The Sorted Effects Method: Discovering Heterogeneous Effects beyond Their Averages,0,0,0,0,0,2018,11,01
86,6,2018-11-01,This paper develops and implements a nonparametric test of random utility models. The motivating application is to test the null hypothesis that a sample of cross-sectional demand distributions was generated by a population of rational consumers. We test a necessary and sufficient condition for this that does not restrict unobserved heterogeneity or the number of goods. We also propose and implement a control function approach to account for endogenous expenditure. An econometric result of independent interest is a test for linear inequality constraints when these are represented as the vertices of a polyhedral cone rather than its faces. An empirical application to the U.K. Household Expenditure Survey illustrates computational feasibility of the method in demand problems with five goods.,"['Stoye, Jorg', 'Kitamura, Yuichi']","['Semiparametric and Nonparametric Methods: General', 'Model Evaluation, Validation, and Selection', 'Consumer Economics: Empirical Analysis']","['C14', 'C52', 'D12']",Nonparametric Analysis of Random Utility Models,0,0,0,0,0,2018,11,01
86,5,2018-09-01,ECONLIT None Found,[nan],[nan],[nan],2017 Election of Fellows to the Econometric Society.,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"More and more economists are finding both empirical and experimental evidence of economic behavior that is well beyond classical economics. In particular, empirical evidence (Jullien and Salanie (2000)) and experimental evidence (Kahneman and Tversky (1979)) supported the importance of risk loving, ambiguity loving, and related behavior in economics. However, these types of preferences have not been analyzed in the general equilibrium literature with a finite number of agents because non-convexity of preferences creates difficulty in proving existence of equilibrium. The main result in this paper provides a set of conditions under which equilibrium exists in such economies.","['Chateauneuf, Alain', 'Novinski, Rodrigo', 'Araujo, Aloisio', 'Gama, Juan Pablo']","['General Equilibrium and Disequilibrium: Financial Markets', 'Criteria for Decision-Making under Risk and Uncertainty']","['D53', 'D81']",General Equilibrium with Uncertainty Loving Preferences,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"Measurements of ambiguity attitudes have so far focused on artificial events, where (subjective) beliefs can be derived from symmetry of events and can be then controlled for. For natural events as relevant in applications, such a symmetry and corresponding control are usually absent, precluding traditional measurement methods. This paper introduces two indexes of ambiguity attitudes, one for aversion and the other for insensitivity/perception, for which we can control for likelihood beliefs even if these are unknown. Hence, we can now measure ambiguity attitudes for natural events. Our indexes are valid under many ambiguity theories, do not require expected utility for risk, and are easy to elicit in practice. We use our indexes to investigate time pressure under ambiguity. People do not become more ambiguity averse under time pressure but become more insensitive (perceive more ambiguity). These findings are plausible and, hence, support the validity of our indexes.","['Huang, Zhenxing', 'Wakker, Peter P.', 'Baillon, Aurelien', 'Selim, Asli']","['Criteria for Decision-Making under Risk and Uncertainty', 'Portfolio Choice; Investment Decisions', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D81', 'G11', 'G14']",Measuring Ambiguity Attitudes for All (Natural) Events,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"This paper analyzes a general equilibrium economy featuring input-output connections, imperfect competition, and external economies of scale owing to entry and exit. The interaction of input-output networks with industry-level market structure affects the amplification of shocks and the pattern of diffusion in the model, generating cascades of firm entry and exit across the economy. In this model, sales provide a poor measure of the systemic importance of industries. Unlike the relevant notions of centrality in competitive constant-returns-to-scale models, systemic importance depends on the industry's role as both a supplier and a consumer of inputs, as well as the market structure of industries. A basic calibration of the model suggests that aggregate output is three times more volatile in response to labor productivity shocks when compared to a perfectly competitive model.","['Baqaee, David Rezza']","['Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Network Formation and Analysis: Theory', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Transactional Relationships; Contracts and Reputation; Networks', 'Contracting Out; Joint Ventures; Technology Licensing']","['D21', 'D24', 'D85', 'J24', 'L14', 'L24']",Cascading Failures in Production Networks,1,0,0,0,0,2018,09,01
86,5,2018-09-01,"In the unconditional moment restriction model of Hansen (1982), specification tests and more efficient estimators are both available whenever the number of moment restrictions exceeds the number of parameters of interest. We show that a similar relationship between potential refutability of a model and existence of more efficient estimators is present in much broader settings. Specifically, a condition we name local overidentification is shown to be equivalent to both the existence of specification tests with nontrivial local power and the existence of more efficient estimators of some ""smooth"" parameters in general semi/nonparametric models. Under our notion of local overidentification, various locally nontrivial specification tests such as Hausman tests, incremental Sargan tests (or optimally weighted quasi likelihood ratio tests) naturally extend to general semi/nonparametric settings. We further obtain simple characterizations of local overidentification for general models of nonparametric conditional moment restrictions with possibly different conditioning sets. The results are applied to determining when semi/nonparametric models with endogeneity are locally testable, and when nonparametric plug-in and semiparametric two-step GMM estimators are semiparametrically efficient. Examples of empirically relevant semi/nonparametric structural models are presented.","['Santos, Andres', 'Chen, Xiaohong']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General', 'Model Construction and Estimation']","['C13', 'C14', 'C51']",Overidentification in Regular Models,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"We propose a model of trade in over-the-counter (OTC) markets in which each dealer with private information can engage in bilateral transactions with other dealers, as determined by her links in a network. Each dealer's strategy is represented as a quantity-price schedule. We analyze the effect of trade decentralization and adverse selection on information diffusion, expected profits, trading costs, and welfare. Information diffusion through prices is not affected by dealers' strategic trading motives, and there is an informational externality that constrains the informativeness of prices. Trade decentralization can both increase or decrease welfare. A dealer's trading cost is driven by both her own and her counterparties' centrality. Central dealers tend to learn more, trade more at lower costs, and earn higher expected profit.","['Babus, Ana', 'Kondor, Peter']","['Asymmetric and Private Information; Mechanism Design', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Investment Banking; Venture Capital; Brokerage; Ratings and Ratings Agencies']","['D82', nan, 'G14', 'G24']",Trading and Information Diffusion in Over-the-Counter Markets,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"We develop a tractable method for augmenting macroeconomic models with autonomous variation in higher-order beliefs. We use this to accommodate a certain type of waves of optimism and pessimism that can be interpreted as the product of frictional coordination and, unlike the one featured in the news literature, regards the short-term economic outlook rather than the medium- to long-run prospects. We show that this enrichment provides a parsimonious explanation of salient features of the data; it accounts for a significant fraction of the business-cycle volatility in estimated models that allow for various competing structural shocks; and it captures a type of fluctuations that have a Keynesian flavor but do not rely on nominal rigidities.","['Angeletos, George-Marios', 'Dellas, Harris', 'Collard, Fabrice']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Business Fluctuations; Cycles']","['D83', nan, 'E32']",Quantifying Confidence,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"We study commodity taxation and characterize the Laffer curve, a trade-off between tax rates and revenue, in noncompetitive markets. Pricing in these markets leads to incomplete tax pass-through and agents re optimize their purchase and pricing decisions in response to any tax change. We use detailed data from Pennsylvania, a state that monopolizes retail sales of alcoholic beverages, to estimate a model of demand for horizontally differentiated products that ties consumers' demographic characteristics to heterogeneous preferences for spirits. We find that under the state's current tax policy, spirits are overpriced. Distillers respond to decreases in the tax rate by increasing wholesale prices, which limits the state's revenue gain to only 13% of the incremental tax revenue predicted under the common assumption of perfect competition. The strategic response of noncompetitive firms to changes in taxation therefore flattens the Laffer curve significantly.","['Miravete, Eugenio J.', 'Seim, Katja', 'Thurk, Jeff']","['Business Taxes and Subsidies including sales and value-added (VAT)', 'State and Local Taxation, Subsidies, and Revenue', 'Public Enterprises; Public-Private Enterprises', 'Food; Beverages; Cosmetics; Tobacco; Wine and Spirits']","['H25', 'H71', 'L32', 'L66']",Market Power and the Laffer Curve,1,0,0,0,0,2018,09,01
86,5,2018-09-01,"In French parliamentary and local elections, candidates ranked first and second in the first round automatically qualify for the second round, while a third candidate qualifies only when selected by more than 12.5 percent of registered citizens. Using a fuzzy RDD around this threshold, we find that the third candidate's presence substantially increases the share of registered citizens who vote for any candidate and reduces the vote share of the top two candidates. It disproportionately harms the candidate ideologically closest to the third and causes her defeat in one fifth of the races. Additional evidence suggests that these results are driven by voters who value voting expressively over voting strategically for the top-two candidate they dislike the least to ensure her victory; and by third candidates who, absent party-level agreements leading to their dropping out, value the benefits associated with competing in the second round more than influencing its outcome.","['Tricaud, Clemence', 'Pons, Vincent']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']",['D72'],Expressive Voting and Its Cost: Evidence from Runoffs with Two or Three Candidates,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"We propose a method for using instrumental variables (IV) to draw inference about causal effects for individuals other than those affected by the instrument at hand. Policy relevance and external validity turn on the ability to do this reliably. Our method exploits the insight that both the IV estimand and many treatment parameters can be expressed as weighted averages of the same underlying marginal treatment effects. Since the weights are identified, knowledge of the IV estimand generally places some restrictions on the unknown marginal treatment effects, and hence on the values of the treatment parameters of interest. We show how to extract information about the treatment parameter of interest from the IV estimand and, more generally, from a class of IV-like estimands that includes the two stage least squares and ordinary least squares estimands, among others. Our method has several applications. First, it can be used to construct nonparametric bounds on the average causal effect of a hypothetical policy change. Second, our method allows the researcher to flexibly incorporate shape restrictions and parametric assumptions, thereby enabling extrapolation of the average effects for compliers to the average effects for different or larger populations. Third, our method can be used to test model specification and hypotheses about behavior, such as no selection bias and/or no selection on gain.","['Mogstad, Magne', 'Torgovitsky, Alexander', 'Santos, Andres']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C21', 'C26']",Using Instrumental Variables for Inference about Policy Relevant Treatment Parameters,0,0,0,0,0,2018,09,01
86,5,2018-09-01,"I construct an informationally robust auction to sell a common-value good. I examine the revenue guarantee of an auction over all information structures of bidders and all equilibria. As the number of bidders gets large, the revenue guarantee of my auction converges to the full surplus, regardless of how information changes as more bidders are added. My auction also maximizes the revenue guarantee when there is a single bidder.","['Du, Songzi']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Robust Mechanisms under Common Valuation,0,0,1,0,0,2018,09,01
86,5,2018-09-01,"The most critical issue in evaluating policies and projects that affect generations of individuals is the choice of social discount rate. This paper shows that there exist social discount rates such that the planner can simultaneously be (i) an exponential discounting expected utility maximizer; (ii) intergenerationally Pareto--that is, if all individuals from all generations prefer one policy/project to another, the planner agrees; and (iii) strongly non-dictatorial--that is, no individual from any generation is ignored. Moreover, to satisfy (i)-(iii), if the time horizon is long enough, it is generically sufficient and necessary for social discounting to be more patient than the most patient individual's long-run discounting, independent of the social risk attitude.","['Ke, Shaowei', 'Feng, Tangren']","['Allocative Efficiency; Cost-Benefit Analysis', 'Project Evaluation; Social Discount Rate']","['D61', 'H43']",Social Discounting and Intergenerational Pareto,0,0,0,0,0,2018,09,01
86,4,2018-07-01,"de Groot, Richter, and Throckmorton, 2018 argue that the model in Basu and Bundick, 2017 can match the empirical evidence only because the model assumes an asymptote in the economy's response to an uncertainty shock. In this Reply, we provide new results showing that our model's ability to match the data does not rely either on assuming preferences that imply an asymptote nor on a particular value of the intertemporal elasticity of substitution. We demonstrate that shifting to preferences that are not vulnerable to the Comment's critique does not change our previous conclusions about the propagation of uncertainty shocks to macroeconomic outcomes.","['Bundick, Brent', 'Basu, Susanto']","['Criteria for Decision-Making under Risk and Uncertainty', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Financial Markets and the Macroeconomy', 'Monetary Policy']","['D81', 'E24', 'E32', 'E43', 'E44', 'E52']",Uncertainty Shocks in a Model of Effective Demand: Reply,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"Basu and Bundick, 2017 showed an intertemporal preference volatility shock has meaningful effects on real activity in a New Keynesian model with Epstein and Zin, 1991 preferences. We show that when the distributional weights on current and future utility in the Epstein-Zin time aggregator do not sum to 1, there is an asymptote in the responses to such a shock with unit intertemporal elasticity of substitution. In the Basu-Bundick model, the intertemporal elasticity of substitution is set near unity and the preference shock only hits current utility, so the sum of the weights differs from 1. We show that when we restrict the weights to sum to 1, the asymptote disappears and preference volatility shocks no longer have large effects. We examine several different calibrations and preferences as potential resolutions with varying degrees of success.","['Throckmorton, Nathaniel A.', 'de Groot, Oliver', 'Richter, Alexander W.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Financial Markets and the Macroeconomy', 'Monetary Policy']","['D81', 'E24', 'E32', 'E43', 'E44', 'E52']",Uncertainty Shocks in a Model of Effective Demand: Comment,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"This paper provides an alternative approach to penalized regression for model selection in the context of high-dimensional linear regressions where the number of covariates is large, often much larger than the number of available observations. We consider the statistical significance of individual covariates one at a time, while taking full account of the multiple testing nature of the inferential problem involved. We refer to the proposed method as One Covariate at a Time Multiple Testing (OCMT) procedure, and use ideas from the multiple testing literature to control the probability of selecting the approximating model, the false positive rate, and the false discovery rate. OCMT is easy to interpret, relates to classical statistical analysis, is valid under general assumptions, is faster to compute, and performs well in small samples. The usefulness of OCMT is also illustrated by an empirical application to forecasting U.S. output growth and inflation.","['Kapetanios, G.', 'Pesaran, M. Hashem', 'Chudik, A.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Evaluation, Validation, and Selection', 'Forecasting Models; Simulation Methods', 'Macroeconomics: Production', 'Macroeconomics: Consumption, Saving, Production, Employment, and Investment: Forecasting and Simulation: Models and Applications', 'Price Level; Inflation; Deflation', 'Prices, Business Fluctuations, and Cycles: Forecasting and Simulation: Models and Applications']","['C22', 'C52', 'C53', 'E23', 'E27', 'E31', 'E37']","A One Covariate at a Time, Multiple Testing Approach to Variable Selection in High-Dimensional Linear Regression Models",0,0,0,0,0,2018,07,01
86,4,2018-07-01,"Johansen's (1988,1991) likelihood ratio test for cointegration rank of a vector autoregression (VAR) depends only on the squared sample canonical correlations between current changes and past levels of a simple transformation of the data. We study the asymptotic behavior of the empirical distribution of those squared canonical correlations when the number of observations and the dimensionality of the VAR diverge to infinity simultaneously and proportionally. We find that the distribution weakly converges to the so-called Wachter distribution. This finding provides a theoretical explanation for the observed tendency of Johansen's test to find ""spurious cointegration.""","['Onatski, Alexei', 'Wang, Chen']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Specific Distributions; Specific Statistics']","['C32', 'C46']",Alternative Asymptotics for Cointegration Tests in Large VARs,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"We analyze dynamic trading by an activist investor who can expend costly effort to affect firm value. We obtain the equilibrium in closed form for a general activism technology, including both binary and continuous outcomes. Variation in parameters can produce either positive or negative relations between market liquidity and economic efficiency, depending on the activism technology and model parameters. Two results that contrast with the previous literature are that (a) the relationship between market liquidity and economic efficiency is independent of the activist's initial stake for a broad set of activism technologies, and (b) an increase in noise trading can reduce market liquidity because it increases uncertainty about the activist's trades (the activist trades in the opposite direction of noise traders) and thereby increases information asymmetry about the activist's intentions.","['Fos, Vyacheslav', 'Collin-Dufresne, Pierre', 'Back, Kerry', 'Ljungqvist, Alexander', 'Li, Tao']","['Household Saving; Personal Finance', 'Asymmetric and Private Information; Mechanism Design', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['D14', 'D82', nan, 'G14', 'G32']","Activism, Strategic Trading, and Liquidity",0,0,0,0,0,2018,07,01
86,4,2018-07-01,"This paper develops a revealed preference theory for the equity premium around macroeconomic announcements. Stock returns realized around pre-scheduled macroeconomic announcements, such as the employment report and the FOMC statements, account for 55% of the market equity premium. We provide a characterization theorem for the set of intertemporal preferences that generates a nonnegative announcement premium. Our theory establishes that the announcement premium identifies a significant deviation from time-separable expected utility and provides asset-market-based evidence for a large class of non-expected utility models. We also provide conditions under which asset prices may rise prior to some macroeconomic announcements and exhibit a pre-announcement drift.","['Ai, Hengjie', 'Bansal, Ravi']","['Criteria for Decision-Making under Risk and Uncertainty', 'Monetary Policy', 'Central Banks and Their Policies', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D81', 'E52', 'E58', nan, 'G14']",Risk Preferences and the Macroeconomic Announcement Premium,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"To study intertemporal decisions under risk, we develop a new recursive model of non-expected-utility preferences. The main axiom of our analysis is called mixture aversion, as it captures a dislike of probabilistic mixtures of lotteries. Our representation for mixture-averse preferences can be interpreted as if an individual optimally selects her risk attitude from some feasible set. We describe some useful parametric examples of our representation and provide comparative statics that tightly link decreases in risk aversion to larger sets of feasible risk attitudes. We then present several applications of the model. In an insurance problem, mixture-averse preferences can produce a marginal willingness to pay for insurance coverage that increases in the level of existing coverage. In investment decisions, our model can generate endogenous heterogeneity in equilibrium stock market participation, even when consumers have identical preferences. Finally, we demonstrate that our model can address the Rabin paradox even in the presence of reasonable levels of background risk.","['Sarver, Todd']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Criteria for Decision-Making under Risk and Uncertainty', 'Portfolio Choice; Investment Decisions', 'Insurance; Insurance Companies; Actuarial Studies']","['D15', 'D81', 'G11', 'G22']",Dynamic Mixture-Averse Preferences,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"We study the problem of resolving conflicting discount rates via a social choice approach. We introduce several axioms, seeking to capture the tension between allowing for intergenerational comparisons of utility, and imposing intergenerational fairness. Depending on which axioms are judged appropriate, we are led to one of several conclusions: a utilitarian, maxmin, or a multi-utilitarian rule, whereby a utility stream is judged by the worst in a set of utilitarian weighting schemes across discount rates.","['Echenique, Federico', 'Chambers, Christopher P.']","['Allocative Efficiency; Cost-Benefit Analysis', 'Social Choice; Clubs; Committees; Associations', 'Project Evaluation; Social Discount Rate', 'Valuation of Environmental Effects', 'Climate; Natural Disasters and Their Management; Global Warming']","['D61', 'D71', 'H43', 'Q51', 'Q54']",On Multiple Discount Rates,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"Conjugate duality relationships are pervasive in matching and implementation problems and provide much of the structure essential for characterizing stable matches and implementable allocations in models with quasilinear (or transferable) utility. In the absence of quasilinearity, a more abstract duality relationship, known as a Galois connection, takes the role of (generalized) conjugate duality. While weaker, this duality relationship still induces substantial structure. We show that this structure can be used to extend existing results for, and gain new insights into, adverse-selection principal-agent problems and two-sided matching problems without quasilinearity.","['Noldeke, Georg', 'Samuelson, Larry']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",The Implementation Duality,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"We consider an oligopoly model in which consumers engage in sequential search based on partial product information and advertised prices. By applying Weitzman's (1979) optimal sequential search solution, we derive a simple static condition that fully summarizes consumers' shopping outcomes and translates the pricing game among the sellers into a familiar discrete-choice problem. Exploiting the discrete-choice reformulation, we provide sufficient conditions that guarantee the existence and uniqueness of market equilibrium and analyze the effects of preference diversity and search frictions on market prices. Among other things, we show that a reduction in search costs raises market prices.","['Kim, Kyungmin', 'Dai, Anovia Yifan', 'Choi, Michael']","['Consumer Economics: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Advertising']","['D11', 'D43', 'D83', 'M37']",Consumer Search and Price Competition,0,0,1,0,0,2018,07,01
86,4,2018-07-01,"Which equilibria will arise in signaling games depends on how the receiver interprets deviations from the path of play. We develop a micro-foundation for these off-path beliefs, and an associated equilibrium refinement, in a model where equilibrium arises through non-equilibrium learning by populations of patient and long-lived senders and receivers. In our model, young senders are uncertain about the prevailing distribution of play, so they rationally send out-of-equilibrium signals as experiments to learn about the behavior of the population of receivers. Differences in the payoff functions of the types of senders generate different incentives for these experiments. Using the Gittins index (Gittins (1979)), we characterize which sender types use each signal more often, leading to a constraint on the receiver's off-path beliefs based on ""type compatibility"" and hence a learning-based equilibrium selection.","['Fudenberg, Drew', 'He, Kevin']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'C78', 'D82']",Learning and Type Compatibility in Signaling Games,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"We explore the learning process and behavior of an individual with unrealistically high expectations (overconfidence) when outcomes also depend on an external fundamental that affects the optimal action. Moving beyond existing results in the literature, we show that the agent's beliefs regarding the fundamental converge under weak conditions. Furthermore, we identify a broad class of situations in which ""learning"" about the fundamental is self-defeating: it leads the individual systematically away from the correct belief and toward lower performance. Due to his overconfidence, the agent--even if initially correct--becomes too pessimistic about the fundamental. As he adjusts his behavior in response, he lowers outcomes and hence becomes even more pessimistic about the fundamental, perpetuating the misdirected learning. The greater is the loss from choosing a suboptimal action, the further the agent's action ends up from optimal. We partially characterize environments in which self-defeating learning occurs, and show that the decision maker learns to take the optimal action if, and in a sense only if, a specific non-identifiability condition is satisfied. In contrast to an overconfident agent, an under confident agent's misdirected learning is self-limiting and therefore not very harmful. We argue that the decision situations in question are common in economic settings, including delegation, organizational, effort, and public-policy choices.","['Koszegi, Botond', 'Heidhues, Paul', 'Strack, Philipp']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations']","['D83', 'D84']",Unrealistic Expectations and Misguided Learning,0,0,0,0,0,2018,07,01
86,4,2018-07-01,"We study trading behavior and the properties of prices in informationally complex markets. Our model is based on the single-period version of the linear-normal framework of Kyle (1985). We allow for essentially arbitrary correlations among the random variables involved in the model: the value of the traded asset, the signals of strategic traders and competitive market makers, and the demand from liquidity traders. We show that there always exists a unique linear equilibrium, characterize it analytically, and illustrate its properties with a number of applications. We then use this characterization to study the informational efficiency of prices as the number of strategic traders becomes large. If liquidity demand is positively correlated (or uncorrelated) with the asset value, then prices in large markets aggregate all available information. If liquidity demand is negatively correlated with the asset value, then prices in large markets aggregate all information except that contained in liquidity demand.","['Panov, Mikhail', 'Lambert, Nicolas S.', 'Ostrovsky, Michael']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D43', 'D83', 'D84', nan, 'G14']",Strategic Trading in Informationally Complex Environments,0,0,1,0,0,2018,07,01
86,3,2018-05-01,"We analyze trading speed and fragmentation in asset markets. In our model, trading venues make technological investments and compete for investors who choose where and how much to trade. Faster venues charge higher fees and attract speed-sensitive investors. Competition among venues increases investor participation, trading volume, and allocative efficiency, but entry and fragmentation can be excessive, and speeds are generically inefficient. Regulations that protect transaction prices (e.g., Securities and Exchange Commission trade-through rule) lead to greater fragmentation. Our model sheds light on the experience of European and U.S. markets since the implementation of Markets in Financial Instruments Directive and Regulation National Markets System.","['Pagnotta, Emiliano S.', 'Philippon, Thomas']","['Market Structure, Pricing, and Design: Monopoly', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading', 'General Financial Markets: Government Policy and Regulation']","['D42', 'D43', nan, 'G14', 'G18']",Competing on Speed,0,0,1,0,0,2018,05,01
86,3,2018-05-01,"We investigate the role of uncertainty in business cycles. First, we demonstrate that microeconomic uncertainty rises sharply during recessions, including during the Great Recession of 2007-2009. Second, we show that uncertainty shocks can generate drops in gross domestic product of around 2.5% in a dynamic stochastic general equilibrium model with heterogeneous firms. However, we also find that uncertainty shocks need to be supplemented by first-moment shocks to fit consumption over the cycle. So our data and simulations suggest recessions are best modelled as being driven by shocks with a negative first moment and a positive second moment. Finally, we show that increased uncertainty can make first-moment policies, like wage subsidies, temporarily less effective because firms become more cautious in responding to price changes.","['Bloom, Nicholas', 'Terry, Stephen J.', 'Floetotto, Max', 'Jaimovich, Nir', 'Saporta-Eksten, Itay']","['Criteria for Decision-Making under Risk and Uncertainty', 'Business Fluctuations; Cycles', 'Financial Crises']","['D81', 'E32', 'G01']",Really Uncertain Business Cycles,0,0,0,0,0,2018,05,01
86,3,2018-05-01,"Work schedules play an important role in utilizing labor in organizations. In this study of emergency department physicians in shift work, schedules induce two distortions: First, physicians ""slack off"" by accepting fewer patients near end of shift (EOS). Second, physicians distort patient care, incurring higher costs as they spend less time on patients assigned near EOS. Examining how these effects change with shift overlap reveals a tradeoff between the two. Within an hour after the normal time of work completion, physicians are willing to spend hospital resources more than six times their market wage to preserve their leisure. Accounting for overall costs, I find that physicians slack off at approximately second-best optimal levels.","['Chan, David C.']","['Analysis of Health Care Markets', 'Time Allocation and Labor Supply', 'Professional Labor Markets; Occupational Licensing', 'Personnel Economics: Labor Management']","['I11', 'J22', 'J44', 'M54']",The Efficiency of Slacking Off: Evidence from the Emergency Department,0,0,0,0,0,2018,05,01
86,3,2018-05-01,"This paper develops asymptotic approximations for kernel-based semiparametric estimators under assumptions accommodating slower-than-usual rates of convergence of their nonparametric ingredients. Our first main result is a distributional approximation for semiparametric estimators that differs from existing approximations by accounting for a bias. This bias is nonnegligible in general, and therefore poses a challenge for inference. Our second main result shows that some (but not all) nonparametric bootstrap distributional approximations provide an automatic method of correcting for the bias. Our general theory is illustrated by means of examples and its main finite sample implications are corroborated in a simulation study.","['Cattaneo, Matias D.', 'Jansson, Michael']","['Semiparametric and Nonparametric Methods: General', 'Statistical Simulation Methods: General']","['C14', 'C15']",Kernel-Based Semiparametric Estimators: Small Bandwidth Asymptotics and Bootstrap Consistency,0,0,0,0,0,2018,05,01
86,3,2018-05-01,"We investigate the welfare effects of vertical integration of regional sports networks (RSNs) with programming distributors in U.S. multichannel television markets. Vertical integration can enhance efficiency by reducing double marginalization and increasing carriage of channels, but can also harm welfare due to foreclosure and incentives to raise rivals' costs. We estimate a structural model of viewership, subscription, distributor pricing, and affiliate fee bargaining using a rich data set on the U.S. cable and satellite television industry (2000-2010). We use these estimates to analyze the impact of simulated vertical mergers and divestitures of RSNs on competition and welfare, and examine the efficacy of regulatory policies introduced by the U.S. Federal Communications Commission to address competition concerns in this industry.","['Whinston, Michael D.', 'Yurukoglu, Ali', 'Lee, Robin S.', 'Crawford, Gregory S.']","['Antitrust Law', 'Firm Organization and Market Structure', 'Vertical Restraints; Resale Price Maintenance; Quantity Discounts', 'Entertainment; Media', 'Sports Economics: Industry Studies']","['K21', 'L22', 'L42', 'L82', 'Z21']",The Welfare Effects of Vertical Integration in Multichannel Television Markets,1,1,0,0,0,2018,05,01
86,3,2018-05-01,"Unlike present-biased individuals, agents who suffer self-control costs as in Gul and Pesendorfer, 2001 may choose to restrict their choice set even when they expect to resist temptation. To identify these self-control types, I design an experiment in which the temptation was to read a story during a tedious task. The identification strategy relies on a two-step procedure. First, I measure commitment demand by eliciting subjects' preferences over menus that did or did not allow access to the story. I then implement preferences using a random mechanism, allowing to observe subjects who faced the choice yet preferred commitment. A quarter to a third of subjects can be classified as self-control types according to their menu preferences. When confronted with the choice, virtually all of them behaved as they anticipated and resisted temptation. These findings suggest that policies restricting the availability of tempting options could have larger welfare benefits than predicted by standard models of present bias.","['Toussaert, Severine']","['Design of Experiments: Laboratory, Individual', 'Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making']","['C91', 'D12', 'D81', 'D83', 'D91']",Eliciting Temptation and Self-Control through Menu Choices: A Lab Experiment,0,0,0,0,0,2018,05,01
86,3,2018-05-01,"Is the standard hyperbolic-discounting model capable of robust qualitative predictions for savings behavior? Despite results suggesting a negative answer, we provide a positive one. We give conditions under which all Markov equilibria display either saving at all wealth levels or dissaving at all wealth levels. Moreover, saving versus dissaving is determined by a simple condition comparing the interest rate to a threshold made up of impatience parameters only. Our robustness results illustrate a well-behaved side of the model and imply that qualitative behavior is determinate, dissipating indeterminacy concerns to the contrary (Krusell and Smith, 2003). We prove by construction that equilibria always exist and that multiplicity is present in some cases, highlighting that our robust predictions are not due to uniqueness. Similar results may be obtainable in related dynamic games, such as political economy models of public spending.","['Cao, Dan', 'Werning, Ivan']","['Existence and Stability Conditions of Equilibrium', 'Household Saving; Personal Finance', 'Macroeconomics: Consumption; Saving; Wealth', 'Interest Rates: Determination, Term Structure, and Effects']","['C62', 'D14', 'E21', 'E43']",Saving and Dissaving with Hyperbolic Discounting,0,0,0,0,0,2018,05,01
86,3,2018-05-01,"We develop inference methods about long-run comovement of two time series. The parameters of interest are defined in terms of population second moments of low-frequency transformations (""low-pass"" filtered versions) of the data. We numerically determine confidence sets that control coverage over a wide range of potential bivariate persistence patterns, which include arbitrary linear combinations of I(0), I(1), near unit roots, and fractionally integrated processes. In an application to U.S. economic data, we quantify the long-run covariability of a variety of series, such as those giving rise to balanced growth, nominal exchange rates and relative nominal prices, the unemployment rate and inflation, money growth and inflation, earnings and stock prices, etc.","['Watson, Mark W.', 'Muller, Ulrich K.']","['Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Macroeconomics: Consumption; Saving; Wealth', 'Macroeconomics: Production', 'Interest Rates: Determination, Term Structure, and Effects', 'Foreign Exchange']","['C13', 'C22', 'E21', 'E23', 'E43', 'F31']",Long-Run Covariability,0,0,0,0,0,2018,05,01
86,2,2018-03-01,"We show how an insight from taxation theory allows identification of both the supply and demand elasticities using only one instrument. Most models of taxation since Ramsey (1927) assume that a tax levied on the demand side only affects demand through the price after taxation. Econometrically, we show that this assumption acts as an exclusion restriction. Under the Ramsey Exclusion Restriction (RER), a single tax reform can serve to simultaneously identify the demand and supply elasticity. We develop an estimation method, which includes 2SLS estimators for the elasticities, and a test for strength of the instrument. We discuss possible applications.","['Zoutman, Floris T.', 'Hopland, Arnt O.', 'Gavrilova, Evelina']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Model Construction and Estimation', 'Taxation and Subsidies: Incidence', 'Business Taxes and Subsidies including sales and value-added (VAT)']","['C23', 'C51', 'H22', 'H25']",Estimating Both Supply and Demand Elasticities Using Variation in a Single Tax Rate,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"This paper proposes a new semi-parametric identification and estimation approach to multinomial choice models in a panel data setting with individual fixed effects. Our approach is based on cyclic monotonicity, which is a defining convex-analytic feature of the random utility framework underlying multinomial choice models. From the cyclic monotonicity property, we derive identifying inequalities without requiring any shape restrictions for the distribution of the random utility shocks. These inequalities point identify model parameters under straightforward assumptions on the covariates. We propose a consistent estimator based on these inequalities.","['Song, Wei', 'Shi, Xiaoxia', 'Shum, Matthew']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Consumer Economics: Empirical Analysis', 'Retail and Wholesale Trade; e-Commerce']","['C23', 'D12', 'L81']",Estimating Semi-parametric Panel Multinomial Choice Models Using Cyclic Monotonicity,1,0,0,0,0,2018,03,01
86,2,2018-03-01,"This paper develops a simple model of firm entry, competition, and exit in oligopolistic markets. It features toughness of competition, sunk entry costs, and market-level demand and cost shocks, but assumes that firms' expected payoffs are identical when entry and survival decisions are made. We prove that this model has an essentially unique symmetric Markov-perfect equilibrium, and we provide an algorithm for its computation. Because this algorithm only requires finding the fixed points of a finite sequence of contraction mappings, it is guaranteed to converge quickly.","['Yang, Nan', 'Tilly, Jan', 'Abbring, Jaap H.', 'Campbell, Jeffrey R.']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D21', 'D43', 'L13']",Very Simple Markov-Perfect Industry Dynamics: Theory,1,0,1,0,0,2018,03,01
86,2,2018-03-01,"In this paper, we develop algorithms to independently draw from a family of conjugate posterior distributions over the structural parameterization when sign and zero restrictions are used to identify structural vector autoregressions (SVARs). We call this family of conjugate posteriors normal-generalized-normal. Our algorithms draw from a conjugate uniform-normal-inverse-Wishart posterior over the orthogonal reduced-form parameterization and transform the draws into the structural parameterization; this transformation induces a normal-generalized-normal posterior over the structural parameterization. The uniform-normal-inverse-Wishart posterior over the orthogonal reduced-form parameterization has been prominent after the work of Uhlig (2005). We use Beaudry, Nam, and Wang's (2011) work on the relevance of optimism shocks to show the dangers of using alternative approaches to implementing sign and zero restrictions to identify SVARs like the penalty function approach. In particular, we analytically show that the penalty function approach adds restrictions to the ones described in the identification scheme.","['Rubio-Ramirez, Juan F.', 'Waggoner, Daniel F.', 'Arias, Jonas E.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Inference Based on Structural Vector Autoregressions Identified with Sign and Zero Restrictions: Theory and Applications,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"We consider the problem of constructing confidence intervals (CIs) for a linear functional of a regression function, such as its value at a point, the regression discontinuity parameter, or a regression coefficient in a linear or partly linear regression. Our main assumption is that the regression function is known to lie in a convex function class, which covers most smoothness and/or shape assumptions used in econometrics. We derive finite-sample optimal CIs and sharp efficiency bounds under normal errors with known variance. We show that these results translate to uniform (over the function class) asymptotic results when the error distribution is not known. When the function class is centrosymmetric, these efficiency bounds imply that minimax CIs are close to efficient at smooth regression functions. This implies, in particular, that it is impossible to form CIs that are substantively tighter using data-dependent tuning parameters, and maintain coverage over the whole function class. We specialize our results to inference on the regression discontinuity parameter, and illustrate them in simulations and an empirical application.","['Kolesar, Michal', 'Armstrong, Timothy B.']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: General', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['C13', 'C14', 'C20', 'D72']",Optimal Inference in a Class of Regression Models,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"We document that consumption growth rates are far from i.i.d. and have a highly persistent component. First, we estimate univariate and multivariate models of cash-flow (consumption, output, dividends) growth that feature measurement errors, time-varying volatilities, and mixed-frequency observations. Monthly consumption data are important for identifying the stochastic volatility process; yet the data are contaminated, which makes the inclusion of measurement errors essential for identifying the predictable component. Second, we develop a novel state-space model for cash flows and asset prices that imposes the pricing restrictions of a representative-agent endowment economy with recursive preferences. To estimate this model, we use a particle MCMC approach that exploits the conditional linear structure of the approximate equilibrium. Once asset return data are included in the estimation, we find even stronger evidence for the persistent component and are able to identify three volatility processes: the one for the predictable cash-flow component is crucial for asset pricing, whereas the other two are important for tracking the data. Our model generates asset prices that are largely consistent with the data in terms of sample moments and predictability features. The state-space approach allows us to track over time the evolution of the predictable component, the volatility processes, the decomposition of the equity premium into risk factors, and the variance decomposition of asset prices.","['Yaron, Amir', 'Schorfheide, Frank', 'Song, Dongho']","['Model Construction and Estimation', 'Macroeconomics: Consumption; Saving; Wealth', 'Macroeconomics: Production', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Payout Policy']","['C51', 'E21', 'E23', nan, 'G35']",Identifying Long-Run Risks: A Bayesian Mixed-Frequency Approach,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"One of the main objectives of empirical analysis of experiments and quasi-experiments is to inform policy decisions that determine the allocation of treatments to individuals with different observable covariates. We study the properties and implementation of the Empirical Welfare Maximization (EWM) method, which estimates a treatment assignment policy by maximizing the sample analog of average social welfare over a class of candidate treatment policies. The EWM approach is attractive in terms of both statistical performance and practical implementation in realistic settings of policy design. Common features of these settings include: (i) feasible treatment assignment rules are constrained exogenously for ethical, legislative, or political reasons, (ii) a policy maker wants a simple treatment assignment rule based on one or more eligibility scores in order to reduce the dimensionality of individual observable characteristics, and/or (iii) the proportion of individuals who can receive the treatment is a priori limited due to a budget or a capacity constraint. We show that when the propensity score is known, the average social welfare attained by EWM rules converges at least at n^{-1/2} rate to the maximum obtainable welfare uniformly over a minimally constrained class of data distributions, and this uniform convergence rate is minimax optimal. We examine how the uniform convergence rate depends on the richness of the class of candidate decision rules, the distribution of conditional treatment effects, and the lack of knowledge of the propensity score. We offer easily implementable algorithms for computing the EWM rule and an application using experimental data from the National JTPA Study.","['Tetenov, Aleksey', 'Kitagawa, Toru']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Returns to Education', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C21', 'I26', 'J24', 'J31']",Who Should Be Treated? Empirical Welfare Maximization Methods for Treatment Choice,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"Individual producers exhibit enormous heterogeneity in many dimensions. This paper develops a theory in which the network structure of production-who buys inputs from whom-forms endogenously. Entrepreneurs produce using labor and exactly one intermediate input; the key decision is which other entrepreneur's good to use as an input. Their choices collectively determine the economy's equilibrium input-output structure, generating large differences in size and shaping both individual and aggregate productivity. When the elasticity of output to intermediate inputs in production is high, star suppliers emerge endogenously. This raises aggregate productivity as, in equilibrium, more supply chains are routed through higher-productivity techniques.","['Oberfield, Ezra']","['General Equilibrium and Disequilibrium: Input-Output Tables and Analysis', 'Network Formation and Analysis: Theory', 'Transactional Relationships; Contracts and Reputation; Networks', 'Entrepreneurship']","['D57', 'D85', 'L14', 'L26']",A Theory of Input-Output Architecture,1,0,0,0,0,2018,03,01
86,2,2018-03-01,"We develop an aggregative games approach to study oligopolistic price competition with multiproduct firms. We introduce a new class of IIA demand systems, derived from discrete/continuous choice, and nesting CES and logit demands. The associated pricing game with multiproduct firms is aggregative and a firm's optimal price vector can be summarized by a uni-dimensional sufficient statistic, the Iota-markup. We prove existence of equilibrium using a nested fixed-point argument, and provide conditions for equilibrium uniqueness. In equilibrium, firms may choose not to offer some products. We analyze the pricing distortions and provide monotone comparative statics. Under (nested) CES and logit demands, another aggregation property obtains: All relevant information for determining a firm's performance and competitive impact is contained in that firm's uni-dimensional type. We extend the model to nonlinear pricing, quantity competition, general equilibrium, and demand systems with a nest structure. Finally, we discuss applications to merger analysis and international trade.","['Schutz, Nicolas', 'Nocke, Volker']","['Noncooperative Games', 'Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['C72', 'D21', 'D43', 'L13']",Multiproduct-Firm Oligopoly: An Aggregative Games Approach,1,0,1,0,0,2018,03,01
86,2,2018-03-01,"Recent evidence suggests that investors are inattentive to their portfolios and hire expensive portfolio managers. This paper develops a life-cycle portfolio-choice model in which the investor experiences loss-averse utility over news and can ignore his portfolio. In such a model, the investor prefers to ignore and not rebalance his portfolio most of the time because he dislikes bad news more than he likes good news such that expected news causes a first-order decrease in utility. Consequently, the investor has a first-order willingness to pay a portfolio manager who rebalances actively on his behalf. Moreover, the investor can diversify over time and his consumption aligns with predictions of mental accounting. I structurally estimate the preference parameters by matching stock shares and stock-market non-participation over the life cycle. My parameter estimates are in line with the literature, generate reasonable intervals of inattention, and simultaneously explain consumption and wealth accumulation over the life cycle. Here, it matters that news utility preserves first-order risk aversion even in the presence of stochastic labor income, which also causes stock shares to rise in wealth.","['Pagel, Michaela']","['Household Saving; Personal Finance', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Portfolio Choice; Investment Decisions', 'Behavioral Finance: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making in Financial Markets']","['D14', 'D15', 'G11', 'G41']",A News-Utility Theory for Inattention and Delegation in Portfolio Choice,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"This paper studies the behavioral foundations of non-Bayesian models of learning over social networks and develops a taxonomy of conditions for information aggregation in a general framework. As our main behavioral assumption, we postulate that agents follow social learning rules that satisfy ""imperfect recall,"" according to which they treat the current beliefs of their neighbors as sufficient statistics for the entire history of their observations. We augment this assumption with various restrictions on how agents process the information provided by their neighbors and obtain representation theorems for the corresponding learning rules (including the canonical model of DeGroot). We then obtain general long-run learning results that are not tied to the learning rules' specific functional forms, thus identifying the fundamental forces that lead to learning, non-learning, and mislearning in social networks. Our results illustrate that, in the presence of imperfect recall, long-run aggregation of information is closely linked to (i) the rate at which agents discount their neighbors' information over time, (ii) the curvature of agents' social learning rules, and (iii) whether their initial tendencies are amplified or moderated as a result of social interactions.","['Molavi, Pooya', 'Jadbabaie, Ali', 'Tahbaz-Salehi, Alireza']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D83', 'Z13']",A Theory of Non-Bayesian Social Learning,0,0,0,0,0,2018,03,01
86,2,2018-03-01,"Several school districts use assignment systems that give students an incentive to misrepresent their preferences. We find evidence consistent with strategic behavior in Cambridge. Such strategizing can complicate preference analysis. This paper develops empirical methods for studying random utility models in a new and large class of school choice mechanisms. We show that preferences are nonparametrically identified under either sufficient variation in choice environments or a preference shifter. We then develop a tractable estimation procedure and apply it to Cambridge. Estimates suggest that while 83% of students are assigned to their stated first choice, only 72% are assigned to their true first choice because students avoid ranking competitive schools. Assuming that students behave optimally, the Immediate Acceptance mechanism is preferred by the average student to the Deferred Acceptance mechanism by an equivalent of 0.08 miles. The estimated difference is smaller if beliefs are biased, and reversed if students report preferences truthfully.","['Agarwal, Nikhil', 'Somaini, Paulo']","['Model Construction and Estimation', 'State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Education', 'Education: Government Policy']","['C51', 'H75', 'I21', 'I28']",Demand Analysis Using Strategic Reports: An Application to a School Choice Mechanism,0,0,0,0,0,2018,03,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2016–2017.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"Conditional independence of treatment assignment from potential outcomes is a commonly used but nonrefutable assumption. We derive identified sets for various treatment effect parameters under nonparametric deviations from this conditional independence assumption. These deviations are defined via a conditional treatment assignment probability, which makes it straightforward to interpret. Our results can be used to assess the robustness of empirical conclusions obtained under the baseline conditional independence assumption.","['Poirier, Alexandre', 'Masten, Matthew A.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Identification of Treatment Effects under Conditional Partial Independence,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"We present new identification results for a class of nonseparable nonparametric simultaneous equations models introduced by Matzkin (2008). These models combine traditional exclusion restrictions with a requirement that each structural error enter through a ""residual index."" Our identification results are constructive and encompass a range of special cases with varying demands on the exogenous variation provided by instruments and the shape of the joint density of the structural errors. The most important results demonstrate identification when instruments have only limited variation. Even when instruments vary only over a small open ball, relatively mild conditions on the joint density suffice. We also show that the primary sufficient conditions for identification are verifiable and that the maintained hypotheses of the model are falsifiable.","['Haile, Philip A.', 'Berry, Steven T.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Identification of Nonparametric Simultaneous Equations Models with a Residual Index Structure,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"This paper provides a framework for identifying preferences in a large network where links are pairwise stable. Network formation models present difficulties for identification, especially when links can be interdependent, for example, when indirect connections matter. We show how one can use the observed proportions of various local network structures to learn about the underlying preference parameters. The key assumption for our approach restricts individuals to have bounded degree in equilibrium, implying a finite number of payoff-relevant local structures. Our main result provides necessary conditions for parameters to belong to the identified set. We then develop a quadratic programming algorithm that can be used to construct this set. With further restrictions on preferences, we show that our conditions are also sufficient for pairwise stability and therefore characterize the identified set precisely. Overall, the use of both the economic model along with pairwise stability allows us to obtain effective dimension reduction.","['Richards-Shubik, Seth', 'de Paula, Aureo', 'Tamer, Elie']","['Consumer Economics: Theory', 'Network Formation and Analysis: Theory']","['D11', 'D85']",Identifying Preferences in Networks with Bounded Degree,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"We introduce the test-set equilibrium refinement of Nash equilibrium to formalize the idea that players contemplate only deviations from equilibrium play in which a single competitor plays a non-equilibrium best response. We then apply this refinement to three well-known auction games, comparing our findings to similar ones previously obtained by specialized equilibrium selections. We also introduce a theory of high stakes versions of games, in which strategies are first proposed and then subjected to a potentially costly review-and-revise process. We demonstrate a sense in which the test-set equilibria emerge from such processes when the cost of revision is small.","['Mollner, Joshua', 'Milgrom, Paul']","['Noncooperative Games', 'Auctions']","['C72', 'D44']",Equilibrium Selection in Auctions and High Stakes Games,0,0,1,0,0,2018,01,01
86,1,2018-01-01,"This paper presents an analysis of general time preferences in the canonical Rubinstein (1982) model of bargaining, allowing for arbitrarily history-dependent strategies. I derive a simple sufficient structure for optimal punishments and thereby fully characterize (i) the set of equilibrium outcomes for any given preference profile, and (ii) the set of preference profiles for which equilibrium is unique. Based on this characterization, I establish that a weak notion of present bias--implied, for example, by any hyperbolic or quasi-hyperbolic discounting--is sufficient for equilibrium to be unique, stationary, and efficient. Conversely, I demonstrate how certain violations of present bias give rise to multiple (non-stationary) equilibria that feature delayed agreement under gradually increasing offers.","['Schweighofer-Kodritsch, Sebastian']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory']","['C73', 'C78']",Time Preferences and Bargaining,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"We develop a recursive dual method for solving dynamic economic problems. The method uses a Lagrangian to pair a dynamic recursive economic problem with a dual problem. We show that such dual problems can be recursively decomposed with costates (i.e., Lagrange multipliers on laws of motion) functioning as state variables. In dynamic contracting and policy settings, the method often replaces an endogenous state space of forward-looking utilities with an exogenously given state space of costates. We provide a principle of optimality for dual problems and give conditions under which the dual Bellman operator is a contraction with the optimal dual value function its unique fixed point. We relate economic problems to their duals, address computational issues, and give examples.","['Sleet, Christopher', 'Pavoni, Nicola', 'Messner, Matthias']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],The Dual Approach to Recursive Optimization: Theory and Examples,0,0,0,0,0,2018,01,01
86,1,2018-01-01,"Two cornerstones of empirical and policy analysis of firms, in macro, labor and industrial organization, are the determinants of the firm size distribution and the determinants of sorting between workers and firms. We propose a unifying theory of production where management resolves a tradeoff between hiring more versus better workers. The span of control or size is therefore intimately intertwined with the sorting pattern. We provide a condition for sorting that captures this tradeoff between the quantity and quality of workers and that generalizes Becker's sorting condition. A system of differential equations determines the equilibrium allocation, the firm size, and wages, and allows us to characterize the allocation of the quality and quantity of labor to firms of different productivity. We show that our model nests a large number of widely used existing models. We also augment the model to incorporate labor market frictions in the presence of sorting with large firms.","['Eeckhout, Jan', 'Kircher, Philipp']","['Bargaining Theory; Matching Theory', 'Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Wage Level and Structure; Wage Differentials', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Firm Performance: Size, Diversification, and Scope']","['C78', 'D21', 'D24', 'J31', 'L11', 'L25']",Assortative Matching with Large Firms,1,0,0,0,0,2018,01,01
86,1,2018-01-01,"We introduce firm and worker heterogeneity into a model of innovation-driven endogenous growth. Individuals who differ in ability sort into either a research activity or a manufacturing sector. Research projects generate new varieties of a differentiated product. Projects differ in quality and the resulting technologies differ in productivity. In both sectors, there is a complementarity between firm quality and worker ability. We study the co-determination of growth and income inequality in both the closed and open economy, as well as the spillover effects of policy in one country to outcomes in others.","['Grossman, Gene M.', 'Helpman, Elhanan']","['Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Personal Income, Wealth, and Their Distributions', 'Trade: General', 'Industry Studies: Manufacturing: General', 'Technological Change: Choices and Consequences; Diffusion Processes', 'One, Two, and Multisector Growth Models']","['D21', 'D24', 'D31', 'F10', 'L60', 'O33', 'O41']","Growth, Trade, and Inequality",1,0,0,1,0,2018,01,01
86,1,2018-01-01,"This paper defines and analyzes a new monotonicity condition for the identification of counterfactuals and treatment effects in unordered discrete choice models with multiple treatments, heterogeneous agents, and discrete-valued instruments. Unordered monotonicity implies and is implied by additive separability of choice of treatment equations in terms of observed and unobserved variables. These results follow from properties of binary matrices developed in this paper. We investigate conditions under which unordered monotonicity arises as a consequence of choice behavior. We characterize IV estimators of counterfactuals as solutions to discrete mixture problems.","['Pinto, Rodrigo', 'Heckman, James J.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C21', 'C26']",Unordered Monotonicity,0,0,0,0,0,2018,01,01
85,6,2017-11-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society 2016 Annual Report of the President.,0,0,0,0,0,2017,11,01
85,6,2017-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 6.,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"Democracies widely differ in the extent to which powerful elites and interest groups retain influence over politics. While a large literature argues that elite capture is rooted in a country's history, our understanding of the determinants of elite persistence is limited. In this paper, we show that allowing old-regime agents to remain in office during democratic transitions is a key determinant of the extent of elite capture. We exploit quasi-random from Indonesia: Soeharto-regime mayors were allowed to finish their terms before being replaced by new leaders. Since mayors' political cycles were not synchronized, this event generated exogenous variation in how long old-regime mayors remained in their position during the democratic transition. Districts with longer exposure to old-regime mayors experience worse governance outcomes, higher elite persistence, and lower political competition in the medium run. The results suggest that slower transitions towards democracy allow the old-regime elites to capture democracy.","['Martinez-Bravo, Monica', 'Mukherjee, Priya', 'Stegmann, Andreas']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Public Goods', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D72', 'H41', 'O17']",The Non-democratic Roots of Elite Capture: Evidence from Soeharto Mayors in Indonesia,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We study a dynamic principal-agent relationship with adverse selection and limited commitment. We show that when the relationship is subject to productivity shocks, the principal may be able to improve her value over time by progressively learning the agent's private information. She may even achieve her first-best payoff in the long run. The relationship may also exhibit path dependence, with early shocks determining the principal's long-run value. These findings contrast sharply with the results of the ratchet effect literature, in which the principal persistently obtains low payoffs, giving up substantial informational rents to the agent.","['Ortner, Juan', 'Acharya, Avidit']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Progressive Learning,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We study persuasion mechanisms in linear environments. A receiver has a private type and chooses between two actions. A sender designs a persuasion mechanism or an experiment to disclose information about a payoff-relevant state. A persuasion mechanism conditions information disclosure on the receiver's report about his type, whereas an experiment discloses information independent of the receiver's type. We establish the equivalence of implementation by persuasion mechanisms and by experiments, and characterize optimal persuasion mechanisms.","['Li, Ming', 'Mylovanov, Tymofiy', 'Kolotilin, Anton', 'Zapechelnyuk, Andriy']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Persuasion of a Privately Informed Receiver,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We develop a theory of how the value of an agent's information advantage depends on the persistence of information. We focus on strategic situations with strict conflict of interest, formalized as stochastic zero-sum games where only one of the players observes the state that evolves according to a Markov operator. Operator Q is said to be better for the informed player than operator P if the value of the game under Q is higher than under P regardless of the stage game. We show that this defines a convex partial order on the space of ergodic Markov operators. Our main result is a full characterization of this partial order, interpretable as an ordinal notion of persistence relevant for games. The analysis relies on a novel characterization of the value of a stochastic game with incomplete information.","['Toikka, Juuso', 'Peski, Marcin']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D82', 'D83']",Value of Persistent Information,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We develop a search model of marriage where men and women draw utility from private consumption and leisure, and from a non-market good that is produced in the home using time resources. We condition individual decisions on wages, education, and an index of family attitudes. A match-specific, stochastic bliss shock induces variation in matching given wages, education, and family values, and triggers renegotiation and divorce. Using BHPS (1991-2008) data, we take as given changes in wages, education, and family values by gender, and we study their impact on marriage decisions and intrahousehold resource allocation. The model allows us to evaluate how much of the observed gender differences in labor supply results from wages, education, and family attitudes. We find that family attitudes are a strong determinant of comparative advantages in home production of men and women, whereas education complementarities induce assortative mating through preferences.","['Robin, Jean-Marc', 'Gousse, Marion', 'Jacquemet, Nicolas']","['Model Construction and Estimation', 'Household Production and Intrahousehold Allocation', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C51', 'D13', 'J12', 'J16', 'J22', 'J24', 'J31']","Marriage, Labor Supply, and Home Production",0,0,0,0,0,2017,11,01
85,6,2017-11-01,"A mixed manna contains goods (that everyone likes) and bads (that everyone dislikes), as well as items that are goods to some agents, but bads or satiated to others. If all items are goods and utility functions are homogeneous of degree 1 and concave (and monotone), the competitive division maximizes the Nash product of utilities (Gale-Eisenberg): hence it is welfarist (determined by the set of feasible utility profiles), unique, continuous, and easy to compute. We show that the competitive division of a mixed manna is still welfarist. If the zero utility profile is Pareto dominated, the competitive profile is strictly positive and still uniquely maximizes the product of utilities. If the zero profile is unfeasible (for instance, if all items are bads), the competitive profiles are strictly negative and are the critical points of the product of disutilities on the efficiency frontier. The latter allows for multiple competitive utility profiles, from which no single-valued selection can be continuous or resource monotonic. Thus the implementation of competitive fairness under linear preferences in interactive platforms like SPLIDDIT will be more difficult when the manna contains bads that overwhelm the goods.","['Sandomirskiy, Fedor', 'Yanovskaya, Elena', 'Moulin, Herve', 'Bogomolnaia, Anna']","['Noncooperative Games', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['C72', 'D63']",Competitive Division of a Mixed Manna,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We introduce a novel economic indicator, named excess idle time (EXIT), measuring the extent of sluggishness in financial prices. Under a null and an alternative hypothesis grounded in no-arbitrage (the null) and market microstructure (the alternative) theories of price determination, we derive a limit theory for EXIT leading to formal tests for staleness in the price adjustments. Empirical implementation of the theory indicates that financial prices are often more sluggish than implied by the (ubiquitous, in frictionless continuous-time asset pricing) semimartingale assumption. EXIT is interpretable as an illiquidity proxy and is easily implementable, for each trading day, using transaction prices only. By using EXIT, we show how to estimate structurally market microstructure models with asymmetric information.","['Bandi, Federico M.', 'Reno, Roberto', 'Pirino, Davide']","['Model Construction and Estimation', 'Asymmetric and Private Information; Mechanism Design', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Contingent Pricing; Futures Pricing; option pricing']","['C51', 'D82', nan, 'G13']",Excess Idle Time,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"We document abrupt increases in retail beer prices just after the consummation of the Miller Coors joint venture, both for Miller Coors and its major competitor, Anheuser-Busch. Within the context of a differentiated-products pricing model, we test and reject the hypothesis that the price increases can be explained by movement from one Nash-Bertrand equilibrium to another. Counterfactual simulations imply that prices after the joint venture are 6%-8% higher than they would have been with Nash-Bertrand competition, and that markups are 17%-18% higher. We relate the results to documentary evidence that the joint venture may have facilitated price coordination.","['Weinberg, Matthew C.', 'Miller, Nathan H.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance', 'Corporate Finance and Governance: Government Policy and Regulation', 'Oligopoly and Other Imperfect Markets', 'Contracting Out; Joint Ventures; Technology Licensing', 'Food; Beverages; Cosmetics; Tobacco; Wine and Spirits']","['D43', 'G34', 'G38', 'L13', 'L24', 'L66']",Understanding the Price Effects of the MillerCoors Joint Venture,1,0,1,0,1,2017,11,01
85,6,2017-11-01,"This paper examines how sales force impacts competition and equilibrium prices in the context of a privatized pension market. We use detailed administrative data on fund manager choices and worker characteristics at the inception of Mexico's privatized social security system, where fund managers had to set prices (management fees) at the national level, but could select sales force levels by local geographic areas. We develop and estimate a model of fund manager choice where sales force can increase or decrease customer price sensitivity. We find exposure to sales force lowered price sensitivity, leading to inelastic demand and high equilibrium fees. We simulate oft-proposed policy solutions: a supply-side policy with a competitive government player and a demand-side policy that increases price elasticity. We find that demand-side policies are necessary to foster competition in social safety net markets with large segments of inelastic consumers.","['Syverson, Chad', 'Hortacsu, Ali', 'Hastings, Justine']","['Model Construction and Estimation', 'Pension Funds; Non-bank Financial Institutions; Financial Instruments; Institutional Investors', 'Social Security and Public Pensions', 'Retirement; Retirement Policies', 'Marketing', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['C51', 'G23', 'H55', 'J26', 'M31', 'O15', 'O16']",Sales Force and Competition in Financial Product Markets: The Case of Mexico's Social Security Privatization,0,0,0,0,0,2017,11,01
85,6,2017-11-01,"This paper studies the impact of time-varying idiosyncratic risk at the establishment level on unemployment fluctuations over 1972-2009. I build a tractable directed search model with firm dynamics and time-varying idiosyncratic volatility. The model allows for endogenous separations, entry and exit, and job-to-job transitions. I show that the model can replicate salient features of the microeconomic behavior of firms and that the introduction of volatility improves the fit of the model for standard business cycle moments. In a series of counterfactual experiments, I show that time-varying risk is important to account for the magnitude of fluctuations in aggregate unemployment for past U.S. recessions. Though the model can account for about 40% of the total increase in unemployment for the 2007-2009 recession, uncertainty alone is not sufficient to explain the magnitude and persistence of unemployment during that episode.","['Schaal, Edouard']","['Criteria for Decision-Making under Risk and Uncertainty', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Labor Contracts', 'Labor Turnover; Vacancies; Layoffs', 'Unemployment: Models, Duration, Incidence, and Job Search']","['D81', 'E24', 'E32', 'J41', 'J63', 'J64']",Uncertainty and Unemployment,0,0,0,0,0,2017,11,01
85,5,2017-09-01,"Owing to the worldwide shortage of deceased-donor organs for transplantation, living donations have become a significant source of transplant organs. However, not all willing donors can donate to their intended recipients because of medical incompatibilities. These incompatibilities can be overcome by an exchange of donors between patients. For kidneys, such exchanges have become widespread in the last decade with the introduction of optimization and market design techniques to kidney exchange. A small but growing number of liver exchanges have also been conducted. Over the last two decades, a number of transplantation procedures emerged where organs from two living donors are transplanted to a single patient. Prominent examples include dual-graft liver transplantation, lobar lung transplantation, and simultaneous liver-kidney transplantation. Exchange, however, has been neither practiced nor introduced in this context. We introduce dual-donor organ exchange as a novel transplantation modality, and through simulations show that living-donor transplants can be significantly increased through such exchanges. We also provide a simple theoretical model for dual-donor organ exchange and introduce optimal exchange mechanisms under various logistical constraints.","['Ergin, Haluk', 'Sonmez, Tayfun', 'Unver, M. Utku']","['Market Design', 'Analysis of Health Care Markets']","['D47', 'I11']",Dual-Donor Organ Exchange,0,0,1,0,0,2017,09,01
85,5,2017-09-01,"This paper provides positive testability results for the identification condition in a nonparametric instrumental variable model, known as completeness, and it links the outcome of the test to properties of an estimator of the structural function. In particular, I show that the data can provide empirical evidence in favor of both an arbitrarily small identified set as well as an arbitrarily small asymptotic bias of the estimator. This is the case for a large class of complete distributions as well as certain incomplete distributions. As a byproduct, the results can be used to estimate an upper bound of the diameter of the identified set and to obtain an easy to report estimator of the identified set itself.","['Freyberger, Joachim']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Model Construction and Estimation']","['C26', 'C51']",On Completeness and Consistency in Nonparametric Instrumental Variable Models,0,0,0,0,0,2017,09,01
85,5,2017-09-01,"This note studies some seemingly anomalous results that arise in possibly misspecified, reduced-rank linear asset-pricing models estimated by the continuously updated generalized method of moments. When a spurious factor (that is, a factor that is uncorrelated with the returns on the test assets) is present, the test for correct model specification has asymptotic power that is equal to the nominal size. In other words, applied researchers will erroneously conclude that the model is correctly specified even when the degree of misspecification is arbitrarily large. The rejection probability of the test for overidentifying restrictions typically decreases further in underidentified models where the dimension of the null space is larger than 1.","['Robotti, Cesare', 'Kan, Raymond', 'Gospodinov, Nikolay']","['Model Construction and Estimation', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', 'C58', nan]",Spurious Inference in Reduced-Rank Asset-Pricing Models,0,0,0,0,0,2017,09,01
85,5,2017-09-01,"We present a flexible and scalable method for computing global solutions of high-dimensional stochastic dynamic models. Within a time iteration or value function iteration setup, we interpolate functions using an adaptive sparse grid algorithm. With increasing dimensions, sparse grids grow much more slowly than standard tensor product grids. Moreover, adaptivity adds a second layer of sparsity, as grid points are added only where they are most needed, for instance, in regions with steep gradients or at nondifferentiabilities. To further speed up the solution process, our implementation is fully hybrid parallel, combining distributed and shared memory parallelization paradigms, and thus permits an efficient use of high-performance computing architectures. To demonstrate the broad applicability of our method, we solve two very different types of dynamic models: first, high-dimensional international real business cycle models with capital adjustment costs and irreversible investment; second, multiproduct menu-cost models with temporary sales and economies of scope in price setting.","['Scheidegger, Simon', 'Brumm, Johannes']","['General Aggregative Models: Neoclassical', 'Investment; Capital; Intangible Capital; Capacity', 'Business Fluctuations; Cycles', 'Monetary Policy', 'Retail and Wholesale Trade; e-Commerce']","['E13', 'E22', 'E32', 'E52', 'L81']",Using Adaptive Sparse Grids to Solve High-Dimensional Dynamic Models,1,0,0,0,0,2017,09,01
85,5,2017-09-01,"We develop a theory that rationalizes the use of a dominant unit of account in an economy. Agents enter into non-contingent contracts with a variety of business partners. Trade unfolds sequentially in credit chains and is subject to random matching. By using a dominant unit of account, agents can lower their exposure to relative price risk, avoid costly default, and create more total surplus. We discuss conditions under which it is optimal to adopt circulating government paper as the dominant unit of account, and the optimal choice of ""currency areas"" when there is variation in the intensity of trade within and across regions.","['Schneider, Martin', 'Doepke, Matthias']","['Monetary Systems; Standards; Regimes; Government and the Monetary System; Payment Systems', 'Neoclassical Models of Trade', 'International Monetary Arrangements and Institutions']","['E42', 'F11', 'F33']",Money as a Unit of Account,0,0,0,0,0,2017,09,01
85,5,2017-09-01,"Stochastic discount factor (SDF) processes in dynamic economies admit a permanent-transitory decomposition in which the permanent component characterizes pricing over long investment horizons. This paper introduces an empirical framework to analyze the permanent-transitory decomposition of SDF processes. Specifically, we show how to estimate nonparametrically the solution to the Perron-Frobenius eigenfunction problem of Hansen and Scheinkman, 2009. Our empirical framework allows researchers to (i) construct time series of the estimated permanent and transitory components and (ii) estimate the yield and the change of measure which characterize pricing over long investment horizons. We also introduce nonparametric estimators of the continuation value function in a class of models with recursive preferences by reinterpreting the value function recursion as a nonlinear Perron-Frobenius problem. We establish consistency and convergence rates of the eigenfunction estimators and asymptotic normality of the eigenvalue estimator and estimators of related functionals. As an application, we study an economy where the representative agent is endowed with recursive preferences, allowing for general (nonlinear) consumption and earnings growth dynamics.","['Christensen, Timothy M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Payout Policy']","['C22', 'C51', 'E32', 'E43', nan, 'G35']",Nonparametric Stochastic Discount Factor Decomposition,0,0,0,0,0,2017,09,01
85,5,2017-09-01,"In this paper, we prove the existence of recursive equilibria in a dynamic stochastic model with infinitely lived heterogeneous agents, several commodities, and general inter- and intratemporal production. We illustrate the usefulness of our result by providing sufficient conditions for the existence of recursive equilibria in heterogeneous agent versions of both the Lucas asset pricing model and the neoclassical stochastic growth model.","['Kryczka, Dominika', 'Kubler, Felix', 'Brumm, Johannes']","['Incomplete Markets', 'General Aggregative Models: Neoclassical', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'One, Two, and Multisector Growth Models']","['D52', 'E13', nan, 'O41']",Recursive Equilibria in Dynamic Economies with Stochastic Production,0,0,0,0,0,2017,09,01
85,5,2017-09-01,"We explore the set of preferences defined over temporal lotteries in an infinite horizon setting. We provide utility representations for all preferences that are both recursive and monotone. Our results indicate that the class of monotone recursive preferences includes Uzawa-Epstein preferences and risk-sensitive preferences, but leaves aside several of the recursive models suggested by Epstein and Zin (1989) and Weil (1990). Our representation result is derived in great generality using Lundberg's (1982, 1985) work on functional equations.","['Kochov, Asen', 'Le Grand, Francois', 'Bommier, Antoine']","['Consumer Economics: Theory', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D44', 'D81']",On Monotone Recursive Preferences,0,0,1,0,0,2017,09,01
85,5,2017-09-01,"A growing number of school districts use centralized assignment mechanisms to allocate school seats in a manner that reflects student preferences and school priorities. Many of these assignment schemes use lotteries to ration seats when schools are oversubscribed. The resulting random assignment opens the door to credible quasi-experimental research designs for the evaluation of school effectiveness. Yet the question of how best to separate the lottery-generated randomization integral to such designs from non-random preferences and priorities remains open. This paper develops easily-implemented empirical strategies that fully exploit the random assignment embedded in a wide class of mechanisms, while also revealing why seats are randomized at one school but not another. We use these methods to evaluate charter schools in Denver, one of a growing number of districts that combine charter and traditional public schools in a unified assignment system. The resulting estimates show large achievement gains from charter school attendance. Our approach generates efficiency gains over ad hoc methods, such as those that focus on schools ranked first, while also identifying a more representative average causal effect. We also show how to use centralized assignment mechanisms to identify causal effects in models with multiple school sectors.","['Abdulkadiroglu, Atila', 'Angrist, Joshua D.', 'Pathak, Parag A.', 'Narita, Yusuke']","['Model Construction and Estimation', 'Market Design', 'State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Education', 'Education: Government Policy']","['C51', 'D47', 'H75', 'I21', 'I28']",Research Design Meets Market Design: Using Centralized Assignment for Impact Evaluation,0,0,1,0,0,2017,09,01
85,5,2017-09-01,"We develop a theory of parent-child relations that rationalizes the choice between alternative parenting styles (as set out in Baumrind, 1967). Parents maximize an objective function that combines Beckerian altruism and paternalism towards children. They can affect their children's choices via two channels: either by influencing children's preferences or by imposing direct restrictions on their choice sets. Different parenting styles (authoritarian, authoritative, and permissive) emerge as equilibrium outcomes and are affected both by parental preferences and by the socioeconomic environment. Parenting style, in turn, feeds back into the children's welfare and economic success. The theory is consistent with the decline of authoritarian parenting observed in industrialized countries and with the greater prevalence of more permissive parenting in countries characterized by low inequality.","['Doepke, Matthias', 'Zilibotti, Fabrizio']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Altruism; Philanthropy; Intergenerational Transfers', 'Returns to Education', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Fertility; Family Planning; Child Care; Children; Youth', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['D63', 'D64', 'I26', 'J12', 'J13', 'J24']",Parenting with Style: Altruism and Paternalism in Intergenerational Preference Transmission,0,0,0,0,0,2017,09,01
85,4,2017-07-01,ECONLIT None Found,[nan],[nan],[nan],2016 Election of Fellows to the Econometric Society.,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"The ill-posedness of the nonparametric instrumental variable (NPIV) model leads to estimators that may suffer from poor statistical performance. In this paper, we explore the possibility of imposing shape restrictions to improve the performance of the NPIV estimators. We assume that the function to be estimated is monotone and consider a sieve estimator that enforces this monotonicity constraint. We define a constrained measure of ill-posedness that is relevant for the constrained estimator and show that, under a monotone IV assumption and certain other mild regularity conditions, this measure is bounded uniformly over the dimension of the sieve space. This finding is in stark contrast to the well-known result that the unconstrained sieve measure of ill-posedness that is relevant for the unconstrained estimator grows to infinity with the dimension of the sieve space. Based on this result, we derive a novel non-asymptotic error bound for the constrained estimator. The bound gives a set of data-generating processes for which the monotonicity constraint has a particularly strong regularization effect and considerably improves the performance of the estimator. The form of the bound implies that the regularization effect can be strong even in large samples and even if the function to be estimated is steep, particularly so if the NPIV model is severely ill-posed. Our simulation study confirms these findings and reveals the potential for large performance gains from imposing the monotonicity constraint.","['Wilhelm, Daniel', 'Chetverikov, Denis']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Nonparametric Instrumental Variable Estimation under Monotonicity,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"The bootstrap is a convenient tool for calculating standard errors of the parameter estimates of complicated econometric models. Unfortunately, the fact that these models are complicated often makes the bootstrap extremely slow or even practically infeasible. This paper proposes an alternative to the bootstrap that relies only on the estimation of one-dimensional parameters. We introduce the idea in the context of M and GMM estimators. A modification of the approach can be used to estimate the variance of two-step estimators.","['Honore, Bo E.', 'Hu, Luojia']",['Statistical Simulation Methods: General'],['C15'],Poor (Wo)man's Bootstrap,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"Differences in preferences are important to explain variation in individuals' behavior. There is, however, no consensus on how to take these differences into account when evaluating policies. While prominent in the economic literature, the standard utilitarian criterion is controversial. According to some, interpersonal comparability of utilities involves value judgments with little objective basis. Others argue that social justice is primarily about the distribution of commodities assigned to individuals, rather than their subjective satisfaction or happiness. In this paper, we propose and axiomatically characterize a criterion, named opportunity-equivalent utilitarian, that addresses these claims. First, our criterion ranks social alternatives on the basis of individuals' ordinal preferences. Second, it compares individuals based on the fairness of their assignments. Opportunity-equivalent utilitarianism requires society to maximize the sum of specific indices of well-being that are cardinal, interpersonally comparable, and represent each individual's preferences.","['Piacquadio, Paolo Giovanni']","['Consumer Economics: Theory', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D11', 'D63']",A Fairness Justification of Utilitarianism,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"We extend Ellsberg's two-urn paradox and propose three symmetric forms of partial ambiguity by limiting the possible compositions in a deck of 100 red and black cards in three ways. Interval ambiguity involves a symmetric range of 50 - n to 50 + n red cards. Complementarily, disjoint ambiguity arises from two nonintersecting intervals of 0 to n and 100 - n to 100 red cards. Two-point ambiguity involves n or 100 - n red cards. We investigate, experimentally, attitudes towards partial ambiguity and the corresponding compound lotteries in which the possible compositions are drawn with equal objective probabilities. This yields three key findings: distinct attitudes towards the three forms of partial ambiguity, significant association across attitudes towards partial ambiguity and compound risk, and source preference between two-point ambiguity and two-point compound risk. Our findings help discriminate among models of ambiguity in the literature.","['Chew, Soo Hong', 'Zhong, Songfa', 'Miao, Bin']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Partial Ambiguity,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"The demand for assets as prices and initial wealth vary identifies beliefs and attitudes towards risk. We derive conditions that guarantee identification with no knowledge, either of the cardinal utility index (attitudes towards risk), or of the distribution of future endowments or payoffs of assets; the argument applies even if the asset market is incomplete and demand is observed only locally.","['Kubler, Felix', 'Polemarchakis, Herakles']","['Household Saving; Personal Finance', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D14', 'D83', 'G11', nan]",The Identification of Beliefs from Asset Demand,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"Modeling intergenerational altruism is crucial to evaluate the long-term consequences of current decisions, and requires a set of principles guiding such altruism. We axiomatically develop a theory of pure, direct altruism: Altruism is pure if it concerns the total utility (rather than the mere consumption utility) of future generations, and direct if it directly incorporates the utility of all future generations. Our axioms deliver a new class of altruistic, forward-looking preferences, whose weight put on the consumption of a future generation generally depends on the consumption of other generations. The only preferences lacking this dependence correspond to the quasi-hyperbolic discounting model, which our theory characterizes. Our approach provides a framework to analyze welfare in the presence of altruistic preferences and addresses technical challenges stemming from the interdependent nature of such preferences.","['Galperti, Simone', 'Strulovici, Bruno']","['Consumer Economics: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Altruism; Philanthropy; Intergenerational Transfers']","['D11', 'D15', 'D64']",A Theory of Intergenerational Altruism,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"We study the estimation of (joint) moments of microstructure noise based on high frequency data. The estimation is conducted under a nonparametric setting, which allows the underlying price process to have jumps, the observation times to be irregularly spaced, and the noise to be dependent on the price process and to have diurnal features. Estimators of arbitrary orders of (joint) moments are provided, for which we establish consistency as well as central limit theorems. In particular, we provide estimators of autocovariances and autocorrelations of the noise. Simulation studies demonstrate excellent performance of our estimators in the presence of jumps, irregular observation times, and even rounding. Empirical studies reveal (moderate) positive autocorrelations of microstructure noise for the stocks tested.","['Zheng, Xinghua', 'Li, Yingying', 'Jacod, Jean']","['Large Data Sets: Modeling and Analysis', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['C55', 'C58', nan, 'G14']",Statistical Properties of Microstructure Noise,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"We study from both a theoretical and an empirical perspective how a network of military alliances and enmities affects the intensity of a conflict. The model combines elements from network theory and from the politico-economic theory of conflict. We obtain a closed-form characterization of the Nash equilibrium. Using the equilibrium conditions, we perform an empirical analysis using data on the Second Congo War, a conflict that involves many groups in a complex network of informal alliances and rivalries. The estimates of the fighting externalities are then used to infer the extent to which the conflict intensity can be reduced through (i) dismantling specific fighting groups involved in the conflict, (ii) weapon embargoes, and (iii) interventions aimed at pacifying animosity among groups. Finally, with the aid of a random utility model, we study how policy shocks can induce a reshaping of the network structure.","['Thoenig, Mathias', 'Zilibotti, Fabrizio', 'Konig, Michael D.', 'Rohner, Dominic']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Network Formation and Analysis: Theory', 'International Conflicts; Negotiations; Sanctions', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D74', 'D85', 'F51', 'O15', 'O17', 'Z13']",Networks in Conflict: Theory and Evidence from the Great War of Africa,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"We use variation in historical state centralization to examine the long-term impact of institutions on cultural norms. The Kuba Kingdom, established in Central Africa in the early 17th century by King Shyaam, had more developed state institutions than the other independent villages and chieftaincies in the region. It had an unwritten constitution, separation of political powers, a judicial system with courts and juries, a police force, a military, taxation, and significant public goods provision. Comparing individuals from the Kuba Kingdom to those from just outside the kingdom, we find that centralized formal institutions are associated with weaker norms of rule following and a greater propensity to cheat for material gain. This finding is consistent with recent models where endogenous investments to inculcate values in children decline when there is an increase in the effectiveness of formal institutions that enforce socially desirable behavior. Consistent with such a mechanism, we find that Kuba parents believe it is less important to teach children values related to rule-following behaviors.","['Nunn, Nathan', 'Weigel, Jonathan L.', 'Robinson, James A.', 'Lowes, Sara']","['Institutions: Design, Formation, Operations, and Impact', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Africa; Oceania', 'Economic History: Government, War, Law, International Relations, and Regulation: Africa; Oceania', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Institutions and Growth', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D02', 'N37', 'N47', 'O17', 'O43', 'Z13']",The Evolution of Culture and Institutions: Evidence from the Kuba Kingdom,0,0,0,0,0,2017,07,01
85,4,2017-07-01,"I introduce a model of undirected dyadic link formation which allows for assortative matching on observed agent characteristics (homophily) as well as unrestricted agent-level heterogeneity in link surplus (degree heterogeneity). Like in fixed effects panel data analyses, the joint distribution of observed and unobserved agent-level characteristics is left unrestricted. Two estimators for the (common) homophily parameter, beta_{0}, are developed and their properties studied under an asymptotic sequence involving a single network growing large. The first, tetrad logit (TL), estimator conditions on a sufficient statistic for the degree heterogeneity. The second, joint maximum likelihood (JML), estimator treats the degree heterogeneity {Alpha_{i0}}^{N}_{i = 1} as additional (incidental) parameters to be estimated. The TL estimate is consistent under both sparse and dense graph sequences, whereas consistency of the JML estimate is shown only under dense graph sequences.","['Graham, Bryan S.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['C25', 'D83', 'D85', 'Z13']",An Econometric Model of Network Formation with Degree Heterogeneity,0,0,0,0,0,2017,07,01
85,3,2017-05-01,"This paper develops a theory of randomization tests under an approximate symmetry assumption. Randomization tests provide a general means of constructing tests that control size in finite samples whenever the distribution of the observed data exhibits symmetry under the null hypothesis. Here, by exhibits symmetry we mean that the distribution remains invariant under a group of transformations. In this paper, we provide conditions under which the same construction can be used to construct tests that asymptotically control the probability of a false rejection whenever the distribution of the observed data exhibits approximate symmetry in the sense that the limiting distribution of a function of the data exhibits symmetry under the null hypothesis. An important application of this idea is in settings where the data may be grouped into a fixed number of ""clusters"" with a large number of observations within each cluster. In such settings, we show that the distribution of the observed data satisfies our approximate symmetry requirement under weak assumptions. In particular, our results allow for the clusters to be heterogeneous and also have dependence not only within each cluster, but also across clusters. This approach enjoys several advantages over other approaches in these settings.","['Romano, Joseph P.', 'Shaikh, Azeem M.', 'Canay, Ivan A.']",['Hypothesis Testing: General'],['C12'],Randomization Tests under an Approximate Symmetry Assumption,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"We propose a novel methodology for evaluating the accuracy of numerical solutions to dynamic economic models. It consists in constructing a lower bound on the size of approximation errors. A small lower bound on errors is a necessary condition for accuracy: If a lower error bound is unacceptably large, then the actual approximation errors are even larger, and hence, the approximation is inaccurate. Our lower-bound error analysis is complementary to the conventional upper-error (worst-case) bound analysis, which provides a sufficient condition for accuracy. As an illustration of our methodology, we assess approximation in the first- and second-order perturbation solutions for two stylized models: a neoclassical growth model and a new Keynesian model. The errors are small for the former model but unacceptably large for the latter model under some empirically relevant parameterizations.","['Maliar, Lilia', 'Maliar, Serguei', 'Judd, Kenneth L.']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'One, Two, and Multisector Growth Models']","['C61', nan, 'O41']",Lower Bounds on Approximation Errors to Numerical Solutions of Dynamic Economic Models,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"This paper develops characterizations of identified sets of structures and structural features for complete and incomplete models involving continuous or discrete variables. Multiple values of unobserved variables can be associated with particular combinations of observed variables. This can arise when there are multiple sources of heterogeneity, censored or discrete endogenous variables, or inequality restrictions on functions of observed and unobserved variables. The models generalize the class of incomplete instrumental variable (IV) models in which unobserved variables are single-valued functions of observed variables. Thus the models are referred to as generalized IV (GIV) models, but there are important cases in which instrumental variable restrictions play no significant role. Building on a definition of observational equivalence for incomplete models the development uses results from random set theory that guarantee that the characterizations deliver sharp bounds, thereby dispensing with the need for case-by-case proofs of sharpness. The use of random sets defined on the space of unobserved variables allows identification analysis under mean and quantile independence restrictions on the distributions of unobserved variables conditional on exogenous variables as well as under a full independence restriction. The results are used to develop sharp bounds on the distribution of valuations in an incomplete model of English auctions, improving on the pointwise bounds available until now. Application of many of the results of the paper requires no familiarity with random set theory.","['Rosen, Adam M.', 'Chesher, Andrew']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Auctions']","['C26', 'D44']",Generalized Instrumental Variable Models,0,0,1,0,0,2017,05,01
85,3,2017-05-01,"Can increased uncertainty about the future cause a contraction in output and its components? An identified uncertainty shock in the data causes significant declines in output, consumption, investment, and hours worked. Standard general-equilibrium models with flexible prices cannot reproduce this comovement. However, uncertainty shocks can easily generate comovement with countercyclical markups through sticky prices. Monetary policy plays a key role in offsetting the negative impact of uncertainty shocks during normal times. Higher uncertainty has even more negative effects if monetary policy can no longer perform its usual stabilizing function because of the zero lower bound. We calibrate our uncertainty shock process using fluctuations in implied stock market volatility, and show that the model with nominal price rigidity is consistent with empirical evidence from a structural vector autoregression. We argue that increased uncertainty about the future likely played a role in worsening the Great Recession. The economic mechanism we identify applies to a large set of shocks that change expectations of the future without changing current fundamentals.","['Bundick, Brent', 'Basu, Susanto']","['Criteria for Decision-Making under Risk and Uncertainty', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Interest Rates: Determination, Term Structure, and Effects', 'Financial Markets and the Macroeconomy', 'Monetary Policy']","['D81', 'E24', 'E32', 'E43', 'E44', 'E52']",Uncertainty Shocks in a Model of Effective Demand,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"The theory of continuous time games (Simon and Stinchcombe (1989), Bergin and MacLeod (1993)) shows that continuous time interactions can generate very different equilibrium behavior than conventional discrete time interactions. We introduce new laboratory methods that allow us to eliminate natural inertia in subjects' decisions in continuous time experiments, thereby satisfying critical premises of the theory and enabling a first-time direct test. Applying these new methods to a simple timing game, we find strikingly large gaps in behavior between discrete and continuous time as the theory suggests. Reintroducing natural inertia into these games causes continuous time behavior to collapse to discrete time-like levels in some settings as predicted by subgame perfect Nash equilibrium. However, contra this prediction, the strength of this effect is fundamentally shaped by the severity of inertia: behavior tends towards discrete time benchmarks as inertia grows large and perfectly continuous time benchmarks as it falls towards zero. We provide evidence that these results are due to changes in the nature of strategic uncertainty as inertia approaches the continuous limit.","['Calford, Evan', 'Oprea, Ryan']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']","Continuity, Inertia, and Strategic Uncertainty: A Test of the Theory of Continuous Time Games",0,0,0,0,0,2017,05,01
85,3,2017-05-01,"We develop a continuum player timing game that subsumes standard wars of attrition and pre-emption games, and introduces a new rushes phenomenon. Payoffs are continuous and single-peaked functions of the stopping time and stopping quantile. We show that if payoffs are hump-shaped in the quantile, then a sudden ""rush"" of players stops in any Nash or subgame perfect equilibrium. Fear relaxes the first mover advantage in pre-emption games, asking that the least quantile beat the average; greed relaxes the last mover advantage in wars of attrition, asking just that the last quantile payoff exceed the average. With greed, play is inefficiently late: an accelerating war of attrition starting at optimal time, followed by a rush. With fear, play is inefficiently early: a slowing pre-emption game, ending at the optimal time, preceded by a rush. The theory predicts the length, duration, and intensity of stopping, and the size and timing of rushes, and offers insights for many common timing games.","['Smith, Lones', 'Park, Andreas', 'Anderson, Axel']",['Noncooperative Games'],['C72'],Rushes in Large Timing Games,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"It is often argued that additional constraints on redistribution such as granting veto power to more players in society better protects property from expropriation. We use a model of multilateral bargaining to demonstrate that this intuition may be flawed. Increasing the number of veto players or raising the supermajority requirement for redistribution may reduce protection on the equilibrium path. The reason is the existence of two distinct mechanisms of property protection. One is formal constraints that allow individuals or groups to block any redistribution that is not in their favor. The other occurs in equilibrium where players without such powers protect each other from redistribution. Players without formal veto power anticipate that the expropriation of other similar players will ultimately hurt them and thus combine their influence to prevent redistributions. In a stable allocation, the society exhibits a ""class"" structure with class members having equal wealth and strategically protecting each other from redistribution.","['Sonin, Konstantin', 'Egorov, Georgy', 'Diermeier, Daniel']","['Bargaining Theory; Matching Theory', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Capitalist Systems: Property Rights']","['C78', 'D63', 'D72', 'H23', 'P14']",Political Economy of Redistribution,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"This paper proposes an empirical model of network formation, combining strategic and random networks features. Payoffs depend on direct links, but also link externalities. Players meet sequentially at random, myopically updating their links. Under mild assumptions, the network formation process is a potential game and converges to an exponential random graph model (ERGM), generating directed dense networks. I provide new identification results for ERGMs in large networks: if link externalities are nonnegative, the ERGM is asymptotically indistinguishable from an Erdos-Renyi model with independent links. We can identify the parameters only when at least one of the externalities is negative and sufficiently large. However, the standard estimation methods for ERGMs can have exponentially slow convergence, even when the model has asymptotically independent links. I thus estimate parameters using a Bayesian MCMC method. When the parameters are identifiable, I show evidence that the estimation algorithm converges in almost quadratic time.","['Mele, Angelo']",['Network Formation and Analysis: Theory'],['D85'],A Structural Model of Dense Network Formation,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"We provide general conditions under which principal-agent problems with either one or multiple agents admit mechanisms that are optimal for the principal. Our results cover as special cases pure moral hazard and pure adverse selection. We allow multidimensional types, actions, and signals, as well as both financial and non-financial rewards. Our results extend to situations in which there are ex ante or interim restrictions on the mechanism, and allow the principal to have decisions in addition to choosing the agent's contract. Beyond measurability, we require no a priori restrictions on the space of mechanisms. It is not unusual for randomization to be necessary for optimality and so it (should be and) is permitted. Randomization also plays an essential role in our proof. We also provide conditions under which some forms of randomization are unnecessary.","['Swinkels, Jeroen M.', 'Kadan, Ohad', 'Reny, Philip J.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Existence of Optimal Mechanisms in Principal-Agent Problems,0,0,0,0,0,2017,05,01
85,3,2017-05-01,"We characterize optimal mechanisms for the multiple-good monopoly problem and provide a framework to find them. We show that a mechanism is optimal if and only if a measure mu derived from the buyer's type distribution satisfies certain stochastic dominance conditions. This measure expresses the marginal change in the seller's revenue under marginal changes in the rent paid to subsets of buyer types. As a corollary, we characterize the optimality of grand-bundling mechanisms, strengthening several results in the literature, where only sufficient optimality conditions have been derived. As an application, we show that the optimal mechanism for n independent uniform items each supported on [c,c + 1] is a grand-bundling mechanism, as long as c is sufficiently large, extending Pavlov's result for two items Pavlov, 2011. At the same time, our characterization also implies that, for all c and for all sufficiently large n, the optimal mechanism for n independent uniform items supported on [c,c + 1] is not a grand-bundling mechanism.","['Deckelbaum, Alan', 'Tzamos, Christos', 'Daskalakis, Constantinos']","['Market Structure, Pricing, and Design: Monopoly', 'Asymmetric and Private Information; Mechanism Design', 'Monopoly; Monopolization Strategies']","['D42', 'D82', 'L12']",Strong Duality for a Multiple-Good Monopolist,1,0,1,0,0,2017,05,01
85,3,2017-05-01,"We develop a new quantile-based panel data framework to study the nature of income persistence and the transmission of income shocks to consumption. Log-earnings are the sum of a general Markovian persistent component and a transitory innovation. The persistence of past shocks to earnings is allowed to vary according to the size and sign of the current shock. Consumption is modeled as an age-dependent nonlinear function of assets, unobservable tastes, and the two earnings components. We establish the nonparametric identification of the nonlinear earnings process and of the consumption policy rule. Exploiting the enhanced consumption and asset data in recent waves of the Panel Study of Income Dynamics, we find that the earnings process features nonlinear persistence and conditional skewness. We confirm these results using population register data from Norway. We then show that the impact of earnings shocks varies substantially across earnings histories, and that this nonlinearity drives heterogeneous consumption responses. The framework provides new empirical measures of partial insurance in which the transmission of income shocks to consumption varies systematically with assets, the level of the shock, and the history of past shocks.","['Blundell, Richard', 'Bonhomme, Stephane', 'Arellano, Manuel']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Macroeconomics: Consumption; Saving; Wealth', 'Wage Level and Structure; Wage Differentials']","['C23', 'C51', 'D12', 'E21', 'J31']",Earnings and Consumption Dynamics: A Nonlinear Panel Data Framework,0,0,0,0,0,2017,05,01
88,6,2020-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,11,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2017–2018.,0,0,0,0,0,2019,01,01
89,2,2021-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 89 Iss. 2.,0,0,0,0,0,2021,03,01
89,2,2021-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 89 Iss. 2.,0,0,0,0,0,2021,03,01
89,2,2021-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2021,03,01
85,2,2017-03-01,"We provide the first analysis of altruism in networks. Agents are embedded in a fixed network and care about the well-being of their network neighbors. Depending on incomes, they may provide financial support to their poorer friends. We study the Nash equilibria of the resulting game of transfers. We show that equilibria maximize a concave potential function. We establish existence, uniqueness of equilibrium consumption, and generic uniqueness of equilibrium transfers. We characterize the geometry of the network of transfers and highlight the key role played by transfer intermediaries. We then study comparative statics. A positive income shock to an individual benefits all. For small changes in incomes, agents in a component of the network of transfers act as if they were organized in an income-pooling community. A decrease in income inequality or expansion of the altruism network may increase consumption inequality.","['Bramoulle, Yann', 'Perez-Richet, Eduardo', 'Bourles, Renaud']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Altruism; Philanthropy; Intergenerational Transfers', 'Network Formation and Analysis: Theory']","['D63', 'D64', 'D85']",Altruism in Networks,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"We propose a novel model of stochastic choice: the single-crossing random utility model (SCRUM). This is a random utility model in which the collection of preferences satisfies the single-crossing property. We offer a characterization of SCRUMs based on two easy-to-check properties: the classic Monotonicity property and a novel condition, Centrality. The identified collection of preferences and associated probabilities is unique. We show that SCRUMs nest both single-peaked and single-dipped random utility models and establish a stochastic monotone comparative result for the case of SCRUMs.","['Apesteguia, Jose', 'Lu, Jay', 'Ballester, Miguel A.']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Single-Crossing Random Utility Models,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"Limited overlap between the covariate distributions of groups with different treatment assignments does not only make estimates of average treatment effects rather imprecise, but can also lead to substantially distorted confidence intervals. This paper argues that this is because the coverage error of traditional confidence intervals is driven by the number of observations in the areas of limited overlap. Some of these ""local sample sizes"" can be very small in applications, up to the point that distributional approximations derived from classical asymptotic theory become unreliable. Building on this observation, this paper constructs confidence intervals based on classical approaches to small sample inference. The approach is easy to implement, and has superior theoretical and practical properties relative to standard methods in empirically relevant settings.","['Rothe, Christoph']","['Estimation: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C13', 'C21', 'C31']",Robust Confidence Intervals for Average Treatment Effects under Limited Overlap,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"We consider forecasting with uncertainty about the choice of predictor variables. The researcher wants to select a model, estimate the parameters, and use the parameter estimates for forecasting. We investigate the distributional properties of a number of different schemes for model choice and parameter estimation, including: in-sample model selection using the Akaike information criterion; out-of-sample model selection; and splitting the data into subsamples for model selection and parameter estimation. Using a weak-predictor local asymptotic scheme, we provide a representation result that facilitates comparison of the distributional properties of the procedures and their associated forecast risks. This representation isolates the source of inefficiency in some of these procedures. We develop a simulation procedure that improves the accuracy of the out-of-sample and split-sample methods uniformly over the local parameter space. We also examine how bootstrap aggregation (bagging) affects the local asymptotic risk of the estimators and their associated forecasts. Numerically, we find that for many values of the local parameter, the out-of-sample and split-sample schemes perform poorly if implemented in the conventional way. But they perform well, if implemented in conjunction with our risk-reduction method or bagging.","['Wright, Jonathan H.', 'Hirano, Keisuke']","['Forecasting Models; Simulation Methods', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Financial Forecasting and Simulation']","['C53', nan, 'G17']",Forecasting with Model Uncertainty: Representations and Risk Reduction,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"What does contract negotiation look like when some parties hold private information and negotiation frictions are negligible? This paper analyzes this question and provides a foundation for renegotiation-proof contracts in this environment. The model extends the framework of the Coase conjecture to situations in which the quantity or quality of the good is endogenously determined and to more general environments in which preferences are nonseparable in the traded goods. As frictions become negligible, all equilibria converge to a unique outcome which is separating, efficient, and straightforward to characterize.","['Strulovici, Bruno']","['Bargaining Theory; Matching Theory', 'Organizational Behavior; Transaction Costs; Property Rights', 'Economics of Contract: Theory']","['C78', 'D23', 'D86']",Contract Negotiation and the Coase Conjecture: A Strategic Foundation for Renegotiation-Proof Contracts,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"I study repeated competition among oligopolists. The only novelty is that firms may go bankrupt and permanently exit: the probability that a firm survives a price war depends on its financial strength, which varies stochastically over time. Under some conditions including no entry, an anti-folk theorem holds: when firms are patient, so that strength levels change relatively quickly, every Nash equilibrium involves an immediate price war that lasts until at most one firm remains. Surprisingly, the possibility of entry may facilitate collusion, as may impatience. The model can explain some observed patterns of collusion and predation.","['Wiseman, Thomas']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Bankruptcy; Liquidation', 'Monopoly; Monopolization Strategies', 'Oligopoly and Other Imperfect Markets']","['C73', 'D43', 'G33', 'L12', 'L13']",When Does Predation Dominate Collusion?,1,0,1,0,0,2017,03,01
85,2,2017-03-01,"We solve a general class of dynamic rational inattention problems in which an agent repeatedly acquires costly information about an evolving state and selects actions. The solution resembles the choice rule in a dynamic logit model, but it is biased toward an optimal default rule that is independent of the realized state. The model provides the same fit to choice data as dynamic logit, but, because of the bias, yields different counterfactual predictions. We apply the general solution to the study of (i) the status quo bias; (ii) inertia in actions leading to lagged adjustments to shocks; and (iii) the tradeoff between accuracy and delay in decision-making.","['Matejka, Filip', 'Stewart, Colin', 'Steiner, Jakub']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D83']",Rational Inattention Dynamics: Inertia and Delay in Decision-Making,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"This paper develops a theory of socially determined, and the interaction of those aspirations with growth and inequality. The interaction is bidirectional: economy-wide outcomes determine individual aspirations, which in turn determine investment incentives and social outcomes. Thus aspirations, income, and the of income evolve jointly. When capital stocks lie in some compact set, steady state distributions must exhibit inequality and are typically clustered around local poles. When sustained growth is possible, initial histories matter. Either there is convergence to an equal distribution (with growth) or there is perennial relative divergence across clusters, with within-cluster convergence. A central feature that drives these results is that aspirations that are moderately above an individual's current standard of living tend to encourage investment, while still higher aspirations may lead to frustration.","['Ray, Debraj', 'Genicot, Garance']","['Personal Income, Wealth, and Their Distributions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'General Welfare; Well-Being', 'One, Two, and Multisector Growth Models']","['D31', 'D63', 'I31', 'O41']",Aspirations and Inequality,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"A principal wishes to screen an agent along several dimensions of private information simultaneously. The agent has quasilinear preferences that are additively separable across the various components. We consider a robust version of the principal's problem, in which she knows the marginal distribution of each component of the agent's type, but does not know the joint distribution. Any mechanism is evaluated by its worst-case expected profit, over all joint distributions consistent with the known marginals. We show that the optimum for the principal is simply to screen along each component separately. This result does not require any assumptions (such as single crossing) on the structure of preferences within each component. The proof technique involves a generalization of the concept of virtual values to arbitrary screening problems. Sample applications include monopoly pricing and a stylized dynamic taxation model.","['Carroll, Gabriel']","['Asymmetric and Private Information; Mechanism Design', 'Taxation, Subsidies, and Revenue: General']","['D82', 'H20']",Robustness and Separation in Multidimensional Screening,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"This paper empirically investigates how sentences to be assigned at trial impact plea bargaining. The analysis is based on the model of bargaining with asymmetric information by Bebchuk, 1984. I provide conditions for the nonparametric identification of the model, propose a consistent nonparametric estimator, and implement it using data on criminal cases from North Carolina. Employing the estimated model, I evaluate how different sentencing reforms affect the outcome of criminal cases. My results indicate that lower mandatory minimum sentences could greatly reduce the total amount of incarceration time assigned by the courts, but may increase conviction rates. In contrast, the broader use of non-incarceration sentences for less serious crimes reduces the number of incarceration convictions, but has a very small effect over the total assigned incarceration time. I also consider the effects of a ban on plea bargains. Depending on the case characteristics, over 20 percent of the defendants who currently receive incarceration sentences would be acquitted if plea bargains were forbidden.","['Silveira, Bernardo S.']","['Model Construction and Estimation', 'Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design', 'Litigation Process']","['C51', 'C78', 'D82', 'K41']",Bargaining with Asymmetric Information: An Empirical Study of Plea Negotiations,0,1,0,0,0,2017,03,01
85,2,2017-03-01,"The impact of insurer competition on welfare, negotiated provider prices, and premiums in the U.S. private health care industry is theoretically ambiguous. Reduced competition may increase the premiums charged by insurers and their payments made to hospitals. However, it may also strengthen insurers' bargaining leverage when negotiating with hospitals, thereby generating offsetting cost decreases. To understand and measure this trade-off, we estimate a model of employer-insurer and hospital-insurer bargaining over premiums and reimbursements, household demand for insurance, and individual demand for hospitals using detailed California admissions, claims, and enrollment data. We simulate the removal of both large and small insurers from consumers' choice sets. Although consumer welfare decreases and premiums typically increase, we find that premiums can fall upon the removal of a small insurer if an employer imposes effective premium constraints through negotiations with the remaining insurers. We also document substantial heterogeneity in hospital price adjustments upon the removal of an insurer, with renegotiated price increases and decreases of as much as 10% across markets.","['Ho, Kate', 'Lee, Robin S.']","['Insurance; Insurance Companies; Actuarial Studies', 'State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Health Care Markets', 'Health Insurance, Public and Private']","['G22', 'H75', 'I11', 'I13']",Insurer Competition in Health Care Markets,0,0,0,0,0,2017,03,01
85,2,2017-03-01,"We present a model of the relationship between real interest rates, credit spreads, and the structure and risk of the banking system. Banks intermediate between entrepreneurs and investors, and can monitor entrepreneurs' projects. We characterize the equilibrium for a fixed aggregate supply of savings, showing that safer entrepreneurs will be funded by nonmonitoring banks and riskier entrepreneurs by monitoring banks. We show that an increase in savings reduces interest rates and spreads, and increases the relative size of the nonmonitoring banking system and the probability of failure of monitoring banks. We also show that the dynamic version of the model exhibits endogenous boom and bust cycles, and rationalizes the existence of countercyclical risk premia and the connection between low interest rates, tight credit spreads, and the buildup of risks during booms.","['Martinez-Miera, David', 'Repullo, Rafael']","['Business Fluctuations; Cycles', 'Financial Markets and the Macroeconomy', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financial Institutions and Services: Government Policy and Regulation', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Bankruptcy; Liquidation', 'Entrepreneurship']","['E32', 'E44', 'G21', 'G28', 'G32', 'G33', 'L26']",Search for Yield,1,0,0,0,0,2017,03,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2015-2016.,0,0,0,0,0,2017,01,01
85,1,2017-01-01,ECONLIT None Found,"['Salanie, Bernard']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Treasurer,0,0,0,0,0,2017,01,01
85,1,2017-01-01,ECONLIT None Found,"['Salanie, Bernard']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Secretary,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"This paper extends the long-term factorization of the stochastic discount factor introduced and studied by Alvarez and Jermann (2005) in discrete-time ergodic environments and by Hansen and Scheinkman (2009) and Hansen (2012) in Markovian environments to general semimartingale environments. The transitory component discounts at the stochastic rate of return on the long bond and is factorized into discounting at the long-term yield and a positive semimartingale that extends the principal eigenfunction of Hansen and Scheinkman (2009) to the semimartingale setting. The permanent component is a martingale that accomplishes a change of probabilities to the long forward measure, the limit of T-forward measures. The change of probabilities from the data-generating to the long forward measure absorbs the long-term risk-return trade-off and interprets the latter as the long-term risk-neutral measure.","['Qin, Likuan', 'Linetsky, Vadim']","['Criteria for Decision-Making under Risk and Uncertainty', 'Interest Rates: Determination, Term Structure, and Effects', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', 'E43', nan]",Long-Term Risk: A Martingale Approach,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"In this paper, we provide efficient estimators and honest confidence bands for a variety of treatment effects including local average (LATE) and local quantile treatment effects (LQTE) in data-rich environments. We can handle control variables, receipt of treatment, treatment effects, and outcomes. Our framework covers the special case of exogenous receipt of treatment, either conditional on controls or unconditionally as in randomized control trials. In the latter case, our approach produces efficient estimators and honest bands for (functional) average treatment effects (ATE) and quantile treatment effects (QTE). To make informative inference possible, we assume that key reduced-form predictive relationships are approximately sparse. This assumption allows the use of regularization and selection methods to estimate those relations, and we provide methods for post-regularization and post-selection inference that are uniformly valid (honest) across a wide range of models. We show that a key ingredient enabling honest inference is the use of orthogonal or doubly robust moment conditions in estimating certain reduced-form functional parameters. We illustrate the use of the proposed methods with an application to estimating the effect of 401(k) eligibility and participation on accumulated assets. The results on program evaluation are obtained as a consequence of more general results on honest inference in a general moment-condition framework, which arises from structural equation models in econometrics. Here, too, the crucial ingredient is the use of orthogonal moment conditions, which can be constructed from the initial moment conditions. We provide results on honest inference for (function-valued) parameters within this general framework where any high-quality, machine learning methods (e.g., boosted trees, deep neural networks, random forest, and their aggregated and hybrid versions) can be used to learn the nonparametric/high-dimensional components of the model. These include a number of supporting auxiliary results that are of major independent interest: namely, we (1) prove uniform validity of a multiplier bootstrap, (2) offer a uniformly valid functional delta method, and (3) provide results for sparsity-based estimation of regression functions for function-valued outcomes.","['Fernandez-Val, I.', 'Hansen, C.', 'Chernozhukov, V.', 'Belloni, A.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Large Data Sets: Modeling and Analysis', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C21', 'C22', 'C26', 'C55', nan]",Program Evaluation and Causal Inference with High-Dimensional Data,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"The availability of high frequency financial data has generated a series of estimators based on intra-day data, improving the quality of large areas of financial econometrics. However, estimating the standard error of these estimators is often challenging. The root of the problem is that traditionally, standard errors rely on estimating a theoretically derived asymptotic variance, and often this asymptotic variance involves substantially more complex quantities than the original parameter to be estimated. Standard errors are important: they are used to assess the precision of estimators in the form of confidence intervals, to create ""feasible statistics"" for testing, to build forecasting models based on, say, daily estimates, and also to optimize the tuning parameters. The contribution of this paper is to provide an alternative and general solution to this problem, which we call Observed Asymptotic Variance. It is a general nonparametric method for assessing asymptotic variance (AVAR). It provides consistent estimators of AVAR for a broad class of integrated parameters theta = integral of theta_{t}dt, where the spot parameter process theta can be a general semimartingale, with continuous and jump components. The observed AVAR is implemented with the help of a two-scales method. Its construction works well in the presence of microstructure noise, and when the observation times are irregular or asynchronous in the multivariate case. The methodology is valid for a wide variety of estimators, including the standard ones for variance and covariance, and also for more complex estimators, such as, of leverage effects, high frequency betas, and semivariance.","['Zhang, Lan', 'Mykland, Per A.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Large Data Sets: Modeling and Analysis', 'Financial Econometrics']","['C22', 'C55', 'C58']",Assessment of Uncertainty in High Frequency Data: The Observed Asymptotic Variance,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"We develop econometric tools for studying jump dependence of two processes from high-frequency observations on a fixed time interval. In this context, only segments of data around a few outlying observations are informative for the inference. We derive an asymptotically valid test for stability of a linear jump relation over regions of the jump size domain. The test has power against general forms of nonlinearity in the jump dependence as well as temporal instabilities. We further propose an efficient estimator for the linear jump regression model that is formed by optimally weighting the detected jumps with weights based on the diffusive volatility around the jump times. We derive the asymptotic limit of the estimator, a semiparametric lower efficiency bound for the linear jump regression, and show that our estimator attains the latter. The analysis covers both deterministic and random jump arrivals. In an empirical application, we use the developed inference techniques to test the temporal stability of market jump betas.","['Li, Jia', 'Todorov, Viktor', 'Tauchen, George']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Large Data Sets: Modeling and Analysis', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C55', 'C58', nan]",Jump Regressions,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"This paper proposes a framework for studying competitive (pure) bundling in an oligopoly market. We find that under fairly general conditions, relative to separate sales, bundling raises market prices, benefits firms, and harms consumers when the number of firms is above a threshold (which can be small). This is in contrast to the findings in the duopoly case on which the existing literature often focuses. Our analysis also sheds new light on how consumer valuation dispersion affects price competition more generally.","['Zhou, Jidong']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D43', 'L13']",Competitive Bundling,1,0,1,0,0,2017,01,01
85,1,2017-01-01,"We explore the impact of private information in sealed-bid first-price auctions. For a given symmetric and arbitrarily correlated prior distribution over values, we characterize the lowest winning-bid distribution that can arise across all information structures and equilibria. The information and equilibrium attaining this minimum leave bidders indifferent between their equilibrium bids and all higher bids. Our results provide lower bounds for bids and revenue with asymmetric distributions over values. We also report further characterizations of revenue and bidder surplus including upper bounds on revenue. Our work has implications for the identification of value distributions from data on winning bids and for the informationally robust comparison of alternative auction mechanisms.","['Bergemann, Dirk', 'Brooks, Benjamin', 'Morris, Stephen']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",First-Price Auctions with General Information Structures: Implications for Bidding and Revenue,0,0,1,0,0,2017,01,01
85,1,2017-01-01,"This paper proposes a perfectly competitive model of a market with adverse selection. Prices are determined by zero-profit conditions, and the set of traded contracts is determined by free entry. Crucially for applications, contract characteristics are endogenously determined, consumers may have multiple dimensions of private information, and an equilibrium always exists. Equilibrium corresponds to the limit of a differentiated products Bertrand game. We apply the model to establish theoretical results on the equilibrium effects of mandates. Mandates can increase efficiency but have unintended consequences. With adverse selection, an insurance mandate reduces the price of low-coverage policies, which necessarily has indirect effects such as increasing adverse selection on the intensive margin and causing some consumers to purchase less coverage.","['Azevedo, Eduardo M.', 'Gottlieb, Daniel']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Insurance; Insurance Companies; Actuarial Studies']","['D82', 'D86', 'G22']",Perfect Competition in Markets with Adverse Selection,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"We assess the empirical content of equilibrium models of labor market sorting based on unobserved (to economists) characteristics. In particular, we show theoretically that all parameters of the classic model of sorting based on absolute advantage in Becker, 1973 with search frictions can be nonparametrically identified using only matched employer-employee data on wages and labor market transitions. In particular, these data are sufficient to nonparametrically estimate the output of any individual worker with any given firm. Our identification proof is constructive and we provide computational algorithms that implement our identification strategy given the limitations of the available data sets. Finally, we add on-the-job search to the model, extend the identification strategy, and apply it to a large German matched employer-employee data set to describe detailed patterns of sorting and properties of the production function.","['Manovskii, Iourii', 'Hagedorn, Marcus', 'Law, Tzuo Hann']","['Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J22', 'J31', 'J41', 'J64']",Identifying Equilibrium Models of Labor Market Sorting,0,0,0,0,0,2017,01,01
85,1,2017-01-01,"We propose a method to correct for sample selection in quantile regression models. Selection is modeled via the cumulative distribution function, or copula, of the percentile error in the outcome equation and the error in the participation decision. Copula parameters are estimated by minimizing a method-of-moments criterion. Given these parameter estimates, the percentile levels of the outcome are readjusted to correct for selection, and quantile parameters are estimated by minimizing a rotated ""check"" function. We apply the method to correct wage percentiles for selection into employment, using data for the UK for the period 1978-2000. We also extend the method to account for the presence of equilibrium effects when performing counterfactual exercises.","['Bonhomme, Stephane', 'Arellano, Manuel']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Economics of Gender; Non-labor Discrimination', 'Wage Level and Structure; Wage Differentials']","['C21', 'J16', 'J31']",Quantile Selection Models with an Application to Understanding Changes in Wage Inequality,0,0,0,0,0,2017,01,01
84,6,2016-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 84 Iss. 6.,0,0,0,0,0,2016,11,01
84,6,2016-11-01,ECONLIT None Found,"['Porter, Robert']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society 2016 Annual Report of the President,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"We present a noncooperative game model of coalitional bargaining, closely based on that of Gul (1989) but solvable by backward induction. In this game, Gul's condition of ""value additivity"" does not suffice to ensure the existence of a subgame perfect Nash equilibrium that supports the Shapley value, but a related condition--""no positive value-externalities""--does. Multiple equilibria can arise only in the event of ties, and with a mild restriction on tie-break rules these equilibria all support the Shapley value.","['McQuillin, Ben', 'Sugden, Robert']","['Noncooperative Games', 'Bargaining Theory; Matching Theory']","['C72', 'C78']",Backward Induction Foundations of the Shapley Value,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"This paper provides a novel mechanism for identifying and estimating latent group structures in panel data using penalized techniques. We consider both linear and nonlinear models where the regression coefficients are heterogeneous across groups but homogeneous within a group and the group membership is unknown. Two approaches are considered--penalized profile likelihood (PPL) estimation for the general nonlinear models without endogenous regressors, and penalized GMM (PGMM) estimation for linear models with endogeneity. In both cases, we develop a new variant of Lasso called classifier-Lasso (C-Lasso) that serves to shrink individual coefficients to the unknown group-specific coefficients. C-Lasso achieves simultaneous classification and consistent estimation in a single step and the classification exhibits the desirable property of uniform consistency. For PPL estimation, C-Lasso also achieves the oracle property so that group-specific parameter estimators are asymptotically equivalent to infeasible estimators that use individual group identity information. For PGMM estimation, the oracle property of C-Lasso is preserved in some special cases. Simulations demonstrate good finite-sample performance of the approach in both classification and estimation. Empirical applications to both linear and nonlinear models are presented.","['Phillips, Peter C. B.', 'Shi, Zhentao', 'Su, Liangjun']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Conflict; Conflict Resolution; Alliances; Revolutions', 'Macroeconomics: Consumption; Saving; Wealth', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['C23', 'D74', 'E21', 'O16']",Identifying Latent Structures in Panel Data,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"Confidence intervals are commonly used to describe parameter uncertainty. In nonstandard problems, however, their frequentist coverage property does not guarantee that they do so in a reasonable fashion. For instance, confidence intervals may be empty or extremely short with positive probability, even if they are based on inverting powerful tests. We apply a betting framework and a notion of bet-proofness to formalize the ""reasonableness"" of confidence intervals as descriptions of parameter uncertainty, and use it for two purposes. First, we quantify the violations of bet-proofness for previously suggested confidence intervals in nonstandard problems. Second, we derive alternative confidence sets that are bet-proof by construction. We apply our framework to several nonstandard problems involving weak instruments, near unit roots, and moment inequalities. We find that previously suggested confidence intervals are not bet-proof, and numerically determine alternative bet-proof confidence sets.","['Norets, Andriy', 'Muller, Ulrich K.']","['Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Model Construction and Estimation']","['C13', 'C22', 'C26', 'C51']",Credibility of Confidence Sets in Nonstandard Econometric Problems,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"We introduce the class of conditional linear combination tests, which reject null hypotheses concerning model parameters when a data-dependent convex combination of two identification-robust statistics is large. These tests control size under weak identification and have a number of optimality properties in a conditional problem. We show that the conditional likelihood ratio test of Moreira, 2003 is a conditional linear combination test in models with one endogenous regressor, and that the class of conditional linear combination tests is equivalent to a class of quasi-conditional likelihood ratio tests. We suggest using minimax regret conditional linear combination tests and propose a computationally tractable class of tests that plug in an estimator for a nuisance parameter. These plug-in tests perform well in simulation and have optimal power in many strongly identified models, thus allowing powerful identification-robust inference in a wide range of linear and nonlinear models without sacrificing efficiency if identification is strong.","['Andrews, Isaiah']","['Hypothesis Testing: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C12', 'C26']",Conditional Linear Combination Tests for Weakly Identified Models,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"We analyze the internal consistency of using the market price of a firm's equity to trigger a contractual change in the firm's capital structure, given that the value of the equity itself depends on the firm's capital structure. Of particular interest is the case of contingent capital for banks, in the form of debt that converts to equity, when conversion is triggered by a decline in the bank's stock price. We analyze the problem of existence and uniqueness of equilibrium values for a firm's liabilities in this context, meaning values consistent with a market-price trigger. Discrete-time dynamics allow multiple equilibria. In contrast, we show that the possibility of multiple equilibria can largely be ruled out in continuous time, where the price of the triggering security adjusts in anticipation of breaching the trigger. Our main condition for existence of an equilibrium requires that the consequences of triggering a conversion be consistent with the direction in which the trigger is crossed. For the design of contingent capital with a stock price trigger, this condition may be interpreted to mean that conversion should be disadvantageous to shareholders, and it is satisfied by setting the trigger sufficiently high. Uniqueness follows provided the trigger is sufficiently accessible by all candidate equilibria. We illustrate precise formulations of these conditions with a variety of applications.","['Glasserman, Paul', 'Nouri, Behzad']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","[nan, 'G14', 'G32']",Market-Triggered Changes in Capital Structure: Equilibrium Price Dynamics,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"The past forty years have seen a rapid rise in top income inequality in the United States. While there is a large number of existing theories of the Pareto tail of the long-run income distributions, almost none of these address the fast rise in top inequality observed in the data. We show that standard theories, which build on a random growth mechanism, generate transition dynamics that are too slow relative to those observed in the data. We then suggest two parsimonious deviations from the canonical model that can explain such changes: ""scale dependence"" that may arise from changes in skill prices, and ""type dependence,"" that is, the presence of some ""high-growth types."" These deviations are consistent with theories in which the increase in top income inequality is driven by the rise of ""superstar"" entrepreneurs or managers.","['Lions, Pierre-Louis', 'Moll, Benjamin', 'Gabaix, Xavier', 'Lasry, Jean-Michel']","['Personal Income, Wealth, and Their Distributions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D31', 'D63']",The Dynamics of Inequality,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"Consider a group of individuals with unobservable perspectives (subjective prior beliefs) about a sequence of states. In each period, each individual receives private information about the current state and forms an opinion (a posterior belief). She also chooses a target individual and observes the target's opinion. This choice involves a trade-off between well-informed targets, whose signals are precise, and well-understood targets, whose perspectives are well known. Opinions are informative about the target's perspective, so observed individuals become better understood over time. We identify a simple condition under which long-run behavior is history independent. When this fails, each individual restricts attention to a small set of experts and observes the most informed among these. A broad range of observational patterns can arise with positive probability, including opinion leadership and information segregation. In an application to areas of expertise, we show how these mechanisms generate own field bias and large field dominance.","['Sethi, Rajiv', 'Yildiz, Muhamet']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory']","['D82', 'D83', 'D85']",Communication with Unknown Perspectives,0,0,0,0,0,2016,11,01
84,6,2016-11-01,"We consider an agent who chooses an option after receiving some private information. This information, however, is unobserved by an analyst, so from the latter's perspective, choice is probabilistic or random. We provide a theory in which information can be fully identified from random choice. In addition, the analyst can perform the following inferences even when information is unobservable: (1) directly compute ex ante valuations of menus from random choice and vice versa, (2) assess which agent has better information by using choice dispersion as a measure of informativeness, (3) determine if the agent's beliefs about information are dynamically consistent, and (4) test to see if these beliefs are well-calibrated or rational.","['Lu, Jay']","['Consumer Economics: Theory', 'Asymmetric and Private Information; Mechanism Design']","['D11', 'D82']",Random Choice and Private Information,0,0,0,0,0,2016,11,01
84,5,2016-09-01,"IO economists often estimate demand for differentiated products using data sets with a small number of large markets. This paper addresses the question of consistency and asymptotic distributions of instrumental variables estimates as the number of products increases in some commonly used models of demand under conditions on economic primitives. I show that, in a Bertrand-Nash equilibrium, product characteristics lose their identifying power as price instruments in the limit in certain cases, leading to inconsistent estimates. The reason is that product characteristic instruments achieve identification through correlation with markups, and, depending on the model of demand, the supply side can constrain markups to converge to a constant quickly relative to sampling error. I find that product characteristic instruments can yield consistent estimates in many of the cases I consider, but care must be taken in modeling demand and choosing instruments. A Monte Carlo study confirms that the asymptotic results are relevant in market sizes of practical importance.","['Armstrong, Timothy B.']","['Model Construction and Estimation', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['C51', 'D43', 'L13']",Large Market Asymptotics for Differentiated Product Demand Estimators with Economic Models of Supply,1,0,1,0,0,2016,09,01
84,5,2016-09-01,"The farm household model has played a central role in improving the understanding of small-scale agricultural households and non-farm enterprises. Under the assumptions that all current and future markets exist and that farmers treat all prices as given, the model simplifies households' simultaneous production and consumption decisions into a recursive form in which production can be treated as independent of preferences of household members. These assumptions, which are the foundation of a large literature in labor and development, have been tested and not rejected in several important studies including Benjamin (1992). Using multiple waves of longitudinal survey data from Central Java, Indonesia, this paper tests a key prediction of the recursive model: demand for farm labor is unrelated to the demographic composition of the farm household. The prediction is unambiguously rejected. The rejection cannot be explained by contamination due to unobserved heterogeneity that is fixed at the farm level, local area shocks, or farm-specific shocks that affect changes in household composition and farm labor demand. We conclude that the recursive form of the farm household model is not consistent with the data. Developing empirically tractable models of farm households when markets are incomplete remains an important challenge.","['LaFave, Daniel', 'Thomas, Duncan']","['Exchange and Production Economies', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Labor Demand', 'Agricultural Labor Markets', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Micro Analysis of Farm Firms, Farm Households, and Farm Input Markets']","['D51', 'J12', 'J23', 'J43', 'O12', 'O13', 'Q12']","Farms, Families, and Markets: New Evidence on Completeness of Markets in Agricultural Settings",0,0,0,0,0,2016,09,01
84,5,2016-09-01,"We consider a decision maker who ranks actions according to the smooth ambiguity criterion of Klibanoff, Marinacci, and Mukerji (2005). An action is justifiable if it is a best reply to some belief over probabilistic models. We show that higher ambiguity aversion expands the set of justifiable actions. A similar result holds for risk aversion. Our results follow from a generalization of the duality lemma of Wald (1949) and Pearce (1984).","['Cerreia-Vioglio, S.', 'Maccheroni, F.', 'Battigalli, P.', 'Marinacci, M.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Note on Comparative Ambiguity Aversion and Justifiability,0,0,0,0,0,2016,09,01
84,5,2016-09-01,"We study families of normal-form games with fixed preferences over pure action profiles but varied preferences over lotteries. That is, we subject players' utilities to monotone but nonlinear transformations and examine changes in the rationalizable set and set of equilibria. Among our results: The rationalizable set always grows under concave transformations (risk aversion) and shrinks under convex transformations (risk love). The rationalizable set reaches an upper bound under extreme risk aversion, and lower bound under risk love, and both of these bounds are characterized by elimination processes. For generic two-player games, under extreme risk love or aversion, all Nash equilibria are close to pure and the limiting set of equilibria can be described using preferences over pure action profiles.","['Weinstein, Jonathan']","['Game Theory and Bargaining Theory: General', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D81', 'D83']",The Effect of Changes in Risk Attitude on Strategic Behavior,0,0,0,0,0,2016,09,01
84,5,2016-09-01,"Two fundamental axioms in social choice theory are consistency with respect to a variable electorate and consistency with respect to components of similar alternatives. In the context of traditional non-probabilistic social choice, these axioms are incompatible with each other. We show that in the context of social choice, these axioms uniquely characterize a function proposed by Fishburn (1984). Fishburn's function returns so-called maximal lotteries, that is, lotteries that correspond to optimal mixed strategies in the symmetric zero-sum game induced by the pairwise majority margins. Maximal lotteries are guaranteed to exist due to von Neumann's Minimax Theorem, are almost always unique, and can be efficiently computed using linear programming.","['Seedig, Hans Georg', 'Brandl, Florian', 'Brandt, Felix']","['Auctions', 'Social Choice; Clubs; Committees; Associations']","['D44', 'D71']",Consistent Probabilistic Social Choice,0,0,1,0,0,2016,09,01
84,5,2016-09-01,Call an economic model incomplete if it does not generate a probabilistic prediction even given knowledge of all parameter values. We propose a method of inference about unknown parameters for such models that is robust to heterogeneity and dependence of unknown form. The key is a Central Limit Theorem for belief functions; robust confidence regions are then constructed in a fashion paralleling the classical approach. Monte Carlo simulations support tractability of the method and demonstrate its enhanced robustness relative to existing methods.,"['Epstein, Larry G.', 'Seo, Kyoungwon', 'Kaido, Hiroaki']","['Hypothesis Testing: General', 'Statistical Simulation Methods: General', 'Game Theory and Bargaining Theory: General', 'Design of Experiments: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C12', 'C15', 'C70', 'C90', 'D83']",Robust Confidence Regions for Incomplete Models,0,0,0,0,0,2016,09,01
84,5,2016-09-01,"I estimate a search-and-bargaining model of a decentralized market to quantify the effects of trading frictions on asset allocations, asset prices, and welfare, and to quantify the effects of intermediaries that facilitate trade. Using business-aircraft data, I find that, relative to the Walrasian benchmark, 18.3 percent of the assets are misallocated; prices are 19.2 percent lower; and the aggregate welfare losses equal 23.9 percent. Dealers play an important role in reducing trading frictions: In a market with no dealers, a larger fraction of assets would be misallocated, and prices would be higher. However, dealers reduce aggregate welfare because their operations are costly, and they impose a negative externality by decreasing the number of agents' direct transactions.","['Gavazza, Alessandro']","['Model Construction and Estimation', 'Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Automobiles; Other Transportation Equipment; Related Parts and Equipment', 'Retail and Wholesale Trade; e-Commerce']","['C51', 'C78', 'D83', 'L62', 'L81']",An Empirical Equilibrium Model of a Decentralized Asset Market,1,0,0,0,0,2016,09,01
84,5,2016-09-01,"We estimate a dynamic model of employment, human capital accumulation--including education, and savings for women in the United Kingdom, exploiting tax and benefit reforms, and use it to analyze the effects of welfare policy. We find substantial elasticities for labor supply and particularly for lone mothers. Returns to experience, which are important in determining the longer-term effects of policy, increase with education, but experience mainly accumulates when in full-time employment. Tax credits are welfare improving in the U.K., increase lone-mother labor supply and marginally reduce educational attainment, but the employment effects do not extend beyond the period of eligibility. Marginal increases in tax credits improve welfare more than equally costly increases in income support or tax cuts.","['Blundell, Richard', 'Meghir, Costas', 'Shaw, Jonathan', 'Costa Dias, Monica']","['Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Returns to Education', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['H24', 'H31', 'I26', 'I38', 'J16', 'J22']","Female Labor Supply, Human Capital, and Welfare Reform",0,0,0,0,0,2016,09,01
84,5,2016-09-01,"We propose a theory of monetary policy and macroprudential interventions in financial markets. We focus on economies with nominal rigidities in goods and labor markets and subject to constraints on monetary policy, such as the zero lower bound or fixed exchange rates. We identify an aggregate demand externality that can be corrected by macroprudential interventions in financial markets. Ex post, the distribution of wealth across agents affects aggregate demand and output. Ex ante, however, these effects are not internalized in private financial decisions. We provide a simple formula for the required financial interventions that depends on a small number of measurable sufficient statistics. We also characterize optimal monetary policy. We extend our framework to incorporate pecuniary externalities, providing a unified approach to both externalities. Finally, we provide a number of applications which illustrate the relevance of our theory.","['Werning, Ivan', 'Farhi, Emmanuel']","['General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Business Fluctuations; Cycles', 'Financial Markets and the Macroeconomy', 'Monetary Policy', 'Comparative or Joint Analysis of Fiscal and Monetary Policy; Stabilization; Treasury Policy', 'Foreign Exchange']","[nan, 'E32', 'E44', 'E52', 'E63', 'F31']",A Theory of Macroprudential Policies in the Presence of Nominal Rigidities,0,0,0,0,0,2016,09,01
84,4,2016-07-01,ECONLIT None Found,[nan],[nan],[nan],2015 Election of Fellows to the Econometric Society.,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"We propose a semiparametric two-step inference procedure for a finite-dimensional parameter based on moment conditions constructed from high-frequency data. The population moment conditions take the form of temporally integrated functionals of state-variable processes that include the latent stochastic volatility process of an asset. In the first step, we nonparametrically recover the volatility path from high-frequency asset returns. The nonparametric volatility estimator is then used to form sample moment functions in the second-step GMM estimation, which requires the correction of a high-order nonlinearity bias from the first step. We show that the proposed estimator is consistent and asymptotically mixed Gaussian and propose a consistent estimator for the conditional asymptotic variance. We also construct a Bierens-type consistent specification test. These infill asymptotic results are based on a novel empirical-process-type theory for general integrated functionals of noisy semimartingale processes.","['Li, Jia', 'Xiu, Dacheng']",['Large Data Sets: Modeling and Analysis'],['C55'],Generalized Method of Integrated Moments for High-Frequency Data,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"This paper shows that the problem of testing hypotheses in moment condition models without any assumptions about identification may be considered as a problem of testing with an infinite-dimensional nuisance parameter. We introduce a sufficient statistic for this nuisance parameter in a Gaussian problem and propose conditional tests. These conditional tests have uniformly correct asymptotic size for a large class of models and test statistics. We apply our approach to construct tests based on quasi-likelihood ratio statistics, which we show are efficient in strongly identified models and perform well relative to existing alternatives in two examples.","['Andrews, Isaiah', 'Mikusheva, Anna']","['Hypothesis Testing: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C12', 'C26']",Conditional Inference with a Functional Nuisance Parameter,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"We develop and estimate a general equilibrium search and matching model that accounts for key business cycle properties of macroeconomic aggregates, including labor market variables. In sharp contrast to leading New Keynesian models, we do not impose wage inertia. Instead we derive wage inertia from our specification of how firms and workers negotiate wages. Our model outperforms a variant of the standard New Keynesian Calvo sticky wage model. According to our estimated model, there is a critical interaction between the degree of price stickiness, monetary policy, and the duration of an increase in unemployment benefits.","['Christiano, Lawrence J.', 'Eichenbaum, Martin S.', 'Trabandt, Mathias']","['General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Monetary Policy', 'Wage Level and Structure; Wage Differentials', 'Unemployment Insurance; Severance Pay; Plant Closings']","[nan, 'E24', 'E32', 'E52', 'J31', 'J65']",Unemployment and Business Cycles,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"What is the role of a country's financial system in determining technology adoption? To examine this, a dynamic contract model is embedded into a general equilibrium setting with competitive intermediation. The terms of finance are dictated by an intermediary's ability to monitor and control a firm's cash flow, in conjunction with the structure of the technology that the firm adopts. It is not always profitable to finance promising technologies. A quantitative illustration is presented where financial frictions induce entrepreneurs in India and Mexico to adopt less-promising ventures than in the United States, despite lower input prices.","['Cole, Harold L.', 'Greenwood, Jeremy', 'Sanchez, Juan M.']","['Financial Markets and the Macroeconomy', 'Investment Banking; Venture Capital; Brokerage; Ratings and Ratings Agencies', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Entrepreneurship', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance', 'Technological Change: Choices and Consequences; Diffusion Processes']","['E44', 'G24', 'G32', 'L26', 'O16', 'O33']",Why Doesn't Technology Flow from Rich to Poor Countries?,1,0,0,1,0,2016,07,01
84,4,2016-07-01,"We extend Kyle's (1985) model of insider trading to the case where noise trading volatility follows a general stochastic process. We determine conditions under which, in equilibrium, price impact and price volatility are both stochastic, driven by shocks to uninformed volume even though the fundamental value is constant. The volatility of price volatility appears 'excessive' because insiders choose to trade more aggressively (and thus more information is revealed) when uninformed volume is higher and price impact is lower. This generates a positive relation between price volatility and trading volume, giving rise to an endogenous subordinate stochastic process for prices.","['Fos, Vyacheslav', 'Collin-Dufresne, Pierre']","['Asymmetric and Private Information; Mechanism Design', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D82', nan, 'G14']","Insider Trading, Stochastic Liquidity, and Equilibrium Prices",0,0,0,0,0,2016,07,01
84,4,2016-07-01,"We study a continuous-time contracting problem under hidden action, where the principal has ambiguous beliefs about the project cash flows. The principal designs a robust contract that maximizes his utility under the worst-case scenario subject to the agent's incentive and participation constraints. Robustness generates endogenous belief heterogeneity and induces a tradeoff between incentives and ambiguity sharing so that the incentive constraint does not always bind. We implement the optimal contract by cash reserves, debt, and equity. In addition to receiving ordinary dividends when cash reserves reach a threshold, outside equity holders also receive special dividends or inject cash in the cash reserves to hedge against model uncertainty and smooth dividends. The equity premium and the credit yield spread generated by ambiguity aversion are state dependent and high for distressed firms with low cash reserves.","['Miao, Jianjun', 'Rivera, Alejandro']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', 'D82', 'D86', nan]",Robust Contracts in Continuous Time,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"Using the intuition that financial markets transfer risks in business time, ""market microstructure invariance"" is defined as the hypotheses that the distributions of risk transfers (""bets"") and transaction costs are constant across assets when measured per unit of business time. The invariance hypotheses imply that bet size and transaction costs have specific, empirically testable relationships to observable dollar volume and volatility. Portfolio transitions can be viewed as natural experiments for measuring transaction costs, and individual orders can be treated as proxies for bets. Empirical tests based on a data set of 400,000+ portfolio transition orders support the invariance hypotheses. The constants calibrated from structural estimation imply specific predictions for the arrival rate of bets (""market velocity""), the distribution of bet sizes, and transaction costs.","['Obizhaeva, Anna A.', 'Kyle, Albert S.']","['Financial Econometrics', 'Organizational Behavior; Transaction Costs; Property Rights', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C58', 'D23', 'G11', nan]",Market Microstructure Invariance: Empirical Hypotheses,0,0,0,0,0,2016,07,01
84,4,2016-07-01,"In a number of interesting environments, dynamic screening involves positive selection: in contrast with Coasian dynamics, only the most motivated remain over time. The paper provides conditions under which the principal's commitment optimum is time consistent and uses this result to derive testable predictions under permanent or transient shocks. It also identifies environments in which time consistency does not hold despite positive selection, and yet simple equilibrium characterizations can be obtained.","['Tirole, Jean']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Monopoly', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'D42', 'D82']",From Bottom of the Barrel to Cream of the Crop: Sequential Screening with Positive Selection,0,0,1,0,0,2016,07,01
84,3,2016-05-01,"Life insurers use reinsurance to move liabilities from regulated and rated companies that sell policies to shadow reinsurers, which are less regulated and unrated off-balance-sheet entities within the same insurance group. U.S. life insurance and annuity liabilities ceded to shadow reinsurers grew from $11 billion in 2002 to $364 billion in 2012. Life insurers using shadow insurance, which capture half of the market share, ceded 25 cents of every dollar insured to shadow reinsurers in 2012, up from 2 cents in 2002. By relaxing capital requirements, shadow insurance could reduce the marginal cost of issuing policies and thereby improve retail market efficiency. However, shadow insurance could also reduce risk-based capital and increase expected loss for the industry. We model and quantify these effects based on publicly available data and plausible assumptions.","['Yogo, Motohiro', 'Koijen, Ralph S. J.']","['Insurance; Insurance Companies; Actuarial Studies', 'Financial Institutions and Services: Government Policy and Regulation', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['G22', 'G28', 'G32']",Shadow Insurance,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"Conventional tests for composite hypotheses in minimum distance models can be unreliable when the relationship between the structural and reduced-form parameters is highly nonlinear. Such nonlinearity may arise for a variety of reasons, including weak identification. In this note, we begin by studying the problem of testing a ""curved null"" in a finite-sample Gaussian model. Using the curvature of the model, we develop new finite-sample bounds on the distribution of minimum-distance statistics. These bounds allow us to construct tests for composite hypotheses which are uniformly asymptotically valid over a large class of data generating processes and structural models.","['Andrews, Isaiah', 'Mikusheva, Anna']",['Hypothesis Testing: General'],['C12'],A Geometric Approach to Nonlinear Econometric Models,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"Individual heterogeneity is an important source of variation in demand. Allowing for general heterogeneity is needed for correct welfare comparisons. We consider general heterogeneous demand where preferences and linear budget sets are statistically independent. Only the marginal distribution of demand for each price and income is identified from cross-section data where only one price and income is observed for each individual. Thus, objects that depend on varying price and/or income for an individual are not generally identified, including average exact consumer surplus. We use bounds on income effects to derive relatively simple bounds on the average surplus, including for discrete/continuous choice. We also sketch an approach to bounding surplus that does not use income effect bounds. We apply the results to gasoline demand. We find tight bounds for average surplus in this application, but wider bounds for average deadweight loss.","['Hausman, Jerry A.', 'Newey, Whitney K.']","['Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis', 'Business Taxes and Subsidies including sales and value-added (VAT)', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Mining, Extraction, and Refining: Hydrocarbon Fuels']","['D11', 'D12', 'H25', 'H31', 'L71']",Individual Heterogeneity and Average Welfare,1,0,0,0,0,2016,05,01
84,3,2016-05-01,"We examine the role of stochastic feasibility in consumer choice using a (RCCSR) and uniquely characterize the model from conditions on stochastic choice data. Feasibility is modeled to permit correlation in availability of alternatives. This provides a natural way to examine substitutability/complementarity. We show that an RCCSR generalizes the of [Manzini and Mariotti, 2014]. We then relate this model to existing literature. In particular, an RCCSR is not a random utility model.","['Rehbeck, John', 'Brady, Richard L.']","['Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory']","['D01', 'D11']",Menu-Dependent Stochastic Feasibility,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"This paper proposes a method for aggregating individual preferences in the context of uncertainty. Individuals are assumed to abide by Savage's model of Subjective Expected Utility, in which everyone has his/her own utility and subjective probability. Disagreement on probabilities among individuals gives rise to uncertainty at the societal level, and thus society may entertain a set of probabilities rather than only one. We assume that social preference admits a Maxmin Expected Utility representation. In this context, two Pareto-type conditions are shown to be equivalent to social utility being a weighted average of individual utilities and the social set of priors containing only weighted averages of individual priors. Thus, society respects consensus among individuals' beliefs and does not add ambiguity beyond disagreement on beliefs. We also deal with the case in which society does not rule out any individual belief.","['Alon, Shiri', 'Gayer, Gabi']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D81', 'D83']",Utilitarian Preferences with Multiple Priors,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"I highlight how reputational concerns provide a natural explanation for ""deadline effects,"" the high frequency of deals prior to a deadline in bargaining. Rational agents imitate the demands of obstinate behavioral types and engage in brinkmanship in the face of uncertainty about the deadline's arrival. I also identify how surplus is divided when the prior probability of behavioral types is vanishingly small. If behavioral types are committed to fixed demands, outcomes converge to the Nash bargaining solution regardless of agents' respective impatience. If behavioral types can adopt more complex demand strategies, outcomes converge to the solution of an alternating offers game without behavioral types for the deadline environment.","['Fanning, Jack']",['Bargaining Theory; Matching Theory'],['C78'],Reputational Bargaining and Deadlines,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"We develop an equilibrium framework that relaxes the standard assumption that people have a correctly specified view of their environment. Each player is characterized by a (possibly misspecified) subjective model, which describes the set of feasible beliefs over payoff-relevant consequences as a function of actions. We introduce the notion of a Berk-Nash equilibrium: Each player follows a strategy that is optimal given her belief, and her belief is restricted to be the best fit among the set of beliefs she considers possible. The notion of best fit is formalized in terms of minimizing the Kullback-Leibler divergence, which is endogenous and depends on the equilibrium strategy profile. Standard solution concepts such as Nash equilibrium and self-confirming equilibrium constitute special cases where players have correctly specified models. We provide a learning foundation for Berk-Nash equilibrium by extending and combining results from the statistics literature on misspecified learning and the economics literature on learning in games.","['Esponda, Ignacio', 'Pouzo, Demian']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D82', 'D83']",Berk-Nash Equilibrium: A Framework for Modeling Agents with Misspecified Models,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"We test for the existence of housing bubbles associated with a failure of the transversality condition that requires the present value of payments occurring infinitely far in the future to be zero. The most prominent such bubble is the classic rational bubble. We study housing markets in the United Kingdom and Singapore, where residential property ownership takes the form of either leaseholds or freeholds. Leaseholds are finite-maturity, pre-paid, and tradeable ownership contracts with maturities often exceeding 700 years. Freeholds are infinite-maturity ownership contracts. The price difference between leaseholds with extremely-long maturities and freeholds reflects the present value of a claim to the freehold after leasehold expiry, and is thus a direct empirical measure of the transversality condition. We estimate this price difference, and find no evidence of failures of the transversality condition in housing markets in the U.K. and Singapore, even during periods when a sizable bubble was regularly thought to be present.","['Maggiori, Matteo', 'Stroebel, Johannes', 'Giglio, Stefano']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Housing Supply and Markets']","[nan, 'R31']",No-Bubble Condition: Model-Free Tests in Housing Markets,0,0,0,0,0,2016,05,01
84,3,2016-05-01,"We develop an econometric methodology to infer the path of risk premia from a large unbalanced panel of individual stock returns. We estimate the time-varying risk premia implied by conditional linear asset pricing models where the conditioning includes both instruments common to all assets and asset-specific instruments. The estimator uses simple weighted two-pass cross-sectional regressions, and we show its consistency and asymptotic normality under increasing cross-sectional and time series dimensions. We address consistent estimation of the asymptotic variance by hard thresholding, and testing for asset pricing restrictions induced by the no-arbitrage assumption. We derive the restrictions given by a continuum of assets in a multi-period economy under an approximate factor structure robust to asset repackaging. The empirical analysis on returns for about ten thousand U.S. stocks from July 1964 to December 2009 shows that risk premia are large and volatile in crisis periods. They exhibit large positive and negative strays from time-invariant estimates, follow the macroeconomic cycles, and do not match risk premia estimates on standard sets of portfolios. The asset pricing restrictions are rejected for a conditional four-factor model capturing market, size, value, and momentum effects.","['Gagliardini, Patrick', 'Ossola, Elisa', 'Scaillet, Olivier']","['Model Construction and Estimation', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', 'C58', nan]",Time-Varying Risk Premium in Large Cross-Sectional Equity Data Sets,0,0,0,0,0,2016,05,01
84,3,2016-05-01,An endogenous growth model is developed where each period firms invest in researching and developing new ideas. An idea increases a firm's productivity. By how much depends on the technological propinquity between an idea and the firm's line of business. Ideas can be bought and sold on a market for patents. A firm can sell an idea that is not relevant to its business or buy one if it fails to innovate. The developed model is matched up with stylized facts about the market for patents in the United States. The analysis gauges how efficiency in the patent market affects growth.,"['Greenwood, Jeremy', 'Akcigit, Ufuk', 'Celik, Murat Alp']","['Firm Behavior: Theory', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Innovation and Invention: Processes and Incentives', 'Intellectual Property and Intellectual Capital', 'One, Two, and Multisector Growth Models']","['D21', 'D25', 'O31', 'O34', 'O41']","Buy, Keep, or Sell: Economic Growth and the Market for Ideas",0,0,0,1,0,2016,05,01
84,3,2016-05-01,"This paper develops a dynamic model of neighborhood choice along with a computationally light multi-step estimator. The proposed empirical framework captures observed and unobserved preference heterogeneity across households and locations in a flexible way. We estimate the model using a newly assembled data set that matches demographic information from mortgage applications to the universe of housing transactions in the San Francisco Bay Area from 1994 to 2004. The results provide the first estimates of the marginal willingness to pay for several non-marketed amenities--neighborhood air pollution, violent crime, and racial composition--in a dynamic framework. Comparing these estimates with those from a static version of the model highlights several important biases that arise when dynamic considerations are ignored.","['Bayer, Patrick', 'Timmins, Christopher', 'Murphy, Alvin', 'McMillan, Robert']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Housing Demand', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['C51', 'D12', 'R21', 'R23']",A Dynamic Model of Demand for Houses and Neighborhoods,0,0,0,0,0,2016,05,01
86,4,2018-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 4.,0,0,0,0,0,2018,07,01
86,3,2018-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 3.,0,0,0,0,0,2018,05,01
88,4,2020-07-01,"We investigate claims made in Giacomini and White (2006) and Diebold (2015) regarding the asymptotic normality of a test of equal predictive ability. A counterexample is provided in which, instead, the test statistic diverges with probability 1 under the null.","['McCracken, Michael W.']","['Forecasting Models; Simulation Methods', 'General Aggregative Models: Forecasting and Simulation: Models and Applications']","['C53', 'E17']",Diverging Tests of Equal Predictive Ability,0,0,0,0,0,2020,07,01
86,2,2018-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 2.,0,0,0,0,0,2018,03,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 1.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2016–2017.,0,0,0,0,0,2018,01,01
85,6,2017-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 6.,0,0,0,0,0,2017,11,01
85,5,2017-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 5.,0,0,0,0,0,2017,09,01
85,4,2017-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 4.,0,0,0,0,0,2017,07,01
85,3,2017-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 3.,0,0,0,0,0,2017,05,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 89 Iss. 1.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 89 Iss. 1.,0,0,0,0,0,2021,01,01
89,1,2021-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2021,01,01
88,6,2020-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 6.,0,0,0,0,0,2020,11,01
88,6,2020-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 6.,0,0,0,0,0,2020,11,01
84,2,2016-03-01,"We analyze the implications of household-level adjustment costs for the dynamics of aggregate consumption. We show that an economy in which agents have ""consumption commitments"" is approximately equivalent to a habit formation model in which the habit stock is a weighted average of past consumption if idiosyncratic risk is large relative to aggregate risk. Consumption commitments can thus explain the empirical regularity that consumption is excessively sensitive and excessively smooth, findings that are typically attributed to habit formation. Unlike habit formation and other theories, but consistent with empirical evidence, the consumption commitments model also predicts that excess sensitivity and smoothness vanish for large shocks. These results suggest that behavior previously attributed to habit formation may be better explained by adjustment costs. We develop additional testable predictions to further distinguish the commitment and habit models and show that the two models have different welfare implications.","['Chetty, Raj', 'Szeidl, Adam']","['Consumer Economics: Theory', 'Household Saving; Personal Finance', 'Macroeconomics: Consumption; Saving; Wealth']","['D11', 'D14', 'E21']",Consumption Commitments and Habit Formation,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"We consider contests with many, possibly heterogeneous, players and prizes, and show that the equilibrium outcomes of such contests are approximated by the outcomes of mechanisms that implement the assortative allocation in an environment with a single agent that has a continuum of possible types. This makes it possible to easily approximate the equilibria of contests whose exact equilibrium characterization is complicated, as well as the equilibria of contests for which there is no existing equilibrium characterization.","['Siegel, Ron', 'Olszewski, Wojciech']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Large Contests,0,0,1,0,0,2016,03,01
84,2,2016-03-01,"We present a methodology for estimating the distributional effects of an endogenous treatment that varies at the group level when there are group-level unobservables, a quantile extension of Hausman and Taylor, 1981. Because of the presence of group-level unobservables, standard quantile regression techniques are inconsistent in our setting even if the treatment is independent of unobservables. In contrast, our estimation technique is consistent as well as computationally simple, consisting of group-by-group quantile regression followed by two-stage least squares. Using the Bahadur representation of quantile estimators, we derive weak conditions on the growth of the number of observations per group that are sufficient for consistency and asymptotic zero-mean normality of our estimator. As in Hausman and Taylor, 1981, micro-level covariates can be used as internal instruments for the endogenous group-level treatment if they satisfy relevance and exogeneity conditions. Our approach applies to a broad range of settings including labor, public finance, industrial organization, urban economics, and development; we illustrate its usefulness with several such examples. Finally, an empirical application of our estimator finds that low-wage earners in the United States from 1990 to 2007 were significantly more affected by increased Chinese import competition than high-wage earners.","['Chetverikov, Denis', 'Larsen, Bradley', 'Palmer, Christopher']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Empirical Studies of Trade', 'Trade and Labor Market Interactions', 'Wage Level and Structure; Wage Differentials', 'Socialist Institutions and Their Transitions: International Trade, Finance, Investment, Relations, and Aid']","['C21', 'C26', 'F14', 'F16', 'J31', 'P33']","IV Quantile Regression for Group-Level Treatments, with an Application to the Distributional Effects of Trade",0,0,0,0,0,2016,03,01
84,2,2016-03-01,"Propensity score matching estimators (Rosenbaum and Rubin (1983)) are widely used in evaluation research to estimate average treatment effects. In this article, we derive the large sample distribution of propensity score matching estimators. Our derivations take into account that the propensity score is itself estimated in a first step, prior to matching. We prove that first step estimation of the propensity score affects the large sample distribution of propensity score matching estimators, and derive adjustments to the large sample variances of propensity score matching estimators of the average treatment effect (ATE) and the average treatment effect on the treated (ATET). The adjustment for the ATE estimator is negative (or zero in some special cases), implying that matching on the estimated propensity score is more efficient than matching on the true propensity score in large samples. However, for the ATET estimator, the sign of the adjustment term depends on the data generating process, and ignoring the estimation error in the propensity score may lead to confidence intervals that are either too large or too small.","['Abadie, Alberto', 'Imbens, Guido W.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Matching on the Estimated Propensity Score,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"We show that firms' individually optimal liquidity management results in socially inefficient boom-and-bust patterns. Financially constrained firms decide on the level of their liquid resources facing cash-flow shocks and time-varying investment opportunities. Firms' liquidity management decisions generate simultaneous waves in aggregate cash holdings and investment, even if technology remains constant. These investment waves are not constrained efficient in general, because the social and private value of liquidity differs. The resulting pecuniary externality affects incentives differentially depending on the state of the economy, and often overinvestment occurs during booms and underinvestment occurs during recessions. In general, policies intended to mitigate underinvestment raise prices during recessions, making overinvestment during booms worse. However, a well-designed price-support policy will increase welfare in both booms and recessions.","['He, Zhiguo', 'Kondor, Peter']","['Firm Behavior: Theory', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Business Fluctuations; Cycles', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['D21', 'D25', 'E32', 'G31', 'G32']",Inefficient Investment Waves,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"This paper studies how the abolition of an elite recruitment system--China's civil exam system that lasted over 1,300 years--affects political stability. Employing a panel data set across 262 prefectures and exploring the variations in the quotas on the entry-level exam candidates, we find that higher quotas per capita were associated with a higher probability of revolution participation after the abolition and a higher incidence of uprisings in 1911 that marked the end of the 2,000 years of imperial rule. This finding is robust to various checks including using the number of small rivers and short-run exam performance before the quota system as instruments. The patterns in the data appear most consistent with the interpretation that in regions with higher quotas per capita under the exam system, more would-be elites were negatively affected by the abolition. In addition, we document that modern human capital in the form of those studying in Japan also contributed to the revolution and that social capital strengthened the effect of quotas on revolution participation.","['Jia, Ruixue', 'Bai, Ying']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Public Administration; Public Sector Accounting and Audits', 'Economic History: Government, War, Law, International Relations, and Regulation: Asia including Middle East', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Socialist Systems and Transitional Economies: Political Economy; Property Rights']","['D72', 'H83', 'N45', 'O17', 'P26']",Elite Recruitment and Political Stability: The Impact of the Abolition of China's Civil Service Exam,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"We study how long it takes for large populations of interacting agents to come close to Nash equilibrium when they adapt their behavior using a stochastic better reply dynamic. Prior work considers this question mainly for 2 x 2 games and potential games; here we characterize convergence times for general weakly acyclic games, including coordination games, dominance solvable games, games with strategic complementarities, potential games, and many others with applications in economics, biology, and distributed control. If players' better replies are governed by idiosyncratic shocks, the convergence time can grow exponentially in the population size; moreover, this is true even in games with very simple payoff structures. However, if their responses are sufficiently correlated due to aggregate shocks, the convergence time is greatly accelerated; in fact, it is bounded for all sufficiently large populations. We provide explicit bounds on the speed of convergence as a function of key structural parameters including the number of strategies, the length of the better reply paths, the extent to which players can influence the payoffs of others, and the desired degree of approximation to Nash equilibrium.","['Arieli, Itai', 'Young, H. Peyton']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Stochastic Learning Dynamics and Speed of Convergence in Population Games,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"The question of whether and how mutual fund managers provide valuable services for their clients motivates one of the largest literatures in finance. One candidate explanation is that funds process information about future asset values and use that information to invest in high-valued assets. But formal theories are scarce because information choice models with many assets are difficult to solve as well as difficult to test. This paper tackles both problems by developing a new attention allocation model that uses the state of the business cycle to predict information choices, which in turn, predict observable patterns of portfolio investments and returns. The predictions about fund portfolios' covariance with payoff shocks, cross-fund portfolio and return dispersion, and their excess returns are all supported by the data. These findings offer new evidence that some investment managers have skill and that attention is allocated rationally.","['Van Nieuwerburgh, Stijn', 'Kacperczyk, Marcin', 'Veldkamp, Laura']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Pension Funds; Non-bank Financial Institutions; Financial Instruments; Institutional Investors']","['D83', 'G11', 'G23']",A Rational Theory of Mutual Funds' Attention Allocation,0,0,0,0,0,2016,03,01
84,2,2016-03-01,"The U.S. Prohibition experience shows a remarkable policy reversal. In only 14 years, a drastic shift in public opinion required two constitutional amendments. I develop and estimate a model of endogenous law enforcement, determined by beliefs about the Prohibition-crime nexus and alcohol-related moral views. In turn, the policy outcomes shape subsequent learning about Prohibition enforcement costs. I estimate the model through maximum likelihood on Prohibition Era city-level data on police enforcement, crime, and alcohol-related legislation. The model can account for the variation in public opinion changes, and the heterogeneous responses of law enforcement and violence across cities. Results show that a 15% increase in the homicide rate can be attributed to Prohibition enforcement. The subsequent learning-driven adjustment of local law enforcement allowed for the alcohol market to rebound to 60% of its pre-Prohibition size. I conclude with counterfactual exercises exploring the welfare implications of policy learning, prior beliefs, preference polarization, and alternative political environments. Results illustrate the importance of incorporating the endogenous nature of law enforcement into our understanding of policy failure and policy success.","['Garcia-Jimeno, Camilo']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Basic Areas of Law: General (Constitutional Law)', 'Illegal Behavior and the Enforcement of Law', 'Economic History: Government, War, Law, International Relations, and Regulation: U.S.; Canada: 1913-']","['D83', 'K10', 'K42', 'N42']",The Political Economy of Moral Conflict: An Empirical Study of Learning and Law Enforcement under Prohibition,0,1,0,0,0,2016,03,01
84,2,2016-03-01,"This paper examines how prices, markups, and marginal costs respond to trade liberalization. We develop a framework to estimate markups from production data with multi-product firms. This approach does not require assumptions on the market structure or demand curves faced by firms, nor assumptions on how firms allocate their inputs across products. We exploit quantity and price information to disentangle markups from quantity-based productivity, and then compute marginal costs by dividing observed prices by the estimated markups. We use India's trade liberalization episode to examine how firms adjust these performance measures. Not surprisingly, we find that trade liberalization lowers factory-gate prices and that output tariff declines have the expected pro-competitive effects. However, the price declines are small relative to the declines in marginal costs, which fall predominantly because of the input tariff liberalization. The reason for this incomplete cost pass-through to prices is that firms offset their reductions in marginal costs by raising markups. Our results demonstrate substantial heterogeneity and variability in markups across firms and time and suggest that producers benefited relative to consumers, at least immediately after the reforms.","['Goldberg, Pinelopi K.', 'Khandelwal, Amit K.', 'Pavcnik, Nina', 'De Loecker, Jan']","['Model Construction and Estimation', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Trade Policy; International Trade Organizations', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Industrialization; Manufacturing and Service Industries; Choice of Technology', 'International Linkages to Development; Role of International Organizations', 'Development Planning and Policy: Trade Policy; Factor Movement; Foreign Exchange Policy']","['C51', 'D24', 'F13', 'L11', 'O14', 'O19', 'O24']","Prices, Markups, and Trade Reform",1,0,0,0,0,2016,03,01
84,2,2016-03-01,"We estimate demand for residential broadband using high-frequency data from subscribers facing a three-part tariff. The three-part tariff makes data usage during the billing cycle a dynamic problem, thus generating variation in the (shadow) price of usage. We provide evidence that subscribers respond to this variation, and we use their dynamic decisions to estimate a flexible distribution of willingness to pay for different plan characteristics. Using the estimates, we simulate demand under alternative pricing and find that usage-based pricing eliminates low-value traffic. Furthermore, we show that the costs associated with investment in fiber-optic networks are likely recoverable in some markets, but that there is a large gap between social and private incentives to invest.","['Turner, John L.', 'Nevo, Aviv', 'Williams, Jonathan W.']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Entertainment; Media', 'Information and Internet Services; Computer Software']","['C51', 'D12', 'G31', 'L82', 'L86']",Usage-Based Pricing and Demand for Residential Broadband,1,0,0,0,0,2016,03,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2014-2015.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2014-2015.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,"We revisit the comparison of mathematical programming with equilibrium constraints (MPEC) and nested fixed point (NFXP) algorithms for estimating structural dynamic models by Su and Judd (2012). Their implementation of the nested fixed point algorithm used successive approximations to solve the inner fixed point problem (NFXP-SA). We redo their comparison using the more efficient version of NFXP proposed by Rust (1987), which combines successive approximations and Newton-Kantorovich iterations to solve the fixed point problem (NFXP-NK). We show that MPEC and NFXP are similar in speed and numerical performance when the more efficient NFXP-NK variant is used.","['Seo, Kyoungwon', 'Lee, Jinhyuk', 'Schjerning, Bertel', 'Iskhakov, Fedor', 'Rust, John']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Construction and Estimation']","['C20', 'C25', 'C30', 'C51']",Constrained Optimization Approaches to Estimation of Structural Models: Comment,0,0,0,0,0,2016,01,01
84,1,2016-01-01,"This paper considers equilibrium quit turnover in a frictional labor market with costly hiring by firms, where large firms employ many workers and face both aggregate and firm specific productivity shocks. There is exogenous firm turnover as new (small) startups enter the market over time, while some existing firms fail and exit. Individual firm growth rates are disperse and evolve stochastically. The paper highlights how dynamic monopsony, where firms trade off lower wages against higher (endogenous) employee quit rates, yields excessive job-to-job quits. Such quits directly crowd out the reemployment prospects of the unemployed. With finite firm productivity states, stochastic equilibrium is fully tractable and can be computed using standard numerical techniques.","['Coles, Melvyn G.', 'Mortensen, Dale T.']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials', 'Labor Turnover; Vacancies; Layoffs', 'Unemployment: Models, Duration, Incidence, and Job Search']","['E24', 'J22', 'J31', 'J63', 'J64']","Equilibrium Labor Turnover, Firm Growth, and Unemployment",0,0,0,0,0,2016,01,01
84,1,2016-01-01,"This paper investigates relational incentive contracts with continuous, privately observed agent types that are persistent over time. With fixed agent types, full separation is not possible when continuation equilibrium payoffs following revelation are on the Pareto frontier of attainable payoffs. This result is related to the ratchet effect in that: (1) a type imitating a less productive type receives an information rent, and (2) with full separation, one imitating a more productive type receives the same future payoff as that more productive type. However, the reason for (2) is fundamentally different than with the ratchet effect. It arises from the dynamic enforcement requirement in relational contracts, not from the principal having all the bargaining power, and applies whatever the distribution between principal and agent of the future gains from the relationship (i.e., whatever the point on the Pareto frontier). This result extends to sufficiently persistent types under certain conditions.","['Malcomson, James M.']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Relational Incentive Contracts with Persistent Private Information: Notes and Comments,0,0,0,0,0,2016,01,01
84,1,2016-01-01,This paper analyzes a sequential search model with adverse selection. We study information aggregation by the price--how close the equilibrium prices are to the full-information prices--when search frictions are small. We identify circumstances under which prices fail to aggregate information well even when search frictions are small. We trace this to a strong form of the winner's curse that is present in the sequential search model. The failure of information aggregation may result in inefficient allocations.,"['Wolinsky, Asher', 'Lauermann, Stephan']","['Auctions', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D82', 'D83']",Search with Adverse Selection,0,0,1,0,0,2016,01,01
84,1,2016-01-01,"We provide a theoretical and empirical analysis of the link between financial and real health care markets. This link is important as financial returns drive investment in medical research and development (R&D), which, in turn, affects real spending growth. We document a ""medical innovation premium"" of 4-6% annually for equity returns of firms in the health care sector. We interpret this premium as compensating investors for government-induced profit risk, and we provide supportive evidence for this hypothesis through company filings and abnormal return patterns surrounding threats of government intervention. We quantify the implications of the premium for the growth in real health care spending by calibrating our model to match historical trends, predicting the share of gross domestic product (GDP) devoted to health care to be 32% in the long run. Policies that had removed government risk would have led to more than a doubling of medical R&D and would have increased the current share of health care spending by more than 3% of GDP.","['Philipson, Tomas J.', 'Koijen, Ralph S. J.', 'Uhlig, Harald']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Business Fluctuations; Cycles', 'Information and Market Efficiency; Event Studies; Insider Trading', 'National Government Expenditures and Health', 'Health: General']","['D15', 'E32', 'G14', 'H51', 'I10']",Financial Health Economics,0,0,0,0,0,2016,01,01
84,1,2016-01-01,"Most countries have automatic rules in their tax-and-transfer systems that are partly intended to stabilize economic fluctuations. This paper measures their effect on the dynamics of the business cycle. We put forward a model that merges the standard incomplete-markets model of consumption and inequality with the new Keynesian model of nominal rigidities and business cycles, and that includes most of the main potential stabilizers in the U.S. data and the theoretical channels by which they may work. We find that the conventional argument that stabilizing disposable income will stabilize aggregate demand plays a negligible role in the dynamics of the business cycle, whereas tax-and-transfer programs that affect inequality and social insurance can have a larger effect on aggregate volatility. However, as currently designed, the set of stabilizers in place in the United States has had little effect on the volatility of aggregate output fluctuations or on their welfare costs despite stabilizing aggregate consumption. The stabilizers have a more important role when monetary policy is constrained by the zero lower bound, and they affect welfare significantly through the provision of social insurance.","['McKay, Alisdair', 'Reis, Ricardo']","['Business Fluctuations; Cycles', 'Monetary Policy', 'Fiscal Policy', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Business Taxes and Subsidies including sales and value-added (VAT)', 'Fiscal Policies and Behavior of Economic Agents: General']","['E32', 'E52', 'E62', 'H23', 'H24', 'H25', 'H30']",The Role of Automatic Stabilizers in the U.S. Business Cycle,0,0,0,0,0,2016,01,01
84,1,2016-01-01,"We study takeovers of firms whose ownership structure is a mixture of minority block-holders and small shareholders. We show that the combination of dispersed private information on the side of small shareholders and the presence of a large shareholder can facilitate profitable takeovers. Furthermore, our analysis implies that even if some model of takeovers predicts a profit for the raider, for example, due to private benefits, the profit will be underestimated unless the large shareholder and the dispersion of information among the small shareholders are modeled.","['Ekmekci, Mehmet', 'Kos, Nenad']","['Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance', 'Information and Product Quality; Standardization and Compatibility', 'Firm Performance: Size, Diversification, and Scope']","['G32', 'G34', 'L15', 'L25']",Information in Tender Offers with a Large Shareholder,1,0,0,0,1,2016,01,01
84,1,2016-01-01,"This paper studies competitive equilibria of economies where assets are heterogeneous and traders have heterogeneous information about them. Markets are defined by a price and a procedure for clearing trades, and any asset can, in principle, be traded in any market. Buyers can use their information to impose acceptance rules which specify which assets they are willing to trade in each market. The set of markets where trade takes place is derived endogenously. The model can be applied to find conditions under which these economies feature fire sales, contagion, and flights to quality.","['Kurlat, Pablo']","['General Equilibrium and Disequilibrium: Financial Markets', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D53', 'D82', 'D83', 'G11', 'G14']",Asset Markets with Heterogeneous Information,0,0,0,0,0,2016,01,01
84,1,2016-01-01,"We analyze money and credit as competing payment instruments in decentralized exchange. In natural environments, we show the economy does not need both: if credit is easy, money is irrelevant; if credit is tight, money is essential, but credit becomes irrelevant. Changes in credit conditions are neutral because real balances respond endogenously to keep total liquidity constant. This is true for both exogenous and endogenous debt limits and policy limits, secured and unsecured lending, and general pricing mechanisms. While we show how to overturn some of these results, the benchmark model suggests credit might matter less than people think.","['Mattesini, Fabrizio', 'Gu, Chao', 'Wright, Randall']","['General Equilibrium and Disequilibrium: Financial Markets', 'Price Level; Inflation; Deflation', 'Monetary Systems; Standards; Regimes; Government and the Monetary System; Payment Systems', 'Monetary Policy', 'National Debt; Debt Management; Sovereign Debt']","['D53', 'E31', 'E42', 'E52', 'H63']",Money and Credit Redux,0,0,0,0,0,2016,01,01
83,6,2015-11-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society 2015 Annual Report of the President.,0,0,0,0,0,2015,11,01
83,6,2015-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 6.,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"We demonstrate the asymptotic equivalence between commonly used test statistics for out-of-sample forecasting performance and conventional Wald statistics. This equivalence greatly simplifies the computational burden of calculating recursive out-of-sample test statistics and their critical values. For the case with nested models, we show that the limit distribution, which has previously been expressed through stochastic integrals, has a simple representation in terms of X[superscript 2]-distributed random variables and we derive its density. We also generalize the limit theory to cover local alternatives and characterize the power properties of the test.","['Hansen, Peter Reinhard', 'Timmermann, Allan']",['Forecasting Models; Simulation Methods'],['C53'],Equivalence between Out-of-Sample Forecast Comparisons and Wald Statistics,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"We consider nonparametric identification and estimation in a nonseparable model where a continuous regressor of interest is a known, deterministic, but kinked function of an observed assignment variable. We characterize a broad class of models in which a sharp ""Regression Kink Design"" (RKD or RK Design) identifies a readily interpretable treatment-on-the-treated parameter (Florens, Heckman, Meghir, and Vytlacil (2008)). We also introduce a ""fuzzy regression kink design"" generalization that allows for omitted variables in the assignment rule, noncompliance, and certain types of measurement errors in the observed values of the assignment variable and the policy variable. Our identifying assumptions give rise to testable restrictions on the distributions of the assignment variable and predetermined covariates around the kink point, similar to the restrictions delivered by Lee (2008) for the regression discontinuity design. Using a kink in the unemployment benefit formula, we apply a fuzzy RKD to empirically estimate the effect of benefit rates on unemployment durations in Austria.","['Pei, Zhuan', 'Weber, Andrea', 'Lee, David S.', 'Card, David']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Unemployment: Models, Duration, Incidence, and Job Search', 'Unemployment Insurance; Severance Pay; Plant Closings']","['C21', 'E24', 'J31', 'J64', 'J65']",Inference on Causal Effects in a Generalized Regression Kink Design,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"This paper examines some of the recent literature on the estimation of production functions. We focus on techniques suggested in two recent papers, Olley and Pakes (1996) and Levinsohn and Petrin (2003). While there are some solid and intuitive identification ideas in these papers, we argue that the techniques can suffer from functional dependence problems. We suggest an alternative approach that is based on the ideas in these papers, but does not suffer from the functional dependence problems and produces consistent estimates under alternative data generating processes for which the original procedures do not.","['Frazer, Garth', 'Ackerberg, Daniel A.', 'Caves, Kevin']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Model Construction and Estimation', 'Macroeconomic Analyses of Economic Development', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['C23', 'C51', 'O11', 'O47']",Identification Properties of Recent Production Function Estimators,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"Perturbed utility functions--the sum of expected utility and a nonlinear perturbation function--provide a simple and tractable way to model various sorts of stochastic choice. We provide two easily understood conditions each of which characterizes this representation: One condition generalizes the acyclicity condition used in revealed preference theory, and the other generalizes Luce's IIA condition. We relate the discrimination or selectivity of choice rules to properties of their associated perturbations, both across different agents and across decision problems. We also show that these representations correspond to a form of ambiguity-averse preferences for an agent who is uncertain about her true utility.","['Iijima, Ryota', 'Fudenberg, Drew', 'Strzalecki, Tomasz']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Stochastic Choice and Revealed Perturbed Utility,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"This paper develops a generalized Roy model with human capital accumulation, moral hazard, and career concerns. We identify and estimate the model with a large panel that matches data on publicly listed firms to information on their executives. The structural estimates obtained are used to decompose the firm-size pay gap. We find that although total compensation and incentive pay increase with firm size, certainty-equivalent pay decreases with firm size. In larger firms, and for more highly ranked executives, weaker signal quality about effort results in higher risk premiums. This risk premium accounts for roughly 80 percent of the firm-size gap in total compensation. Larger firms are also willing to pay more than smaller ones to attract executives. Finally, the estimated coefficients on human capital accumulation from formal education and experience gained from different firms are individually significant, but their collective effect on firm-size pay differentials nets out.","['Gayle, George-Levi', 'Golan, Limor', 'Miller, Robert A.']","['Model Construction and Estimation', 'Asymmetric and Private Information; Mechanism Design', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Firm Performance: Size, Diversification, and Scope', 'Personnel Management; Executives; Executive Compensation', 'Personnel Economics: Firm Employment Decisions; Promotions', 'Personnel Economics: Compensation and Compensation Methods and Their Effects']","['C51', 'D82', 'J24', 'L25', 'M12', 'M51', 'M52']","Promotion, Turnover, and Compensation in the Executive Labor Market",1,0,0,0,0,2015,11,01
83,6,2015-11-01,"We develop a parsimonious model to study the equilibrium and socially optimal decisions of banks to enter, trade in, and possibly exit, an OTC market. Although we endow all banks with the same trading technology, banks' optimal entry and trading decisions endogenously lead to a realistic market structure composed of dealers and customers with distinct trading patterns. We decompose banks' entry incentives into incentives to hedge risk and incentives to make intermediation profits. We show that dealer banks enter more than is socially optimal. In the face of large negative shocks, they may also exit more than is socially optimal when markets are not perfectly resilient.","['Weill, Pierre-Olivier', 'Eisfeldt, Andrea L.', 'Atkeson, Andrew G.']","['Contingent Pricing; Futures Pricing; option pricing', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['G13', 'G21', 'L11']",Entry and Exit in OTC Derivatives Markets,1,0,0,0,0,2015,11,01
83,6,2015-11-01,"Our paper provides a complete characterization of leverage and default in binomial economies with financial assets serving as collateral. Our Binomial No-Default Theorem states that any equilibrium is equivalent (in real allocations and prices) to another equilibrium in which there is no default. Thus actual default is irrelevant, though the potential for default drives the equilibrium and limits borrowing. This result is valid with arbitrary preferences and endowments, contingent or noncontingent promises, many assets and consumption goods, production, and multiple periods. We also show that only no-default equilibria would be selected if there were the slightest cost of using collateral or handling default. Our Binomial Leverage Theorem shows that equilibrium Loan to Value (LTV) for noncontingent debt contracts is the ratio of the worst-case return of the asset to the riskless gross rate of interest. In binomial economies, leverage is determined by down risk and not by volatility.","['Geanakoplos, John', 'Fostel, Ana']","['General Equilibrium and Disequilibrium: Financial Markets', 'Financial Markets and the Macroeconomy', 'Financial Crises', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D53', 'E44', 'G01', nan]",Leverage and Default in Binomial Economies: A Complete Characterization,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"This paper develops a quantitative model of internal city structure that features agglomeration and dispersion forces and an arbitrary number of heterogeneous city blocks. The model remains tractable and amenable to empirical analysis because of stochastic shocks to commuting decisions, which yield a gravity equation for commuting flows. To structurally estimate agglomeration and dispersion forces, we use data on thousands of city blocks in Berlin for 1936, 1986, and 2006 and exogenous variation from the city's division and reunification. We estimate substantial and highly localized production and residential externalities. We show that the model with the estimated agglomeration parameters can account both qualitatively and quantitatively for the observed changes in city structure. We show how our quantitative framework can be used to undertake counterfactuals for changes in the organization of economic activity within cities in response, for example, to changes in the transport network.","['Wolf, Nikolaus', 'Sturm, Daniel M.', 'Ahlfeldt, Gabriel M.', 'Redding, Stephen J.']","['Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Europe: 1913-', 'Regional and Urban History: Europe: 1913-', 'Regional Economic Activity: Growth, Development, Environmental Issues, and Changes', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics', 'Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise', 'Regional Development Planning and Policy']","['N34', 'N94', 'R11', 'R23', 'R41', 'R58']",The Economics of Density: Evidence from the Berlin Wall,0,0,0,0,0,2015,11,01
83,6,2015-11-01,"Both aristocratic privileges and constitutional constraints in traditional monarchies can be derived from a ruler's incentive to minimize expected costs of moral-hazard rents for high officials. We consider a dynamic moral-hazard model of governors serving a sovereign prince, who must deter them from rebellion and hidden corruption which could cause costly crises. To minimize costs, a governor's rewards for good performance should be deferred up to the maximal credit that the prince can be trusted to pay. In the long run, we find that high officials can become an entrenched aristocracy with low turnover and large claims on the ruler. Dismissals for bad performance should be randomized to avoid inciting rebellions, but the prince can profit from reselling vacant offices, and so his decisions to dismiss high officials require institutionalized monitoring. A soft budget constraint that forgives losses for low-credit governors can become efficient when costs of corruption are low.","['Myerson, Roger B.']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Bureaucracy; Administrative Processes in Public Organizations; Corruption', 'Asymmetric and Private Information; Mechanism Design']","['D72', 'D73', 'D82']",Moral Hazard in High Office and the Dynamics of Aristocracy,0,0,0,0,0,2015,11,01
83,5,2015-09-01,"Strategic choice data from a carefully chosen set of ring-network games are used to obtain individual-level estimates of higher-order rationality. The experimental design exploits a natural exclusion restriction that is considerably weaker than the assumptions underlying alternative designs in the literature. In our data set, 93 percent of subjects are rational, 71 percent are rational and believe others are rational, 44 percent are rational and hold second-order beliefs that others are rational, and 22 percent are rational and hold at least third-order beliefs that others are rational.","['Kneeland, Terri']","['Design of Experiments: Laboratory, Individual', 'Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C91', 'D11', 'D12', 'D83']",Identifying Higher-Order Rationality,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"This paper develops a specification test for instrument validity in the heterogeneous treatment effect model with a binary treatment and a discrete instrument. The strongest testable implication for instrument validity is given by the condition for nonnegativity of point-identifiable compliers' outcome densities. Our specification test infers this testable implication using a variance-weighted Kolmogorov-Smirnov test statistic. The test can be applied to both discrete and continuous outcome cases, and an extension of the test to settings with conditioning covariates is provided.","['Kitagawa, Toru']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Returns to Education', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C26', 'I26', 'J24', 'J31']",A Test for Instrument Validity,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"We propose a method to set identify bounds on the sharing rule for a general collective household consumption model. Unlike the effects of distribution factors, the level of the sharing rule cannot be uniquely identified without strong assumptions on preferences across households. Our new results show that, though not point identified without these assumptions, strong bounds on the sharing rule can be obtained. We get these bounds by applying revealed preference restrictions implied by the collective model to the household's continuous aggregate demand functions. We obtain informative bounds even if nothing is known about whether each good is public, private, or assignable within the household, though having such information tightens the bounds. We apply our method to US PSID data, obtaining narrow bounds that yield useful conclusions regarding the effects of income and wages on intrahousehold resource sharing, and on the prevalence of individual (as opposed to household level) poverty.","['Vermeulen, Frederic', 'Lewbel, Arthur', 'De Rock, Bram', 'Cherchye, Laurens']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Household Production and Intrahousehold Allocation', 'Measurement and Analysis of Poverty', 'Wage Level and Structure; Wage Differentials']","['C51', 'D12', 'D13', 'I32', 'J31']",Sharing Rule Identification for General Collective Consumption Models,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"This paper makes the following original contributions to the literature. (i) We develop a simpler analytical characterization and numerical algorithm for Bayesian inference in structural vector autoregressions (VARs) that can be used for models that are overidentified, just-identified, or underidentified. (ii) We analyze the asymptotic properties of Bayesian inference and show that in the underidentified case, the asymptotic posterior distribution of contemporaneous coefficients in an -variable VAR is confined to the set of values that orthogonalize the population variance-covariance matrix of ordinary least squares residuals, with the height of the posterior proportional to the height of the prior at any point within that set. For example, in a bivariate VAR for supply and demand identified solely by sign restrictions, if the population correlation between the VAR residuals is positive, then even if one has available an infinite sample of data, any inference about the demand elasticity is coming exclusively from the prior distribution. (iii) We provide analytical characterizations of the informative prior distributions for impulse-response functions that are implicit in the traditional sign-restriction approach to VARs, and we note, as a special case of result (ii), that the influence of these priors does not vanish asymptotically. (iv) We illustrate how Bayesian inference with informative priors can be both a strict generalization and an unambiguous improvement over frequentist inference in just-identified models. (v) We propose that researchers need to explicitly acknowledge and defend the role of prior beliefs in influencing structural conclusions and we illustrate how this could be done using a simple model of the U.S. labor market.","['Hamilton, James D.', 'Baumeister, Christiane']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Time Allocation and Labor Supply', 'Labor Demand']","['C32', 'D83', 'J22', 'J23']","Sign Restrictions, Structural Vector Autoregressions, and Useful Prior Information",0,0,0,0,0,2015,09,01
83,5,2015-09-01,"This paper analyzes South Africa's Free Basic Water Policy, under which households receive a free water allowance equal to the World Health Organization's recommended minimum. I estimate residential water demand, evaluate the welfare effects of free water, and provide optimal price schedules derived from a social planner's problem. I use a data set of monthly metered billing data for 60,000 households for 2002-2009 from a particularly disadvantaged suburb of Pretoria, with rich price variation across 20 different nonlinear tariff schedules. I find that the free allowance acts as a lump-sum subsidy, without large effects on water consumption. However, it is possible to reallocate the current subsidy to form an optimal tariff without a free allowance, which would increase welfare while leaving the water provider's profit unchanged. This optimal tariff would also reduce the number of households consuming low quantities of water, a desirable policy goal according to the WHO.","['Szabo, Andrea']","['Consumer Economics: Empirical Analysis', 'Gas Utilities; Pipelines; Water Utilities', 'Industry Studies: Utilities and Transportation: Government Policy', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Renewable Resources and Conservation: Water']","['D12', 'L95', 'L98', 'O12', 'O13', 'Q25']",The Value of Free Water: Analyzing South Africa's Free Basic Water Policy,1,0,0,0,0,2015,09,01
83,5,2015-09-01,"We argue that poverty can perpetuate itself by undermining the capacity for self-control. In line with a distinguished psychological literature, we consider modes of self-control that involve the self-imposed use of contingent punishments and rewards. We study settings in which consumers with quasi-hyperbolic preferences confront an otherwise standard intertemporal allocation problem with credit constraints. Our main result demonstrates that low initial assets can limit self-control, trapping people in poverty, while individuals with high initial assets can accumulate indefinitely. Thus, even temporary policies that accumulation among the poor may be effective. We examine implications concerning the effect of access to credit on saving, the demand for commitment devices, the design of financial accounts to promote accumulation, and the variation of the marginal propensity to consume across income from different sources. We also explore the nature of optimal self-control, demonstrating that it has a simple and behaviorally plausible structure that is immune to self-renegotiation.","['Ray, Debraj', 'Bernheim, B. Douglas', 'Yeltekin, Sevin']","['Household Saving; Personal Finance', 'Social Security and Public Pensions', 'Measurement and Analysis of Poverty', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs']","['D14', 'H55', 'I32', 'I38']",Poverty and Self-Control,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"We consider a large market where auctioneers with private reservation values compete for bidders by announcing cheap-talk messages. If auctioneers run efficient first-price auctions, then there always exists an equilibrium in which each auctioneer truthfully reveals her type. The equilibrium is constrained efficient, assigning more bidders to auctioneers with larger gains from trade. The choice of the trading mechanism is crucial for the result. Most notably, the use of second-price auctions (equivalently, ex post bidding) leads to the nonexistence of any informative equilibrium. We examine the robustness of our finding in various dimensions, including finite markets and equilibrium selection.","['Kim, Kyungmin', 'Kircher, Philipp']","['Consumer Economics: Theory', 'Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D44', 'D83']",Efficient Competition through Cheap Talk: The Case of Competing Auctions,0,0,1,0,0,2015,09,01
83,5,2015-09-01,"This paper characterizes an equilibrium payoff subset for dynamic Bayesian games as discounting vanishes. Monitoring is imperfect, transitions may depend on actions, types may be correlated, and values may be interdependent. The focus is on equilibria in which players report truthfully. The characterization generalizes that for repeated games, reducing the analysis to static Bayesian games with transfers. With independent private values, the restriction to truthful equilibria is without loss, except for the punishment level: if players withhold their information during punishment-like phases, a folk theorem obtains.","['Vieille, Nicolas', 'Horner, Johannes', 'Takahashi, Satoru']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D82', 'D83']",Truthful Equilibria in Dynamic Bayesian Games,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"We consider a group of strategic agents who must each repeatedly take one of two possible actions. They learn which of the two actions is preferable from initial private signals and by observing the actions of their neighbors in a social network. We show that the question of whether or not the agents learn efficiently depends on the topology of the social network. In particular, we identify a geometric ""egalitarianism"" condition on the social network that guarantees learning in infinite networks, or learning with high probability in large finite networks, in any equilibrium. We also give examples of nonegalitarian networks with equilibria in which learning fails.","['Mossel, Elchanan', 'Sly, Allan', 'Tamuz, Omer']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['C73', 'D11', 'D83', 'Z13']",Strategic Learning and the Topology of Social Networks,0,0,0,0,0,2015,09,01
83,5,2015-09-01,"We analyze the Vickrey mechanism for auctions of multiple identical goods when the players have both Knightian uncertainty over their own valuations and incomplete preferences. In this model, the Vickrey mechanism is no longer dominant-strategy, and we prove that all dominant-strategy mechanisms are inadequate. However, we also prove that, in undominated strategies, the social welfare produced by the Vickrey mechanism in the worst case is not only very good, but also essentially optimal.","['Micali, Silvio', 'Chiesa, Alessandro', 'Zhu, Zeyuan Allen']","['Consumer Economics: Theory', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D44', 'D81']",Knightian Analysis of the Vickrey Mechanism,0,0,1,0,0,2015,09,01
83,5,2015-09-01,"There is a widely held view within the general public that large corporations should act in the interests of a broader group of agents than just their shareholders (the stakeholder view). This paper presents a framework where this idea can be justified. The point of departure is the observation that a large firm typically faces endogenous risks that may have a significant impact on the workers it employs and the consumers it serves. These risks generate externalities on these stakeholders which are not internalized by shareholders. As a result, in the competitive equilibrium, there is under-investment in the prevention of these risks. We suggest that this under-investment problem can be alleviated if firms are instructed to maximize the total welfare of their stakeholders rather than shareholder value alone (stakeholder equilibrium). The stakeholder equilibrium can be implemented by introducing new property rights (employee rights and consumer rights) and instructing managers to maximize the total value of the firm (the value of these rights plus shareholder value). If there is only one firm, the stakeholder equilibrium is Pareto optimal. However, this is not true with more than one firm and/or heterogeneous agents, which illustrates some of the limits of the stakeholder model.","['Quinzii, Martine', 'Magill, Michael', 'Rochet, Jean-Charles']","['Firm Behavior: Theory', 'Organizational Behavior; Transaction Costs; Property Rights', 'Criteria for Decision-Making under Risk and Uncertainty', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance', 'Contract Law']","['D21', 'D23', 'D81', 'G34', 'K12']",A Theory of the Stakeholder Corporation,0,1,0,0,1,2015,09,01
83,4,2015-07-01,ECONLIT None Found,[nan],[nan],[nan],Fellows of the Econometric Society.,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"This paper concerns the two-stage game introduced in Nash (1953). It formalizes a suggestion made (but not pursued) by Nash regarding equilibrium selection in that game, and hence offers an arguably more solid foundation for the ""Nash bargaining with endogenous threats"" solution. Analogous reasoning is then applied to an infinite horizon game to provide equilibrium selection in two-person repeated games with contracts. In this setting, issues about enforcement of threats are much less problematic than in Nash's static setting. The analysis can be extended to stochastic games with contracts.","['Pearce, David', 'Abreu, Dilip']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory', 'Economics of Contract: Theory']","['C72', 'C73', 'C78', 'D86']",A Dynamic Reinterpretation of Nash Bargaining with Endogenous Threats,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"Mechanism design enables a social planner to obtain a desired outcome by leveraging the players' rationality and their beliefs. It is thus a fundamental, but yet unproven, intuition that the higher the level of rationality of the players, the better the set of obtainable outcomes. In this paper, we prove this fundamental intuition for players with possibilistic beliefs, a model long considered in epistemic game theory. Specifically, we define a sequence of monotonically increasing revenue benchmarks for single-good auctions, G[superscript 0] <= G[superscript 1] <= G[superscript 2] <= . . . , where each G[superscript i] is defined over the players' beliefs and G[superscript 0] is the second-highest valuation (i.e., the revenue benchmark achieved by the second-price mechanism). We (1) construct a single, interim individually rational, auction mechanism that, without any clue about the rationality level of the players, guarantees revenue G[superscript k] if all players have rationality levels >= k + 1, and (2) prove that no such mechanism can guarantee revenue even close to G[superscript k] when at least two players are at most level-k rational.","['Micali, Silvio', 'Pass, Rafael', 'Chen, Jing']","['Consumer Economics: Theory', 'Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D44', 'D83']",Tight Revenue Bounds with Possibilistic Beliefs and Level-k Rationality,0,0,1,0,0,2015,07,01
83,4,2015-07-01,"This paper studies the dynamics of long-term contracts in repeated principal-agent relationships with an impatient agent. Despite the absence of exogenous uncertainty, Pareto-optimal dynamic contracts generically oscillate between favoring the principal and favoring the agent.","['Zhu, John Y.', 'Opp, Marcus M.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['C73', 'D82', 'D86']",Impatience versus Incentives,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"This paper presents a test of the exogeneity of a single explanatory variable in a multivariate model. It does not require the exogeneity of the other regressors or the existence of instrumental variables. The fundamental maintained assumption is that the model must be continuous in the explanatory variable of interest. This test has power when unobservable confounders are discontinuous with respect to the explanatory variable of interest, and it is particularly suitable for applications in which that variable has bunching points. An application of the test to the problem of estimating the effects of maternal smoking in birth weight shows evidence of remaining endogeneity, even after controlling for the most complete covariate specification in the literature.","['Caetano, Carolina']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Health Behavior', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Gender; Non-labor Discrimination']","['C26', 'I12', 'J13', 'J16']",A Test of Exogeneity without Instrumental Variables in Models with Bunching,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"In this paper, we study the least squares (LS) estimator in a linear panel regression model with number of factors appearing as interactive fixed effects. Assuming that the number of factors used in estimation is larger than the true number of factors in the data, we establish the limiting distribution of the LS estimator for the regression coefficients as the number of time periods and the number of cross-sectional units jointly go to infinity. The main result of the paper is that under certain assumptions, the limiting distribution of the LS estimator is independent of the number of factors used in the estimation as long as this number is not underestimated. The important practical implication of this result is that for inference on the regression coefficients, one does not necessarily need to estimate the number of interactive fixed effects consistently.","['Weidner, Martin', 'Moon, Hyungsik Roger']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse', 'Family and Personal Law']","['C23', 'J12', 'K36']",Linear Regression for Panel with Unknown Number of Factors as Interactive Fixed Effects,0,1,0,0,0,2015,07,01
83,4,2015-07-01,"We propose a novel technique to boost the power of testing a high-dimensional vector H : theta = 0 against sparse alternatives where the null hypothesis is violated by only a few components. Existing tests based on quadratic forms such as the Wald statistic often suffer from low powers due to the accumulation of errors in estimating high-dimensional parameters. More powerful tests for sparse alternatives such as thresholding and extreme value tests, on the other hand, require either stringent conditions or bootstrap to derive the null distribution and often suffer from size distortions due to the slow convergence. Based on a screening technique, we introduce a ""power enhancement component,"" which is zero under the null hypothesis with high probability, but diverges quickly under sparse alternatives. The proposed test statistic combines the power enhancement component with an asymptotically pivotal statistic, and strengthens the power under sparse alternatives. The null distribution does not require stringent regularity conditions, and is completely determined by that of the pivotal statistic. The proposed methods are then applied to testing the factor pricing models and validating the cross-sectional independence in panel data models.","['Liao, Yuan', 'Fan, Jianqing', 'Yao, Jiawei']","['Large Data Sets: Modeling and Analysis', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C55', 'C58', nan]",Power Enhancement in High-Dimensional Cross-Sectional Tests,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"We develop a behavioral axiomatic characterization of subjective expected utility (SEU) under risk aversion. Given is an individual agent's behavior in the market: assume a finite collection of asset purchases with corresponding prices. We show that such behavior satisfies a ""revealed preference axiom"" if and only if there exists a SEU model (a subjective probability over states and a concave utility function over money) that accounts for the given asset purchases.","['Echenique, Federico', 'Saito, Kota']","['Consumer Economics: Theory', 'Household Saving; Personal Finance', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D14', 'D81']",Savage in the Market,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"This paper develops a theory of optimal provision of commitment devices to people who value both commitment and flexibility and whose preferences differ in the degree of time inconsistency. If time inconsistency is observable, both a planner and a monopolist provide devices that help each person commit to the efficient level of flexibility. However, the combination of unobservable time inconsistency and preference for flexibility causes an adverse-selection problem. To solve this problem, the monopolist and (possibly) the planner curtail flexibility in the device for a more inconsistent person at both ends of the efficient choice range; moreover, they may have to add unused options to the device for a less inconsistent person and also distort his actual choices. This theory has normative and positive implications for private and public provision of commitment devices.","['Galperti, Simone']","['Firm Behavior: Theory', 'Market Structure, Pricing, and Design: Monopoly', 'Asymmetric and Private Information; Mechanism Design', 'Monopoly; Monopolization Strategies']","['D21', 'D42', 'D82', 'L12']","Commitment, Flexibility, and Optimal Screening of Time Inconsistency",1,0,1,0,0,2015,07,01
83,4,2015-07-01,"This paper develops a new model for empirically analyzing dynamic matching in the marriage market and then applies that model to recent changes in the U.S. marriage distribution. Its primary objective is to estimate gains by age from being married today (till death of at least one spouse) relative to remaining single for that same time period. An empirical methodology that relies on the model's equilibrium outcomes identifies the marriage gains using a single cross-section of observed aggregate matches. This behavioral dynamic model rationalizes a new marriage matching function. The model also solves the inverse problem of computing the vector of aggregate marriages, given a new distribution of available single individuals and estimated preferences. Finally, this paper develops a simple test of the model's empirical validity. Using aggregate data of new marriages and available single men and women in the United States over two decades from 1970 to 1990, I investigate the changes in marriage gains over this period.","['Choo, Eugene']","['Bargaining Theory; Matching Theory', 'Marriage; Marital Dissolution; Family Structure; Domestic Abuse']","['C78', 'J12']",Dynamic Marriage Matching: An Empirical Framework,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"Using an exhaustive data set on claims held by trade creditors (suppliers) on failed trade debtors (customers), we quantify the importance of trade credit chains for the propagation of corporate bankruptcy. We show that trade creditors experience significant trade credit losses due to trade debtor failures and that creditors' bankruptcy risks increase in the size of incurred losses. By exploring the roles of financial constraints and creditor-debtor dependences, we infer that the trade credit failure propagation mechanism is driven by both credit losses and demand shrinkage. Finally, we show that the documented propagation mechanism constitutes a significant part of the overall bankruptcy frequency, suggesting that it has measurable implications for the aggregate level.","['von Schedvin, Erik', 'Jacobson, Tor']","['Model Construction and Estimation', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Bankruptcy; Liquidation']","['C51', 'G21', 'G32', 'G33']",Trade Credit and the Propagation of Corporate Failure: An Empirical Analysis,0,0,0,0,0,2015,07,01
83,4,2015-07-01,"This paper studies regulated health insurance markets known as exchanges, motivated by the increasingly important role they play in both public and private insurance provision. We develop a framework that combines data on health outcomes and insurance plan choices for a population of insured individuals with a model of a competitive insurance exchange to predict outcomes under different exchange designs. We apply this framework to examine the effects of regulations that govern insurers' ability to use health status information in pricing. We investigate the welfare implications of these regulations with an emphasis on two potential sources of inefficiency: (i) adverse selection and (ii) premium reclassification risk. We find substantial adverse selection leading to full unraveling of our simulated exchange, even when age can be priced. While the welfare cost of adverse selection is substantial when health status cannot be priced, that of reclassification risk is five times larger when insurers can price based on some health status information. We investigate several extensions including (i) contract design regulation, (ii) self-insurance through saving and borrowing, and (iii) insurer risk adjustment transfers.","['Handel, Ben', 'Whinston, Michael D.', 'Hendel, Igal']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Insurance; Insurance Companies; Actuarial Studies', 'Health Insurance, Public and Private']","['D81', 'D82', 'D86', 'G22', 'I13']",Equilibria in Health Exchanges: Adverse Selection versus Reclassification Risk,0,0,0,0,0,2015,07,01
83,3,2015-05-01,ECONLIT None Found,[nan],[nan],[nan],2014 Election of Fellows to the Econometric Society.,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"Levy (2013) presented examples of discounted stochastic games that do not have stationary equilibria. The second named author has pointed out that one of these examples is incorrect. In addition to describing the details of this error, this note presents a new example by the first named author that succeeds in demonstrating that discounted stochastic games with absolutely continuous transitions can fail to have stationary equilibria.","['McLennan, Andrew', 'Levy, Yehuda John']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Discounted Stochastic Games with No Stationary Nash Equilibrium: Two Examples: Corrigendum,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"We develop a strategic theory of counterfeiting as a multi-market large game. Bad guys choose whether to counterfeit, and what quality to produce. Opposing them is a continuum of good guys who select a costly verification effort. In equilibrium, counterfeiters produce better quality at higher notes, but verifiers try sufficiently harder that verification still improves. We develop a graphical framework for deducing comparative statics. Passed and counterfeiting rates vanish for low and high notes. Our predictions are consistent with time series and cross-sectional patterns in a unique data set assembled largely from the Secret Service.","['Quercioli, Elena', 'Smith, Lones']","['Noncooperative Games', 'Illegal Behavior and the Enforcement of Law']","['C72', 'K42']",The Economics of Counterfeiting,0,1,0,0,0,2015,05,01
83,3,2015-05-01,"We study the identification through instruments of a nonseparable function that relates a continuous outcome to a continuous endogenous variable. Using group and dynamical systems theories, we show that full identification can be achieved under strong exogeneity of the instrument and a dual monotonicity condition, even if the instrument is discrete. When identified, the model is also testable. Our results therefore highlight the identifying power of strong exogeneity when combined with monotonicity restrictions.","['Fevrier, Philippe', ""D'Haultfoeuille, Xavier""]","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Identification of Nonseparable Triangular Models with Discrete Instruments,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"I consider nonparametric identification of nonseparable instrumental variables models with continuous endogenous variables. If both the outcome and first stage equations are strictly increasing in a scalar unobservable, then many kinds of continuous, discrete, and even binary instruments can be used to point-identify the levels of the outcome equation. This contrasts sharply with related work by Imbens and Newey, 2009 that requires continuous instruments with large support. One implication is that assumptions about the dimension of heterogeneity can provide nonparametric point-identification of the distribution of treatment response for a continuous treatment in a randomized controlled experiment with partial compliance.","['Torgovitsky, Alexander']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Identification of Nonseparable Models Using Instruments with Small Support,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"This paper introduces time-varying grouped patterns of heterogeneity in linear panel data models. A distinctive feature of our approach is that group membership is left unrestricted. We estimate the parameters of the model using a ""grouped fixed-effects"" estimator that minimizes a least squares criterion with respect to all possible groupings of the cross-sectional units. Recent advances in the clustering literature allow for fast and efficient computation. We provide conditions under which our estimator is consistent as both dimensions of the panel tend to infinity, and we develop inference methods. Finally, we allow for grouped patterns of unobserved heterogeneity in the study of the link between income and democracy across countries.","['Manresa, Elena', 'Bonhomme, Stephane']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Institutions and the Macroeconomy', 'Macroeconomics: Production', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Institutions and Growth']","['C23', 'C33', 'D72', 'E02', 'E23', 'O17', 'O43']",Grouped Patterns of Heterogeneity in Panel Data,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"We develop a new parametric estimation procedure for option panels observed with error. We exploit asymptotic approximations assuming an ever increasing set of option prices in the moneyness (cross-sectional) dimension, but with a fixed time span. We develop consistent estimators for the parameters and the dynamic realization of the state vector governing the option price dynamics. The estimators converge stably to a mixed-Gaussian law and we develop feasible estimators for the limiting variance. We also provide semiparametric tests for the option price dynamics based on the distance between the spot volatility extracted from the options and one constructed nonparametrically from high-frequency data on the underlying asset. Furthermore, we develop new tests for the day-by-day model fit over specific regions of the volatility surface and for the stability of the risk-neutral dynamics over time. A comprehensive Monte Carlo study indicates that the inference procedures work well in empirically realistic settings. In an empirical application to S&P 500 index options, guided by the new diagnostic tests, we extend existing asset pricing models by allowing for a flexible dynamic relation between volatility and priced jump tail risk. Importantly, we document that the priced jump tail risk typically responds in a more pronounced and persistent manner than volatility to large negative market shocks.","['Todorov, Viktor', 'Andersen, Torben G.', 'Fusari, Nicola']","['Financial Econometrics', 'Contingent Pricing; Futures Pricing; option pricing']","['C58', 'G13']",Parametric Inference and Dynamic State Recovery from Option Panels,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"This paper considers inference on functionals of semi/nonparametric conditional moment restrictions with possibly nonsmooth generalized residuals, which include all of the (nonlinear) nonparametric instrumental variables (IV) as special cases. These models are often ill-posed and hence it is difficult to verify whether a (possibly nonlinear) functional is root-estimable or not. We provide computationally simple, unified inference procedures that are asymptotically valid regardless of whether a functional is root-estimable or not. We establish the following new useful results: (1) the asymptotic normality of a plug-in penalized sieve minimum distance (PSMD) estimator of a (possibly nonlinear) functional; (2) the consistency of simple sieve variance estimators for the plug-in PSMD estimator, and hence the asymptotic chi-square distribution of the sieve Wald statistic; (3) the asymptotic chi-square distribution of an optimally weighted sieve quasi likelihood ratio (QLR) test under the null hypothesis; (4) the asymptotic tight distribution of a non-optimally weighted sieve QLR statistic under the null; (5) the consistency of generalized residual bootstrap sieve Wald and QLR tests; (6) local power properties of sieve Wald and QLR tests and of their bootstrap versions; (7) asymptotic properties of sieve Wald and SQLR for functionals of increasing dimension. Simulation studies and an empirical illustration of a nonparametric quantile IV regression are presented.","['Pouzo, Demian', 'Chen, Xiaohong']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Sieve Wald and QLR Inferences on Semi/Nonparametric Conditional Moment Models,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"Harsanyi (1974) criticized the von Neumann-Morgenstern (vNM) stable set for its presumption that coalitions are myopic about their prospects. He proposed a new dominance relation incorporating farsightedness, but retained another feature of the stable set: that a coalition can impose any imputation as long as its restriction to is feasible for it. This implicitly gives an objecting coalition complete power to arrange the payoffs of players elsewhere, which is clearly unsatisfactory. While this assumption is largely innocuous for myopic dominance, it is of crucial significance for its farsighted counterpart. Our modification of the Harsanyi set respects ""coalitional sovereignty."" The resulting farsighted stable set is very different from both the Harsanyi and the vNM sets. We provide a necessary and sufficient condition for the existence of a farsighted stable set containing just a single-payoff allocation. This condition roughly establishes an equivalence between core allocations and the union of allocations over all single-payoff farsighted stable sets. We then conduct a comprehensive analysis of the existence and structure of farsighted stable sets in simple games. This last exercise throws light on both single-payoff and multi-payoff stable sets, and suggests that they do not coexist.","['Ray, Debraj', 'Vohra, Rajiv']",['Cooperative Games'],['C71'],The Farsighted Stable Set,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"When people interact in familiar settings, social conventions usually develop so that people tend to disregard alternatives outside the convention. For rational players to usually restrict attention to a block of conventional strategies, no player should prefer to deviate from the block when others are likely to act conventionally and rationally inside the block. We explore two set-valued concepts, coarsely and finely tenable blocks, that formalize this notion for finite normal-form games. We then identify settled equilibria, which are Nash equilibria with support in minimal tenable blocks. For a generic class of normal-form games, our coarse and fine concepts are equivalent, and yet they differ from standard solution concepts on open sets of games. We demonstrate the nature and power of the solutions by way of examples. Settled equilibria are closely related to persistent equilibria but are strictly more selective on an open set of games. With fine tenability, we obtain invariance under the insertion of a subgame with a unique totally mixed payoff-equivalent equilibrium, a property that other related concepts have not satisfied.","['Weibull, Jorgen', 'Myerson, Roger']","['Cooperative Games', 'Noncooperative Games', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['C71', 'C72', 'Z13']",Tenable Strategy Blocks and Settled Equilibria,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"This paper studies two-sided matching markets with non-transferable utility when the number of market participants grows large. We consider a model in which each agent has a random preference ordering over individual potential matching partners, and agents' types are only partially observed by the econometrician. We show that in a large market, the inclusive value is a sufficient statistic for an agent's endogenous choice set with respect to the probability of being matched to a spouse of a given observable type. Furthermore, while the number of pairwise stable matchings for a typical realization of random utilities grows at a fast rate as the number of market participants increases, the inclusive values resulting from any stable matching converge to a unique deterministic limit. We can therefore characterize the limiting distribution of the matching market as the unique solution to a fixed-point condition on the inclusive values. Finally we analyze identification and estimation of payoff parameters from the asymptotic distribution of observable characteristics at the level of pairs resulting from a stable matching.","['Menzel, Konrad']","['Bargaining Theory; Matching Theory', 'Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory']","['C78', 'D01', 'D11']",Large Matching Markets as Two-Sided Demand Systems,0,0,0,0,0,2015,05,01
83,3,2015-05-01,"We study markets in which agents first make investments and are then matched into potentially productive partnerships. Equilibrium investments and the equilibrium matching will be efficient if agents can simultaneously negotiate investments and matches, but we focus on markets in which agents must first sink their investments before matching. Additional equilibria may arise in this sunk-investment setting, even though our matching market is competitive. These equilibria exhibit inefficiencies that we can interpret as coordination failures. All allocations satisfying a constrained efficiency property are equilibria, and the converse holds if preferences satisfy a separability condition. We identify sufficient conditions (most notably, quasiconcave utilities) for the investments of matched agents to satisfy an exchange efficiency property as well as sufficient conditions (most notably, a single crossing property) for agents to be matched positive assortatively, with these conditions then forming the core of sufficient conditions for the efficiency of equilibrium allocations.","['Noldeke, Georg', 'Samuelson, Larry']","['Bargaining Theory; Matching Theory', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['C78', 'D25', 'G31']",Investment and Competitive Matching,0,0,0,0,0,2015,05,01
88,5,2020-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 5.,0,0,0,0,0,2020,09,01
88,5,2020-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 5.,0,0,0,0,0,2020,09,01
88,5,2020-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,09,01
85,2,2017-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 2.,0,0,0,0,0,2017,03,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2017,01,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 85 Iss. 1.,0,0,0,0,0,2017,01,01
85,1,2017-01-01,ECONLIT None Found,"['Tamer, Elie', 'Gilboa, Itzhak', 'Sobel, Joel', 'Violante, Giovanni L.', 'Bergemann, Dirk', 'Einav, Liran']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Editors 2015-2016,0,0,0,0,0,2017,01,01
83,2,2015-03-01,"It is well known that the finite-sample properties of tests of hypotheses on the co-integrating vectors in vector autoregressive models can be quite poor, and that current solutions based on Bartlett-type corrections or bootstrap based on unrestricted parameter estimators are unsatisfactory, in particular in those cases where also asymptotic x[superscript 2] tests fail most severely. In this paper, we solve this inference problem by showing the novel result that a bootstrap test where the null hypothesis is imposed on the bootstrap sample is asymptotically valid. That is, not only does it have asymptotically correct size, but, in contrast to what is claimed in existing literature, it is consistent under the alternative. Compared to the theory for bootstrap tests on the co-integration rank (Cavaliere, Rahbek, and Taylor, 2012), establishing the validity of the bootstrap in the framework of hypotheses on the co-integrating vectors requires new theoretical developments, including the introduction of multivariate Ornstein-Uhlenbeck processes with random (reduced rank) drift parameters. Finally, as documented by Monte Carlo simulations, the bootstrap test outperforms existing methods.","['Nielsen, Heino Bohn', 'Cavaliere, Giuseppe', 'Rahbek, Anders']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Bootstrap Testing of Hypotheses on Co-integration Relations in Vector Autoregressive Models,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"This paper considers nonstandard hypothesis testing problems that involve a nuisance parameter. We establish an upper bound on the weighted average power of all valid tests, and develop a numerical algorithm that determines a feasible test with power close to the bound. The approach is illustrated in six applications: inference about a linear regression coefficient when the sign of a control coefficient is known; small sample inference about the difference in means from two independent Gaussian samples from populations with potentially different variances; inference about the break date in structural break models with moderate break magnitude; predictability tests when the regressor is highly persistent; inference about an interval identified parameter; and inference about a linear regression coefficient when the necessity of a control is in doubt.","['Elliott, Graham', 'Watson, Mark W.', 'Muller, Ulrich K.']",['Hypothesis Testing: General'],['C12'],Nearly Optimal Tests When a Nuisance Parameter Is Present under the Null Hypothesis,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"This paper presents a new method for the analysis of moral hazard principal-agent problems. The new approach avoids the stringent assumptions on the distribution of outcomes made by the classical first-order approach and instead only requires the agent's expected utility to be a rational function of the action. This assumption allows for a reformulation of the agent's utility maximization problem as an equivalent system of equations and inequalities. This reformulation in turn transforms the principal's utility maximization problem into a nonlinear program. Under the additional assumptions that the principal's expected utility is a polynomial and the agent's expected utility is rational in the wage, the final nonlinear program can be solved to global optimality. The paper also shows how to first approximate expected utility functions that are not rational by polynomials, so that the polynomial optimization approach can be applied to compute an approximate solution to nonpolynomial problems. Finally, the paper demonstrates that the polynomial optimization approach extends to principal-agent models with multidimensional action sets.","['Schmedders, Karl', 'Renner, Philipp']",['Asymmetric and Private Information; Mechanism Design'],['D82'],A Polynomial Optimization Approach to Principal-Agent Problems,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"Many violations of the independence axiom of expected utility can be traced to subjects' attraction to risk-free prospects. The key axiom in this paper, negative certainty independence ([Dillenberger, 2010]), formalizes this tendency. Our main result is a utility representation of all preferences over monetary lotteries that satisfy negative certainty independence together with basic rationality postulates. Such preferences can be represented as if the agent were unsure of how to evaluate a given lottery p; instead, she has in mind a set of possible utility functions over outcomes and displays a cautious behavior: she computes the certainty equivalent of p with respect to each possible function in the set and picks the smallest one. The set of utilities is unique in a well defined sense. We show that our representation can also be derived from a ""cautious"" completion of an incomplete preference relation.","['Dillenberger, David', 'Ortoleva, Pietro', 'Cerreia-Vioglio, Simone']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Cautious Expected Utility and the Certainty Effect,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"We characterize a generalization of discounted logistic choice that incorporates a parameter to capture different views the agent might have about the costs and benefits of larger choice sets. The discounted logit model used in the empirical literature is the special case that displays a ""preference for flexibility"" in the sense that the agent always prefers to add additional items to a menu. Other cases display varying levels of ""choice aversion,"" where the agent prefers to remove items from a menu if their ex ante value is below a threshold. We show that higher choice aversion, as measured by dislike of bigger menus, also corresponds to an increased preference for putting off decisions as late as possible.","['Fudenberg, Drew', 'Strzalecki, Tomasz']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Consumer Economics: Theory']","['C25', 'D11']",Dynamic Logit with Choice Aversion,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"We consider empirical measurement of equivalent variation (EV) and compensating variation (CV) resulting from price change of a discrete good using individual-level data when there is unobserved heterogeneity in preferences. We show that for binary and unordered multinomial choice, the marginal distributions of EV and CV can be expressed as simple closed-form functionals of conditional choice probabilities under essentially unrestricted preference distributions. These results hold even when the distribution and dimension of unobserved heterogeneity are neither known nor identified, and utilities are neither quasilinear nor parametrically specified. The welfare distributions take simple forms that are easy to compute in applications. In particular, average EV for a price rise equals the change in average Marshallian consumer surplus and is smaller than average CV for a normal good. These nonparametric point-identification results fail for ordered choice if the unit price is identical for all alternatives, thereby providing a connection to Hausman-Newey's (2014) partial identification results for the limiting case of continuous choice.","['Bhattacharya, Debopam']","['Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory']","['D01', 'D11']",Nonparametric Welfare Analysis for Discrete Choice,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"We study social dilemmas in (quasi-) continuous-time experiments, comparing games with different durations and termination rules. We discover a stark qualitative contrast in behavior in continuous time as compared to previously studied behavior in discrete-time games: cooperation is easier to achieve and sustain with deterministic horizons than with stochastic ones, and end-game effects emerge, but subjects postpone them with experience. Analysis of individual strategies provides a basis for a simple reinforcement learning model that proves to be consistent with this evidence. An additional treatment lends further support to this explanation.","['Bigoni, Maria', 'Casari, Marco', 'Spagnolo, Giancarlo', 'Skrzypacz, Andrzej']","['Econometrics of Games and Auctions', 'Cooperative Games', 'Noncooperative Games', 'Design of Experiments: Laboratory, Individual']","['C57', 'C71', 'C72', 'C91']",Time Horizon and Cooperation in Continuous Time,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"We formalize the Keynesian insight that aggregate demand driven by sentiments can generate output fluctuations under rational expectations. When production decisions must be made under imperfect information about demand, optimal decisions based on sentiments can generate stochastic self-fulfilling rational expectations equilibria in standard economies without persistent informational frictions, externalities, nonconvexities, or strategic complementarities in production. The models we consider are deliberately simple, but could serve as benchmarks for more complicated equilibrium models with additional features.","['Benhabib, Jess', 'Wen, Yi', 'Wang, Pengfei']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Macroeconomics: Production', 'Business Fluctuations; Cycles']","['D82', 'D83', 'D84', nan, 'E23', 'E32']",Sentiments and Aggregate Demand Fluctuations,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"We examine the link between the threat of violence and democratization in the context of the Great Reform Act passed by the British Parliament in 1832. We geo-reference the so-called Swing riots, which occurred between the 1830 and 1831 parliamentary elections, and compute the number of these riots that happened within a 10 km radius of the 244 English constituencies. Our empirical analysis relates this constituency-specific measure of the threat perceptions held by the 344,000 voters in the Unreformed Parliament to the share of seats won in each constituency by pro-reform politicians in 1831. We find that the Swing riots induced voters to vote for pro-reform politicians after experiencing first-hand the violence of the riots.","['Franck, Raphael', 'Aidt, Toke S.']","['Model Construction and Estimation', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Conflict; Conflict Resolution; Alliances; Revolutions', 'Economic History: Government, War, Law, International Relations, and Regulation: Europe: Pre-1913']","['C51', 'D72', 'D74', 'N43']",Democratization under the Threat of Revolution: Evidence from the Great Reform Act of 1832,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"Is African politics characterized by concentrated power in the hands of a narrow group (ethnically determined) that then fluctuates from one extreme to another via frequent coups? Employing data on the ethnicity of cabinet ministers since independence, we show that African ruling coalitions are surprisingly large and that political power is allocated proportionally to population shares across ethnic groups. This holds true even restricting the analysis to the subsample of the most powerful ministerial posts. We argue that the likelihood of revolutions from outsiders and coup threats from insiders are major forces explaining allocations within these regimes. Alternative allocation mechanisms are explored. Counterfactual experiments that shed light on the role of Western policies in affecting African national coalitions and leadership group premia are performed.","['Francois, Patrick', 'Rainer, Ilia', 'Trebbi, Francesco']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Conflict; Conflict Resolution; Alliances; Revolutions', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D72', 'D74', 'J15', 'O15', 'O17']",How Is Power Shared in Africa?,0,0,0,0,0,2015,03,01
83,2,2015-03-01,"This paper studies the introduction of electronic voting technology in Brazilian elections. Estimates exploiting a regression discontinuity design indicate that electronic voting reduced residual (error-ridden and uncounted) votes and promoted a large de facto enfranchisement of mainly less educated citizens. Estimates exploiting the unique pattern of the technology's phase-in across states over time suggest that, as predicted by political economy models, it shifted government spending toward health care, which is particularly beneficial to the poor. Positive effects on both the utilization of health services (prenatal visits) and newborn health (low-weight births) are also found for less educated mothers, but not for the more educated.","['Fujiwara, Thomas']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Health Behavior', 'Health: Government Policy; Regulation; Public Health', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D72', 'I12', 'I18', 'J13', 'O15', 'O17']","Voting Technology, Political Responsiveness, and Infant Health: Evidence from Brazil",0,0,0,0,0,2015,03,01
83,1,2015-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports. Econometrica Referees 2013-2014.,0,0,0,0,0,2015,01,01
83,1,2015-01-01,ECONLIT None Found,"['Acemoglu, Daron', 'Sobel, Joel', 'Jackson, Matthew O.', 'Hansen, Lars Peter', 'Einav, Liran', 'Jehiel, Philippe']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Editors 2013-2014,0,0,0,0,0,2015,01,01
83,1,2015-01-01,ECONLIT None Found,"['Salanie, Bernard']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Treasurer,0,0,0,0,0,2015,01,01
83,1,2015-01-01,ECONLIT None Found,"['Salanie, Bernard']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Secretary,0,0,0,0,0,2015,01,01
83,1,2015-01-01,"Ivanov, Levin, and Niederle (2010) use a common-value second-price auction experiment to reject beliefs-based explanations for the winner's curse. ILN's conclusion, however, stems from the misuse of theoretical arguments. Beliefs-based models are even compatible with some observations from ILN's experiment.","['Shimoji, Makoto', 'Costa-Gomes, Miguel A.']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",Can Relaxation of Beliefs Rationalize the Winner's Curse?: An Experimental Study: Comment,0,0,1,0,0,2015,01,01
83,1,2015-01-01,"In this paper, I construct players' prior beliefs and show that these prior beliefs lead the players to learn to play an approximate Nash equilibrium uniformly in any infinitely repeated slightly perturbed game with discounting and perfect monitoring. That is, given any epsilon > 0, there exists a (single) profile of players' prior beliefs that leads play to almost surely converge to an epsilon-Nash equilibrium uniformly for any (finite normal form) stage game with slight payoff perturbation and any discount factor less than 1.","['Noguchi, Yuichi']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D83']","Bayesian Learning, Smooth Approximate Optimal Behavior, and Convergence to E-Nash Equilibrium",0,0,0,0,0,2015,01,01
83,1,2015-01-01,"A sequence of experiments documents static and dynamic ""preference reversals"" between sooner-smaller and later--larger rewards, when the sooner reward could be immediate. The theoretically motivated design permits separate identification of time consistent, stationary, and time invariant choices. At least half of the subjects are time consistent, but only three-quarters of them exhibit stationary choices. About half of subjects with time inconsistent choices have stationary preferences. These results challenge the view that present-bias preferences are the main source of time inconsistent choices.","['Halevy, Yoram']","['Consumer Economics: Empirical Analysis', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D12', 'D15']",Time Consistency: Stationarity and Time Invariance,0,0,0,0,0,2015,01,01
83,1,2015-01-01,This paper provides conditions under which the inequality constraints generated by either single agent optimizing behavior or the best response condition of multiple agent problems can be used as a basis for estimation and inference. An application illustrates how the use of these inequality constraints can simplify the analysis of complex behavioral models.,"['Porter, J.', 'Ho, Kate', 'Ishii, Joy', 'Pakes, A.']","['Model Construction and Estimation', 'Econometrics of Games and Auctions', 'Microeconomic Behavior: Underlying Principles', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['C51', 'C57', 'D01', 'G21', 'L11']",Moment Inequalities and Their Application,1,0,0,0,0,2015,01,01
83,1,2015-01-01,"We develop a model of the market for federal funds that explicitly accounts for its two distinctive features: banks have to search for a suitable counterparty, and once they meet, both parties negotiate the size of the loan and the repayment. The theory is used to answer a number of positive and normative questions: What are the determinants of the fed funds rate? How does the market reallocate funds? Is the market able to achieve an efficient reallocation of funds? We also use the model for theoretical and quantitative analyses of policy issues facing modern central banks.","['Lagos, Ricardo', 'Afonso, Gara']","['Interest Rates: Determination, Term Structure, and Effects', 'Monetary Policy', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages']","['E43', 'E52', 'G21']",Trade Dynamics in the Market for Federal Funds,0,0,0,0,0,2015,01,01
83,1,2015-01-01,This paper axiomatizes an intertemporal version of the maxmin expected-utility model. It employs two axioms specific to a dynamic setting. The first requires that smoothing consumption across states of the world is more beneficial to the individual than smoothing consumption across time. Such behavior is viewed as the intertemporal manifestation of ambiguity aversion. The second axiom extends Koopmans' notion of stationarity from deterministic to stochastic environments.,"['Kochov, Asen']","['Consumer Economics: Theory', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D44', 'D81']",Time and No Lotteries: An Axiomatization of Maxmin Expected Utility,0,0,1,0,0,2015,01,01
83,1,2015-01-01,"The paper analyzes dynamic principal-agent models with short period lengths. The two main contributions are: (i) an analytic characterization of the values of optimal contracts in the limit as the period length goes to 0, and (ii) the construction of relatively simple (almost) optimal contracts for fixed period lengths. Our setting is flexible and includes the pure hidden action or pure hidden information models as special cases. We show how such details of the underlying information structure affect the optimal provision of incentives and the value of the contracts. The dependence is very tractable and we obtain sharp comparative statics results. The results are derived with a novel method that uses a quadratic approximation of the Pareto boundary of the equilibrium value set.","['Stacchetti, Ennio', 'Sadzik, Tomasz']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Agency Models with Frequent Actions,0,0,0,0,0,2015,01,01
83,1,2015-01-01,"For an arbitrary data set D = {(p, x)} subset (R[subscript +][superscript m]\ {0}) x R[subscript +][superscript m], finite or infinite, it is shown that the following three conditions are equivalent: (a) D satisfies GARP; (b) D can be rationalized by a utility function; (c) D can be rationalized by a utility function that is quasiconcave, nondecreasing, and that strictly increases when all its coordinates strictly increase. Examples of infinite data sets satisfying GARP are provided for which every utility rationalization fails to be lower semicontinuous, upper semicontinuous, or concave. Thus condition (c) cannot be substantively improved upon.","['Reny, Philip J.']",['Consumer Economics: Theory'],['D11'],A Characterization of Rationalizable Consumer Behavior,0,0,0,0,0,2015,01,01
83,1,2015-01-01,"Internet advertising has been the fastest growing advertising channel in recent years, with paid search ads comprising the bulk of this revenue. We present results from a series of large-scale field experiments done at eBay that were designed to measure the causal effectiveness of paid search ads. Because search clicks and purchase intent are correlated, we show that returns from paid search are a fraction of non-experimental estimates. As an extreme case, we show that brand keyword ads have no measurable short-term benefits. For non-brand keywords, we find that new and infrequent users are positively influenced by ads but that more frequent users whose purchasing behavior is not influenced by ads account for most of the advertising expenses, resulting in average returns that are negative.","['Tadelis, Steven', 'Nosko, Chris', 'Blake, Thomas']","['Field Experiments', 'Consumer Economics: Empirical Analysis', 'Advertising']","['C93', 'D12', 'M37']",Consumer Heterogeneity and Paid Search Effectiveness: A Large-Scale Field Experiment,0,0,0,0,0,2015,01,01
83,1,2015-01-01,"Are there times when durable spending is less responsive to economic stimulus? We argue that aggregate durable expenditures respond more sluggishly to economic shocks during recessions because microeconomic frictions lead to declines in the frequency of households' durable adjustment. We show this by first using indirect inference to estimate a heterogeneous agent incomplete markets model with fixed costs of durable adjustment to match consumption dynamics in PSID microdata. We then show that aggregating this model delivers an extremely procyclical Impulse Response Function (IRF) of durable spending to aggregate shocks. For example, the response of durable spending to an income shock in 1999 is estimated to be almost twice as large as if it occurred in 2009. This procyclical IRF holds in response to standard business cycle shocks as well as in response to various policy shocks, and it is robust to general equilibrium. After estimating this robust theoretical implication of micro frictions, we provide additional direct empirical evidence for its importance using both cross-sectional and time-series data.","['Vavra, Joseph', 'Berger, David']","['Model Construction and Estimation', 'Macroeconomics: Consumption; Saving; Wealth', 'Business Fluctuations; Cycles']","['C51', 'E21', 'E32']",Consumption Dynamics during Recessions,0,0,0,0,0,2015,01,01
83,1,2015-01-01,"This study provides causal evidence that a shock to the relative supply of inputs to production can (1) affect the direction of technological progress and (2) lead to a rebound in the relative price of the input that became relatively more abundant (the strong induced-bias hypothesis). I exploit the impact of the U.S. Civil War on the British cotton textile industry, which reduced supplies of cotton from the Southern United States, forcing British producers to shift to lower-quality Indian cotton. Using detailed new data, I show that this shift induced the development of new technologies that augmented Indian cotton. As these new technologies became available, I show that the relative price of Indian/U.S. cotton rebounded to its pre-war level, despite the increased relative supply of Indian cotton. This is the first paper to establish both of these patterns empirically, lending support to the two key predictions of leading directed technical change theories.","['Hanlon, W. Walker']","['Other Consumer Nondurables: Clothing, Textiles, Shoes, and Leather Goods; Household Goods; Sports Equipment', 'Economic History: Government, War, Law, International Relations, and Regulation: U.S.; Canada: Pre-1913', 'Economic History: Agriculture, Natural Resources, Environment, and Extractive Industries: Europe: Pre-1913', 'Economic History: Manufacturing and Construction: Europe: Pre-1913', 'Economic History: Transport, Trade, Energy, Technology, and Other Services: U.S.; Canada: Pre-1913', 'Economic History: Transport, Trade, Energy, Technology, and Other Services: Europe: Pre-1913', 'Technological Change: Choices and Consequences; Diffusion Processes']","['L67', 'N41', 'N53', 'N63', 'N71', 'N73', 'O33']",Necessity Is the Mother of Invention: Input Supplies and Directed Technical Change,1,0,0,1,0,2015,01,01
83,1,2015-01-01,"We introduce methods for estimating nonparametric, nonadditive models with simultaneity. The methods are developed by directly connecting the elements of the structural system to be estimated with features of the density of the observable variables, such as ratios of derivatives or averages of products of derivatives of this density. The estimators are therefore easily computed functionals of a nonparametric estimator of the density of the observable variables. We consider in detail a model where to each structural equation there corresponds an exclusive regressor and a model with one equation of interest and one instrument that is included in a second equation. For both models, we provide new characterizations of observational equivalence on a set, in terms of the density of the observable variables and derivatives of the structural functions. Based on those characterizations, we develop two estimation methods. In the first method, the estimators of the structural derivatives are calculated by a simple matrix inversion and matrix multiplication, analogous to a standard least squares estimator, but with the elements of the matrices being averages of products of derivatives of nonparametric density estimators. In the second method, the estimators of the structural derivatives are calculated in two steps. In a first step, values of the instrument are found at which the density of the observable variables satisfies some properties. In the second step, the estimators are calculated directly from the values of derivatives of the density of the observable variables evaluated at the found values of the instrument. We show that both pointwise estimators are consistent and asymptotically normal.","['Matzkin, Rosa L.']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Multiple or Simultaneous Equation Models: Instrumental Variables (IV) Estimation']","['C14', 'C26', 'C36']",Estimation of Nonparametric Models with Simultaneity,0,0,0,0,0,2015,01,01
84,6,2016-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 84 Iss. 6.,0,0,0,0,0,2016,11,01
84,5,2016-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 84 Iss. 5.,0,0,0,0,0,2016,09,01
84,4,2016-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 84 Iss. 4.,0,0,0,0,0,2016,07,01
82,6,2014-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 6.,0,0,0,0,0,2014,11,01
82,6,2014-11-01,ECONLIT None Found,"['Heckman, James J.']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society 2013 Annual Report of the President,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"We study dominant strategy incentive compatibility in a mechanism design setting with contingent contracts where the payoff of each agent is observed by the principal and can be contracted upon. Our main focus is on the class of linear contracts (one of the most commonly used contingent contracts) which consist of a transfer and a flat rate of profit sharing. We characterize outcomes implementable by linear contracts and provide a foundation for them by showing that, in finite type spaces, every social choice function that can be implemented using a more general nonlinear contingent contract can also be implemented using a linear contract. We then qualitatively describe the set of implementable outcomes. We show that a general class of social welfare criteria can be implemented. This class contains social choice functions (such as the Rawlsian) which cannot be implemented using (uncontingent) transfers. Under additional conditions, we show that only social choice functions in this class are implementable.","['Deb, Rahul', 'Mishra, Debasis']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Implementation with Contingent Contracts,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"This paper develops the fixed-smoothing asymptotics in a two-step generalized method of moments (GMM) framework. Under this type of asymptotics, the weighting matrix in the second-step GMM criterion function converges weakly to a random matrix and the two-step GMM estimator is asymptotically mixed normal. Nevertheless, the Wald statistic, the GMM criterion function statistic, and the Lagrange multiplier statistic remain asymptotically pivotal. It is shown that critical values from the fixed-smoothing asymptotic distribution are high order correct under the conventional increasing-smoothing asymptotics. When an orthonormal series covariance estimator is used, the critical values can be approximated very well by the quantiles of a noncentral F distribution. A simulation study shows that statistical tests based on the new fixed-smoothing approximation are much more accurate in size than existing tests.","['Sun, Yixiao']","['Hypothesis Testing: General', 'Estimation: General']","['C12', 'C13']",Fixed-Smoothing Asymptotics in a Two-Step Generalized Method of Moments Framework,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"In the regression-discontinuity (RD) design, units are assigned to treatment based on whether their value of an observed covariate exceeds a known cutoff. In this design, local polynomial estimators are now routinely employed to construct confidence intervals for treatment effects. The performance of these confidence intervals in applications, however, may be seriously hampered by their sensitivity to the specific bandwidth employed. Available bandwidth selectors typically yield a ""large"" bandwidth, leading to data-driven confidence intervals that may be biased, with empirical coverage well below their nominal target. We propose new theory-based, more robust confidence interval estimators for average treatment effects at the cutoff in sharp RD, sharp kink RD, fuzzy RD, and fuzzy kink RD designs. Our proposed confidence intervals are constructed using a bias-corrected RD estimator together with a novel standard error estimator. For practical implementation, we discuss mean squared error optimal bandwidths, which are by construction not valid for conventional confidence intervals but are valid with our robust approach, and consistent standard error estimators based on our new variance formulas. In a special case of practical interest, our procedure amounts to running a quadratic instead of a linear local regression. More generally, our results give a formal justification to simple inference procedures based on increasing the order of the local polynomial estimator employed. We find in a simulation study that our confidence intervals exhibit close-to-correct empirical coverage and good empirical interval length on average, remarkably improving upon the alternatives available in the literature. All results are readily available in R and STATA using our companion software packages described in Calonico, Cattaneo, and Titiunik (2014d, 2014b).","['Calonico, Sebastian', 'Titiunik, Rocio', 'Cattaneo, Matias D.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Robust Nonparametric Confidence Intervals for Regression-Discontinuity Designs,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"Before choosing among two actions with state-dependent payoffs, a Bayesian decision-maker with a finite memory sees a sequence of informative signals, ending each period with fixed chance. He summarizes information observed with a finite-state automaton. I characterize the optimal protocol as an equilibrium of a dynamic game of imperfect recall; a new player runs each memory state each period. Players act as if maximizing expected payoffs in a common finite action decision problem. I characterize equilibrium play with many multinomial signals. The optimal protocol rationalizes many behavioral phenomena, like ""stickiness,"" salience, confirmation bias, and belief polarization.","['Wilson, Andrea']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Bounded Memory and Biases in Information Processing,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"Subjects in a laboratory experiment withdraw earnings from a cash reserve evolving according to an arithmetic Brownian motion in near-continuous time. Aggressive withdrawal policies expose subjects to risk of bankruptcy, but the policy that maximizes expected earnings need not maximize the odds of survival. When profit maximization is consistent with high rates of survival (HS parameters), subjects adjust decisively towards the optimum. When survival and profit maximization are sharply at odds (LS parameters), subjects persistently (and sub-optimally) hoard excess cash in an evident effort to improve survival rates. The design ensures that this hoarding is not due to standard risk aversion. Analysis of period-to-period adjustments in strategies suggests instead that hoarding is due to a widespread bias towards survival in the subject population. Robustness treatments varying feedback, parameters, and framing fail to eliminate the bias.","['Oprea, Ryan']","['Firm Behavior: Theory', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Firm Performance: Size, Diversification, and Scope']","['D21', 'D25', 'G31', 'L25']",Survival versus Profit Maximization in a Dynamic Stochastic Experiment,1,0,0,0,0,2014,11,01
82,6,2014-11-01,"We show that deterioration in household balance sheets, or the housing net worth channel, played a significant role in the sharp decline in U.S. employment between 2007 and 2009. Counties with a larger decline in housing net worth experience a larger decline in non-tradable employment. This result is not driven by industry-specific supply-side shocks, exposure to the construction sector, policy-induced business uncertainty, or contemporaneous credit supply tightening. We find little evidence of labor market adjustment in response to the housing net worth shock. There is no significant expansion of the tradable sector in counties with the largest decline in housing net worth. Further, there is little evidence of wage adjustment within or emigration out of the hardest hit counties.","['Mian, Atif', 'Sufi, Amir']","['Household Saving; Personal Finance', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Housing Supply and Markets']","['D14', 'E24', 'E32', 'R31']",What Explains the 2007-2009 Drop in Employment?,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"U.S. data reveal three facts: (1) the share of goods in total expenditure declines at a constant rate over time, (2) the price of goods relative to services declines at a constant rate over time, and (3) poor households spend a larger fraction of their budget on goods than do rich households. I provide a macroeconomic model with non-Gorman preferences that rationalizes these facts, along with the aggregate Kaldor facts. The model is parsimonious and admits an analytical solution. Its functional form allows a decomposition of U.S. structural change into an income and substitution effect. Estimates from micro data show each of these effects to be of roughly equal importance.","['Boppart, Timo']","['Macroeconomics: Production', 'Aggregate Factor Income Distribution', 'One, Two, and Multisector Growth Models', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['E23', 'E25', 'O41', 'O47']",Structural Change and the Kaldor Facts in a Growth Model with Relative Price Effects and Non-Gorman Preferences,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"Studying Native American reservations, and their historical formation, I find that their forced integration of autonomous polities into a system of shared governance had large negative long-run consequences, even though the affected people were ethnically and linguistically homogenous. Reservations that combined multiple sub-tribal bands when they were formed are 30% poorer today, even when conditioning on pre-reservation political traditions. The results hold with tribe fixed effects, identifying only off within-tribe variation across reservations. I also provide estimates from an instrumental variable strategy based on historical mining rushes that led to exogenously more centralized reservations. Data on the timing of economic divergence and on contemporary political conflict suggest that the primary mechanism runs from persistent social divisions through the quality of local governance to the local economic environment.","['Dippel, Christian']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Regional Economic Activity: Growth, Development, Environmental Issues, and Changes', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['D72', 'J15', 'R11', 'R23']",Forced Coexistence and Economic Development: Evidence from Native American Reservations,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"This paper uses the information contained in the joint dynamics of individuals' labor earnings and consumption-choice decisions to quantify both the amount of income risk that individuals face and the extent to which they have access to informal insurance against this risk. We accomplish this task by using indirect inference to estimate a structural consumption-savings model, in which individuals both learn about the nature of their income process and partly insure shocks via informal mechanisms. In this framework, we estimate (i) the degree of partial insurance, (ii) the extent of systematic differences in income growth rates, (iii) the precision with which individuals know their own income growth rates when they begin their working lives, (iv) the persistence of typical labor income shocks, (v) the tightness of borrowing constraints, and (vi) the amount of measurement error in the data. In implementing indirect inference, we find that an auxiliary model that approximates the true structural equations of the model (which are not estimable) works very well, with negligible small sample bias. The main substantive findings are that income shocks are moderately persistent, systematic differences in income growth rates are large, individuals have substantial amounts of information about their income growth rates, and about one-half of income shocks are smoothed via partial insurance. Putting these findings together, the amount of uninsurable lifetime income risk that individuals perceive is substantially smaller than what is typically assumed in calibrated macroeconomic models with incomplete markets.","['Smith, Anthony A., Jr.', 'Guvenen, Fatih']","['Incomplete Markets', 'Criteria for Decision-Making under Risk and Uncertainty', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Macroeconomics: Consumption; Saving; Wealth', 'Insurance; Insurance Companies; Actuarial Studies']","['D52', 'D81', 'D15', 'E21', 'G22']",Inferring Labor Income Risk and Partial Insurance from Economic Choices,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"It is costly to learn about market conditions elsewhere, especially in developing countries. This paper examines how such information frictions affect trade. Using data on regional agricultural trade in the Philippines, I first document a number of observed patterns in trade flows and prices that suggest the presence of information frictions. I then incorporate information frictions into a perfect competition trade model by embedding a process whereby heterogeneous producers engage in a costly sequential search process to determine where to sell their produce. I show that introducing information frictions reconciles the theory with the observed patterns in the data. Structural estimation of the model finds that information frictions are quantitatively important: roughly half the observed regional price dispersion is due to information frictions. Furthermore, incorporating information frictions improves the out-of-sample predictive power of the model.","['Allen, Treb']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Agriculture: Aggregate Supply and Demand Analysis; Prices', 'Size and Spatial Distributions of Regional Economic Activity']","['D83', 'O13', 'O18', 'Q11', 'R12']",Information Frictions in Trade,0,0,0,0,0,2014,11,01
82,6,2014-11-01,"Philosophers, psychologists, and economists have long argued that certain decision rights carry not only instrumental value but may also be valuable for their own sake. The ideas of autonomy, freedom, and liberty derive their intuitive appeal--at least partly--from an assumed positive intrinsic value of decision rights. Providing clean evidence for the existence of this intrinsic value and measuring its size, however, is intricate. Here, we develop a method capable of achieving these goals. The data reveal that the large majority of our subjects intrinsically value decision rights beyond their instrumental benefit. The intrinsic valuation of decision rights has potentially important consequences for corporate governance, human resource management, and optimal job design: it may explain why managers value power, why employees appreciate jobs with task discretion, why individuals sort into self-employment, and why the reallocation of decision rights is often very difficult and cumbersome. Our method and results may also prove useful in developing an empirical revealed preference foundation for concepts such as ""freedom of choice"" and ""individual autonomy.""","['Bartling, Bjorn', 'Fehr, Ernst', 'Herz, Holger']","['Organizational Behavior; Transaction Costs; Property Rights', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design']","['D23', 'D44', 'D81', 'D82']",The Intrinsic Value of Decision Rights,0,0,1,0,0,2014,11,01
82,5,2014-09-01,"This paper considers the problem of testing a finite number of moment inequalities. We propose a two-step approach. In the first step, a confidence region for the moments is constructed. In the second step, this set is used to provide information about which moments are ""negative."" A Bonferonni-type correction is used to account for the fact that, with some probability, the moments may not lie in the confidence region. It is shown that the test controls size uniformly over a large class of distributions for the observed data. An important feature of the proposal is that it remains computationally feasible, even when the number of moments is large. The finite-sample properties of the procedure are examined via a simulation study, which demonstrates, among other things, that the proposal remains competitive with existing procedures while being computationally more attractive.","['Romano, Joseph P.', 'Wolf, Michael', 'Shaikh, Azeem M.']",['Hypothesis Testing: General'],['C12'],A Practical Two-Step Method for Testing Moment Inequalities,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"We axiomatize preferences that can be represented by a monotonic aggregation of subjective expected utilities generated by a utility function and some set of i.i.d. probability measures over a product state space, S[superscript infinity]. For such preferences, we define relevant measures, show that they are treated as if they were the only marginals possibly governing the state space, and connect them with the measures appearing in the aforementioned representation. These results allow us to interpret relevant measures as reflecting part of perceived ambiguity, meaning subjective uncertainty about probabilities over states. Under mild conditions, we show that increases or decreases in ambiguity aversion cannot affect the relevant measures. This property, necessary for the conclusion that these measures reflect only perceived ambiguity, distinguishes the set of relevant measures from the leading alternative in the literature. We apply our findings to a number of well-known models of ambiguity-sensitive preferences. For each model, we identify the set of relevant measures and the implications of comparative ambiguity aversion.","['Klibanoff, Peter', 'Seo, Kyoungwon', 'Mukerji, Sujoy']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Perceived Ambiguity and Relevant Measures,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"Risk aversion (a second-order risk preference) is a time-proven concept in economic models of choice under risk. More recently, the higher order risk preferences of prudence (third-order) and temperance (fourth-order) also have been shown to be quite important. While a majority of the population seems to exhibit both risk aversion and these higher order risk preferences, a significant minority does not. We show how both risk-averse and risk-loving behaviors might be generated by a simple type of basic lottery preference for either (1) combining ""good"" outcomes with ""bad"" ones, or (2) combining ""good with good"" and ""bad with bad,"" respectively. We further show that this dichotomy is fairly robust at explaining higher order risk attitudes in the laboratory. In addition to our own experimental evidence, we take a second look at the extant laboratory experiments that measure higher order risk preferences and we find a fair amount of support for this dichotomy. Our own experiment also is the first to look beyond fourth-order risk preferences, and we examine risk attitudes at even higher orders.","['Deck, Cary', 'Schlesinger, Harris']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Consistency of Higher Order Risk Preferences,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"We develop an extension of Luce's random choice model to study violations of the weak axiom of revealed preference. We introduce the notion of a stochastic preference and show that it implies the Luce model. Then, to address well-known difficulties of the Luce model, we define the attribute rule and establish that the existence of a well-defined stochastic preference over attributes characterizes it. We prove that the set of attribute rules and random utility maximizers are essentially the same. Finally, we show that both the Luce and attribute rules have a unique consistent extension to dynamic problems.","['Pesendorfer, Wolfgang', 'Natenzon, Paulo', 'Gul, Faruk']","['Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory']","['D01', 'D11']",Random Choice as Behavioral Optimization,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"This paper considers mechanism design problems in environments with ambiguity-sensitive individuals. The novel idea is to introduce ambiguity in mechanisms so as to exploit the ambiguity sensitivity of individuals. Deliberate engineering of ambiguity, through ambiguous mediated communication, can allow (partial) implementation of social choice functions that are not incentive compatible with respect to prior beliefs. We provide a complete characterization of social choice functions partially implementable by ambiguous mechanisms.","['Bose, Subir', 'Renou, Ludovic']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design']","['D81', 'D82']",Mechanism Design with Ambiguous Communication Devices,0,0,0,0,0,2014,09,01
82,5,2014-09-01,This paper studies inference in models that are identified by moment restrictions. We show how instability of the moments can be used constructively to improve the identification of structural parameters that are stable over time. A leading example is macroeconomic models that are immune to the well-known (Lucas (1976)) critique in the face of policy regime shifts. This insight is used to develop novel econometric methods that extend the widely used generalized method of moments (GMM). The proposed methods yield improved inference on the parameters of the new Keynesian Phillips curve.,"['Magnusson, Leandro M.', 'Mavroeidis, Sophocles']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Price Level; Inflation; Deflation']","['C32', nan, 'E31']",Identification Using Stability Restrictions,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"We present new identification results for nonparametric models of differentiated products markets, using only market level observables. We specify a nonparametric random utility discrete choice model of demand allowing rich preference heterogeneity, product/market unobservables, and endogenous prices. Our supply model posits nonparametric cost functions, allows latent cost shocks, and nests a range of standard oligopoly models. We consider identification of demand, identification of changes in aggregate consumer welfare, identification of marginal costs, identification of firms' marginal cost functions, and discrimination between alternative models of firm conduct. We explore two complementary approaches. The first demonstrates identification under the same nonparametric instrumental variables conditions required for identification of regression models. The second treats demand and supply in a system of nonparametric simultaneous equations, leading to constructive proofs exploiting exogenous variation in demand shifters and cost shifters. We also derive testable restrictions that provide the first general formalization of Bresnahan's (1982) intuition for empirically distinguishing between alternative models of oligopoly competition. From a practical perspective, our results clarify the types of instrumental variables needed with market level data, including tradeoffs between functional form and exclusion restrictions.","['Haile, Philip A.', 'Berry, Steven T.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['C25', 'C26', 'D43', 'L13']",Identification in Differentiated Products Markets Using Market Level Data,1,0,1,0,0,2014,09,01
82,5,2014-09-01,"Hunger during pre-harvest lean seasons is widespread in the agrarian areas of Asia and Sub-Saharan Africa. We randomly assign an $8.50 incentive to households in rural Bangladesh to temporarily out-migrate during the lean season. The incentive induces 22% of households to send a seasonal migrant, their consumption at the origin increases significantly, and treated households are 8-10 percentage points more likely to re-migrate 1 and 3 years after the incentive is removed. These facts can be explained qualitatively by a model in which migration is risky, mitigating risk requires individual-specific learning, and some migrants are sufficiently close to subsistence that failed migration is very costly. We document evidence consistent with this model using heterogeneity analysis and additional experimental variation, but calibrations with forward-looking households that can save up to migrate suggest that it is difficult for the model to quantitatively match the data. We conclude with extensions to the model that could provide a better quantitative accounting of the behavior.","['Bryan, Gharad', 'Chowdhury, Shyamal', 'Mobarak, Ahmed Mushfiq']","['Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Geographic Labor Mobility; Immigrant Workers', 'Microeconomic Analyses of Economic Development', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['I38', 'J61', 'O12', 'O13', 'O18', 'O33', 'R23']",Underinvestment in a Profitable Technology: The Case of Seasonal Migration in Bangladesh,0,0,0,1,0,2014,09,01
82,5,2014-09-01,"In this paper, we describe a series of laboratory experiments that implement specific examples of a general network structure. Specifically, actions are either strategic substitutes or strategic complements, and participants have either complete or incomplete information about the structure of a random network. Since economic environments typically have a considerable degree of complementarity or substitutability, this framework applies to a wide variety of settings. We examine behavior and equilibrium selection. The degree of equilibrium play is striking, in particular with incomplete information. Behavior closely resembles the theoretical equilibrium whenever this is unique; when there are multiple equilibria, general features of networks, such as connectivity, clustering, and the degree of the players, help to predict informed behavior in the lab. People appear to be strongly attracted to maximizing aggregate payoffs (social efficiency), but there are forces that moderate this attraction: (1) people seem content with (in the aggregate) capturing only the lion's share of the efficient profits in exchange for reduced exposure to loss, and (2) uncertainty about the network structure makes it considerably more difficult to coordinate on a demanding, but efficient, equilibrium that is typically implemented with complete information.","['Sutter, Matthias', 'Feri, Francesco', 'Charness, Gary', 'Melendez-Jimenez, Miguel A.']","['Design of Experiments: Laboratory, Individual', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Network Formation and Analysis: Theory']","['C91', 'D81', 'D83', 'D85']",Experimental Games on Networks: Underpinnings of Behavior and Equilibrium Selection,0,0,0,0,0,2014,09,01
82,5,2014-09-01,"This paper studies the optimal level of discretion in policymaking. We consider a fiscal policy model where the government has time-inconsistent preferences with a present bias toward public spending. The government chooses a fiscal rule to trade off its desire to commit to not overspend against its desire to have flexibility to react to privately observed shocks to the value of spending. We analyze the optimal fiscal rule when the shocks are persistent. Unlike under independent and identically distributed shocks, we show that the ex ante optimal rule is not sequentially optimal, as it provides dynamic incentives. The ex ante optimal rule exhibits history dependence, with high shocks leading to an erosion of future fiscal discipline compared to low shocks, which lead to the reinstatement of discipline. The implied policy distortions oscillate over time given a sequence of high shocks, and can force the government to accumulate maximal debt and become immiserated in the long run.","['Halac, Marina', 'Yared, Pierre']","['Asymmetric and Private Information; Mechanism Design', 'Fiscal Policy', 'National Government Expenditures and Related Policies: General', 'National Debt; Debt Management; Sovereign Debt']","['D82', 'E62', 'H50', 'H63']",Fiscal Rules and Discretion under Persistent Shocks,0,0,0,0,0,2014,09,01
82,4,2014-07-01,ECONLIT None Found,[nan],[nan],[nan],2013 Election of Fellows to the Econometric Society.,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"We study a principal-agent model in which the agent is boundedly rational in his ability to understand the principal's decision rule. The principal wishes to elicit an agent's true profile so as to determine whether or not to grant him a certain request. The principal designs a questionnaire and commits himself to accepting certain responses. In designing such a questionnaire, the principal takes into account the bounded rationality of the agent and wishes to reduce the success probability of a dishonest agent who is trying to game the system. It is shown that the principal can construct a sufficiently complex questionnaire that will allow him to respond optimally to agents who tell the truth and at the same time to almost eliminate the probability that a dishonest agent will succeed in cheating.","['Rubinstein, Ariel', 'Glazer, Jacob']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Complex Questionnaires,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"We develop a model of experimentation and learning in policymaking when control of power is temporary. We demonstrate how an early office holder who would otherwise not experiment is nonetheless induced to experiment when his hold on power is temporary. This preemptive policy experiment is profitable for the early office holder as it reveals information about the policy mapping to his successor, information that shapes future policy choices. Thus policy choices today can cast a long shadow over future choices purely through information transmission and absent any formal institutional constraints or real state variables. The model we develop utilizes a recent innovation that represents the policy mapping as the realized path of a Brownian motion. We provide a precise characterization of when preemptive experimentation emerges in equilibrium and the form it takes. We apply the model to several well known episodes of policymaking, reinterpreting the policy choices as preemptive experiments.","['Callander, Steven', 'Hummel, Patrick']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Positive Analysis of Policy Formulation and Implementation', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D72', 'D78', 'D83']",Preemptive Policy Experimentation,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"This paper studies the interaction between default and liquidity for corporate bonds that are traded in an over-the-counter secondary market with search frictions. Bargaining with dealers determines a bond's endogenous liquidity, which depends on both the firm fundamental and the time-to-maturity of the bond. Corporate default decisions interact with the endogenous secondary market liquidity via the rollover channel. A default-liquidity loop arises: Assuming a relative illiquid secondary bond market in default, earlier endogenous default worsens a bond's secondary market liquidity, which amplifies equity holders' rollover losses, which in turn leads to earlier endogenous default. Besides characterizing in closed form the full interdependence between liquidity and default for credit spreads, our calibrated model can jointly match empirically observed credit spreads and liquidity measures of bonds across different rating classes.","['He, Zhiguo', 'Milbradt, Konstantin']","['Asymmetric and Private Information; Mechanism Design', 'Financial Crises', 'General Financial Markets: General (includes Measurement and Data)', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['D82', 'G01', nan, nan, 'G32']",Endogenous Liquidity and Defaultable Bonds,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"We argue that the notion of Pareto dominance is not as compelling in the presence of uncertainty as it is under certainty. In particular, voluntary trade based on differences in tastes is commonly accepted as desirable, because tastes cannot be wrong. By contrast, voluntary trade based on incompatible beliefs may indicate that at least one agent entertains mistaken beliefs. We propose and characterize a weaker, ""No Betting,"" notion of Pareto domination which requires, on top of unanimity of preference, the existence of shared beliefs that can rationalize such preference for each agent.","['Gilboa, Itzhak', 'Schmeidler, David', 'Samuelson, Larry']","['Consumer Economics: Theory', 'Welfare Economics: General', 'Allocative Efficiency; Cost-Benefit Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D60', 'D61', 'D81', 'D83']",No-Betting-Pareto Dominance,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"We evaluate the effect of land use regulation on the value of land and on welfare. Our estimates are based on a decomposition of the effects of regulation into three components: an own-lot effect, which reflects the cost of regulatory constraints to the owner of a parcel; an external effect, which reflects the value of regulatory constraints on one's neighbors; a supply effect, which reflects the effect of regulated scarcity of developable land. Using this decomposition, we arrive at a novel strategy for estimating a plausibly causal effect of land use regulation on land value and welfare. This strategy exploits cross-border changes in development, prices, and regulation in regions near municipal borders. Our estimates suggest large negative effects of regulation on the value of land and welfare in these regions.","['van der Klaauw, Wilbert', 'Haughwout, Andrew', 'Turner, Matthew A.']","['Economics of Regulation', 'Renewable Resources and Conservation: Land', 'Renewable Resources and Conservation: Government Policy', 'Regional Government Analysis: Land Use and Other Regulations', 'Regional Development Planning and Policy']","['L51', 'Q24', 'Q28', 'R52', 'R58']",Land Use Regulation and Welfare,1,0,0,0,0,2014,07,01
82,4,2014-07-01,"This paper uses a data base covering the universe of French firms for the period 1990-2007 to provide a forensic account of the role of individual firms in generating aggregate fluctuations. We set up a simple multisector model of heterogeneous firms selling to multiple markets to motivate a theoretically founded decomposition of firms' annual sales growth rate into different components. We find that the firm-specific component contributes substantially to aggregate sales volatility, mattering about as much as the components capturing shocks that are common across firms within a sector or country. We then decompose the firm-specific component to provide evidence on two mechanisms that generate aggregate fluctuations from microeconomic shocks highlighted in the recent literature: (i) when the firm size distribution is fat-tailed, idiosyncratic shocks to large firms directly contribute to aggregate fluctuations, and (ii) aggregate fluctuations can arise from idiosyncratic shocks due to input-output linkages across the economy. Firm linkages are approximately three times as important as the direct effect of firm shocks in driving aggregate fluctuations.","['Mejean, Isabelle', 'Levchenko, Andrei A.', 'di Giovanni, Julian']","['Firm Behavior: Empirical Analysis', 'Business Fluctuations; Cycles', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Firm Performance: Size, Diversification, and Scope']","['D22', 'E32', 'L11', 'L16', 'L25']","Firms, Destinations, and Aggregate Fluctuations",1,0,0,0,0,2014,07,01
82,4,2014-07-01,"Using a high-stakes field experiment conducted with a financial brokerage, we implement a novel design to separately identify two channels of social influence in financial decisions, both widely studied theoretically. When someone purchases an asset, his peers may also want to purchase it, both because they learn from his choice (""social learning"") and because his possession of the asset directly affects others' utility of owning the same asset (""social utility""). We randomize whether one member of a peer pair who chose to purchase an asset has that choice implemented, thus randomizing his ability to possess the asset. Then, we randomize whether the second member of the pair: (i) receives no information about the first member, or (ii) is informed of the first member's desire to purchase the asset--the result of the randomization that determined possession. This allows us to estimate the effects of learning plus possession, and learning alone, relative to a (no information) control group. We find that both social learning and social utility channels have statistically and economically significant effects on investment decisions. Evidence from a follow-up survey reveals that social learning effects are greatest when the first (second) investor is financially sophisticated (financially unsophisticated); investors report updating their beliefs about asset quality after learning about their peer's revealed preference; and, they report motivations consistent with ""keeping up with the Joneses"" when learning about their peer's possession of the asset. These results can help shed light on the mechanisms underlying herding behavior in financial markets and peer effects in consumption and investment decisions.","['Yuchtman, Noam', 'Bursztyn, Leonardo', 'Ederer, Florian', 'Ferman, Bruno']","['Field Experiments', 'Household Saving; Personal Finance', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['C93', 'D14', 'D83', 'G11', 'O16']",Understanding Mechanisms Underlying Peer Effects: Evidence from a Field Experiment on Financial Decisions,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"This paper uses an unusual pay reform to test the responsiveness of investment in schooling to changes in redistribution schemes that increase the rate of return to education. We exploit an episode where different Israeli kibbutzim shifted from equal sharing to productivity-based wages in different years and find that students in kibbutzim that reformed earlier invested more in high school education and, in the long run, also in post-secondary schooling. We further show that the effect is mainly driven by students in kibbutzim that reformed to a larger degree. Our findings support the prediction that education is highly responsive to changes in the redistribution policy.","['Abramitzky, Ran', 'Lavy, Victor']","['State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Education', 'Returns to Education', 'Education: Government Policy', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['H75', 'I21', 'I26', 'I28', 'J24', 'J31']",How Responsive Is Investment in Schooling to Changes in Redistributive Policies and in Returns?,0,0,0,0,0,2014,07,01
82,4,2014-07-01,"A wide body of empirical evidence finds that approximately 25 percent of fiscal stimulus payments (e.g., tax rebates) are spent on nondurable household consumption in the quarter that they are received. To interpret this fact, we develop a structural economic model where households can hold two assets: a low-return liquid asset (e.g., cash, checking account) and a high-return illiquid asset that carries a transaction cost (e.g., housing, retirement account). The optimal life-cycle pattern of portfolio choice implies that many households in the model are ""wealthy hand-to-mouth"": they hold little or no liquid wealth despite owning sizable quantities of illiquid assets. Therefore, they display large propensities to consume out of additional transitory income, and small propensities to consume out of news about future income. We document the existence of such households in data from the Survey of Consumer Finances. A version of the model parameterized to the 2001 tax rebate episode yields consumption responses to fiscal stimulus payments that are in line with the evidence, and an order of magnitude larger than in the standard ""one-asset"" framework. The model's nonlinearities with respect to the rebate size and the prevailing aggregate economic conditions have implications for policy design.","['Violante, Giovanni L.', 'Kaplan, Greg']","['Household Saving; Personal Finance', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Macroeconomics: Consumption; Saving; Wealth', 'Business Fluctuations; Cycles', 'Fiscal Policy', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['D14', 'D15', 'E21', 'E32', 'E62', 'H24']",A Model of the Consumption Response to Fiscal Stimulus Payments,0,0,0,0,0,2014,07,01
82,3,2014-05-01,"Local to unity limit theory is used in applications to construct confidence intervals (CIs) for autoregressive roots through inversion of a unit root test (Stock (1991)). Such CIs are asymptotically valid when the true model has an autoregressive root that is local to unity (rho = 1 + c/n), but are shown here to be invalid at the limits of the domain of definition of the localizing coefficient c because of a failure in tightness and the escape of probability mass. Failure at the boundary implies that these CIs have zero asymptotic coverage probability in the stationary case and vicinities of unity that are wider than O(n[superscript -1/3]). The inversion methods of Hansen (1999) and Mikusheva (2007) are asymptotically valid in such cases. Implications of these results for predictive regression tests are explored. When the predictive regressor is stationary, the popular Campbell and Yogo (2006) CIs for the regression coefficient have zero coverage probability asymptotically, and their predictive test statistic Q erroneously indicates predictability with probability approaching unity when the null of no predictability holds. These results have obvious cautionary implications for the use of the procedures in empirical practice.","['Phillips, Peter C. B.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Forecasting Models; Simulation Methods']","['C22', 'C53']",On Confidence Intervals for Autoregressive Roots and Predictive Regression,0,0,0,0,0,2014,05,01
82,3,2014-05-01,"We model a boundedly rational agent who suffers from limited attention. The agent considers each feasible alternative with a given (unobservable) probability, the attention parameter, and then chooses the alternative that maximizes a preference relation within the set of considered alternatives. We show that this random choice rule is the only one for which the impact of removing an alternative on the choice probability of any other alternative is asymmetric and menu independent. Both the preference relation and the attention parameters are identified uniquely by stochastic choice data.","['Mariotti, Marco', 'Manzini, Paola']",['Microeconomic Behavior: Underlying Principles'],['D01'],Stochastic Choice and Consideration Sets,0,0,0,0,0,2014,05,01
82,3,2014-05-01,"We test the portability of level-0 assumptions in level-k theory in an experimental investigation of behavior in Coordination, Discoordination, and Hide and Seek games with common, non-neutral frames. Assuming that level-0 behavior depends only on the frame, we derive hypotheses that are independent of prior assumptions about salience. Those hypotheses are not confirmed. Our findings contrast with previous research which has fitted parameterized level-k models to Hide and Seek data. We show that, as a criterion of successful explanation, the existence of a plausible model that replicates the main patterns in these data has a high probability of false positives.","['Hargreaves Heap, Shaun', 'Sugden, Robert', 'Rojo Arjona, David']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D83']",How Portable Is Level-0 Behavior? A Test of Level-k Theory in Games with Non-neutral Frames,0,0,0,0,0,2014,05,01
82,3,2014-05-01,"This article asks when communication with certifiable information leads to complete information revelation. We consider Bayesian games augmented by a pre-play communication phase in which announcements are made publicly. We first characterize the augmented games in which there exists a fully revealing sequential equilibrium with extremal beliefs (i.e., any deviation is attributed to a single type of the deviator). Next, we define a class of games for which existence of a fully revealing equilibrium is equivalent to a richness property of the evidence structure. This characterization enables us to provide different sets of sufficient conditions for full information disclosure that encompass and extend all known results in the literature, and are easily applicable. We use these conditions to obtain new insights in games with strategic complementarities, voting with deliberation, and persuasion games with multidimensional types.","['Perez-Richet, Eduardo', 'Koessler, Frederic', 'Hagenbach, Jeanne']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D83']",Certifiable Pre-play Communication: Full Disclosure,0,0,0,0,0,2014,05,01
82,3,2014-05-01,"The paper studies how asset prices are determined in a decentralized market with asymmetric information about asset values. We consider an economy in which a large number of agents trade two assets in bilateral meetings. A fraction of the agents has private information about the asset values. We show that, over time, uninformed agents can elicit information from their trading partners by making small offers. This form of experimentation allows the uninformed agents to acquire information as long as there are potential gains from trade in the economy. As a consequence, the economy converges to a Pareto efficient allocation.","['Golosov, Mikhail', 'Tsyvinski, Aleh', 'Lorenzoni, Guido']","['Asymmetric and Private Information; Mechanism Design', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D82', nan, 'G14']",Decentralized Trading with Private Information,0,0,0,0,0,2014,05,01
82,3,2014-05-01,"We develop and estimate a comprehensive dynamic programming (DP) model for the joint decisions of residential location, employment location, occupational choices, and labor market outcomes. We use data on immigrants from the former Soviet Union (FSU). We provide an extensive empirical evaluation of policies that have been designed to affect the residential and employment location decisions of the migrant population. The results shed new, and important, light on several issues regarding this group of immigrants. We find large regional differences in wages for the white-collar workers, but only little differences for the blue-collar workers. A careful examination of a number of policy measures indicate that a direct subsidy, in the form of a lump-sum transfer, is most effective in achieving the government stated goal of inducing people to reside in the northern region of the Galilee and southern region of the Negev. Other policies, such as rental and wage subsidies, can also be quite effective, but these are more difficult to administer.","['Gotlibovski, Chemi', 'Lifshitz, Osnat', 'Buchinsky, Moshe']","['Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Geographic Labor Mobility; Immigrant Workers', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['J15', 'J24', 'J31', 'J61', 'R23']","Residential Location, Work Location, and Labor Market Outcomes of Immigrants in Israel",0,0,0,0,0,2014,05,01
82,3,2014-05-01,"In this paper, we compare how two different types of political regimes--direct versus representative democracy--redistribute income toward the relatively poor segments of society after the introduction of universal and equal suffrage. Swedish local governments are used as a testing ground since this setting offers a number of attractive features for a credible impact evaluation. Most importantly, we exploit the existence of a population threshold, which partly determined a local government's choice of democracy to implement a regression-discontinuity design. The results indicate that direct democracies spend 40-60 percent less on public welfare. Our interpretation is that direct democracy may be more prone to elite capture than representative democracy since the elite's potential to exercise de facto power is likely to be greater in direct democracy after democratization.","['Pettersson-Lidbom, Per', 'Hinnerich, Bjorn Tyrefors']","['Personal Income, Wealth, and Their Distributions', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Europe: 1913-', 'Economic History: Government, War, Law, International Relations, and Regulation: Europe: 1913-']","['D31', 'D72', 'H23', 'N34', 'N44']","Democracy, Redistribution, and Political Participation: Evidence from Sweden 1919-1938",0,0,0,0,0,2014,05,01
82,3,2014-05-01,"We formulate and solve a range of dynamic models of constrained credit/insurance that allow for moral hazard and limited commitment. We compare them to full insurance and exogenously incomplete financial regimes (autarky, saving only, borrowing and lending in a single asset). We develop computational methods based on mechanism design, linear programming, and maximum likelihood to estimate, compare, and statistically test these alternative dynamic models with financial/information constraints. Our methods can use both cross-sectional and panel data and allow for measurement error and unobserved heterogeneity. We estimate the models using data on Thai households running small businesses from two separate samples. We find that in the rural sample, the exogenously incomplete saving only and borrowing regimes provide the best fit using data on consumption, business assets, investment, and income. Family and other networks help consumption smoothing there, as in a moral hazard constrained regime. In contrast, in urban areas, we find mechanism design financial/information regimes that are decidedly less constrained, with the moral hazard model best fitting combined business and consumption data. We perform numerous robustness checks in both the Thai data and in Monte Carlo simulations and compare our maximum likelihood criterion with results from other metrics and data not used in the estimation. A prototypical counterfactual policy evaluation exercise using the estimation results is also featured.","['Karaivanov, Alexander', 'Townsend, Robert M.']","['Consumer Economics: Empirical Analysis', 'Asymmetric and Private Information; Mechanism Design', 'Financial Institutions and Services: General', 'Firm Performance: Size, Diversification, and Scope', 'Microeconomic Analyses of Economic Development', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance', 'Micro Analysis of Farm Firms, Farm Households, and Farm Input Markets']","['D12', 'D82', 'G20', 'L25', 'O12', 'O16', 'Q12']",Dynamic Financial Constraints: Distinguishing Mechanism Design from Exogenously Incomplete Regimes,1,0,0,0,0,2014,05,01
82,3,2014-05-01,"This paper estimates a structural dynamic equilibrium model of the Brazilian labor market in order to study trade-induced transitional dynamics. The model features a multi-sector economy with overlapping generations, heterogeneous workers, endogenous accumulation of sector-specific experience, and costly switching of sectors. The model's estimates yield median costs of mobility ranging from 1.4 to 2.7 times annual average wages, but a high dispersion of these costs across the population. In addition, sector-specific experience is imperfectly transferable across sectors, leading to additional barriers to mobility. Using the estimated model for counterfactual trade liberalization experiments, the main findings are: (1) there is a large labor market response following trade liberalization but the transition may take several years; (2) potential aggregate welfare gains are significantly reduced due to the delayed adjustment; (3) trade-induced welfare effects depend on initial sector of employment and on worker demographics such as age and education. The experiments also highlight the sensitivity of the transitional dynamics with respect to assumptions regarding the mobility of capital.","['Dix-Carneiro, Rafael']","['Trade Policy; International Trade Organizations', 'Trade and Labor Market Interactions', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Job, Occupational, and Intergenerational Mobility; Promotion', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'International Linkages to Development; Role of International Organizations']","['F13', 'F16', 'J24', 'J62', 'O15', 'O19']",Trade Liberalization and Labor Market Dynamics,0,0,0,0,0,2014,05,01
87,5,2019-09-01,ECONLIT None Found,"['Lipman, Barton L.', 'Muller, Ulrich K.', 'Imbens, Guido W.', 'Jones, Charles I.', 'Lizzeri, Alessandro', 'Donaldson, Dave']",['Introductory Material'],['Y20'],Editorial,0,0,0,0,0,2019,09,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],Invited Papers and Discussions.,0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 4.,0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 4.,0,0,0,0,0,2020,07,01
88,4,2020-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,07,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 3.,0,0,0,0,0,2020,05,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 3.,0,0,0,0,0,2020,05,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 3.,0,0,0,0,0,2020,05,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 3.,0,0,0,0,0,2020,05,01
88,3,2020-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,05,01
88,2,2020-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 2.,0,0,0,0,0,2020,03,01
88,2,2020-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 2.,0,0,0,0,0,2020,03,01
88,2,2020-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,03,01
82,2,2014-03-01,"We consider the identification of counterfactual distributions and treatment effects when the outcome variables and conditioning covariates are observed in separate data sets. Under the standard selection on observables assumption, the counterfactual distributions and treatment effect parameters are no longer point identified. However, applying the classical monotone rearrangement inequality, we derive sharp bounds on the counterfactual distributions and policy parameters of interest.","['Sherman, Robert', 'Shum, Matthew', 'Fan, Yanqin']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Identifying Treatment Effects under Data Combination,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"In parametric, nonlinear structural models, a classical sufficient condition for local identification, like Fisher (1966) and Rothenberg (1971), is that the vector of moment conditions is differentiable at the true parameter with full rank derivative matrix. We derive an analogous result for the nonparametric, nonlinear structural models, establishing conditions under which an infinite dimensional analog of the full rank condition is sufficient for local identification. Importantly, we show that additional conditions are often needed in nonlinear, nonparametric models to avoid nonlinearities overwhelming linear effects. We give restrictions on a neighborhood of the true value that are sufficient for local identification. We apply these results to obtain new, primitive identification conditions in several important models, including nonseparable quantile instrumental variable (IV) models and semiparametric consumption-based asset pricing models.","['Chernozhukov, Victor', 'Lee, Sokbae', 'Chen, Xiaohong', 'Newey, Whitney K.']",['Semiparametric and Nonparametric Methods: General'],['C14'],Local Identification of Nonparametric and Semiparametric Models,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"This paper proposes a class of optimal tests for the constancy of parameters in random coefficients models. Our testing procedure covers the class of Hamilton's models, where the parameters vary according to an unobservable Markov chain, but also applies to nonlinear models where the random coefficients need not be Markov. We show that the contiguous alternatives converge to the null hypothesis at a rate that is slower than the standard rate. Therefore, standard approaches do not apply. We use Bartlett-type identities for the construction of the test statistics. This has several desirable properties. First, it only requires estimating the model under the null hypothesis where the parameters are constant. Second, the proposed test is asymptotically optimal in the sense that it maximizes a weighted power function. We derive the asymptotic distribution of our test under the null and local alternatives. Asymptotically valid bootstrap critical values are also proposed.","['Hu, Liang', 'Ploberger, Werner', 'Carrasco, Marine']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Optimal Test for Markov Switching Parameters,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"Cities exist because of the productivity gains that arise from clustering production and workers, a process called agglomeration. How important is agglomeration for aggregate growth? This paper constructs a dynamic stochastic general equilibrium model of cities and uses it to estimate the effect of local agglomeration on aggregate growth. We combine aggregate time-series and city-level panel data to estimate the model's parameters via generalized method of moments. The estimates imply a statistically and economically significant impact of local agglomeration on the growth rate of per capita consumption, raising it by about 10%.","['Davis, Morris A.', 'Fisher, Jonas D. M.', 'Whited, Toni M.']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence', 'Regional Economic Activity: Growth, Development, Environmental Issues, and Changes', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics', 'Other Spatial Production and Pricing Analysis']","['J24', 'O33', 'O47', 'R11', 'R23', 'R32']",Macroeconomic Implications of Agglomeration,0,0,0,1,0,2014,03,01
82,2,2014-03-01,"This study documents two empirical facts using matched employer-employee data for Denmark and Portugal. First, workers who are hired last, are the first to leave the firm. Second, workers' wages rise with seniority, where seniority is defined as a worker's tenure relative to the tenure of his colleagues. Controlling for tenure, the probability of a worker leaving the firm decreases with seniority. The increase in expected seniority with tenure explains a large part of the negative duration dependence of the separation hazard. Conditional on ten years of tenure, the wage differential between the 10th and the 90th percentiles of the seniority distribution is 1.1-1.4 percentage points in Denmark and 2.3-3.4 in Portugal.","['van Vuuren, Aico', 'Buhai, I. Sebastian', 'Teulings, Coen N.', 'Portela, Miguel A.']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Unemployment: Models, Duration, Incidence, and Job Search', 'Personnel Management; Executives; Executive Compensation', 'Personnel Economics: Firm Employment Decisions; Promotions']","['J24', 'J31', 'J64', 'M12', 'M51']",Returns to Tenure or Seniority?,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"We consider a decision maker who faces dynamic decision situations that involve intertemporal trade-offs, as in consumption-savings problems, and who experiences taste shocks that are transient contingent on the state of the world. We axiomatize a recursive representation of choice over state contingent infinite horizon consumption problems, where uncertainty about consumption utilities depends on the observable state and the state follows a subjective Markov process. The parameters of the representation are the subjective process that governs the evolution of beliefs over consumption utilities and the discount factor; they are uniquely identified from behavior. We characterize a natural notion of greater preference for flexibility in terms of a dilation of beliefs. An important special case of our representation is a recursive version of the Anscombe-Aumann model with parameters that include a subjective Markov process over states and state-dependent utilities, all of which are uniquely identified.","['Sadowski, Philipp', 'Krishna, R. Vijay']","['Consumer Economics: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D11', 'D15']",Dynamic Preference for Flexibility,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"We study mechanism design in dynamic quasilinear environments where private information arrives over time and decisions are made over multiple periods. We make three contributions. First, we provide a necessary condition for incentive compatibility that takes the form of an envelope formula for the derivative of an agent's equilibrium expected payoff with respect to his current type. It combines the familiar marginal effect of types on payoffs with novel marginal effects of the current type on future ones that are captured by ""impulse response functions."" The formula yields an expression for dynamic virtual surplus that is instrumental to the design of optimal mechanisms and to the study of distortions under such mechanisms. Second, we characterize the transfers that satisfy the envelope formula and establish a sense in which they are pinned down by the allocation rule (""revenue equivalence""). Third, we characterize perfect Bayesian equilibrium-implementable allocation rules in Markov environments, which yields tractable sufficient conditions that facilitate novel applications. We illustrate the results by applying them to the design of optimal mechanisms for the sale of experience goods (""bandit auctions"").","['Toikka, Juuso', 'Segal, Ilya', 'Pavan, Alessandro']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Dynamic Mechanism Design: A Myersonian Approach,0,0,1,0,0,2014,03,01
82,2,2014-03-01,"We show in an environment of incomplete information that monotonicity and the Pareto property applied only when there is common knowledge of Pareto dominance imply (i) there must exist a common prior over the smallest common knowledge event, and (ii) aggregation must be ex ante and ex post utilitarian with respect to that common prior and individual von Neumann-Morgenstern utility indices.","['Chambers, Christopher P.', 'Hayashi, Takashi']","['Social Choice; Clubs; Committees; Associations', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D71', 'D83']",Preference Aggregation with Incomplete Information,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"We formulate a notion of stable outcomes in matching problems with one-sided asymmetric information. The key conceptual problem is to formulate a notion of a blocking pair that takes account of the inferences that the uninformed agent might make. We show that the set of stable outcomes is nonempty in an incomplete-information environments, and is a superset of the set of complete-information stable outcomes. We then provide sufficient conditions for incomplete-information stable matchings to be efficient. Lastly, we define a notion of price-sustainable allocations and show that the set of incomplete-information stable matchings is a subset of the set of such allocations.","['Samuelson, Larry', 'Postlewaite, Andrew', 'Mailath, George J.', 'Liu, Qingmin']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'D82', 'D83']",Stable Matching with Incomplete Information,0,0,0,0,0,2014,03,01
82,2,2014-03-01,"In many real-life house allocation problems, rents are bounded from above by price ceilings imposed by a government or a local administration. This is known as rent control. Because some price equilibria may be disqualified given such restrictions, this paper proposes an alternative equilibrium concept, called rationing price equilibrium, tailored to capture the specific features of housing markets with rent control. An allocation rule that always selects a rationing price equilibrium is defined, and it is demonstrated to be constrained efficient and (group) non-manipulable for ""almost all"" preference profiles. In its bounding cases, the rule reduces to a number of well-known mechanisms from the matching literature. In this sense, the housing market with rent control investigated in this paper integrates several of the predominant matching models into a more general framework.","['Svensson, Lars-Gunnar', 'Andersson, Tommy']","['Bargaining Theory; Matching Theory', 'Rationing; Licensing', 'Housing Supply and Markets', 'Production Analysis and Firm Location: Government Policy']","['C78', 'D45', 'R31', 'R38']",Non-manipulable House Allocation with Rent Control,0,0,1,0,0,2014,03,01
82,2,2014-03-01,"We identify the effects of monetary policy on credit risk-taking with an exhaustive credit register of loan applications and contracts. We separate the changes in the composition of the supply of credit from the concurrent changes in the volume of supply and quality, and the volume of demand. We employ a two-stage model that analyzes the granting of loan applications in the first stage and loan outcomes for the applications granted in the second stage, and that controls for both observed and unobserved, time-varying, firm and bank heterogeneity through time*firm and time*bank fixed effects. We find that a lower overnight interest rate induces lowly capitalized banks to grant more loan applications to ex ante risky firms and to commit larger loan volumes with fewer collateral requirements to these firms, yet with a higher ex post likelihood of default. A lower long-term interest rate and other relevant macroeconomic variables have no such effects.","['Peydro, Jose-Luis', 'Jimenez, Gabriel', 'Ongena, Steven', 'Saurina, Jesus']","['Interest Rates: Determination, Term Structure, and Effects', 'Financial Markets and the Macroeconomy', 'Monetary Policy', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financial Institutions and Services: Government Policy and Regulation', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['E43', 'E44', 'E52', 'G21', 'G28', 'G32']",Hazardous Times for Monetary Policy: What Do Twenty-Three Million Bank Loans Say about the Effects of Monetary Policy on Credit Risk-Taking?,0,0,0,0,0,2014,03,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Treasurer.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Secretary.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Econometrica Referees 2012-2013.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors 2012-2013.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"Say that one information structure is eventually Blackwell sufficient for another if, for every large enough n, an n-sample from the first is Blackwell sufficient (1951, 1954) for an n-sample from the second. This note shows that eventual Blackwell sufficiency lies strictly between (one-shot) Blackwell sufficiency and the ordering of information structures formulated by Moscarini and Smith (2002), and thus offers a new criterion for comparing experiments. A characterization of eventual Blackwell sufficiency in terms of the one-shot experiments remains an open question.","['Azrieli, Yaron']","['Operations Research; Statistical Decision Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C44', 'D83']",The Law of Large Demand for Information: Comment,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"This paper examines the efficient estimation of partially identified models defined by moment inequalities that are convex in the parameter of interest. In such a setting, the identified set is itself convex and hence fully characterized by its support function. We provide conditions under which, despite being an infinite dimensional parameter, the support function admits the square root of n-consistent regular estimators. A semiparametric efficiency bound is then derived for its estimation, and it is shown that any regular estimator attaining it must also minimize a wide class of asymptotic loss functions. In addition, we show that the ""plug-in"" estimator is efficient, and devise a consistent bootstrap procedure for estimating its limiting distribution. The setting we examine is related to an incomplete linear model studied in Beresteanu and Molinari (2008) and Bontemps, Magnac, and Maurin (2012), which further enables us to establish the semiparametric efficiency of their proposed estimators for that problem.","['Santos, Andres', 'Kaido, Hiroaki']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: General']","['C13', 'C14', 'C20']",Asymptotically Efficient Estimation of Models Defined by Convex Moment Inequalities,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"This paper introduces a general method to convert a model defined by moment conditions that involve both observed and unobserved variables into equivalent moment conditions that involve only observable variables. This task can be accomplished without introducing infinite-dimensional nuisance parameters using a least favorable entropy-maximizing distribution. We demonstrate, through examples and simulations, that this approach covers a wide class of latent variables models, including some game-theoretic models and models with limited dependent variables, interval-valued data, errors-in-variables, or combinations thereof. Both point- and set-identified models are transparently covered. In the latter case, the method also complements the recent literature on generic set-inference methods by providing the moment conditions needed to construct a generalized method of moments-type objective function for a wide class of models. Extensions of the method that cover conditional moments, independence restrictions, and some state-space models are also given.","['Schennach, Susanne M.']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Entropic Latent Variable Integration via Simulation,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"This paper considers nonparametric identification of a two-stage entry and bidding game we call the affiliated-signal (AS) model. This model assumes that potential bidders have private values, observe signals of their values prior to entry, and then choose whether to undertake a costly entry process, but imposes only minimal structure on the relationship between signals and values. It thereby nests a wide range of entry processes, including in particular the Samuelson (1985) and Levin and Smith (1994) models as special cases. Working within the AS model, we map variation in factors affecting entry behavior (potential competition or entry costs) into identified bounds on model fundamentals. These bounds are constructive, collapse to point identification when available entry variation is continuous, and can readily be refined to produce the pointwise sharp identified set. We then extend our core results to accommodate nonseparable unobserved auction-level heterogeneity and potential endogeneity of entry shifters, thereby establishing a formal identification framework for structural analysis of auctions with selective entry.","['Li, Tong', 'Gentry, Matthew']","['Econometrics of Games and Auctions', 'Auctions', 'Asymmetric and Private Information; Mechanism Design']","['C57', 'D44', 'D82']",Identification in Auctions with Selective Entry,0,0,1,0,0,2014,01,01
82,1,2014-01-01,"We define the class of two-player, zero-sum games with payoffs having mild discontinuities, which in applications typically stem from how ties are resolved. For such games, we establish sufficient conditions for existence of a value of the game, maximin and minimax strategies for the players, and a Nash equilibrium. If all discontinuities favor one player, then a value exists and that player has a maximin strategy. A property called payoff approachability implies existence of an equilibrium, and that the resulting value is invariant: games with the same payoffs at points of continuity have the same value and [epsilon]-equilibria. For voting games in which two candidates propose policies and a candidate wins the election if a weighted majority of voters prefer his proposed policy, we provide tie-breaking rules and assumptions about voters' preferences sufficient to imply payoff approachability. These assumptions are satisfied by generic preferences if the dimension of the space of policies exceeds the number of voters; or with no dimensional restriction, if the electorate is sufficiently large. Each Colonel Blotto game is a special case in which each candidate allocates a resource among several constituencies and a candidate gets votes from those allocated more than his opponent offers; in this case, for simple-majority rule we prove existence of an equilibrium with zero probability of ties.","['Barelli, Paulo', 'Wilson, Robert', 'Govindan, Srihari']","['Noncooperative Games', 'Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['C72', 'D71', 'D72']",Competition for a Majority,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"Does Islamic political control affect women's empowerment? Several countries have recently experienced Islamic parties coming to power through democratic elections. Due to strong support among religious conservatives, constituencies with Islamic rule often tend to exhibit poor women's rights. Whether this reflects a causal relationship or a spurious one has so far gone unexplored. I provide the first piece of evidence using a new and unique data set of Turkish municipalities. In 1994, an Islamic party won multiple municipal mayor seats across the country. Using a regression discontinuity (RD) design, I compare municipalities where this Islamic party barely won or lost elections. Despite negative raw correlations, the RD results reveal that, over a period of six years, Islamic rule increased female secular high school education. Corresponding effects for men are systematically smaller and less precise. In the longer run, the effect on female education remained persistent up to 17 years after, and also reduced adolescent marriages. An analysis of long-run political effects of Islamic rule shows increased female political participation and an overall decrease in Islamic political preferences. The results are consistent with an explanation that emphasizes the Islamic party's effectiveness in overcoming barriers to female entry for the poor and pious.","['Meyersson, Erik']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Analysis of Education', 'Economics of Gender; Non-labor Discrimination', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Cultural Economics: Religion']","['D72', 'I21', 'J16', 'O15', 'O17', 'Z12']",Islamic Rule and the Empowerment of the Poor and Pious,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"Short-run subsidies for health products are common in poor countries. How do they affect long-run adoption? A common fear among development practitioners is that one-off subsidies may negatively affect long-run adoption through reference-dependence: people might anchor around the subsidized price and be unwilling to pay more for the product later. But for experience goods, one-off subsidies could also boost long-run adoption through learning. This paper uses data from a two-stage randomized pricing experiment in Kenya to estimate the relative importance of these effects for a new, improved antimalarial bed net. Reduced form estimates show that a one-time subsidy has a positive impact on willingness to pay a year later inherit. To separately identify the learning and anchoring effects, we estimate a parsimonious experience-good model. Estimation results show a large, positive learning effect but no anchoring. We black then discuss the types of products and the contexts inherit for which these results may apply.","['Dupas, Pascaline']","['Field Experiments', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Health Behavior', 'Health: Government Policy; Regulation; Public Health', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Technological Change: Choices and Consequences; Diffusion Processes']","['C93', 'D83', 'I12', 'I18', 'O15', 'O33']",Short-Run Subsidies and Long-Run Adoption of New Health Products: Evidence from a Field Experiment,0,0,0,1,0,2014,01,01
82,1,2014-01-01,"Parents gauge school quality in part by the level of student achievement and a school's racial and socioeconomic mix. The importance of school characteristics in the housing market can be seen in the jump in house prices at school district boundaries where peer characteristics change. The question of whether schools with more attractive peers are really better in a value-added sense remains open, however. This paper uses a fuzzy regression-discontinuity design to evaluate the causal effects of peer characteristics. Our design exploits admissions cutoffs at Boston and New York City's heavily over-subscribed exam schools. Successful applicants near admissions cutoffs for the least selective of these schools move from schools with scores near the bottom of the state SAT score distribution to schools with scores near the median. Successful applicants near admissions cutoffs for the most selective of these schools move from above-average schools to schools with students whose scores fall in the extreme upper tail. Exam school students can also expect to study with fewer nonwhite classmates than unsuccessful applicants. Our estimates suggest that the marked changes in peer characteristics at exam school admissions cutoffs have little causal effect on test scores or college quality.","['Abdulkadiroglu, Atila', 'Angrist, Joshua', 'Pathak, Parag']","['State and Local Government: Health; Education; Welfare; Public Pensions', 'Analysis of Education', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['H75', 'I21', 'J15', 'R23']",The Elite Illusion: Achievement Effects at Boston and New York Exam Schools,0,0,0,0,0,2014,01,01
82,1,2014-01-01,"We model the decisions of a multiproduct firm that faces a fixed ""menu"" cost: once it is paid, the firm can adjust the price of all its products. We characterize analytically the steady state firm's decisions in terms of the structural parameters: the variability of the flexible prices, the curvature of the profit function, the size of the menu cost, and the number of products sold. We provide expressions for the steady state frequency of adjustment, the hazard rate of price adjustments, and the size distribution of price changes, all in terms of the structural parameters. We study analytically the impulse response of aggregate prices and output to a monetary shock. The size of the output response and its duration both increase with the number of products; they more than double as the number of products goes from 1 to 10, quickly converging to the response of Taylor's staggered price model.","['Alvarez, Fernando', 'Lippi, Francesco']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Price Level; Inflation; Deflation', 'Money Supply; Credit; Money Multipliers', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Firm Performance: Size, Diversification, and Scope']","['D24', 'D43', 'D25', 'E31', 'E51', 'L11', 'L25']",Price Setting with Menu Cost for Multiproduct Firms,1,0,1,0,0,2014,01,01
82,1,2014-01-01,"We analyze a dynamic stochastic general-equilibrium (DSGE) model with an externality--through climate change--from using fossil energy. Our central result is a simple formula for the marginal externality damage of emissions (or, equivalently, for the optimal carbon tax). This formula, which holds under quite plausible assumptions, reveals that the damage is proportional to current GDP, with the proportion depending only on three factors: (i) discounting, (ii) the expected damage elasticity (how many percent of the output flow is lost from an extra unit of carbon in the atmosphere), and (iii) the structure of carbon depreciation in the atmosphere. Thus, the stochastic values of future output, consumption, and the atmospheric CO2 concentration, as well as the paths of technology (whether endogenous or exogenous) and population, and so on, all disappear from the formula. We find that the optimal tax should be a bit higher than the median, or most well-known, estimates in the literature. We also formulate a parsimonious yet comprehensive and easily solved model allowing us to compute the optimal and market paths for the use of different sources of energy and the corresponding climate change. We find coal--rather than oil--to be the main threat to economic welfare, largely due to its abundance. We also find that the costs of inaction are particularly sensitive to the assumptions regarding the substitutability of different energy sources and technological progress.","['Hassler, John', 'Golosov, Mikhail', 'Tsyvinski, Aleh', 'Krusell, Per']","['Taxation and Subsidies: Efficiency; Optimal Taxation', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Mining, Extraction, and Refining: Hydrocarbon Fuels', 'Nonrenewable Resources and Conservation: Demand and Supply; Prices', 'Energy: Demand and Supply; Prices', 'Climate; Natural Disasters and Their Management; Global Warming', 'Environmental Economics: Government Policy']","['H21', 'H23', 'L71', 'Q31', 'Q41', 'Q54', 'Q58']",Optimal Taxes on Fossil Fuel in General Equilibrium,1,0,0,0,0,2014,01,01
82,1,2014-01-01,"We introduce and analyze expected uncertain utility (EUU) theory. A prior and an interval utility characterize an EUU decision maker. The decision maker transforms each uncertain prospect into an interval-valued prospect that assigns an interval of prizes to each state. She then ranks prospects according to their expected interval utilities. We define uncertainty aversion for EUU, use the EUU model to address the Ellsberg Paradox and other ambiguity evidence, and relate EUU theory to existing models.","['Pesendorfer, Wolfgang', 'Gul, Faruk']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Expected Uncertain Utility Theory,0,0,0,0,0,2014,01,01
89,4,2021-07-01,"Lemma 1 of Ray and Vohra (2019) is false as stated, but holds under alternative conditions which are consistent with the ideas of coalitional sovereignty that motivate the cited paper.","['Newton, Jonathan']",['Game Theory and Bargaining Theory: General'],['C70'],Corrigendum to 'Maximality in the Farsighted Stable Set',0,0,0,0,0,2021,07,01
89,4,2021-07-01,"This note points out that the proof of Theorem 1, the main theorem, in Ergin (2002) needs two corrections. We provide two counterexamples to Ergin's (2002) proof and show that the theorem holds as it is by providing an alternative proof.","['Narita, Yusuke']",['Allocative Efficiency; Cost-Benefit Analysis'],['D61'],Comment on 'Efficient Resource Allocation on the Basis of Priorities',0,0,0,0,0,2021,07,01
89,4,2021-07-01,ECONLIT None Found,"['Eeckhout, Jan', 'Kircher, Philipp', 'Lafuente, Cristina', 'Macci, Gabriele']","['Bargaining Theory; Matching Theory', 'Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Wage Level and Structure; Wage Differentials', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Firm Performance: Size, Diversification, and Scope']","['C78', 'D21', 'D24', 'G31', 'J31', 'L11', 'L25']",Corrigendum to Capital Investment in 'Assortative Matching with Large Firms',1,0,0,0,0,2021,07,01
89,4,2021-07-01,"In their analysis of strategic information transmission, Vincent Crawford and Joel Sobel (1982) showed the existence of partition equilibria (Theorem 1). Although the theorem itself is correct, the proof contains some incorrect statements. We present a counter-example and provide a correct version of the proof.","['Kandori, Michihiro', 'Kono, Haruki']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Corrigendum to Crawford and Sobel (1982) 'Strategic Information Transmission',0,0,0,0,0,2021,07,01
84,2,2016-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 84 Iss. 2.,0,0,0,0,0,2016,03,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 84 Iss. 1.,0,0,0,0,0,2016,01,01
81,6,2013-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 81 Iss. 6.,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"This paper proposes a test for common conditionally heteroskedastic (CH) features in asset returns. Following Engle and Kozicki (1993), the common CH features property is expressed in terms of testable overidentifying moment restrictions. However, as we show, these moment conditions have a degenerate Jacobian matrix at the true parameter value and therefore the standard asymptotic results of Hansen (1982) do not apply. We show in this context that Hansen's (1982) J-test statistic is asymptotically distributed as the minimum of the limit of a certain random process with a markedly nonstandard distribution. If two assets are considered, this asymptotic distribution is a fifty-fifty mixture of chi[superscript 2]H - 1 and chi[superscript 2]H, where H is the number of moment conditions, as opposed to a chi[superscript 2]H - 1. With more than two assets, this distribution lies between the chi[superscript 2]H - p and chi[superscript 2]H (p denotes the number of parameters). These results show that ignoring the lack of first-order identification of the moment condition model leads to oversized tests with a possibly increasing overrejection rate with the number of assets. A Monte Carlo study illustrates these findings.","['Dovonon, Prosper', 'Renault, Eric']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C58', nan]",Testing for Common Conditionally Heteroskedastic Factors,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"This paper examines three distinct hypothesis testing problems that arise in the context of identification of some nonparametric models with endogeneity. The first hypothesis testing problem we study concerns testing necessary conditions for identification in some nonparametric models with endogeneity involving mean independence restrictions. These conditions are typically referred to as completeness conditions. The second and third hypothesis testing problems we examine concern testing for identification directly in some nonparametric models with endogeneity involving quantile independence restrictions. For each of these hypothesis testing problems, we provide conditions under which any test will have power no greater than size against any alternative. In this sense, we conclude that no nontrivial tests for these hypothesis testing problems exist.","['Shaikh, Azeem M.', 'Santos, Andres', 'Canay, Ivan A.']","['Hypothesis Testing: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C12', 'C26']",On the Testability of Identification in Some Nonparametric Models with Endogeneity,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"A choice function is backwards-induction rationalizable if there exists a finite perfect-information extensive-form game such that for each subset of alternatives, the backwards-induction outcome of the restriction of the game to that subset of alternatives coincides with the choice from that subset. We prove that every choice function is backwards-induction rationalizable.","['Sprumont, Yves', 'Bossert, Walter']","['Game Theory and Bargaining Theory: General', 'Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory']","['C70', 'D01', 'D11']",Every Choice Function Is Backwards-Induction Rationalizable,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"We develop a network-flow approach for characterizing interim-allocation rules that can be implemented by ex post allocations. Our method can be used to characterize feasible interim allocations in general multi-unit auctions where agents face capacity constraints, both ceilings and floors. Applications include a variety of settings of practical interest, ranging from individual and group-specific capacity constraints, set-aside sale, partnership dissolution, and government license reallocation.","['Mierendorff, Konrad', 'Kim, Jinwoo', 'Che, Yeon-Koo']",['Auctions'],['D44'],Generalized Reduced-Form Auctions: A Network-Flow Approach,0,0,1,0,0,2013,11,01
81,6,2013-11-01,"This paper constructs an efficient, budget-balanced, Bayesian incentive-compatible mechanism for a general dynamic environment with quasilinear payoffs in which agents observe private information and decisions are made over countably many periods. First, under the assumption of ""private values"" (other agents' private information does not directly affect an agent's payoffs), we construct an efficient, ex post incentive-compatible mechanism, which is not budget-balanced. Second, under the assumption of ""independent types"" (the distribution of each agent's private information is not directly affected by other agents' private information), we show how the budget can be balanced without compromising agents' incentives. Finally, we show that the mechanism can be made self-enforcing when agents are sufficiently patient and the induced stochastic process over types is an ergodic finite Markov chain.","['Athey, Susan', 'Segal, Ilya']",['Asymmetric and Private Information; Mechanism Design'],['D82'],An Efficient Dynamic Mechanism,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"We propose a model of firm reputation in which a firm can invest or disinvest in product quality and the firm's reputation is defined as the market's belief about this quality. We analyze the relationship between a firm's reputation and its investment incentives, and derive implications for reputational dynamics. Reputational incentives depend on the specification of market learning. When consumers learn about quality through perfect good news signals, incentives decrease in reputation and there is a unique work-shirk equilibrium with ergodic dynamics. When learning is through perfect bad news signals, incentives increase in reputation and there is a continuum of shirk-work equilibria with path-dependent dynamics. For a class of imperfect Poisson learning processes and low investment costs, we show that there exists a work-shirk equilibrium with ergodic dynamics. For a subclass of these learning processes, any equilibrium must feature working at all low and intermediate levels of reputation and shirking at the top.","['Meyer-ter-Vehn, Moritz', 'Board, Simon']","['Firm Behavior: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['D21', 'D83', 'D25', 'G31']",Reputation for Quality,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"The aim of this paper is to develop revealed preference tests for Cournot equilibrium. The tests are akin to the widely used revealed preference tests for consumption, but have to take into account the presence of strategic interaction in a game-theoretic setting. The tests take the form of linear programs, the solutions to which also allow us to recover cost information on the firms. To check that these nonparametric tests are sufficiently discriminating to reject real data, we apply them to the market for crude oil.","['Carvajal, Andres', 'Quah, John K.-H.', 'Fenske, James', 'Deb, Rahul']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Monopoly; Monopolization Strategies', 'Oligopoly and Other Imperfect Markets', 'Mining, Extraction, and Refining: Hydrocarbon Fuels', 'Energy: Demand and Supply; Prices']","['D43', 'L12', 'L13', 'L71', 'Q41']",Revealed Preference Tests of the Cournot Model,1,0,1,0,0,2013,11,01
81,6,2013-11-01,"This paper proposes a new approach to equilibrium selection in repeated games with transfers, supposing that in each period the players bargain over how to play. Although the bargaining phase is cheap talk (following a generalized alternating-offer protocol), sharp predictions arise from three axioms. Two axioms allow the players to meaningfully discuss whether to deviate from their plan; the third embodies a ""theory of disagreement""--that play under disagreement should not vary with the manner in which bargaining broke down. Equilibria that satisfy these axioms exist for all discount factors and are simple to construct; all equilibria generate the same welfare. Optimal play under agreement generally requires suboptimal play under disagreement. Whether patient players attain efficiency depends on both the stage game and the bargaining protocol. The theory extends naturally to games with imperfect public monitoring and heterogeneous discount factors, and yields new insights into classic relational contracting questions.","['Watson, Joel', 'Miller, David A.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory']","['C73', 'C78']",A Theory of Disagreement in Repeated Games with Bargaining,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"What preferences will prevail in a society of rational individuals when preference evolution is driven by the resulting payoffs? We show that when individuals' preferences are their private information, a convex combination of selfishness and morality stands out as evolutionarily stable. We call individuals with such preferences homo moralis. At one end of the spectrum is homo oeconomicus, who acts so as to maximize his or her own payoff. At the opposite end is homo kantiensis, who does what would be ""the right thing to do,"" in terms of payoffs, if all others would do likewise. We show that the stable degree of morality--the weight placed on the moral goal--is determined by the degree of assortativity in the process whereby individuals are matched to interact.","['Weibull, Jorgen W.', 'Alger, Ingela']","['Bargaining Theory; Matching Theory', 'Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D01', 'D11', 'D82']",Homo Moralis--Preference Evolution under Incomplete Information and Assortative Matching,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"Counterfactual distributions are important ingredients for policy analysis and decomposition analysis in empirical economics. In this article, we develop modeling and inference tools for counterfactual distributions based on regression methods. The counterfactual scenarios that we consider consist of ceteris paribus changes in either the distribution of covariates related to the outcome of interest or the conditional distribution of the outcome given covariates. For either of these scenarios, we derive joint functional central limit theorems and bootstrap validity results for regression-based estimators of the status quo and counterfactual outcome distributions. These results allow us to construct simultaneous confidence sets for function-valued effects of the counterfactual changes, including the effects on the entire distribution and quantile functions of the outcome as well as on related functionals. These confidence sets can be used to test functional hypotheses such as no-effect, positive effect, or stochastic dominance. Our theory applies to general counterfactual changes and covers the main regression methods including classical, quantile, duration, and distribution regressions. We illustrate the results with an empirical application to wage decompositions using data for the United States. As a part of developing the main results, we introduce distribution regression as a comprehensive and flexible tool for modeling and estimating the entire conditional distribution. We show that distribution regression encompasses the Cox duration regression and represents a useful alternative to quantile regression. We establish functional central limit theorems and bootstrap validity results for the empirical distribution regression process and various related functionals.","['Chernozhukov, Victor', 'Fernandez-Val, Ivan', 'Melly, Blaise']","['Single Equation Models; Single Variables: General', 'Wage Level and Structure; Wage Differentials', 'Wages, Compensation, and Labor Costs: Public Policy']","['C20', 'J31', 'J38']",Inference on Counterfactual Distributions,0,0,0,0,0,2013,11,01
81,6,2013-11-01,"We develop a property-rights model of the firm in which production entails a continuum of uniquely sequenced stages. In each stage, a final-good producer contracts with a distinct supplier for the procurement of a customized stage-specific component. Our model yields a sharp characterization for the optimal allocation of ownership rights along the value chain. We show that the incentive to integrate suppliers varies systematically with the relative position (upstream versus downstream) at which the supplier enters the production line. Furthermore, the nature of the relationship between integration and ""downstreamness"" depends crucially on the elasticity of demand faced by the final-good producer. Our model readily accommodates various sources of asymmetry across final-good producers and across suppliers within a production line, and we show how it can be taken to the data with international trade statistics. Combining data from the U.S. Census Bureau's Related Party Trade database and estimates of U.S. import demand elasticities from Broda and Weinstein (2006), we find empirical evidence broadly supportive of our key predictions. In the process, we develop two novel measures of the average position of an industry in the value chain, which we construct using U.S. Input-Output Tables.","['Chor, Davin', 'Antras, Pol']","['Firm Behavior: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'General Equilibrium and Disequilibrium: Input-Output Tables and Analysis', 'Multinational Firms; International Business', 'Transactional Relationships; Contracts and Reputation; Networks', 'Organization of Production']","['D21', 'D24', 'D57', 'F23', 'L14', 'L23']",Organizing the Global Value Chain,1,0,0,0,0,2013,11,01
81,5,2013-09-01,"This comment corrects two results in the 2006 Econometrica paper by Amador, Werning, and Angeletos (AWA), that features a model in which individuals face a trade-off between flexibility and commitment. First, in contrast to Proposition 1 in AWA, we show that money-burning can be part of the ex ante optimal contract when there are two states. Second, in contrast to Proposition 2 in AWA, we show that money-burning can be imposed at the top (in the highest liquidity shock state), even when there is a continuum of states. We provide corrected versions of the above results.","['Ambrus, Attila', 'Egorov, Georgy']","['Asymmetric and Private Information; Mechanism Design', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D82', 'D15']",Commitment vs. Flexibility: Comment,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"We consider the invertibility (injectivity) of a nonparametric nonseparable demand system. Invertibility of demand is important in several contexts, including identification of demand, estimation of demand, testing of revealed preference, and economic theory exploiting existence of an inverse demand function or (in an exchange economy) uniqueness of Walrasian equilibrium prices. We introduce the notion of ""connected substitutes"" and show that this structure is sufficient for invertibility. The connected substitutes conditions require weak substitution between all goods and sufficient strict substitution to necessitate treating them in a single demand system. The connected substitutes conditions have transparent economic interpretation, are easily checked, and are satisfied in many standard models. They need only hold under some transformation of demand and can accommodate many models in which goods are complements. They allow one to show invertibility without strict gross substitutes, functional form restrictions, smoothness assumptions, or strong domain restrictions. When the restriction to weak substitutes is maintained, our sufficient conditions are also ""nearly necessary"" for even local invertibility.","['Berry, Steven', 'Gandhi, Amit', 'Haile, Philip']","['Consumer Economics: Theory', 'Exchange and Production Economies']","['D11', 'D51']",Connected Substitutes and Invertibility of Demand,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"This paper presents a theoretical and empirical analysis of the role of life expectancy for optimal schooling and lifetime labor supply. The results of a simple prototype Ben-Porath model with age-specific survival rates show that an increase in lifetime labor supply is not a necessary, or a sufficient, condition for greater life expectancy to increase optimal schooling. The observed increase in survival rates during working ages that follows from the ""rectangularization"" of the survival function is crucial for schooling and labor supply. The empirical results suggest that the relative benefits of schooling have been increasing across cohorts of U.S. men born between 1840 and 1930. A simple quantitative analysis shows that a realistic shift in the survival function can lead to an increase in schooling and a reduction in lifetime labor hours.","['Cervellati, Matteo', 'Sunde, Uwe']","['Health Behavior', 'Analysis of Education', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S.; Canada: Pre-1913', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S.; Canada: 1913-']","['I12', 'I21', 'J22', 'J24', 'N31', 'N32']","Life Expectancy, Schooling, and Lifetime Labor Supply: Theory and Evidence Revisited",0,0,0,0,0,2013,09,01
81,5,2013-09-01,"Using centuries of Nile flood data, I document that during deviant Nile floods, Egypt's highest-ranking religious authority was less likely to be replaced and relative allocations to religious structures increased. These findings are consistent with historical evidence that Nile shocks increased this authority's political influence by raising the probability he could coordinate a revolt. I find that the available data provide support for this interpretation and weigh against some of the most plausible alternatives. For example, I show that while Nile shocks increased historical references to social unrest, deviant floods did not increase a proxy for popular religiosity. Together, the results suggest an increase in the political power of religious leaders during periods of economic downturn.","['Chaney, Eric']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Asia including Middle East', 'Economic History: Government, War, Law, International Relations, and Regulation: Asia including Middle East', 'Economic History: Agriculture, Natural Resources, Environment, and Extractive Industries: Asia including Middle East', 'Climate; Natural Disasters and Their Management; Global Warming', 'Cultural Economics: Religion']","['D72', 'N35', 'N45', 'N55', 'Q54', 'Z12']","Revolt on the Nile: Economic Shocks, Religion, and Political Power",0,0,0,0,0,2013,09,01
81,5,2013-09-01,"This paper proposes a symmetry-breaking model of trade with a (large but) finite number of (ex ante) identical countries and a continuum of tradeable goods, which differ in their dependence on local differentiated producer services. Productivity differences across countries arise endogenously through free entry to the local service sector in each country. In any stable equilibrium, the countries sort themselves into specializing in different sets of tradeable goods, and a strict ranking of countries in per capita income, TFP, and the capital-labor ratio emerges endogenously. Furthermore, the distribution of country shares, the Lorenz curve, is unique and analytically solvable in the limit, as the number of countries grows unbounded. Using this limit as an approximation allows us to study what determines the shape of distribution, to perform various comparative statics, and to evaluate the welfare effects of trade.","['Matsuyama, Kiminori']","['Models of Trade with Imperfect Competition and Scale Economies; Fragmentation', 'Economic Impacts of Globalization: Economic Development']","['F12', 'F63']",Endogenous Ranking and Equilibrium Lorenz Curve across (Ex Ante) Identical Countries,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"We present two examples of discounted stochastic games, each with a continuum of states, finitely many players, and actions, that possess no stationary equilibria. The first example has deterministic transitions--an assumption undertaken in most of the early applications of dynamics games in economics--and perfect information, and does not possess even stationary approximate equilibria or Markovian equilibria. The second example satisfies, in addition to stronger regularity assumptions, that all transitions are absolutely continuous with respect to a fixed measure--an assumption that has been widely used in more recent economic applications. This assumption has been undertaken in several positive results on the existence of stationary equilibria in special cases, and in particular, guarantees the existence of stationary approximate equilibria.","['Levy, Yehuda']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Discounted Stochastic Games with No Stationary Nash Equilibrium: Two Examples,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"This paper studies a dynamic agency problem which includes limited liability, moral hazard, and adverse selection. The paper develops a robust approach to dynamic contracting based on calibrating the incentive properties of simple benchmark contracts that are attractive but infeasible, due to limited liability constraints. The resulting dynamic contracts are detail-free and satisfy robust performance bounds independently of the underlying process for returns, which need not be i.i.d. or even ergodic.","['Chassang, Sylvain']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Calibrated Incentive Contracts,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"We study repeated Bayesian games with communication and observable actions in which the players' privately known payoffs evolve according to an irreducible Markov chain whose transitions are independent across players. Our main result implies that, generically, any Pareto-efficient payoff vector above a stationary minmax value can be approximated arbitrarily closely in a perfect Bayesian equilibrium as the discount factor goes to 1. As an intermediate step, we construct an approximately efficient dynamic mechanism for long finite horizons without assuming transferable utility.","['Toikka, Juuso', 'Escobar, Juan F.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'D82']",Efficiency in Games with Markovian Private Information,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"This paper derives optimal inheritance tax formulas that capture the key equity-efficiency trade-off, are expressed in terms of estimable sufficient statistics, and are robust to the underlying structure of preferences. We consider dynamic stochastic models with general and heterogeneous bequest tastes and labor productivities. We limit ourselves to simple but realistic linear or two-bracket tax structures to obtain tractable formulas. We show that long-run optimal inheritance tax rates can always be expressed in terms of aggregate earnings and bequest elasticities with respect to tax rates, distributional parameters, and social preferences for redistribution. Those results carry over with tractable modifications to (a) the case with social discounting (instead of steady-state welfare maximization), (b) the case with partly accidental bequests, and (c) the standard Barro-Becker dynastic model. The optimal tax rate is positive and quantitatively large if the elasticity of bequests to the tax rate is low, bequest concentration is high, and society cares mostly about those receiving little inheritance. We propose a calibration using micro-data for France and the United States. We find that, for realistic parameters, the optimal inheritance tax rate might be as large as 50%-60%--or even higher for top bequests, in line with historical experience.","['Saez, Emmanuel', 'Piketty, Thomas']","['Personal Income, Wealth, and Their Distributions', 'Taxation and Subsidies: Efficiency; Optimal Taxation', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies']","['D31', 'H21', 'H23']",A Theory of Optimal Inheritance Taxation,0,0,0,0,0,2013,09,01
81,5,2013-09-01,"It is well known that, in misspecified parametric models, the maximum likelihood estimator (MLE) is consistent for the pseudo-true value and has an asymptotically normal sampling distribution with ""sandwich"" covariance matrix. Also, posteriors are asymptotically centered at the MLE, normal, and of asymptotic variance that is, in general, different than the sandwich matrix. It is shown that due to this discrepancy, Bayesian inference about the pseudo-true parameter value is, in general, of lower asymptotic frequentist risk when the original posterior is substituted by an artificial normal posterior centered at the MLE with sandwich covariance matrix. An algorithm is suggested that allows the implementation of this artificial posterior also in models with high dimensional nuisance parameters which cannot reasonably be estimated by maximizing the likelihood.","['Mueller, Ulrich K.']","['Bayesian Analysis: General', 'Single Equation Models; Single Variables: General', 'General Aggregative Models: Neoclassical']","['C11', 'C20', 'E13']","Risk of Bayesian Inference in Misspecified Models, and the Sandwich Covariance Matrix",0,0,0,0,0,2013,09,01
81,5,2013-09-01,"This article predicts how radio station formats would change if, as was recently proposed, music stations were made to pay fees for musical performance rights. It does so by estimating and solving, using parametric approximations to firms' value functions, a dynamic model that captures important features of the industry such as vertical and horizontal product differentiation, demographic variation in programming tastes, and multi-station ownership. The estimated model predicts that high fees would cause the number of music stations to fall significantly and quite quickly. For example, a fee equal to 10% of revenues would cause a 4.6% drop in the number of music stations within 2 1/2 years, and a 9.4% drop in the long run. The size of the change is limited, however, by the fact that many listeners, particularly in demographics that are valued by advertisers, have strong preferences for music programming.","['Sweeting, Andrew']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets', 'Entertainment; Media', 'Intellectual Property and Intellectual Capital']","['D43', 'L13', 'L82', 'O34']",Dynamic Product Positioning in Differentiated Product Markets: The Effect of Fees for Musical Performance Rights on the Commercial Radio Industry,1,0,1,1,0,2013,09,01
81,5,2013-09-01,"Across a wide set of nongroup insurance markets, applicants are rejected based on observable, often high-risk, characteristics. This paper argues that private information, held by the potential applicant pool, explains rejections. I formulate this argument by developing and testing a model in which agents may have private information about their risk. I first derive a new no-trade result that theoretically explains how private information could cause rejections. I then develop a new empirical methodology to test whether this no-trade condition can explain rejections. The methodology uses subjective probability elicitations as noisy measures of agents' beliefs. I apply this approach to three nongroup markets: long-term care, disability, and life insurance. Consistent with the predictions of the theory, in all three settings I find significant amounts of private information held by those who would be rejected; I find generally more private information for those who would be rejected relative to those who can purchase insurance, and I show it is enough private information to explain a complete absence of trade for those who would be rejected. The results suggest that private information prevents the existence of large segments of these three major insurance markets.","['Hendren, Nathaniel']","['Asymmetric and Private Information; Mechanism Design', 'Insurance; Insurance Companies; Actuarial Studies', 'Economics of the Elderly; Economics of the Handicapped; Non-labor Market Discrimination']","['D82', 'G22', 'J14']",Private Information and Insurance Rejections,0,0,0,0,0,2013,09,01
81,4,2013-07-01,ECONLIT None Found,"['Rochet, Jean-Charles']",[nan],[nan],THE ECONOMETRIC SOCIETY 2012 ANNUAL REPORT OF THE PRESIDENT.,0,0,0,0,0,2013,07,01
81,4,2013-07-01,ECONLIT None Found,[nan],[nan],[nan],2012 ELECTION OF FELLOWS TO THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"We develop an asymptotic theory for the pre-averaging estimator when asset price jumps are weakly identified, here modeled as local to zero. The theory unifies the conventional asymptotic theory for continuous and discontinuous semimartingales as two polar cases with a continuum of local asymptotics, and explains the breakdown of the conventional procedures under weak identification. We propose simple bias-corrected estimators for jump power variations, and construct robust confidence sets with valid asymptotic size in a uniform sense. The method is also robust to certain forms of microstructure noise.","['Li, Jia']","['Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C58', nan]",Robust Estimation and Inference for Jumps in Noisy High Frequency Data: A Local-to-Continuity Theory for the Pre-averaging Method,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"We study the role of incomplete information and outside options in determining bargaining postures and surplus division in repeated bargaining between a long-run player and a sequence of short-run players. The outside option is not only a disagreement point, but reveals information privately held by the long-run player. In equilibrium, the uninformed short-run players' offers do not always respond to changes in reputation and the informed long-run player's payoffs are discontinuous. The long-run player invokes inefficient random outside options repeatedly to build reputation to a level where the subsequent short-run players succumb to his extraction of a larger payoff, but he also runs the risk of losing reputation and relinquishing bargaining power. We investigate equilibrium properties when the discount factor goes to 1 and when the informativeness of outside options diffuses. In both cases, bargaining outcomes become more inefficient and the limit reputation-building probabilities are interior.","['Lee, Jihong', 'Liu, Qingmin']","['Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'D83']",Gambling Reputation: Repeated Bargaining with Outside Options,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"We consider a general representation of the delegation problem, with and without money burning, and provide sufficient and necessary conditions under which an interval allocation is optimal. We also apply our results to the theory of trade agreements among privately informed governments. For both perfect and monopolistic competition settings, we provide conditions under which tariff caps are optimal.","['Bagwell, Kyle', 'Amador, Manuel']","['Asymmetric and Private Information; Mechanism Design', 'Trade Policy; International Trade Organizations']","['D82', 'F13']",The Theory of Optimal Delegation with an Application to Tariff Caps,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"We propose a bubble game that involves sequential trading of an asset commonly known to be valueless. Because no trader is ever sure to be last in the market sequence, the game allows for a bubble at the Nash equilibrium when there is no cap on the maximum price. We run experiments both with and without a price cap. Structural estimation of behavioral game theory models suggests that quantal responses and analogy-based expectations are important drivers of speculation.","['Moinas, Sophie', 'Pouget, Sebastien']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C73', 'G11', nan]",The Bubble Game: An Experimental Study of Speculation,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"We model a dynamic, competitive market, where in every period, risk-neutral traders trade a one-period bond against an infinitely lived asset, with limited short-selling of the long-term asset. Traders lack structural knowledge and use different ""incomplete theories,"" all of which give statistically correct beliefs about next period's market price of the long-term asset. The more theories there are in the market, the higher is the equilibrium price of the long-term asset. Investors with more complete theories do not necessarily earn higher returns than those with less complete ones, who can earn above the risk-free rate. We provide two necessary conditions for a trader to earn above the risk-free rate.","['Eyster, Erik', 'Piccione, Michele']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],An Approach to Asset Pricing under Incomplete and Diverse Perceptions,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"Information costs, which comprise costs of gathering and processing information about stock values and costs of deciding how to respond to this information, induce a consumer to remain inattentive to the stock market for finite intervals of time. Whether, and how much, a consumer transfers assets between accounts depends on the costs of undertaking such transactions. In general, optimal behavior by a consumer facing both information costs and transactions costs is state-dependent, with the timing of observations and the timing and size of transactions depending on the state. Surprisingly, if the fixed component of the transactions cost is sufficiently small, then eventually, with probability 1, a time-dependent rule emerges: the interval between observations is constant and on each observation date, the consumer converts enough assets to liquid assets to finance consumption until the next observation. If the fixed component of transactions costs is large, the optimal rule remains state-dependent indefinitely.","['Abel, Andrew B.', 'Eberly, Janice C.', 'Panageas, Stavros']","['Household Saving; Personal Finance', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions']","['D14', 'D83', 'G11']",Optimal Inattention to the Stock Market with Information Costs and Transactions Costs,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"In this paper, we use indirect inference to estimate a joint model of earnings, employment, job changes, wage rates, and work hours over a career. We use the model to address a number of important questions in labor economics, including the source of the experience profile of wages, the response of job changes to outside wage offers, and the effects of seniority on job changes. We also study the dynamic response of wage rates, hours, and earnings to various shocks, and measure the relative contributions of the shocks to the variance of earnings in a given year and over a lifetime. We find that human capital accounts for most of the growth of earnings over a career, although job seniority and job mobility also play significant roles. Unemployment shocks have a large impact on earnings in the short run, as well as a substantial long-term effect that operates through the wage rate. Shocks associated with job changes and unemployment make a large contribution to the variance of career earnings and operate mostly through the job-specific error components of wages and hours.","['Vidangos, Ivan', 'Altonji, Joseph G.', 'Smith, Anthony A., Jr.']","['Model Construction and Estimation', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Job, Occupational, and Intergenerational Mobility; Promotion', 'Unemployment: Models, Duration, Incidence, and Job Search']","['C51', 'J22', 'J24', 'J31', 'J62', 'J64']",Modeling Earnings Dynamics,0,0,0,0,0,2013,07,01
81,4,2013-07-01,"The impact of R&D on growth through spillovers has been a major topic of economic research over the last thirty years. A central problem in the literature is that firm performance is affected by two countervailing ""spillovers"": a positive effect from technology (knowledge) spillovers and a negative business stealing effects from product market rivals. We develop a general framework incorporating these two types of spillovers and implement this model using measures of a firm's position in technology space and product market space. Using panel data on U.S. firms, we show that technology spillovers quantitatively dominate, so that the gross social returns to R&D are at least twice as high as the private returns. We identify the causal effect of R&D spillovers by using changes in federal and state tax incentives for R&D. We also find that smaller firms generate lower social returns to R&D because they operate more in technological niches. Finally, we detail the desirable properties of an ideal spillover measure and how existing approaches, including our new Mahalanobis measure, compare to these criteria.","['Van Reenen, John', 'Schankerman, Mark', 'Bloom, Nicholas']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Firm Performance: Size, Diversification, and Scope', 'Management of Technological Innovation and R&D', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Intellectual Property and Intellectual Capital']","['D24', 'L25', 'O32', 'O33', 'O34']",Identifying Technology Spillovers and Product Market Rivalry,1,0,0,1,0,2013,07,01
81,4,2013-07-01,"We study European banks' demand for short-term funds (liquidity) during the summer 2007 subprime market crisis. We use bidding data from the European Central Bank's auctions for one-week loans, their main channel of monetary policy implementation. Our analysis provides a high-frequency, disaggregated perspective on the 2007 crisis, which was previously studied through comparisons of collateralized and uncollateralized interbank money market rates which do not capture the heterogeneous impact of the crisis on individual banks. Through a model of bidding, we show that banks' bids reflect their cost of obtaining short-term funds elsewhere (e.g., in the interbank market) as well as a strategic response to other bidders. The strategic response is empirically important: while a naive interpretation of the raw bidding data may suggest that virtually all banks suffered an increase in the cost of short-term funding, we find that, for about one third of the banks, the change in bidding behavior was simply a strategic response. We also find considerable heterogeneity in the short-term funding costs among banks: for over one third of the bidders, funding costs increased by more than 20 basis points, and funding costs vary widely with respect to the country-of-origin. The funding costs we estimate using bidding data are also predictive of market- and accounting-based measures of bank performance, reinforcing the usefulness of ""revealed preference"" information contained in bids.","['Cassola, Nuno', 'Hortacsu, Ali', 'Kastl, Jakub']","['Auctions', 'Monetary Policy', 'Central Banks and Their Policies', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages']","['D44', 'E52', 'E58', 'G21']",The 2007 Subprime Market Crisis through the Lens of European Central Bank Auctions for Short-Term Funds,0,0,1,0,0,2013,07,01
81,4,2013-07-01,"We analyze games of incomplete information and offer equilibrium predictions that are valid for, and in this sense robust to, all possible private information structures that the agents may have. The set of outcomes that can arise in equilibrium for some information structure is equal to the set of Bayes correlated equilibria. We completely characterize the set of Bayes correlated equilibria in a class of games with quadratic payoffs and normally distributed uncertainty in terms of restrictions on the first and second moments of the equilibrium action-state distribution. We derive exact bounds on how prior knowledge about the private information refines the set of equilibrium predictions. We consider information sharing among firms under demand uncertainty and find new optimal information policies via the Bayes correlated equilibria. We also reverse the perspective and investigate the identification problem under concerns for robustness to private information. The presence of private information leads to set rather than point identification of the structural parameters of the game.","['Bergemann, Dirk', 'Morris, Stephen']","['Econometrics of Games and Auctions', 'Game Theory and Bargaining Theory: General', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C57', 'C70', 'D82', 'D83']",Robust Predictions in Games with Incomplete Information,0,0,0,0,0,2013,07,01
81,3,2013-05-01,"If voter preferences depend on a noisy state variable, under what conditions do large elections deliver outcomes ""as if"" the state were common knowledge? While the existing literature models elections using the jury metaphor where a change in information regarding the state induces all voters to switch in favor of only one alternative, we allow for more general preferences where a change in information can induce a switch in favor of either alternative. We show that information is aggregated for any voting rule if, for a randomly chosen voter, the probability of switching in favor of one alternative is strictly greater than the probability of switching away from that alternative for any given change in belief over states. If the preference distribution violates this condition, there exist equilibria that produce outcomes different from the full information outcome with high probability for large classes of voting rules. In other words, unless preferences closely conform to the jury metaphor, information aggregation is not guaranteed to obtain.","['Bhattacharya, Sourav']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D72', 'D83']",Preference Monotonicity and Information Aggregation in Elections,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"This paper proposes two new estimators for determining the number of factors (r) in static approximate factor models. We exploit the well-known fact that the r largest eigenvalues of the variance matrix of N response variables grow unboundedly as N increases, while the other eigenvalues remain bounded. The new estimators are obtained simply by maximizing the ratio of two adjacent eigenvalues. Our simulation results provide promising evidence for the two estimators.","['Ahn, Seung C.', 'Horenstein, Alex R.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models']","['C23', 'C38']",Eigenvalue Ratio Test for the Number of Factors,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"This paper is concerned with robust estimation under moment restrictions. A moment restriction model is semiparametric and distribution-free; therefore it imposes mild assumptions. Yet it is reasonable to expect that the probability law of observations may have some deviations from the ideal distribution being modeled, due to various factors such as measurement errors. It is then sensible to seek an estimation procedure that is robust against slight perturbation in the probability measure that generates observations. This paper considers local deviations within shrinking topological neighborhoods to develop its large sample theory, so that both bias and variance matter asymptotically. The main result shows that there exists a computationally convenient estimator that achieves optimal minimax robust properties. It is semiparametrically efficient when the model assumption holds, and, at the same time, it enjoys desirable robust properties when it does not.","['Evdokimov, Kirill', 'Kitamura, Yuichi', 'Otsu, Taisuke']","['Estimation: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C13', 'C20', 'C30']","Robustness, Infinitesimal Neighborhoods, and Moment Restrictions",0,0,0,0,0,2013,05,01
81,3,2013-05-01,"We argue that positive co-movements between land prices and business investment are a driving force behind the broad impact of land-price dynamics on the macroeconomy. We develop an economic mechanism that captures the co-movements by incorporating two key features into a DSGE model: we introduce land as a collateral asset in firms' credit constraints, and we identify a shock that drives most of the observed fluctuations in land prices. Our estimates imply that these two features combine to generate an empirically important mechanism that amplifies and propagates macroeconomic fluctuations through the joint dynamics of land prices and business investment.","['Liu, Zheng', 'Wang, Pengfei', 'Zha, Tao']","['Investment; Capital; Intangible Capital; Capacity', 'Business Fluctuations; Cycles', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Renewable Resources and Conservation: Land']","['E22', 'E32', 'G31', 'Q24']",Land-Price Dynamics and Macroeconomic Fluctuations,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"News--or foresight--about future economic fundamentals can create rational expectations equilibria with non-fundamental representations that pose substantial challenges to econometric efforts to recover the structural shocks to which economic agents react. Using tax policies as a leading example of foresight, simple theory makes transparent the economic behavior and information structures that generate non-fundamental equilibria. Econometric analyses that fail to model foresight will obtain biased estimates of output multipliers for taxes; biases are quantitatively important when two canonical theoretical models are taken as data generating processes. Both the nature of equilibria and the inferences about the effects of anticipated tax changes hinge critically on hypothesized information flows. Different methods for extracting or hypothesizing the information flows are discussed and shown to be alternative techniques for resolving a non-uniqueness problem endemic to moving average representations.","['Yang, Shu-Chun Susan', 'Leeper, Eric M.', 'Walker, Todd B.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Fiscal Policy', 'Taxation, Subsidies, and Revenue: General', 'One, Two, and Multisector Growth Models']","['D83', 'D84', 'E62', 'H20', 'O41']",Fiscal Foresight and Information Flows,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"We derive the analogue of the classic Arrow-Pratt approximation of the certainty equivalent under model uncertainty as described by the smooth model of decision making under ambiguity of Klibanoff, Marinacci, and Mukerji (2005). We study its scope by deriving a tractable mean-variance model adjusted for ambiguity and solving the corresponding portfolio allocation problem. In the problem with a risk-free asset, a risky asset, and an ambiguous asset, we find that portfolio rebalancing in response to higher ambiguity aversion only depends on the ambiguous asset's alpha, setting the performance of the risky asset as benchmark. In particular, a positive alpha corresponds to a long position in the ambiguous asset, a negative alpha corresponds to a short position in the ambiguous asset, and greater ambiguity aversion reduces optimal exposure to ambiguity. The analytical tractability of the enhanced Arrow-Pratt approximation renders our model especially well suited for calibration exercises aimed at exploring the consequences of model uncertainty on equilibrium asset prices.","['Maccheroni, Fabio', 'Ruffino, Doriana', 'Marinacci, Massimo']","['Criteria for Decision-Making under Risk and Uncertainty', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', 'G11', nan]",Alpha as Ambiguity: Robust Mean-Variance Portfolio Analysis,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"Dynamic models of ambiguity aversion are increasingly popular in applied work. This paper shows that there is a strong interdependence in such models between the ambiguity attitude and the preference for the timing of the resolution of uncertainty, as defined by the classic work of Kreps and Porteus (1978). The modeling choices made in the domain of ambiguity aversion influence the set of modeling choices available in the domain of timing attitudes. The main result is that the only model of ambiguity aversion that exhibits indifference to timing is the maxmin expected utility of Gilboa and Schmeidler (1989). This paper examines the structure of the timing nonindifference implied by the other commonly used models of ambiguity aversion. This paper also characterizes the indifference to long-run risk, a notion introduced by Duffie and Epstein (1992). The interdependence of ambiguity and timing that this paper identifies is of interest both conceptually and practically--especially for economists using these models in applications.","['Strzalecki, Tomasz']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Temporal Resolution of Uncertainty and Recursive Models of Ambiguity Aversion,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"I investigate the role of demand shocks in the ready-mix concrete industry. Using Census data on more than 15,000 plants, I estimate a model of investment and entry in oligopolistic markets. These estimates are used to simulate the effect of eliminating short-term local demand changes. A policy of smoothing the volatility of demand has a market expansion effect: the model predicts a 39% increase in the number of plants in the industry. Since bigger markets have both more plants and larger plants, a demand-smoothing fiscal policy would increase the share of large plants by 20%. Finally, the policy of smoothing demand reduces entry and exit by 25%, but has no effect on the rate at which firms change their size.","['Collard-Wexler, Allan']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Oligopoly and Other Imperfect Markets', 'Metals and Metal Products; Cement; Glass; Ceramics']","['C73', 'G31', 'L11', 'L13', 'L61']",Demand Fluctuations in the Ready-Mix Concrete Industry,1,0,0,0,0,2013,05,01
81,3,2013-05-01,"A dynamic structural model of labor supply, welfare participation, and food stamp participation is estimated using the 1992, 1993, and 1996 panels of the Survey of Income and Program Participation. Details of various policies including welfare time limits, work requirements, and Earned Income Tax Credit (EITC) are incorporated formally in the budget constraint. Policy simulations reveal that the economy accounts for half of the increase in the labor supply of female heads of family between 1992 and 1999. A time limit results in a larger efficiency gain than a work requirement or a direct reduction in welfare benefits. A reform package can lead to both a reduction in the government expenditure and an improvement in utility. The EITC expansion results in a substantial efficiency gain among individuals with the lowest expected wage. These individuals are almost unaffected by the economic expansion, but their income and utility increase significantly under the reform package.","['Chan, Marc K.']","['Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['H23', 'I38', 'J16', 'J22']",A Dynamic Model of Welfare Reform,0,0,0,0,0,2013,05,01
81,3,2013-05-01,"Few microfinance-funded businesses grow beyond subsistence entrepreneurship. This paper considers one possible explanation: that the structure of existing microfinance contracts may discourage risky but high-expected-return investments. To explore this possibility, I develop a theory that unifies models of investment choice, informal risk-sharing, and formal financial contracts. I then test the predictions of this theory using a series of experiments with clients of a large microfinance institution in India. The experiments confirm the theoretical predictions that joint liability creates two potential inefficiencies. First, borrowers free-ride on their partners, making risky investments without compensating partners for this risk. Second, the addition of peer-monitoring overcompensates, leading to sharp reductions in risk-taking and profitability. Equity-like financing, in which partners share both the benefits and risks of more profitable projects, overcomes both of these inefficiencies and merits further testing in the field.","['Fischer, Greg']","['Economics of Contract: Theory', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Insurance; Insurance Companies; Actuarial Studies', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['D86', 'G21', 'G22', 'G32', 'I38', 'O16']","Contract Structure, Risk-Sharing, and Investment Choice",0,0,0,0,0,2013,05,01
81,3,2013-05-01,"We take cohorts of entering freshmen at the United States Air Force Academy and assign half to peer groups designed to maximize the academic performance of the lowest ability students. Our assignment algorithm uses nonlinear peer effects estimates from the historical pre-treatment data, in which students were randomly assigned to peer groups. We find a negative and significant treatment effect for the students we intended to help. We provide evidence that within our ""optimally"" designed peer groups, students avoided the peers with whom we intended them to interact and instead formed more homogeneous subgroups. These results illustrate how policies that manipulate peer groups for a desired social outcome can be confounded by changes in the endogenous patterns of social interactions within the group.","['West, James E.', 'Carrell, Scott E.', 'Sacerdote, Bruce I.']","['Higher Education; Research Institutions', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['I23', 'Z13']",From Natural Variation to Optimal Policy? The Importance of Endogenous Peer Group Formation,0,0,0,0,0,2013,05,01
83,6,2015-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 6.,0,0,0,0,0,2015,11,01
83,5,2015-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 5.,0,0,0,0,0,2015,09,01
83,4,2015-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 4.,0,0,0,0,0,2015,07,01
83,3,2015-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 3.,0,0,0,0,0,2015,05,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 88 Iss. 1.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 88 Iss. 1.,0,0,0,0,0,2020,01,01
88,1,2020-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2020,01,01
87,6,2019-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,11,01
87,6,2019-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 6.,0,0,0,0,0,2019,11,01
87,6,2019-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 6.,0,0,0,0,0,2019,11,01
81,2,2013-03-01,"We study whether priors that admit full surplus extraction (FSE) are generic, an issue that becomes a gauge to evaluate the validity of the current mechanism design paradigm. We consider the space of priors on the universal type space, and thereby relax the assumption of a fixed finite number of types made by Cremer and McLean (1988). We show that FSE priors are topologically generic, contrary to the result of Heifetz and Neeman (2006) that FSE is generically impossible, both geometrically and measure-theoretically. Instead of using the BDP approach or convex combinations of priors adopted in Heifetz and Neeman (2006), we prove our genericity results by showing a robustness property of Cremer-McLean mechanisms.","['Xiong, Siyang', 'Chen, Yi-Chun']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Genericity and Robustness of Full Surplus Extraction,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"In this note, we prove an equilibrium existence theorem for games with discontinuous payoffs and convex and compact strategy spaces. It generalizes the classical result of Reny (1999), as well as the recent paper of McLennan, Monteiro, and Tourky (2011). Our conditions are simple and easy to verify. Importantly, examples of spatial location models show that our conditions allow for economically meaningful payoff discontinuities, that are not covered by other conditions in the literature.","['Meneghel, Idione', 'Barelli, Paulo']","['Game Theory and Bargaining Theory: General', 'Noncooperative Games']","['C70', 'C72']",A Note on the Equilibrium Existence Problem in Discontinuous Games,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"Different people use language in different ways. We capture this by making language competence--the set of messages an agent can use and understand--private information. Our primary focus is on common-interest games. Communication generally remains possible; it may be severely impaired even with common knowledge that language competence is adequate; and, indeterminacy of meaning, the confounding of payoff-relevant information with information about language competence, is optimal.","['Board, Oliver', 'Blume, Andreas']","['Game Theory and Bargaining Theory: General', 'Organizational Behavior; Transaction Costs; Property Rights', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D23', 'D83']",Language Barriers,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"This paper develops a new theory of fluctuations--one that helps accommodate the notions of ""animal spirits"" and ""market sentiment"" in unique-equilibrium, rational-expectations, macroeconomic models. To this goal, we limit the communication that is embedded in a neoclassical economy by allowing trading to be random and decentralized. We then show that the business cycle may be driven by a certain type of extrinsic shocks which we call sentiments. These shocks formalize shifts in expectations of economic activity without shifts in the underlying preferences and technologies; they are akin to sunspots, but operate in unique-equilibrium models. We further show how communication may help propagate these shocks in a way that resembles the spread of fads and rumors and that gives rise to boom-and-bust phenomena. We finally illustrate the quantitative potential of our insights within a variant of the RBC model.","['Angeletos, George-Marios', ""La'O, Jennifer""]","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'General Aggregative Models: Neoclassical', 'Business Fluctuations; Cycles']","['D83', 'D84', 'E13', 'E32']",Sentiments,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"We develop a practical and novel method for inference on intersection bounds, namely bounds defined by either the infimum or supremum of a parametric or nonparametric function, or, equivalently, the value of a linear programming problem with a potentially infinite constraint set. We show that many bounds characterizations in econometrics, for instance bounds on parameters under conditional moment inequalities, can be formulated as intersection bounds. Our approach is especially convenient for models comprised of a continuum of inequalities that are separable in parameters, and also applies to models with inequalities that are nonseparable in parameters. Since analog estimators for intersection bounds can be severely biased in finite samples, routinely underestimating the size of the identified set, we also offer a median-bias-corrected estimator of such bounds as a by-product of our inferential procedures. We develop theory for large sample inference based on the strong approximation of a sequence of series or kernel-based empirical processes by a sequence of ""penultimate"" Gaussian processes. These penultimate processes are generally not weakly convergent, and thus are non-Donsker. Our theoretical results establish that we can nonetheless perform asymptotically valid inference based on these processes. Our construction also provides new adaptive inequality/moment selection methods. We provide conditions for the use of nonparametric kernel and series estimators, including a novel result that establishes strong approximation for any general series estimator admitting linearization, which may be of independent interest.","['Chernozhukov, Victor', 'Lee, Sokbae', 'Rosen, Adam M.']","['Estimation: General', 'Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C13', 'C20', 'C21', 'C26']",Intersection Bounds: Estimation and Inference,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"In this paper, we propose an instrumental variable approach to constructing confidence sets (CS's) for the true parameter in models defined by conditional moment inequalities/equalities. We show that by properly choosing instrument functions, one can transform conditional moment inequalities/equalities into unconditional ones without losing identification power. Based on the unconditional moment inequalities/equalities, we construct CS's by inverting Cramer-von Mises-type or Kolmogorov-Smirnov-type tests. Critical values are obtained using generalized moment selection (GMS) procedures. We show that the proposed CS's have correct uniform asymptotic coverage probabilities. New methods are required to establish these results because an infinite-dimensional nuisance parameter affects the asymptotic distributions. We show that the tests considered are consistent against all fixed alternatives and typically have power against n-1/2-local alternatives to some, but not all, sequences of distributions in the null hypothesis. Monte Carlo simulations for five different models show that the methods perform well in finite samples.","['Shi, Xiaoxia', 'Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Estimation: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C12', 'C13', 'C21', 'C26']",Inference Based on Conditional Moment Inequalities,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"This paper considers random coefficients binary choice models. The main goal is to estimate the density of the random coefficients nonparametrically. This is an ill-posed inverse problem characterized by an integral transform. A new density estimator for the random coefficients is developed, utilizing Fourier-Laplace series on spheres. This approach offers a clear insight on the identification problem. More importantly, it leads to a closed form estimator formula that yields a simple plug-in procedure requiring no numerical optimization. The new estimator, therefore, is easy to implement in empirical applications, while being flexible about the treatment of unobserved heterogeneity. Extensions including treatments of nonrandom coefficients and models with endogeneity are discussed.","['Gautier, Eric', 'Kitamura, Yuichi']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],Nonparametric Estimation in Random Coefficients Binary Choice Models,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"Nonseparable panel models are important in a variety of economic settings, including discrete choice. This paper gives identification and estimation results for nonseparable models under time-homogeneity conditions that are like ""time is randomly assigned"" or ""time is an instrument."" Partial-identification results for average and quantile effects are given for discrete regressors, under static or dynamic conditions, in fully nonparametric and in semiparametric models, with time effects. It is shown that the usual, linear, fixed-effects estimator is not a consistent estimator of the identified average effect, and a consistent estimator is given. A simple estimator of identified quantile treatment effects is given, providing a solution to the important problem of estimating quantile treatment effects from panel data. Bounds for overall effects in static and dynamic models are given. The dynamic bounds provide a partial-identification solution to the important problem of estimating the effect of state dependence in the presence of unobserved heterogeneity. The impact of T, the number of time periods, is shown by deriving shrinkage rates for the identified set as T grows. We also consider semiparametric, discrete-choice models and find that semiparametric panel bounds can be much tighter than nonparametric bounds. Computationally convenient methods for semiparametric models are presented. We propose a novel inference method that applies in panel data and other settings and show that it produces uniformly valid confidence regions in large samples. We give empirical illustrations.","['Chernozhukov, Victor', 'Newey, Whitney', 'Fernandez-Val, Ivan', 'Hahn, Jinyong']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Wage Level and Structure; Wage Differentials', 'Trade Unions: Objectives, Structure, and Effects']","['C21', 'C23', 'J31', 'J51']",Average and Quantile Effects in Nonseparable Panel Models,0,0,0,0,0,2013,03,01
81,2,2013-03-01,"We introduce and apply a new nonparametric approach to identification and inference on data from ascending auctions. We exploit variation in the number of bidders across auctions to nonparametrically identify useful bounds on seller profit and bidder surplus using a general model of correlated private values that nests the standard independent private values (IPV) model. We also translate our identified bounds into closed form and asymptotically valid confidence intervals for several economic measures of interest. Applying our methods to much studied U.S. Forest Service timber auctions, we find evidence of correlation among values after controlling for a rich vector of relevant auction covariates; this correlation causes expected profit, the profit-maximizing reserve price, and bidder surplus to be substantially lower than conventional (IPV) analysis of the data would suggest.","['Quint, Daniel', 'Gandhi, Amit', 'Aradillas-Lopez, Andres']","['Model Construction and Estimation', 'Auctions', 'Renewable Resources and Conservation: Forestry']","['C51', 'D44', 'Q23']",Identification and Inference in Ascending Auctions with Correlated Private Values,0,0,1,0,0,2013,03,01
81,2,2013-03-01,"Branch selection is a key decision in a cadet's military career. Cadets at USMA can increase their branch priorities at a fraction of slots by extending their service agreement. This real-life matching problem fills an important gap in the market design literature, providing strong empirical legitimacy to a series of elegant theoretical works on matching with contracts. Although priorities fail a key substitutes condition, the agent-optimal stable mechanism is well defined, and in contrast to the current USMA mechanism it is fair, stable, strategy-proof, and respects improvements in cadet priorities. Adoption of this mechanism benefits cadets and the Army. This new application shows that the matching with contracts model is practically relevant beyond traditional domains that satisfy the substitutes condition.","['Switzer, Tobias B.', 'Sonmez, Tayfun']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Public Sector Labor Markets']","['C78', 'D82', 'D86', 'J45']",Matching with (Branch-of-Choice) Contracts at the United States Military Academy,0,0,0,0,0,2013,03,01
81,1,2013-01-01,ECONLIT None Found,[nan],[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS ECONOMETRICA REFEREES 2011-2012.,0,0,0,0,0,2013,01,01
81,1,2013-01-01,ECONLIT None Found,"['STOCK, JAMES H.', 'ACEMOGLU, DARON', 'JACKSON, MATTHEW O.', 'ROBIN, JEAN-MARC', 'JEHIEL, PHILIPPE', 'HANSEN, LARS PETER', 'PESENDORFER, WOLFGANG']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE EDITORS 2011-2012.,0,0,0,0,0,2013,01,01
81,1,2013-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE TREASURER.,0,0,0,0,0,2013,01,01
81,1,2013-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE SECRETARY.,0,0,0,0,0,2013,01,01
81,1,2013-01-01,ECONLIT None Found,"['Martimort, David', 'Biais, Bruno', 'Rochet, Jean-Charles']",['General Financial Markets: General (includes Measurement and Data)'],[nan],Competing Mechanisms in a Common Value Environment: Corrigendum,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We characterize and prove the existence of Nash equilibrium in a limit order market with a finite number of risk-neutral liquidity providers. We show that if there is sufficient adverse selection, then pointwise optimization (maximizing in p for each q) in a certain nonlinear pricing game produces a Nash equilibrium in the limit order market. The need for a sufficient degree of adverse selection does not vanish as the number of liquidity providers increases. Our formulation of the nonlinear pricing game encompasses various specifications of informed and liquidity trading, including the case in which nature chooses whether the market-order trader is informed or a liquidity trader. We solve for an equilibrium analytically in various examples and also present examples in which the first-order condition for pointwise optimization does not define an equilibrium, because the amount of adverse selection is insufficient.","['Back, Kerry', 'Baruch, Shmuel']","['Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['G11', nan]",Strategic Liquidity Provision in Limit Order Markets,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We study a two-stage model where the agent has preferences over menus as in Dekel, Lipman, and Rustichini (2001) in the first period and then makes random choices from menus as in Gul and Pesendorfer (2006) in the second period. Both preference for flexibility in the first period and strictly random choices in the second period can be, respectively, rationalized by subjective state spaces. Our main result characterizes the representation where the two state spaces align, so the agent correctly anticipates her future choices. The joint representation uniquely identifies probabilities over subjective states and magnitudes of utilities across states. We also characterize when the agent completely overlooks some subjective states that realize at the point of choice.","['Sarver, Todd', 'Ahn, David S.']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Preference for Flexibility and Random Choice,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We study the asymptotic distribution of three-step estimators of a finite-dimensional parameter vector where the second step consists of one or more nonparametric regressions on a regressor that is estimated in the first step. The first-step estimator is either parametric or nonparametric. Using Newey's (1994) path-derivative method, we derive the contribution of the first-step estimator to the influence function. In this derivation, it is important to account for the dual role that the first-step estimator plays in the second-step nonparametric regression, that is, that of conditioning variable and that of argument.","['Ridder, Geert', 'Hahn, Jinyong']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C20', 'C21']",Asymptotic Variance of Semiparametric Estimators with Generated Regressors,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We consider the estimation of dynamic panel data models in the presence of incidental parameters in both dimensions: individual fixed-effects and time fixed-effects, as well as incidental parameters in the variances. We adopt the factor analytical approach by estimating the sample variance of individual effects rather than the effects themselves. In the presence of cross-sectional heteroskedasticity, the factor method estimates the average of the cross-sectional variances instead of the individual variances. The method thereby eliminates the incidental-parameter problem in the means and in the variances over the cross-sectional dimension. We further show that estimating the time effects and heteroskedasticities in the time dimension does not lead to the incidental-parameter bias even when T and N are comparable. Moreover, efficient and robust estimation is obtained by jointly estimating heteroskedasticities.","['Bai, Jushan']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models']","['C23', 'C33']",Fixed-Effects Dynamic Panel Models: A Factor Analytical Method,0,0,0,0,0,2013,01,01
81,1,2013-01-01,This paper extends the subjective expected utility model of decision making under uncertainty to include incomplete beliefs and tastes. The main results are two axiomatizations of the multiprior expected multiutility representations of preference relations under uncertainty. The paper also introduces new axiomatizations of Knightian uncertainty and the expected multiutility model with complete beliefs.,"['Karni, Edi', 'Galaabaatar, Tsogbadral']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D81', 'D83']",Subjective Expected Utility with Incomplete Preferences,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We study selection rules: voting procedures used by committees to choose whether to place an issue on their agenda. At the selection stage of the model, committee members are uncertain about their final preferences. They only have some private information about these preferences. We show that voters become more conservative when the selection rule itself becomes more conservative. The decision rule has the opposite effect. We compare these voting procedures to the designation of an agenda setter among the committee and to a utilitarian social planner with all the ex interim private information.","['Perez-Richet, Eduardo', 'Godefroy, Raphael']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Choosing Choices: Agenda Selection with Uncertain Issues,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We consider a standard social choice environment with linear utilities and independent, one-dimensional, private types. We prove that for any Bayesian incentive compatible mechanism there exists an equivalent dominant strategy incentive compatible mechanism that delivers the same interim expected utilities for all agents and the same ex ante expected social surplus. The short proof is based on an extension of an elegant result due to Gutmann, Kemperman, Reeds, and Shepp (1991). We also show that the equivalence between Bayesian and dominant strategy implementation generally breaks down when the main assumptions underlying the social choice model are relaxed or when the equivalence concept is strengthened to apply to interim expected allocations.","['Kushnir, Alexey', 'Moldovanu, Benny', 'Goeree, Jacob K.', 'Gershkov, Alex', 'Shi, Xianwen']","['Auctions', 'Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D71', 'D82']",On the Equivalence of Bayesian and Dominant Strategy Implementation,0,0,1,0,0,2013,01,01
81,1,2013-01-01,"A group of peers must choose one of them to receive a prize; everyone cares only about winning, not about who gets the prize if someone else. An award rule is impartial if one's message never influences whether or not one wins the prize. We explore the consequences of impartiality when each agent nominates a single (other) agent for the prize. On the positive side, we construct impartial nomination rules where both the influence of individual messages and the requirements to win the prize are not very different across agents. Partition the agents in two or more districts, each of size at least 3, and call an agent a local winner if he is nominated by a majority of members of his own district; the rule selects a local winner with the largest support from nonlocal winners, or a fixed default agent in case there is no local winner. On the negative side, impartiality implies that ballots cannot be processed anonymously as in plurality voting. Moreover, we cannot simultaneously guarantee that the winner always gets at least one nomination, and that an agent nominated by everyone else always wins.","['Holzman, Ron', 'Moulin, Herve']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Social Choice; Clubs; Committees; Associations']","['D63', 'D71']",Impartial Nominations for a Prize,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We investigate the testable implications of the theory of stable matchings. We provide a characterization of the matchings that are rationalizable as stable matchings when agents' preferences are unobserved. The characterization is a simple nonparametric test for stability, in the tradition of revealed preference tests. We also characterize the observed stable matchings when monetary transfers are allowed and the stable matchings that are best for one side of the market: extremal stable matchings. We find that the theory of extremal stable matchings is observationally equivalent to requiring that there be a unique stable matching or that the matching be consistent with unrestricted monetary transfers.","['Echenique, Federico', 'Yenmez, M. Bumin', 'Shum, Matthew', 'Lee, Sangmok']","['Bargaining Theory; Matching Theory', 'Consumer Economics: Theory']","['C78', 'D11']",The Revealed Preference Theory of Stable and Extremal Stable Matchings,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"We investigate the role of deeply rooted pre-colonial ethnic institutions in shaping comparative regional development within African countries. We combine information on the spatial distribution of ethnicities before colonization with regional variation in contemporary economic performance, as proxied by satellite images of light density at night. We document a strong association between pre-colonial ethnic political centralization and regional development. This pattern is not driven by differences in local geographic features or by other observable ethnic-specific cultural and economic variables. The strong positive association between pre-colonial political complexity and contemporary development also holds within pairs of adjacent ethnic homelands with different legacies of pre-colonial political institutions.","['Michalopoulos, Stelios', 'Papaioannou, Elias']","['Institutions: Design, Formation, Operations, and Impact', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Economic History: Government, War, Law, International Relations, and Regulation: Africa; Oceania', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Institutions and Growth']","['D02', 'D72', 'N47', 'O17', 'O18', 'O43']",Pre-colonial Ethnic Institutions and Contemporary African Development,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"This paper investigates the behavior of asset prices in an endowment economy in which a representative agent with power utility consumes the dividends of multiple assets. The assets are Lucas trees; a collection of Lucas trees is a Lucas orchard. The model generates return correlations that vary endogenously, spiking at times of disaster. Since disasters spread across assets, the model generates large risk premia even for assets with stable cashflows. Very small assets may comove endogenously and hence earn positive risk premia even if their cashflows are independent of the rest of the economy. I provide conditions under which the variation in a small asset's price-dividend ratio can be attributed almost entirely to variation in its risk premium.","['Martin, Ian']","['General Aggregative Models: Neoclassical', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Payout Policy']","['E13', nan, 'G35']",The Lucas Orchard,0,0,0,0,0,2013,01,01
81,1,2013-01-01,"Belief disagreements have been suggested as a major contributing factor to the recent subprime mortgage crisis. This paper theoretically evaluates this hypothesis. I assume that optimists have limited wealth and take on leverage so as to take positions in line with their beliefs. To have a significant effect on asset prices, they need to borrow from traders with pessimistic beliefs using loans collateralized by the asset itself. Since pessimists do not value the collateral as much as optimists do, they are reluctant to lend, which provides an endogenous constraint on optimists' ability to borrow and to influence asset prices. I demonstrate that the tightness of this constraint depends on the nature of belief disagreements. Optimism concerning the probability of downside states has no or little effect on asset prices because these types of optimism are disciplined by this constraint. Instead, optimism concerning the relative probability of upside states could have significant effects on asset prices. This asymmetric disciplining effect is robust to allowing for short selling because pessimists that borrow the asset face a similar endogenous constraint. These results emphasize that what investors disagree about matters for asset prices, to a greater extent than the level of disagreements. When richer contracts are available, relatively complex contracts that resemble some of the recent financial innovations in the mortgage market endogenously emerge to facilitate betting.","['Simsek, Alp']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Financial Crises', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D83', 'G01', nan, 'G14']",Belief Disagreements and Collateral Constraints,0,0,0,0,0,2013,01,01
80,6,2012-11-01,ECONLIT None Found,"['Holmstrom, Bengt']",[nan],[nan],THE ECONOMETRIC SOCIETY 2011 ANNUAL REPORT OF THE PRESIDENT.,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"This paper considers local and global multiple-prior representations of ambiguity for preferences that are (i) monotonic, (ii) Bernoullian, that is, admit an affine utility representation when restricted to constant acts, and (iii) locally Lipschitz continuous. We do not require either certainty independence or uncertainty aversion. We show that the set of priors identified by Ghirardato, Maccheroni, and Marinacci's (2004) ""unambiguous preference"" relation can be characterized as a union of Clarke differentials. We then introduce a behavioral notion of ""locally better deviation"" at an act and show that it characterizes the Clarke differential of the preference representation at that act. These results suggest that the priors identified by these preference statements are directly related to (local) optimizing behavior.","['Siniscalchi, Marciano', 'Ghirardato, Paolo']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Ambiguity in the Small and in the Large,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"This paper is concerned with tests and confidence intervals for parameters that are not necessarily point identified and are defined by moment inequalities. In the literature, different test statistics, critical-value methods, and implementation methods (i.e., the asymptotic distribution versus the bootstrap) have been proposed. In this paper, we compare these methods. We provide a recommended test statistic, moment selection critical value, and implementation method. We provide data-dependent procedures for choosing the key moment selection tuning parameter kappa and a size-correction factor eta.","['Barwick, Panle Jia', 'Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Statistical Simulation Methods: General', 'Single Equation Models; Single Variables: General']","['C12', 'C15', 'C20']",Inference for Parameters Defined by Moment Inequalities: A Recommended Moment Selection Procedure,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"This paper proposes a dynamic politico-economic theory of fiscal policy in a world comprising a set of small open economies, whose driving force is the intergenerational conflict over debt, taxes, and public goods. Subsequent generations of voters choose fiscal policy through repeated elections. The presence of young voters induces fiscal discipline, that is, low taxes and low debt accumulation. The paper characterizes the Markov-perfect equilibrium of the voting game in each economy, as well as the stationary equilibrium debt distribution and interest rate of the world economy. The equilibrium can reproduce some salient features of fiscal policy in modern economies.","['Storesletten, Kjetil', 'Song, Zheng', 'Zilibotti, Fabrizio']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Open Economy Macroeconomics', 'Public Goods']","['D72', 'E62', 'F41', 'H41']",Rotten Parents and Disciplined Children: A Politico-economic Theory of Public Expenditure and Debt,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"We propose a model of monopolistic competition with additive preferences and variable marginal costs. Using the concept of ""relative love for variety,"" we provide a full characterization of the free-entry equilibrium. When the relative love for variety increases with individual consumption, the market generates pro-competitive effects. When it decreases, the market mimics anti-competitive behavior. The constant elasticity of substitution is the only case in which all competitive effects are washed out. We also show that our results hold true when the economy involves several sectors, firms are heterogeneous, and preferences are given by the quadratic utility and the translog.","['Parenti, Mathieu', 'Thisse, Jacques-Francois', 'Zhelobodko, Evgeny', 'Kokovin, Sergey']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D43', 'L13']",Monopolistic Competition: Beyond the Constant Elasticity of Substitution,1,0,1,0,0,2012,11,01
80,6,2012-11-01,"In the context of a dynamic, stochastic, general equilibrium model, we perform classical maximum likelihood and Bayesian estimations of the contribution of anticipated shocks to business cycles in the postwar United States. Our identification approach relies on the fact that forward-looking agents react to anticipated changes in exogenous fundamentals before such changes materialize. It further allows us to distinguish changes in fundamentals by their anticipation horizon. We find that anticipated shocks account for about half of predicted aggregate fluctuations in output, consumption, investment, and employment.","['Schmitt-Grohe, Stephanie', 'Uribe, Martin']","['Model Construction and Estimation', 'Macroeconomics: Consumption; Saving; Wealth', 'Investment; Capital; Intangible Capital; Capacity', 'Macroeconomics: Production', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles']","['C51', 'E21', 'E22', 'E23', 'E24', 'E32']",What's News in Business Cycles,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"We consider model based inference in a fractionally cointegrated (or cofractional) vector autoregressive model, based on the Gaussian likelihood conditional on initial values. We give conditions on the parameters such that the process X[subscript t] is fractional of order d and cofractional of order d - b; that is, there exist vectors beta for which beta prime X[subscript t] is fractional of order d - b and no other fractionality order is possible. For b = 1, the model nests the I(d - 1) vector autoregressive model. We define the statistical model by 0 < b <= d, but conduct inference when the true values satisfy 0 <= d[subscript 0] - b[subscript 0] < 1/2 and b[subscript 0] does not equal 1/2, for which beta prime[subscript 0] X[subscript t] is (asymptotically) a stationary process. Our main technical contribution is the proof of consistency of the maximum likelihood estimators. To this end, we prove weak convergence of the conditional likelihood as a continuous stochastic process in the parameters when errors are independent and identically distributed with suitable moment conditions and initial values are bounded. Because the limit is deterministic, this implies uniform convergence in probability of the conditional likelihood function. If the true value b[subscript 0] > 1/2, we prove that the limit distribution of T[superscript b[subscript 0]](Beta-hat - Beta[subscript 0]) is mixed Gaussian, while for the remaining parameters it is Gaussian. The limit distribution of the likelihood ratio test for cointegration rank is a functional of fractional Brownian motion of type II. If b[subscript 0] < 1/2, all limit distributions are Gaussian or chi-squared. We derive similar results for the model with d = b, allowing for a constant term.","['Nielsen, Morten Orregaard', 'Johansen, Soren']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Likelihood Inference for a Fractionally Cointegrated Vector Autoregressive Model,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"We consider tests of a simple null hypothesis on a subset of the coefficients of the exogenous and endogenous regressors in a single-equation linear instrumental variables regression model with potentially weak identification. Existing methods of subset inference (i) rely on the assumption that the parameters not under test are strongly identified, or (ii) are based on projection-type arguments. We show that, under homoskedasticity, the subset Anderson and Rubin (1949) test that replaces unknown parameters by limited information maximum likelihood estimates has correct asymptotic size without imposing additional identification assumptions, but that the corresponding subset Lagrange multiplier test is size distorted asymptotically.","['Kleibergen, Frank', 'Mavroeidis, Sophocles', 'Guggenberger, Patrik', 'Chen, Linchun']",['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation'],['C26'],On the Asymptotic Sizes of Subset Anderson-Rubin and Lagrange Multiplier Tests in Linear Instrumental Variables Regression,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"This paper studies information aggregation in dynamic markets with a finite number of partially informed strategic traders. It shows that, for a broad class of securities, information in such markets always gets aggregated. Trading takes place in a bounded time interval, and in every equilibrium, as time approaches the end of the interval, the market price of a ""separable"" security converges in probability to its expected value conditional on the traders' pooled information. If the security is ""non-separable,"" then there exists a common prior over the states of the world and an equilibrium such that information does not get aggregated. The class of separable securities includes, among others, Arrow-Debreu securities, whose value is 1 in one state of the world and 0 in all others, and ""additive"" securities, whose value can be interpreted as the sum of traders' signals.","['Ostrovsky, Michael']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D83', 'D84', 'G14']",Information Aggregation in Dynamic Markets with Strategic Traders,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"Firms are more productive, on average, in larger cities. Two main explanations have been offered: firm selection (larger cities toughen competition, allowing only the most productive to survive) and agglomeration economies (larger cities promote interactions that increase productivity), possibly reinforced by localized natural advantage. To distinguish between them, we nest a generalized version of a tractable firm selection model and a standard model of agglomeration. Stronger selection in larger cities left-truncates the productivity distribution, whereas stronger agglomeration right-shifts and dilates the distribution. Using this prediction, French establishment-level data, and a new quantile approach, we show that firm selection cannot explain spatial productivity differences. This result holds across sectors, city size thresholds, establishment samples, and area definitions.","['Roux, Sebastien', 'Gobillon, Laurent', 'Duranton, Gilles', 'Combes, Pierre-Philippe', 'Puga, Diego']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Regional Economic Activity: Growth, Development, Environmental Issues, and Changes', 'Other Spatial Production and Pricing Analysis']","['D24', 'R11', 'R32']",The Productivity Advantages of Large Cities: Distinguishing Agglomeration from Firm Selection,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"In many financial markets, dealers have the advantage of observing the orders of their customers. To quantify the economic benefit that dealers derive from this advantage, we study detailed data from Canadian Treasury auctions, where dealers observe customer bids while preparing their own bids. In this setting, dealers can use information on customer bids to learn about (i) competition, that is, the distribution of competing bids in the auction, and (ii) fundamentals, that is, the ex post value of the security being auctioned. We devise formal hypothesis tests for both sources of informational advantage. In our data, we do not find evidence that dealers are learning about fundamentals. We find that the ""information about competition"" contained in customer bids accounts for 13-27% of dealers' expected profits.","['Hortacsu, Ali', 'Kastl, Jakub']","['Auctions', 'Expectations; Speculations', 'Comparative or Joint Analysis of Fiscal and Monetary Policy; Stabilization; Treasury Policy', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading', 'Investment Banking; Venture Capital; Brokerage; Ratings and Ratings Agencies']","['D44', 'D84', 'E63', nan, 'G14', 'G24']",Valuing Dealers' Informational Advantage: A Study of Canadian Treasury Auctions,0,0,1,0,0,2012,11,01
80,6,2012-11-01,"We present a model for the equilibrium movement of capital between asset markets that are distinguished only by the levels of capital invested in each. Investment in that market with the greatest amount of capital earns the lowest risk premium. Intermediaries optimally trade off the costs of intermediation against fees that depend on the gain they can offer to investors for moving their capital to the market with the higher mean return. The bargaining power of an investor depends on potential access to alternative intermediaries. In equilibrium, the speeds of adjustment of mean returns and of capital between the two markets are increasing in the degree to which capital is imbalanced between the two markets, and can be reduced by competition among intermediaries.","['Duffie, Darrell', 'Strulovici, Bruno']","['Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Financial Institutions and Services: General']","['G11', nan, 'G20']",Capital Mobility and Asset Pricing,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"We investigate the welfare properties of the one-sector neoclassical growth model with uninsurable idiosyncratic shocks. We focus on the notion of constrained efficiency used in the general equilibrium literature. Our characterization of constrained efficiency uses the first-order condition of a constrained planner's problem. This condition highlights the margins of relevance for whether capital is too high or too low: the factor composition of income of the (consumption-)poor. Using three calibrations commonly considered in the literature, we illustrate that there can be either over- or underaccumulation of capital in steady state and that the constrained optimum may or may not be consistent with a nondegenerate long-run distribution of wealth. For the calibration that roughly matches the income and wealth distribution, the constrained inefficiency of the market outcome is rather striking: it has much too low a steady-state capital stock.","['Rios-Rull, Jose-Victor', 'Davila, Julio', 'Krusell, Per', 'Hong, Jay H.']","['Personal Income, Wealth, and Their Distributions', 'Investment; Capital; Intangible Capital; Capacity', 'One, Two, and Multisector Growth Models']","['D31', 'E22', 'O41']",Constrained Efficiency in the Neoclassical Growth Model with Uninsurable Idiosyncratic Shocks,0,0,0,0,0,2012,11,01
80,6,2012-11-01,"We develop results for the use of Lasso and post-Lasso methods to form first-stage predictions and estimate optimal instruments in linear instrumental variables (IV) models with many instruments, p. Our results apply even when p is much larger than the sample size, n. We show that the IV estimator based on using Lasso or post-Lasso in the first stage is root-n consistent and asymptotically normal when the first stage is approximately sparse, that is, when the conditional expectation of the endogenous variables given the instruments can be well-approximated by a relatively small set of variables whose identities may be unknown. We also show that the estimator is semiparametrically efficient when the structural error is homoscedastic. Notably, our results allow for imperfect model selection, and do not rely upon the unrealistic ""beta-min"" conditions that are widely used to establish validity of inference following model selection (see also Belloni, Chernozhukov, and Hansen (2011b)). In simulation experiments, the Lasso-based IV estimator with a data-driven penalty performs well compared to recently advocated many-instrument robust procedures. In an empirical example dealing with the effect of judicial eminent domain decisions on economic outcomes, the Lasso-based IV estimator outperforms an intuitive benchmark. Optimal instruments are conditional expectations. In developing the IV results, we establish a series of new results for Lasso and post-Lasso estimators of nonparametric conditional expectation functions which are of independent theoretical and practical interest. We construct a modification of Lasso designed to deal with non-Gaussian, heteroscedastic disturbances that uses a data-weighted l[subscript 1]-penalty function. By innovatively using moderate deviation theory for self-normalized sums, we provide convergence rates for the resulting Lasso and post-Lasso estimators that are as sharp as the corresponding rates in the homoscedastic Gaussian case under the condition that log p = o(n[superscript 1/3]). We also provide a data-driven method for choosing the penalty level that must be specified in obtaining Lasso and post-Lasso estimates and establish its asymptotic validity under non-Gaussian, heteroscedastic disturbances.","['Chen, D.', 'Hansen, C.', 'Chernozhukov, V.', 'Belloni, A.']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Multiple or Simultaneous Equation Models: Instrumental Variables (IV) Estimation', 'Model Construction and Estimation', 'Property Law', 'Housing Supply and Markets', 'Regional Government Analysis: Land Use and Other Regulations']","['C26', 'C36', 'C51', 'K11', 'R31', 'R52']",Sparse Models and Methods for Optimal Instruments with an Application to Eminent Domain,0,1,0,0,0,2012,11,01
80,5,2012-09-01,"I propose a new mechanism design approach to the problem of ranking standard auctions with two heterogeneous bidders. A key feature of the approach is that it may be possible to rank two auctions even if neither dominates the other for all combinations of types. The approach simplifies the analysis and unifies results in the existing literature. Roughly speaking, the first-price auction is more profitable than the second-price auction when the strong bidder's distribution is flatter and more disperse than the weak bidder's distribution. Applications include auctions with one-sided externalities. Moreover, contrary to previous work, reserve prices are easily handled. Finally, the method can be extended to some environments with many bidders.","['Kirkegaard, Rene']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",A Mechanism Design Approach to Ranking Asymmetric Auctions,0,0,1,0,0,2012,09,01
80,5,2012-09-01,"The single crossing property plays a crucial role in economic theory, yet there are important instances where the property cannot be directly assumed or easily derived. Difficulties often arise because the property cannot be aggregated: the sum or convex combination of two functions with the single crossing property need not have that property. We introduce a new condition characterizing when the single crossing property is stable under aggregation, and also identify sufficient conditions for the preservation of the single crossing property under multidimensional aggregation. We use our results to establish properties of objective functions (convexity, log-supermodularity), the monotonicity of optimal decisions under uncertainty, and the existence of monotone equilibria in Bayesian games.","['Quah, John K.-H.', 'Strulovici, Bruno']","['Mathematical Methods; Programming Models; Mathematical and Simulation Modeling: General', 'Game Theory and Bargaining Theory: General', 'Microeconomic Behavior: Underlying Principles', 'Criteria for Decision-Making under Risk and Uncertainty']","['C60', 'C70', 'D01', 'D81']",Aggregating the Single Crossing Property,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"Seemingly absent from the arsenal of currently available ""nearly efficient"" testing procedures for the unit root hypothesis, that is, tests whose asymptotic local power functions are virtually indistinguishable from the Gaussian power envelope, is a test admitting a (quasi-)likelihood ratio interpretation. We study the large sample properties of a quasi-likelihood ratio unit root test based on a Gaussian likelihood and show that this test is nearly efficient.","['Nielsen, Morten Orregaard', 'Jansson, Michael']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Nearly Efficient Likelihood Ratio Tests of the Unit Root Hypothesis,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"This paper considers the estimation problem of structural models for which empirical restrictions are characterized by a fixed point constraint, such as structural dynamic discrete choice models or models of dynamic games. We analyze a local condition under which the nested pseudo likelihood (NPL) algorithm converges to a consistent estimator, and derive its convergence rate. We find that the NPL algorithm may not necessarily converge to a consistent estimator when the fixed point mapping does not have a local contraction property. To address the issue of divergence, we propose alternative sequential estimation procedures that can converge to a consistent estimator even when the NPL algorithm does not.","['Kasahara, Hiroyuki', 'Shimotsu, Katsumi']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C23', 'C25', 'C73']",Sequential Estimation of Structural Models with a Fixed Point Constraint,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"In this paper, we propose a method to evaluate the effect of a counterfactual change in the unconditional distribution of a single covariate on the unconditional distribution of an outcome variable of interest. Both fixed and infinitesimal changes are considered. We show that such effects are point identified under general conditions if the covariate affected by the counterfactual change is continuously distributed, but are typically only partially identified if its distribution is discrete. For the latter case, we derive informative bounds, making use of the available information. We also discuss estimation and inference.","['Rothe, Christoph']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Specific Distributions; Specific Statistics', 'Wage Level and Structure; Wage Differentials']","['C20', 'C21', 'C46', 'J31']",Partial Distributional Policy Effects,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"The widely used estimator of Berry, Levinsohn, and Pakes (1995) produces estimates of consumer preferences from a discrete-choice demand model with random coefficients, market-level demand shocks, and endogenous prices. We derive numerical theory results characterizing the properties of the nested fixed point algorithm used to evaluate the objective function of BLP's estimator. We discuss problems with typical implementations, including cases that can lead to incorrect parameter estimates. As a solution, we recast estimation as a mathematical program with equilibrium constraints, which can be faster and which avoids the numerical issues associated with nested inner loops. The advantages are even more pronounced for forward-looking demand models where the Bellman equation must also be solved repeatedly. Several Monte Carlo and real-data experiments support our numerical concerns about the nested fixed point approach and the advantages of constrained optimization. For static BLP, the constrained optimization approach can be as much as ten to forty times faster for large-dimensional problems with many markets.","['Fox, Jeremy T.', 'Su, Che-Lin', 'Dube, Jean-Pierre']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Model Construction and Estimation']","['C25', 'C51']",Improving the Numerical Performance of Static and Dynamic Aggregate Discrete Choice Random Coefficients Demand Estimation,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"Estimating structural models is often viewed as computationally difficult, an impression partly due to a focus on the nested fixed-point (NFXP) approach. We propose a new constrained optimization approach for structural estimation. We show that our approach and the NFXP algorithm solve the same estimation problem, and yield the same estimates. Computationally, our approach can have speed advantages because we do not repeatedly solve the structural equation at each guess of structural parameters. Monte Carlo experiments on the canonical Zurcher bus-repair model demonstrate that the constrained optimization approach can be significantly faster.","['Su, Che-Lin', 'Judd, Kenneth L.']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Construction and Estimation']","['C20', 'C25', 'C30', 'C51']",Constrained Optimization Approaches to Estimation of Structural Models,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"This paper analyzes the properties of standard estimators, tests, and confidence sets (CS's) for parameters that are unidentified or weakly identified in some parts of the parameter space. The paper also introduces methods to make the tests and CS's robust to such identification problems. The results apply to a class of extremum estimators and corresponding tests and CS's that are based on criterion functions that satisfy certain asymptotic stochastic quadratic expansions and that depend on the parameter that determines the strength of identification. This covers a class of models estimated using maximum likelihood (ML), least squares (LS), quantile, generalized method of moments, generalized empirical likelihood, minimum distance, and semi-parametric estimators. The consistency/lack-of-consistency and asymptotic distributions of the estimators are established under a full range of drifting sequences of true distributions. The asymptotic sizes (in a uniform sense) of standard and identification-robust tests and CS's are established. The results are applied to the ARMA(1, 1) time series model estimated by ML and to the nonlinear regression model estimated by LS. In companion papers, the results are applied to a number of other models.","['Cheng, Xu', 'Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C12', 'C22', 'C32']","Estimation and Inference with Weak, Semi-strong, and Strong Identification",0,0,0,0,0,2012,09,01
80,5,2012-09-01,"In this paper, we study identification and estimation of a correlated random coefficients (CRC) panel data model. The outcome of interest varies linearly with a vector of endogenous regressors. The coefficients on these regressors are heterogenous across units and may covary with them. We consider the average partial effect (APE) of a small change in the regressor vector on the outcome (cf. Chamberlain (1984), Wooldridge (2005a)). Chamberlain (1992) calculated the semiparametric efficiency bound for the APE in our model and proposed a square root of N-consistent estimator. Nonsingularity of the APE's information bound, and hence the appropriateness of Chamberlain's (1992) estimator, requires (i) the time dimension of the panel (T) to strictly exceed the number of random coefficients (p) and (ii) strong conditions on the time series properties of the regressor vector. We demonstrate irregular identification of the APE when T = p and for more persistent regressor processes. Our approach exploits the different identifying content of the subpopulations of stayers--or units whose regressor values change little across periods--and movers--or units whose regressor values change substantially across periods. We propose a feasible estimator based on our identification result and characterize its large sample properties. While irregularity precludes our estimator from attaining parametric rates of convergence, its limiting distribution is normal and inference is straightforward to conduct. Standard software may be used to compute point estimates and standard errors. We use our methods to estimate the average elasticity of calorie consumption with respect to total outlay for a sample of poor Nicaraguan households.","['Powell, James L.', 'Graham, Bryan S.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Model Construction and Estimation', 'Health Behavior', 'Microeconomic Analyses of Economic Development']","['C23', 'C51', 'I12', 'O12']",Identification and Estimation of Average Partial Effects in 'Irregular' Correlated Random Coefficient Panel Data Models,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"According to standard theory, the set of implementable efficient outcome functions is greatly reduced if the mechanism or contract can be renegotiated ex post. In some cases, contracts can achieve nothing and so, for example, the hold-up problem may be severe. This paper shows that if the mechanism is designed in such a way that sending a message involves a small cost, then renegotiation essentially does not restrict the set of efficient implementable functions. Given a weak preference-reversal condition, any Pareto-efficient, bounded social choice function can be implemented in subgame-perfect equilibrium in a renegotiation-proof manner, for any strictly positive message cost. The key point is that messages themselves can act as punishments.","['Evans, Robert']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Mechanism Design with Renegotiation and Costly Messages,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"Two players announce bargaining postures to which they may become committed and then bargain over the division of a surplus. The share of the surplus that a player can guarantee herself under first-order knowledge of rationality is determined (as a function of her probability of becoming committed), as is the bargaining posture that she must announce in order to guarantee herself this much. This ""maxmin"" share of the surplus is large relative to the probability of becoming committed (e.g., it equals 30% if the commitment probability is 1 in 10 and equals 13% if the commitment probability is 1 in 1,000), and the corresponding bargaining posture simply demands this share plus compensation for any delay in reaching agreement.","['Wolitzky, Alexander']",['Bargaining Theory; Matching Theory'],['C78'],Reputational Bargaining with Minimal Knowledge of Rationality,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"This paper establishes existence of a stationary Markov perfect equilibrium in general stochastic games with noise--a component of the state that is nonatomically distributed and not directly affected by the previous period's state and actions. Noise may be simply a payoff-irrelevant public randomization device, delivering known results on the existence of correlated equilibrium as a special case. More generally, noise can take the form of shocks that enter into players' stage payoffs and the transition probability on states. The existence result is applied to a model of industry dynamics and to a model of dynamic electoral competition.","['Duggan, John']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['C73', 'D72', 'L11']",Noisy Stochastic Games,1,0,0,0,0,2012,09,01
80,5,2012-09-01,"This paper argues that, in the presence of intersectoral input-output linkages, microeconomic idiosyncratic shocks may lead to aggregate fluctuations. We show that, as the economy becomes more disaggregated, the rate at which aggregate volatility decays is determined by the structure of the network capturing such linkages. Our main results provide a characterization of this relationship in terms of the importance of different sectors as suppliers to their immediate customers, as well as their role as indirect suppliers to chains of downstream sectors. Such higher-order interconnections capture the possibility of ""cascade effects"" whereby productivity shocks to a sector propagate not only to its immediate downstream customers, but also to the rest of the economy. Our results highlight that sizable aggregate volatility is obtained from sectoral idiosyncratic shocks only if there exists significant asymmetry in the roles that sectors play as suppliers to others, and that the ""sparseness"" of the input-output matrix is unrelated to the nature of aggregate fluctuations.","['Ozdaglar, Asuman', 'Acemoglu, Daron', 'Carvalho, Vasco M.', 'Tahbaz-Salehi, Alireza']","['Network Formation and Analysis: Theory', 'Business Fluctuations; Cycles', 'Transactional Relationships; Contracts and Reputation; Networks']","['D85', 'E32', 'L14']",The Network Origins of Aggregate Fluctuations,1,0,0,0,0,2012,09,01
80,5,2012-09-01,"In this paper, we derive and experimentally test a theoretical model of speculation in multiperiod asset markets with public information flows. The speculation arises from the traders' heterogeneous posteriors as they make different inferences from sequences of public information. This leads to overpricing in the sense that price exceeds the most optimistic belief about the real value of the asset. We find evidence of speculative overpricing in both incomplete and complete markets, where the information flow is a gradually revealed sequence of imperfect public signals about the state of the world. We also find evidence of asymmetric price reaction to good news and bad news, another feature of equilibrium price dynamics under our model. Markets with a relaxed short-sale constraint exhibit less overpricing.","['Wang, Stephanie W.', 'Palfrey, Thomas R.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D83', 'D84', nan, 'G14']",Speculative Overpricing in Asset Markets with Information Flows,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"This paper examines the incentives offered by frictionless markets to innovate asset-backed securities by owners who maximize the assets' values. Assuming identical preferences across investors with heterogeneous risk-sharing needs, we characterize economies in which competition provides insufficient incentives to innovate so that, in equilibrium, financial markets are incomplete in all (pure strategy) equilibria, even when innovation is essentially costless. Thus, value maximization does not generally result in complete markets.","['Rostek, Marzena', 'Carvajal, Andres', 'Weretka, Marek']","['Incomplete Markets', 'General Equilibrium and Disequilibrium: Financial Markets', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Pension Funds; Non-bank Financial Institutions; Financial Instruments; Institutional Investors']","['D52', 'D53', nan, 'G23']",Competition in Financial Innovation,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"Observers often interpret boom-bust episodes in asset markets as speculative frenzies where asymmetrically informed investors buy overvalued assets hoping to sell to a greater fool before the crash. Despite its intuitive appeal, however, this notion of speculative bubbles has proven difficult to reconcile with economic theory. Existing models have been criticized on the basis that they assume irrationality, that prices are somewhat unresponsive to sales, or that they depend on fragile, knife-edge restrictions. To address these issues, I construct a rational version of Abreu and Brunnermeier (2003), where agents invest growing endowments into an asset, fueling appreciation and eventual overvaluation. Riding bubbles is optimal as long as the growth rate of the bubble and the probability of selling before the crash are high enough. This probability increases with the amount of noise in the economy, as random short-term fluctuations make it difficult for agents to infer information from prices.","['Doblas-Madrid, Antonio']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', 'D83', 'D84', 'G11', nan]",A Robust Model of Bubbles with Multidimensional Uncertainty,0,0,0,0,0,2012,09,01
80,5,2012-09-01,"Empirical evidence suggests that perfectionism can affect choice behavior. When striving for perfection, a person can desire to keep normatively appealing options feasible even if she persistently fails to use these options later. For instance, she can ""pay not to go to the gym,"" as in DellaVigna and Malmendier (2006). By contrast, some perfectionists may avoid normatively important tasks for fear of negative self-evaluation of their performance. This paper models perfectionist behaviors in Gul and Pesendorfer's (2001) menu framework where agents may be tempted to deviate from their long-term normative objectives. In addition to self-control costs, I identify a utility component that reflects emotional costs and benefits of perfectionism. My model is derived from axioms imposed on preferences over menus in an essentially unique way.","['Kopylov, Igor']","['Consumer Economics: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D11', 'D15']",Perfectionism and Choice,0,0,0,0,0,2012,09,01
80,4,2012-07-01,"An autoregressive model with Markov regime-switching is analyzed that reflects on the properties of the quasi-likelihood ratio test developed by Cho and White (2007). For such a model, we show that consistency of the quasi-maximum likelihood estimator for the population parameter values, on which consistency of the test is based, does not hold. We describe a condition that ensures consistency of the estimator and discuss the consistency of the test in the absence of consistency of the estimator.","['Carter, Andrew V.', 'Steigerwald, Douglas G.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Testing for Regime Switching: A Comment,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"We investigate the classical Anscombe-Aumann model of decision-making under uncertainty without the completeness axiom. We distinguish between the dual traits of ""indecisiveness in beliefs"" and ""indecisiveness in tastes."" The former is captured by the Knightian uncertainty model, the latter by the single-prior expected multi-utility model. We characterize axiomatically the latter model. Then we show that, under independence and continuity, these two models can be jointly characterized by means of a partial completeness property.","['Ok, Efe A.', 'Ortoleva, Pietro', 'Riella, Gil']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D83']",Incomplete Preferences under Uncertainty: Indecisiveness in Beliefs versus Tastes,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"We examine challenges to estimation and inference when the objects of interest are nondifferentiable functionals of the underlying data distribution. This situation arises in a number of applications of bounds analysis and moment inequality models, and in recent work on estimating optimal dynamic treatment regimes. Drawing on earlier work relating differentiability to the existence of unbiased and regular estimators, we show that if the target object is not differentiable in the parameters of the data distribution, there exist no estimator sequences that are locally asymptotically unbiased or a-quantile unbiased. This places strong limits on estimators, bias correction methods, and inference procedures, and provides motivation for considering other criteria for evaluating estimators and inference procedures, such as local asymptotic minimaxity and one-sided quantile unbiasedness.","['Porter, Jack R.', 'Hirano, Keisuke']",['Estimation: General'],['C13'],Impossibility Results for Nondifferentiable Functionals,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"This paper studies the behavior, under local misspecification, of several confidence sets (CSs) commonly used in the literature on inference in moment (in)equality models. We propose the amount of asymptotic confidence size distortion as a criterion to choose among competing inference methods. This criterion is then applied to compare across test statistics and critical values employed in the construction of CSs. We find two important results under weak assumptions. First, we show that CSs based on subsampling and generalized moment selection (Andrews and Soares (2010)) suffer from the same degree of asymptotic confidence size distortion, despite the fact that asymptotically the latter can lead to CSs with strictly smaller expected volume under correct model specification. Second, we show that the asymptotic confidence size of CSs based on the quasi-likelihood ratio test statistic can be an arbitrary small fraction of the asymptotic confidence size of CSs based on the modified method of moments test statistic.","['Guggenberger, Patrik', 'Canay, Ivan A.', 'Bugni, Federico A.']",['Hypothesis Testing: General'],['C12'],Distortions of Asymptotic Confidence Size in Locally Misspecified Moment Inequality Models,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"This paper discusses a consistent bootstrap implementation of the likelihood ratio (LR) co-integration rank test and associated sequential rank determination procedure of Johansen (1996). The bootstrap samples are constructed using the restricted parameter estimates of the underlying vector autoregressive (VAR) model that obtain under the reduced rank null hypothesis. A full asymptotic theory is provided that shows that, unlike the bootstrap procedure in Swensen (2006) where a combination of unrestricted and restricted estimates from the VAR model is used, the resulting bootstrap data are I(1) and satisfy the null co-integration rank, regardless of the true rank. This ensures that the bootstrap LR test is asymptotically correctly sized and that the probability that the bootstrap sequential procedure selects a rank smaller than the true rank converges to zero. Monte Carlo evidence suggests that our bootstrap procedures work very well in practice.","['Cavaliere, Giuseppe', 'Rahbek, Anders', 'Taylor, A. M. Robert']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Bootstrap Determination of the Co-integration Rank in Vector Autoregressive Models,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"We present a simple way to estimate the effects of changes in a vector of observable variables X on a limited dependent variable Y when Y is a general nonseparable function of X and unobservables, and X is independent of the unobservables. We treat models in which Y is censored from above, below, or both. The basic idea is to first estimate the derivative of the conditional mean of Y given X at x with respect to x on the uncensored sample without correcting for the effect of x on the censored population. We then correct the derivative for the effects of the selection bias. We discuss nonparametric and semiparametric estimators for the derivative. We also discuss the cases of discrete regressors and of endogenous regressors in both cross section and panel data contexts.","['Otsu, Taisuke', 'Altonji, Joseph G.', 'Ichimura, Hidehiko']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models']","['C13', 'C14', 'C24']",Estimating Derivatives in Nonseparable Models with Limited Dependent Variables,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"For a finite game with perfect recall, a refinement of its set of Nash equilibria selects closed connected subsets, called solutions. Assume that each solution's equilibria use undominated strategies and some of its equilibria are quasi-perfect, and that all solutions are immune to presentation effects; namely, if the game is embedded in a larger game with more pure strategies and more players such that the original players' feasible mixed strategies and expected payoffs are preserved regardless of what other players do, then the larger game's solutions project to the original game's solutions. Then, for a game with two players and generic payoffs, each solution is an essential component of the set of equilibria that use undominated strategies, and thus a stable set of equilibria as defined by Mertens (1989).","['Wilson, Robert', 'Govindan, Srihari']",['Game Theory and Bargaining Theory: General'],['C70'],Axiomatic Equilibrium Selection for Generic Two-Player Games,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"In this paper, we introduce a notion of continuous implementation and characterize when a social choice function is continuously implementable. More specifically, we say that a social choice function is continuously (partially) implementable if it is (partially) implementable for types in the model under study and it continues to be (partially) implementable for types ""close"" to this initial model. Our results show that this notion is tightly connected to full implementation in rationalizable strategies.","['Oury, Marion', 'Tercieux, Olivier']","['Social Choice; Clubs; Committees; Associations', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D71', 'D83']",Continuous Implementation,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"Stochastic sequential bargaining models (Merlo and Wilson (1995, 1998)) have found wide applications in different fields including political economy and macroeconomics due to their flexibility in explaining delays in reaching an agreement. This paper presents new results in nonparametric identification and estimation of such models under different data scenarios.","['Tang, Xun', 'Merlo, Antonio']","['Model Construction and Estimation', 'Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Bankruptcy; Liquidation', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance']","['C51', 'C78', 'D83', 'G33', 'G34']",Identification and Estimation of Stochastic Bargaining Models,0,0,0,0,1,2012,07,01
80,4,2012-07-01,"We study the asymptotic distribution of Tikhonov regularized estimation of quantile structural effects implied by a nonseparable model. The nonparametric instrumental variable estimator is based on a minimum distance principle. We show that the minimum distance problem without regularization is locally ill-posed, and we consider penalization by the norms of the parameter and its derivatives. We derive pointwise asymptotic normality and develop a consistent estimator of the asymptotic variance. We study the small sample properties via simulation results and provide an empirical illustration of estimation of nonlinear pricing curves for telecommunications services in the United States.","['Gagliardini, Patrick', 'Scaillet, Olivier']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Telecommunications']","['C21', 'C26', 'L11', 'L96']",Nonparametric Instrumental Variable Estimation of Structural Quantile Effects,1,0,0,0,0,2012,07,01
80,4,2012-07-01,"This paper studies endogenous risk-taking by embedding a concern for status (relative consumption) into an otherwise conventional model of economic growth. We prove that if the intertemporal production function is strictly concave, an equilibrium must converge to a unique steady state in which there is recurrent endogenous risk-taking. (The role played by concavity is clarified by considering a special case in which the production function is instead convex, in which there is no persistent risk-taking.) The steady state is fully characterized. It displays features that are consistent with the stylized facts that individuals both insure downside risk and gamble over upside risk, and it generates similar patterns of risk-taking and avoidance across environments with quite different overall wealth levels. Endogenous risk-taking here is generally Pareto-inefficient. A concern for status thus implies that persistent and inefficient risk-taking hinders the attainment of full equality.","['Ray, Debraj', 'Robson, Arthur']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']","Status, Intertemporal Choice, and Risk-Taking",0,0,0,0,0,2012,07,01
80,4,2012-07-01,"We study a dynamic setting in which stochastic information (news) about the value of a privately informed seller's asset is gradually revealed to a market of buyers. We construct an equilibrium that involves periods of no trade or market failure. The no-trade period ends in one of two ways: either enough good news arrives, restoring confidence and markets reopen, or bad news arrives, making buyers more pessimistic and forcing capitulation that is, a partial sell-off of low-value assets. Conditions under which the equilibrium is unique are provided. We analyze welfare and efficiency as they depend on the quality of the news. Higher quality news can lead to more inefficient outcomes. Our model encompasses settings with or without a standard static adverse selection problem--in a dynamic setting with sufficiently informative news, reservation values arise endogenously from the option to sell in the future and the two environments have the same equilibrium structure.","['Green, Brett', 'Daley, Brendan']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Information and Product Quality; Standardization and Compatibility']","['C73', 'D82', 'D83', 'L15']",Waiting for News in the Market for Lemons,1,0,0,0,0,2012,07,01
80,4,2012-07-01,"We analyze subprime consumer lending and the role played by down payment requirements in screening high-risk borrowers and limiting defaults. To do this, we develop an empirical model of the demand for financed purchases that incorporates both adverse selection and repayment incentives. We estimate the model using detailed transaction-level data on subprime auto loans. We show how different elements of loan contracts affect the quality of the borrower pool and subsequent loan performance. We also evaluate the returns to credit scoring that allows sellers to customize financing terms to individual applicants. Our approach shows how standard econometric tools for analyzing demand and supply under imperfect competition extend to settings in which firms care about the identity of their customers and their postpurchase behavior.","['Levin, Jonathan', 'Einav, Liran', 'Jenkins, Mark']","['Model Construction and Estimation', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages']","['C51', 'D82', 'D86', 'G21']",Contract Pricing in Consumer Credit Markets,0,0,0,0,0,2012,07,01
80,4,2012-07-01,"In nonlinear panel data models, the incidental parameter problem remains a challenge to econometricians. Available solutions are often based on ingenious, model-specific methods. In this paper, we propose a systematic approach to construct moment restrictions on common parameters that are free from the individual fixed effects. This is done by an orthogonal projection that differences out the unknown distribution function of individual effects. Our method applies generally in likelihood models with continuous dependent variables where a condition of non-surjectivity holds. The resulting method-of-moments estimators are root-N consistent (for fixed T) and asymptotically normal, under regularity conditions that we spell out. Several examples and a small-scale simulation exercise complete the paper.","['Bonhomme, Stephane']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Functional Differencing,0,0,0,0,0,2012,07,01
80,3,2012-05-01,ECONLIT None Found,[nan],[nan],[nan],2011 Election of Fellows to the Econometric Society.,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"We find that Epstein's (2010) Ellsberg-style thought experiments pose, contrary to his claims, no paradox or difficulty for the smooth ambiguity model of decision making under uncertainty developed by Klibanoff, Marinacci, and Mukerji (2005). Not only are the thought experiments naturally handled by the smooth ambiguity model, but our reanalysis shows that they highlight some of its strengths compared to models such as the maxmin expected utility model (Gilboa and Schmeidler (1989)). In particular, these examples pose no challenge to the model's foundations--interpretation of the model as affording a separation of ambiguity and ambiguity attitude or the potential for calibrating ambiguity attitude in the model.","['Klibanoff, Peter', 'Mukerji, Sujoy', 'Marinacci, Massimo']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],On the Smooth Ambiguity Model: A Reply,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"We study the random Strotz model, a version of the Strotz (1955) model with uncertainty about the nature of the temptation that will strike. We show that the random Strotz representation is unique and characterize a comparative notion of ""more temptation averse."" Also, we demonstrate an unexpected connection between the random Strotz model and a generalization of the Gul-Pesendorfer (GP) (2001) model of temptation which allows for the temptation to be uncertain and which we call random GP. In particular, a preference over menus has a random GP representation if and only if it also has a representation via a random Strotz model with sufficiently smooth uncertainty about the intensity of temptation. We also show that choices of menus combined with choices from menus can distinguish the random GP and random Strotz models.","['Lipman, Barton L.', 'Dekel, Eddie']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Costly Self-Control and Random Self-Indulgence,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"We study the existence of dynamic equilibria with endogenously complete markets in continuous-time, heterogenous agents economies driven by diffusion processes. Our main results show that under appropriate conditions on the transition density of the state variables, market completeness can be deduced from the primitives of the economy. In particular, we prove that a sufficient condition for market completeness is that the volatility of dividends be invertible and provide higher order conditions that apply when this condition fails as is the case in the presence of fixed income securities. In contrast to previous research, our formulation does not require that securities pay terminal dividends, and thus allows for both finite and infinite horizon economies.","['Hugonnier, J.', 'Malamud, S.', 'Trubowitz, E.']","['Exchange and Production Economies', 'General Equilibrium and Disequilibrium: Financial Markets', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Payout Policy']","['D51', 'D53', nan, 'G35']",Endogenous Completeness of Diffusion Driven Equilibrium Markets,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"This paper studies a dynamic model of perfectly competitive price posting under demand uncertainty. Firms must produce output in advance. After observing aggregate sales in prior periods, firms post prices for their unsold output. In each period, the demand of a new batch of consumers is randomly activated. Existing customers who have not yet bought and then new customers arrive at the market in random order, observe the posted prices, and either purchase at the lowest available price or delay their purchase decision. We construct a sequential equilibrium in which the output produced and its allocation across consumers is efficient. Thus consumers endogenously sort themselves efficiently, with the highest valuations purchasing first. Transaction prices in each period rise continuously, as firms become more optimistic about demand, followed by a market correction. By the last period, prices are market clearing.","['Peck, James', 'Deneckere, Raymond']","['Market Structure, Pricing, and Design: Perfect Competition', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['D41', 'L11']",Dynamic Competition with Random Demand and Costless Search: A Theory of Price Posting,1,0,1,0,0,2012,05,01
80,3,2012-05-01,"Checking parameter stability of econometric models is a long-standing problem. Almost all existing structural change tests in econometrics are designed to detect abrupt breaks. Little attention has been paid to smooth structural changes, which may be more realistic in economics. We propose a consistent test for smooth structural changes as well as abrupt structural breaks with known or unknown change points. The idea is to estimate smooth time-varying parameters by local smoothing and compare the fitted values of the restricted constant parameter model and the unrestricted time-varying parameter model. The test is asymptotically pivotal and does not require prior information about the alternative. A simulation study highlights the merits of the proposed test relative to a variety of popular tests for structural changes. In an application, we strongly reject the stability of univariate and multivariate stock return prediction models in the postwar and post-oil-shocks periods.","['Chen, Bin', 'Hong, Yongmiao']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Forecasting Models; Simulation Methods', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C53', 'C58', nan]",Testing for Smooth Structural Changes in Time Series Models via Nonparametric Regression,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"We analyze the identification and estimation of parameters beta satisfying the incomplete linear moment restrictions E(z[top](x beta - y)) = E(z[top]u(z)), where z is a set of instruments and u(z) an unknown bounded scalar function. We first provide empirically relevant examples of such a setup. Second, we show that these conditions set identify beta where the identified set B is bounded and convex. We provide a sharp characterization of the identified set not only when the number of moment conditions is equal to the number of parameters of interest, but also in the case in which the number of conditions is strictly larger than the number of parameters. We derive a necessary and sufficient condition of the validity of supernumerary restrictions which generalizes the familiar Sargan condition. Third, we provide new results on the asymptotics of analog estimates constructed from the identification results. When B is a strictly convex set, we also construct a test of the null hypothesis, beta[subscript 0] is an element of B, whose size is asymptotically correct and which relies on the minimization of the support function of the set B - {beta[subscript 0]}. Results of some Monte Carlo experiments are presented.","['Bontemps, Christian', 'Maurin, Eric', 'Magnac, Thierry']",['Single Equation Models; Single Variables: General'],['C20'],Set Identified Linear Models,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"We introduce and derive the asymptotic behavior of a new measure constructed from high-frequency data which we call the realized Laplace transform of volatility. The statistic provides a nonparametric estimate for the empirical Laplace transform function of the latent stochastic volatility process over a given interval of time and is robust to the presence of jumps in the price process. With a long span of data, that is, under joint long-span and infill asymptotics, the statistic can be used to construct a nonparametric estimate of the volatility Laplace transform as well as of the integrated joint Laplace transform of volatility over different points of time. We derive feasible functional limit theorems for our statistic both under fixed-span and infill asymptotics as well as under joint long-span and infill asymptotics which allow us to quantify the precision in estimation under both sampling schemes.","['Todorov, Viktor', 'Tauchen, George']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Specific Distributions; Specific Statistics', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Contingent Pricing; Futures Pricing; option pricing']","['C22', 'C46', 'C58', nan, 'G13']",The Realized Laplace Transform of Volatility,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"Does switching the composition of jobs between low-paying and high-paying industries have important effects on wages in other sectors? In this paper, we build on search and bargaining theory to clarify a key general equilibrium channel through which changes in industrial composition could have substantial effects on wages in all sectors. In this class of models, wage determination takes the form of a social interaction problem and we illustrate how the implied sectoral linkages can be empirically explored using U.S. Census data. We find that sector-level wages interact as implied by the model and that the predicted general equilibrium effects are present and substantial. We interpret our results as highlighting the relevance of search and bargaining theory for understanding the determination of wages, and we argue that the results provide support for the view that industrial composition is important for understanding wage outcomes.","['Beaudry, Paul', 'Sand, Benjamin', 'Green, David A.']","['Bargaining Theory; Matching Theory', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices']","['C78', 'J31', 'J41', 'L16']",Does Industrial Composition Matter for Wages? A Test of Search and Bargaining Theory,1,0,0,0,0,2012,05,01
80,3,2012-05-01,"The typical cost analysis of an environmental regulation consists of an engineering estimate of the compliance costs. In industries where fixed costs are an important determinant of market structure, this static analysis ignores the dynamic effects of the regulation on entry, investment, and market power. I evaluate the welfare costs of the 1990 Amendments to the Clean Air Act on the U.S. Portland cement industry, accounting for these effects through a dynamic model of oligopoly in the tradition of Ericson and Pakes (1995). Using the two-step estimator of Bajari, Benkard, and Levin (2007), I recover the entire cost structure of the industry, including the distributions of sunk entry costs and capacity adjustment costs. My primary finding is that the Amendments have significantly increased the sunk cost of entry, leading to a loss of between $810 M and $3.2 B in product market surplus. A static analysis misses the welfare penalty on consumers, and obtains the wrong sign of the welfare effects on incumbent firms.","['Ryan, Stephen P.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets', 'Economics of Regulation', 'Metals and Metal Products; Cement; Glass; Ceramics', 'Pollution Control Adoption and Costs; Distributional Effects; Employment Effects', 'Environmental Economics: Government Policy']","['D43', 'L13', 'L51', 'L61', 'Q52', 'Q58']",The Costs of Environmental Regulation in a Concentrated Industry,1,0,1,0,0,2012,05,01
80,3,2012-05-01,"How can price elasticities be identified when agents face optimization frictions such as adjustment costs or inattention? I derive bounds on structural price elasticities that are a function of the observed effect of a price change on demand, the size of the price change, and the degree of frictions. The degree of frictions is measured by the utility losses agents tolerate to deviate from the frictionless optimum. The bounds imply that frictions affect intensive margin elasticities much more than extensive margin elasticities. I apply these bounds to the literature on labor supply. The utility costs of ignoring the tax changes used to identify intensive margin labor supply elasticities are typically less than 1% of earnings. As a result, small frictions can explain the differences between micro and macro elasticities, extensive and intensive margin elasticities, and other disparate findings. Pooling estimates from existing studies, I estimate a Hicksian labor supply elasticity of 0.33 on the intensive margin and 0.25 on the extensive margin after accounting for frictions.","['Chetty, Raj']","['Model Construction and Estimation', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Time Allocation and Labor Supply']","['C51', 'H24', 'H31', 'J22']",Bounds on Elasticities with Optimization Frictions: A Synthesis of Micro and Macro Evidence on Labor Supply,0,0,0,0,0,2012,05,01
80,3,2012-05-01,"I explore the equilibrium value implications of economic models that incorporate responses to a stochastic environment with growth. I propose dynamic valuation decompositions (DVD's) designed to distinguish components of an underlying economic model that influence values over long investment horizons from components that impact only the short run. A DVD represents the values of stochastically growing claims to consumption payoffs or cash flows using a stochastic discount process that both discounts the future and adjusts for risk. It is enabled by constructing operators indexed by the elapsed time between the trading date and the date of the future realization of the payoff. Thus formulated, methods from applied mathematics permit me to characterize valuation behavior and the term structure of risk prices in a revealing manner. I apply this approach to investigate how investor beliefs and the associated uncertainty are reflected in current-period values and risk-price elasticities.","['Hansen, Lars Peter']","['Model Construction and Estimation', 'Financial Econometrics', 'Financial Markets and the Macroeconomy', 'General Financial Markets: General (includes Measurement and Data)']","['C51', 'C58', 'E44', nan]",Dynamic Valuation Decomposition within Stochastic Economies,0,0,0,0,0,2012,05,01
83,2,2015-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 2.,0,0,0,0,0,2015,03,01
83,1,2015-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 83 Iss. 1.,0,0,0,0,0,2015,01,01
83,1,2015-01-01,ECONLIT None Found,"['Ely, Jeffrey C.', 'Andrews, Donald W. K.']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Editors of the Monograph Series,0,0,0,0,0,2015,01,01
82,6,2014-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 6.,0,0,0,0,0,2014,11,01
82,5,2014-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 5.,0,0,0,0,0,2014,09,01
82,4,2014-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 4.,0,0,0,0,0,2014,07,01
82,3,2014-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 3.,0,0,0,0,0,2014,05,01
87,5,2019-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,09,01
87,5,2019-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 5.,0,0,0,0,0,2019,09,01
87,5,2019-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 5.,0,0,0,0,0,2019,09,01
86,4,2018-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 4.,0,0,0,0,0,2018,07,01
86,3,2018-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 3.,0,0,0,0,0,2018,05,01
80,2,2012-03-01,"We report an experiment on effects of varying institutional format and dynamic structure of centipede games and Dutch auctions. Centipede games with a clock format unravel, as predicted by theory but not reported in previous literature on two-player tree-format centipede games. Dutch auctions with a tree format produce bids close to risk neutral Nash equilibrium bids, unlike previous literature on clock-format Dutch auctions. Our data provide a new, expanded set of stylized facts which may provide a foundation for unified modeling of play in a class of games that includes centipede games and Dutch auctions.","['Cox, James C.', 'James, Duncan']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Auctions']","['C73', 'D44']",Clocks and Trees: Isomorphic Dutch Auctions and Centipede Games,0,0,1,0,0,2012,03,01
80,2,2012-03-01,"While vote-buying is common, little is known about how politicians determine who to target. We argue that vote-buying can be sustained by an internalized norm of reciprocity. Receiving money engenders feelings of obligation. Combining survey data on vote-buying with an experiment-based measure of reciprocity, we show that politicians target reciprocal individuals. Overall, our findings highlight the importance of social preferences in determining political behavior.","['Schechter, Laura', 'Finan, Frederico']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D72', 'O17']",Vote-Buying and Reciprocity,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"This paper studies the asymptotic properties of the quasi-maximum likelihood estimator of (generalized autoregressive conditional heteroscedasticity) GARCH(1, 1) models without strict stationarity constraints and considers applications to testing problems. The estimator is unrestricted in the sense that the value of the intercept, which cannot be consistently estimated in the explosive case, is not fixed. A specific behavior of the estimator of the GARCH coefficients is obtained at the boundary of the stationarity region, but, except for the intercept, this estimator remains consistent and asymptotically normal in every situation. The asymptotic variance is different in the stationary and nonstationary situations, but is consistently estimated with the same estimator in both cases. Tests of strict stationarity and nonstationarity are proposed. The tests developed for the classical GARCH(1, 1) model are able to detect nonstationarity in more general GARCH models. A numerical illustration based on stock indices and individual stock returns is proposed.","['Zakoian, Jean-Michel', 'Francq, Christian']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C58', nan]",Strict Stationarity Testing and Estimation of Explosive and Stationary Generalized Autoregressive Conditional Heteroscedasticity Models,0,0,0,0,0,2012,03,01
80,2,2012-03-01,We study mixed hitting-time models that specify durations as the first time a Levy process--a continuous-time process with stationary and independent increments--crosses a heterogeneous threshold. Such models are of substantial interest because they can be deduced from optimal-stopping models with heterogeneous agents that do not naturally produce a mixed proportional hazards structure. We show how strategies for analyzing the identifiability of the mixed proportional hazards model can be adapted to prove identifiability of a hitting-time model with observed covariates and unobserved heterogeneity. We discuss inference from censored data and give examples of structural applications. We conclude by discussing the relative merits of both models as complementary frameworks for econometric duration analysis.,"['Abbring, Jaap H.']",['Duration Analysis; Optimal Timing Strategies'],['C41'],Mixed Hitting-Time Models,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"A large-sample approximation of the posterior distribution of partially identified structural parameters is derived for models that can be indexed by an identifiable finite-dimensional reduced-form parameter vector. It is used to analyze the differences between Bayesian credible sets and frequentist confidence sets. We define a plug-in estimator of the identified set and show that asymptotically Bayesian highest-posterior-density sets exclude parts of the estimated identified set, whereas it is well known that frequentist confidence sets extend beyond the boundaries of the estimated identified set. We recommend reporting estimates of the identified set and information about the conditional prior along with Bayesian credible sets. A numerical illustration for a two-player entry game is provided.","['Schorfheide, Frank', 'Moon, Hyungsik Roger']","['Bayesian Analysis: General', 'Estimation: General']","['C11', 'C13']",Bayesian and Frequentist Inference in Partially Identified Models,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"This paper develops a new estimation procedure for characteristic-based factor models of stock returns. We treat the factor model as a weighted additive nonparametric regression model, with the factor returns serving as time-varying weights and a set of univariate nonparametric functions relating security characteristic to the associated factor betas. We use a time-series and cross-sectional pooled weighted additive nonparametric regression methodology to simultaneously estimate the factor returns and characteristic-beta functions. By avoiding the curse of dimensionality, our methodology allows for a larger number of factors than existing semiparametric methods. We apply the technique to the three-factor Fama-French model, Carhart's four-factor extension of it that adds a momentum factor, and a five-factor extension that adds an own-volatility factor. We find that momentum and own-volatility factors are at least as important, if not more important, than size and value in explaining equity return comovements. We test the multifactor beta pricing theory against a general alternative using a new nonparametric test.","['Connor, Gregory', 'Linton, Oliver', 'Hagmann, Matthias']","['Multiple or Simultaneous Equation Models: Classification Methods; Cluster Analysis; Principal Components; Factor Models', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C38', 'C58', nan]",Efficient Semiparametric Estimation of the Fama-French Model and Extensions,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"This paper investigates the effects of market size on the ability of price to aggregate traders' private information. To account for heterogeneity in correlation of trader values, a Gaussian model of double auction is introduced that departs from the standard information structure based on a common (fundamental) shock. The paper shows that markets are informationally efficient only if correlations of values coincide across all bidder pairs. As a result, with heterogeneously interdependent values, price informativeness may not increase monotonically with market size. As a necessary and sufficient condition for the monotonicity, price informativeness increases with the number of traders if the implied reduction in (the absolute value of) an average correlation statistic of an information structure is sufficiently small.","['Rostek, Marzena', 'Weretka, Marek']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Price Inference in Small Markets,0,0,1,0,0,2012,03,01
80,2,2012-03-01,"We study the question of whether local incentive constraints are sufficient to imply full incentive compatibility in a variety of mechanism design settings, allowing for probabilistic mechanisms. We give a unified approach that covers both continuous and discrete type spaces. On many common preference domains--including any convex domain of cardinal or ordinal preferences, single-peaked ordinal preferences, and successive single-crossing ordinal preferences--local incentive compatibility (suitably defined) implies full incentive compatibility. On domains of cardinal preferences that satisfy a strong nonconvexity condition, local incentive compatibility is not sufficient. Our sufficiency results hold for dominant-strategy and Bayesian Nash solution concepts, and allow for some interdependence in preferences.","['Carroll, Gabriel']",['Asymmetric and Private Information; Mechanism Design'],['D82'],When Are Local Incentive Constraints Sufficient?,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"Weinstein and Yildiz (2007) have shown that in static games, only very weak predictions are robust to perturbations of higher order beliefs. These predictions are precisely those provided by interim correlated rationalizability (ICR). This negative result is obtained under the assumption that agents have no information on payoffs. This assumption is unnatural in many settings. It is therefore natural to ask whether Weinstein and Yildiz's results remain true under more general information structures. This paper characterizes the ""robust predictions"" in static and dynamic games, under arbitrary information structures. This characterization is provided by an extensive form solution concept: interim sequential rationalizability (ISR). In static games, ISR coincides with ICR and does not depend on the assumptions on agents' information. Hence the ""no information"" assumption entails no loss of generality in these settings. This is not the case in dynamic games, where ISR refines ICR and depends on the details of the information structure. In these settings, the robust predictions depend on the assumptions on agents' information. This reveals a hitherto neglected interaction between information and higher order uncertainty, raising novel questions of robustness.","['Penta, Antonio']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D81', 'D83']",Higher Order Uncertainty and Information: Static and Dynamic Games,0,0,0,0,0,2012,03,01
80,2,2012-03-01,"We propose a theory of task trade between countries that have similar relative factor endowments and technological capabilities, but may differ in size. Firms produce differentiated goods by performing a continuum of tasks, each of which generates local spillovers. Tasks can be performed at home or abroad, but offshoring entails costs that vary by task. In equilibrium, the tasks with the highest offshoring costs may not be traded. Among the remainder, those with the relatively higher offshoring costs are performed in the country that has the higher wage and the higher aggregate output. We discuss the relationship between equilibrium wages, equilibrium outputs, and relative country size.","['Grossman, Gene M.', 'Rossi-Hansberg, Esteban']","['Neoclassical Models of Trade', 'Multinational Firms; International Business', 'Transactional Relationships; Contracts and Reputation; Networks', 'Contracting Out; Joint Ventures; Technology Licensing']","['F11', 'F23', 'L14', 'L24']",Task Trade between Similar Countries,1,0,0,0,0,2012,03,01
80,2,2012-03-01,"We propose a novel generalized recursive smooth ambiguity model which permits a three-way separation among risk aversion, ambiguity aversion, and intertemporal substitution. We apply this utility model to a consumption-based asset-pricing model in which consumption and dividends follow hidden Markov regime-switching processes. Our calibrated model can match the mean equity premium, the mean risk-free rate, and the volatility of the equity premium observed in the data. In addition, our model can generate a variety of dynamic asset-pricing phenomena, including the procyclical variation of price-dividend ratios, the countercyclical variation of equity premia and equity volatility, the leverage effect, and the mean reversion of excess returns. The key intuition is that an ambiguity-averse agent behaves pessimistically by attaching more weight to the pricing kernel in bad times when his continuation values are low.","['Miao, Jianjun', 'Ju, Nengjiu']","['Financial Econometrics', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C58', 'D81', 'D83', nan]","Ambiguity, Learning, and Asset Returns",0,0,0,0,0,2012,03,01
80,2,2012-03-01,"It is generally presumed that stronger legal enforcement of lender rights increases credit access for all borrowers because it expands the set of incentive compatible loan contracts. This result relies on an assumption that the supply of credit is infinitely elastic. In contrast, with inelastic supply, stronger enforcement generates general equilibrium effects that may reduce credit access for small borrowers and expand it for wealthy borrowers. In a firm-level panel, we find evidence that an Indian judicial reform that increased banks' ability to recover nonperforming loans had such an adverse distributive impact.","['Visaria, Sujata', 'von Lilienfeld-Toal, Ulf', 'Mookherjee, Dilip']","['Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Business and Securities Law', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['G21', 'G32', 'K22', 'O16', 'O17']",The Distributive Impact of Reforms in Credit Enforcement: Evidence from Indian Debt Recovery Tribunals,0,1,0,0,0,2012,03,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Econometrica Referees 2010-2011.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Secretary.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors 2010-2011.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Treasurer.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"The delta method and continuous mapping theorem are among the most extensively used tools in asymptotic derivations in econometrics. Extensions of these methods are provided for sequences of functions that are commonly encountered in applications and where the usual methods sometimes fail. Important examples of failure arise in the use of simulation-based estimation methods such as indirect inference. The paper explores the application of these methods to the indirect inference estimator (IIE) in first order autoregressive estimation. The IIE uses a binding function that is sample size dependent. Its limit theory relies on a sequence-based delta method in the stationary case and a sequence-based implicit continuous mapping theorem in unit root and local to unity cases. The new limit theory shows that the IIE achieves much more than (partial) bias correction. It changes the limit theory of the maximum likelihood estimator (MLE) when the autoregressive coefficient is in the locality of unity, reducing the bias and the variance of the MLE without affecting the limit theory of the MLE in the stationary case. Thus, in spite of the fact that the IIE is a continuously differentiable function of the MLE, the limit distribution of the IIE is not simply a scale multiple of the MLE, but depends implicitly on the full binding function mapping. The unit root case therefore represents an important example of the failure of the delta method and shows the need for an implicit mapping extension of the continuous mapping theorem.","['Phillips, Peter C. B.']","['Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C13', 'C22']","Folklore Theorems, Implicit Maps, and Indirect Inference",0,0,0,0,0,2012,01,01
80,1,2012-01-01,"We show by example that empirical likelihood and other commonly used tests for moment restrictions are unable to control the (exponential) rate at which the probability of a Type I error tends to zero unless the possible distributions for the observed data are restricted appropriately. From this, it follows that for the optimality claim for empirical likelihood in Kitamura (2001) to hold, additional assumptions and qualifications are required. Under stronger assumptions than those in Kitamura (2001), we establish the following optimality result: (i) empirical likelihood controls the rate at which the probability of a Type I error tends to zero and (ii) among all procedures for which the probability of a Type I error tends to zero at least as fast, empirical likelihood maximizes the rate at which the probability of a Type II error tends to zero for most alternatives. This result further implies that empirical likelihood maximizes the rate at which the probability of a Type II error tends to zero for all alternatives among a class of tests that satisfy a weaker criterion for their Type I error probabilities.","['Shaikh, Azeem M.', 'Kitamura, Yuichi', 'Santos, Andres']",['Hypothesis Testing: General'],['C12'],On the Asymptotic Optimality of Empirical Likelihood for Testing Moment Restrictions,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper analyzes Bayesian normal form games in which players write contracts that condition their actions on the contracts of other players. These contracts are required to be representable in a formal language. This is accomplished by constructing contracts which are definable functions of the Godel code of every other player's contract. We provide a complete characterization of the set of allocations supportable as pure-strategy Bayesian equilibria of this contracting game. When information is complete, this characterization provides a folk theorem. In general, the set of supportable allocations is smaller than the set supportable by a centralized mechanism designer.","['Szentes, Balazs', 'Peters, Michael']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Definable and Contractible Contracts,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"We study matching and coalition formation environments allowing complementarities and peer effects. Agents have preferences over coalitions, and these preferences vary with an underlying, and commonly known, state of nature. Assuming that there is substantial variability of preferences across states of nature, we show that there exists a core stable coalition structure in every state if and only if agents' preferences are pairwise-aligned in every state. This implies that there is a stable coalition structure if agents' preferences are generated by Nash bargaining over coalitional outputs. We further show that all stability-inducing rules for sharing outputs can be represented by a profile of agents' bargaining functions and that agents match assortatively with respect to these bargaining functions. This framework allows us to show how complementarities and peer effects overturn well known comparative statics of many-to-one matching.","['Pycia, Marek']",['Bargaining Theory; Matching Theory'],['C78'],Stability and Preference Alignment in Matching and Coalition Formation,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper studies nonparametric estimation of conditional moment restrictions in which the generalized residual functions can be nonsmooth in the unknown functions of endogenous variables. This is a nonparametric nonlinear instrumental variables (IV) problem. We propose a class of penalized sieve minimum distance (PSMD) estimators, which are minimizers of a penalized empirical minimum distance criterion over a collection of sieve spaces that are dense in the infinite-dimensional function parameter space. Some of the PSMD procedures use slowly growing finite-dimensional sieves with flexible penalties or without any penalty; others use large dimensional sieves with lower semicompact and/or convex penalties. We establish their consistency and the convergence rates in Banach space norms (such as a sup-norm or a root mean squared norm), allowing for possibly noncompact infinite-dimensional parameter spaces. For both mildly and severely ill-posed nonlinear inverse problems, our convergence rates in Hilbert space norms (such as a root mean squared norm) achieve the known minimax optimal rate for the nonparametric mean IV regression. We illustrate the theory with a nonparametric additive quantile IV regression. We present a simulation study and an empirical application of estimating nonparametric quantile IV Engel curves.","['Pouzo, Demian', 'Chen, Xiaohong']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Multiple or Simultaneous Equation Models: Instrumental Variables (IV) Estimation']","['C26', 'C30', 'C36']",Estimation of Nonparametric Conditional Moment Models with Possibly Nonsmooth Generalized Residuals,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper develops methods for hypothesis testing in a nonparametric instrumental variables setting within a partial identification framework. We construct and derive the asymptotic distribution of a test statistic for the hypothesis that at least one element of the identified set satisfies a conjectured restriction. The same test statistic can be employed under identification, in which case the hypothesis is whether the true model satisfies the posited property. An almost sure consistent bootstrap procedure is provided for obtaining critical values. Possible applications include testing for semiparametric specifications as well as building confidence regions for certain functionals on the identified set. As an illustration we obtain confidence intervals for the level and slope of Brazilian fuel Engel curves. A Monte Carlo study examines finite sample performance.","['Santos, Andres']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Inference in Nonparametric Instrumental Variables with Partial Identification,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper examines the problem of testing and confidence set construction for one-dimensional functions of the coefficients in autoregressive (AR(p)) models with potentially persistent time series. The primary example concerns inference on impulse responses. A new asymptotic framework is suggested and some new theoretical properties of known procedures are demonstrated. I show that the likelihood ratio (LR) and LR[superscript +/-] statistics for a linear hypothesis in an AR(p) can be uniformly approximated by a weighted average of local-to-unity and normal distributions. The corresponding weights depend on the weight placed on the largest root in the null hypothesis. The suggested approximation is uniform over the set of all linear hypotheses. The same family of distributions approximates the LR and LR[superscript +/-] statistics for tests about impulse responses, and the approximation is uniform over the horizon of the impulse response. I establish the size properties of tests about impulse responses proposed by Inoue and Kilian (2002) and Gospodinov (2004), and theoretically explain some of the empirical findings of Pesavento and Rossi (2007). An adaptation of the grid bootstrap for impulse response functions is suggested and its properties are examined.","['Mikusheva, Anna']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],One-Dimensional Inference in Autoregressive Models with the Potential Presence of a Unit Root,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper studies the inference of interaction effects in discrete simultaneous games with incomplete information. We propose a test for the signs of state-dependent interaction effects that does not require parametric specifications of players' payoffs, the distributions of their private signals, or the equilibrium selection mechanism. The test relies on the commonly invoked assumption that players' private signals are independent conditional on observed states. The procedure is valid in (but does not rely on) the presence of multiple equilibria in the data-generating process (DGP). As a by-product, we propose a formal test for multiple equilibria in the DGP. We also implement the test using data on radio programming of commercial breaks in the United States, and infer stations' incentives to synchronize their commercial breaks. Our results support the earlier finding by Sweeting (2009) that stations have stronger incentives to coordinate and air commercials at the same time during rush hours and in smaller markets.","['Tang, Xun', 'de Paula, Aureo']","['Model Construction and Estimation', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C51', 'C73', 'D83']",Inference of Signs of Interaction Effects in Simultaneous Games with Incomplete Information,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"We study elections that simultaneously decide multiple issues, where voters have independent private values over bundles of issues. The innovation is in considering nonseparable preferences, where issues may be complements or substitutes. Voters face a political exposure problem: the optimal vote for a particular issue will depend on the resolution of the other issues. Moreover, the probabilities that the other issues will pass should be conditioned on being pivotal. We prove that equilibrium exists when distributions over values have full support or when issues are complements. We then study large elections with two issues. There exists a nonempty open set of distributions where the probability of either issue passing fails to converge to either 1 or 0 for all limit equilibria. Thus, the outcomes of large elections are not generically predictable with independent private values, despite the fact that there is no aggregate uncertainty regarding fundamentals. While the Condorcet winner is not necessarily the outcome of a multi-issue election, we provide sufficient conditions that guarantee the implementation of the Condorcet winner.","['Oliveros, Santiago', 'Ahn, David S.']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Combinatorial Voting,0,0,0,0,0,2012,01,01
80,1,2012-01-01,"This paper shows that information imperfections and common values can solve coordination problems in multicandidate elections. We analyze an election in which (i) the majority is divided between two alternatives and (ii) the minority backs a third alternative, which the majority views as strictly inferior. Standard analyses assume voters have a fixed preference ordering over candidates. Coordination problems cannot be overcome in such a case, and it is possible that inferior candidates win. In our setup, the majority is also divided as a result of information imperfections. The majority thus faces two problems: aggregating information and coordinating to defeat the minority candidate. We show that when the common value component is strong enough, approval voting produces full information and coordination equivalence: the equilibrium is unique and solves both problems. Thus, the need for information aggregation helps resolve the majority's coordination problem under approval voting. This is not the case under standard electoral systems.","['Castanheira, Micael', 'Bouton, Laurent']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D72', 'D83']","One Person, Many Votes: Divided Majority and Information Aggregation",0,0,0,0,0,2012,01,01
80,1,2012-01-01,"The standard dual-self model of self-control, with a shorter-run self who cares only about the current period, is excessively sensitive to the timing of decisions and to the interpolation of additional ""no-action"" time periods in between the dates when decisions are made. We show that when the shorter-run self is not completely myopic, this excess sensitivity goes away. To accommodate the combination of short time periods and convex costs of self-control, we introduce a cognitive resource variable that tracks how the control cost depends on the self-control that has been used in the recent past. We consider models with both linear and convex control costs, illustrating the theory through a series of examples. We examine when opportunities to consume will be avoided or delayed, and we consider the way in which the marginal interest declines with delay.","['Fudenberg, Drew', 'Levine, David K.']","['Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making', 'Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D91', 'D11', 'D81', 'D15']",Timing and Self-Control,0,0,0,0,0,2012,01,01
79,6,2011-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 79 Iss. 6.,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"This paper studies dynamic identification of parameters of a dynamic stochastic general equilibrium model from the first and second moments of the data. Classical results for dynamic simultaneous equations do not apply because the state space solution of the model does not constitute a standard reduced form. Full rank of the Jacobian matrix of derivatives of the solution parameters with respect to the parameters of interest is necessary but not sufficient for identification. We use restrictions implied by observational equivalence to obtain two sets of rank and order conditions: one for stochastically singular models and another for nonsingular models. Measurement errors, mean, long-run, and priori restrictions can be accommodated. An example is considered to illustrate the results.","['Ng, Serena', 'Komunjer, Ivana']","['General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'General Aggregative Models: Neoclassical']","[nan, 'E13']",Dynamic Identification of Dynamic Stochastic General Equilibrium Models,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"This paper examines repeated implementation of a social choice function (SCF) with infinitely lived agents whose preferences are determined randomly in each period. An SCF is repeatedly implementable in Nash equilibrium if there exists a sequence of (possibly history-dependent) mechanisms such that its Nash equilibrium set is nonempty and every equilibrium outcome path results in the desired social choice at every possible history of past play and realizations of uncertainty. We show, with minor qualifications, that in the complete information environment an SCF is repeatedly implementable in Nash equilibrium if and only if it is efficient. We also discuss several extensions of our analysis.","['Sabourian, Hamid', 'Lee, Jihong']","['Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D71', 'D82']",Efficient Repeated Implementation,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"A finite number of sellers (n) compete in schedules to supply an elastic demand. The cost of each seller is random, with common and private value components, and the seller receives a private signal about it. A Bayesian supply function equilibrium is characterized: The equilibrium is privately revealing and the incentives to rely on private signals are preserved. Supply functions are steeper with higher correlation among the cost parameters. For high (positive) correlation, supply functions are downward sloping, price is above the Cournot level, and as we approach the common value case, price tends to the collusive level. As correlation becomes maximally negative, we approach the competitive outcome. With positive correlation, private information coupled with strategic behavior induces additional distortionary market power above full information levels. Efficiency can be restored with appropriate subsidy schemes or with a precise enough public signal about the common value component. As the market grows large with the number of sellers, the equilibrium becomes price-taking, bid shading is on the order of 1/n, and the order of magnitude of welfare losses is 1/n[superscript 2]. The results extend to inelastic demand, demand uncertainty, and demand schedule competition. A range of applications in product and financial markets is presented.","['Vives, Xavier']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Auctions', 'Exchange and Production Economies', 'General Equilibrium and Disequilibrium: Financial Markets', 'Asymmetric and Private Information; Mechanism Design', 'Expectations; Speculations']","['D43', 'D44', 'D51', 'D53', 'D82', 'D84']",Strategic Supply Function Competition with Private Information,0,0,1,0,0,2011,11,01
79,6,2011-11-01,"A seller can trade an endowment of a perfectly divisible good, the quality of which she privately knows. Buyers compete by offering menus of nonexclusive contracts, so that the seller can privately trade with several buyers. In this setting, we show that an equilibrium exists under mild conditions and that aggregate equilibrium allocations are generically unique. Although the good for sale is divisible, in equilibrium the seller ends up trading her whole endowment or not trading at all. Trades take place at a price equal to the expected quality of the good, conditional on the seller being ready to trade at that price. Our model thus provides a novel strategic foundation for Akerlof's (1970) results. It also contrasts with competitive screening models in which contracts are assumed to be exclusive, as in Rothschild and Stiglitz (1976). Latent contracts that are issued but not traded in equilibrium play an important role in our analysis.","['Salanie, Francois', 'Mariotti, Thomas', 'Attar, Andrea']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Information and Product Quality; Standardization and Compatibility']","['D82', 'D86', 'L15']",Nonexclusive Competition in the Market for Lemons,1,0,0,0,0,2011,11,01
79,6,2011-11-01,"We adapt the expectation-maximization algorithm to incorporate unobserved heterogeneity into conditional choice probability (CCP) estimators of dynamic discrete choice problems. The unobserved heterogeneity can be time-invariant or follow a Markov chain. By developing a class of problems where the difference in future value terms depends on a few conditional choice probabilities, we extend the class of dynamic optimization problems where CCP estimators provide a computationally cheap alternative to full solution methods. Monte Carlo results confirm that our algorithms perform quite well, both in terms of computational time and in the precision of the parameter estimates.","['Arcidiacono, Peter', 'Miller, Robert A.']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],Conditional Choice Probability Estimation of Dynamic Discrete Choice Models with Unobserved Heterogeneity,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"We provide a tractable characterization of the sharp identification region of the parameter vector theta in a broad class of incomplete econometric models. Models in this class have set-valued predictions that yield a convex set of conditional or unconditional moments for the observable model variables. In short, we call these models with convex moment predictions. Examples include static, simultaneous-move finite games of complete and incomplete information in the presence of multiple equilibria; best linear predictors with interval outcome and covariate data; and random utility models of multinomial choice in the presence of interval regressors data. Given a candidate value for theta, we establish that the convex set of moments yielded by the model predictions can be represented as the Aumann expectation of a properly defined random set. The sharp identification region of theta, denoted Theta[subscript I], can then be obtained as the set of minimizers of the distance from a properly specified vector of moments of random variables to this Aumann expectation. Algorithms in convex programming can be exploited to efficiently verify whether a candidate theta is in Theta[subscript I]. We use examples analyzed in the literature to illustrate the gains in identification and computational tractability afforded by our method.","['Molchanov, Ilya', 'Beresteanu, Arie', 'Molinari, Francesca']","['Econometric and Statistical Methods and Methodology: General', 'Forecasting Models; Simulation Methods', 'Optimization Techniques; Programming Models; Dynamic Analysis', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C10', 'C53', 'C61', 'C73']",Sharp Identification Regions in Models with Convex Moment Predictions,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"We propose a new and flexible nonparametric framework for estimating the jump tails of Ito semimartingale processes. The approach is based on a relatively simple-to-implement set of estimating equations associated with the compensator for the jump measure, or its intensity, that only utilizes the weak assumption of regular variation in the jump tails, along with in-fill asymptotic arguments for directly estimating the ""large"" jumps. The procedure assumes that the large-sized jumps are identically distributed, but otherwise allows for very general dynamic dependencies in jump occurrences, and, importantly, does not restrict the behavior of the ""small"" jumps or the continuous part of the process and the temporal variation in the stochastic volatility. On implementing the new estimation procedure with actual high-frequency data for the S&P 500 aggregate market portfolio, we find strong evidence for richer and more complex dynamic dependencies in the jump tails than hitherto entertained in the literature.","['Todorov, Viktor', 'Bollerslev, Tim']","['Financial Econometrics', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C58', 'G11', nan]",Estimation of Jump Tails,0,0,0,0,0,2011,11,01
79,6,2011-11-01,"The increase in female employment and participation rates is one of the most dramatic changes to have taken place in the economy during the last century. However, while the employment rate of married women more than doubled during the last 50 years, that of unmarried women remained almost constant. To empirically analyze these trends, we estimate a female dynamic labor supply model using an extended version of Eckstein and Wolpin (1989) to compare the various explanations in the literature for the observed trends. This dynamic model provides a much better fit to the life-cycle employment pattern than a static version of the model and a standard static reduced form model (Heckman (1979)). The main finding using the dynamic model is that the rise in education levels accounts for about 33 percent of the increase in female employment, and the rise in wages and narrowing of the gender wage gap account for another 20 percent, while about 40 percent remains unexplained by observed household characteristics. We show that this unexplained portion can be empirically attributed to cohort-specific changes in preferences or the costs of child-rearing and household maintenance. Finally, the decline in fertility and the increase in divorce rates account for only a small share of the increase in female employment rates.","['Lifshitz, Osnat', 'Eckstein, Zvi']","['Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['J13', 'J16', 'J22', 'J24', 'J31']",Dynamic Female Labor Supply,0,0,0,0,0,2011,11,01
79,5,2011-09-01,ECONLIT None Found,"['Mooe, John']",[nan],[nan],The Econometric Society 2010 Annual Report of the President.,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"We provide a pure Nash equilibrium existence theorem for games with discontinuous payoffs whose hypotheses are in a number of ways weaker than those of the theorem of Reny (1999). In comparison with Reny's argument, our proof is brief. Our result subsumes a prior existence result of Reny (1999) that is not covered by his theorem. We use the main result to prove the existence of pure Nash equilibrium in a class of finite games in which agents' pure strategies are subsets of a given set, and in turn use this to prove the existence of stable configurations for games, similar to those used by Schelling (1971, 1972) to study residential segregation, in which agents choose locations.","['Tourky, Rabee', 'McLennan, Andrew', 'Monteiro, Paulo K.']",['Noncooperative Games'],['C72'],Games with Discontinuous Payoffs: A Strengthening of Reny's Existence Theorem,0,0,0,0,0,2011,09,01
79,5,2011-09-01,We introduce entropy techniques to study the classical reputation model in which a long-run player faces a series of short-run players. The long-run player's actions are possibly imperfectly observed. We derive explicit lower and upper bounds on the equilibrium payoffs to the long-run player.,"['Gossner, Olivier']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Simple Bounds on the Value of a Reputation,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"It is common for a majority of people to rank themselves as better than average on simple tasks and worse than average on difficult tasks. The literature takes for granted that this apparent misconfidence is problematic. We argue, however, that this behavior is consistent with purely rational Bayesian updaters. In fact, better-than-average data alone cannot be used to show overconfidence; we indicate which type of data can be used. Our theory is consistent with empirical patterns found in the literature.","['Dubra, Juan', 'Benoit, Jean-Pierre']","['Micro-Based Behavioral Economics: Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D91', 'D83']",Apparent Overconfidence,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"The coefficient of relative risk aversion is a key parameter for analyses of behavior toward risk, but good estimates of this parameter do not exist. A promising place for reliable estimation is rare macroeconomic disasters, which have a major influence on the equity premium. The premium depends on the probability and size distribution of disasters, gauged by proportionate declines in per capita consumption or gross domestic product. Long-term national-accounts data for 36 countries provide a large sample of disasters of magnitude 10% or more. A power-law density provides a good fit to the size distribution, and the upper-tail exponent, alpha, is estimated to be around 4. A higher alpha signifies a thinner tail and, therefore, a lower equity premium, whereas a higher coefficient of relative risk aversion, gamma, implies a higher premium. The premium is finite if alpha > gamma. The observed premium of 5% generates an estimated gamma close to 3, with a 95% confidence interval of 2 to 4. The results are robust to uncertainty about the values of the disaster probability and the equity premium, and can accommodate seemingly paradoxical situations in which the equity premium may appear to be infinite.","['Jin, Tao', 'Barro, Robert J.']","['Specific Distributions; Specific Statistics', 'Criteria for Decision-Making under Risk and Uncertainty', 'General Aggregative Models: Neoclassical', 'Macroeconomics: Production', 'Business Fluctuations; Cycles', 'Financial Markets and the Macroeconomy']","['C46', 'D81', 'E13', 'E23', 'E32', 'E44']",On the Size Distribution of Macroeconomic Disasters,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"The focus of this paper is the nonparametric estimation of an instrumental regression function phi defined by conditional moment restrictions that stem from a structural econometric model E[Y - phi(Z)|W] = 0, and involve endogenous variables Y and Z and instruments W. The function phi is the solution of an ill-posed inverse problem and we propose an estimation procedure based on Tikhonov regularization. The paper analyzes identification and overidentification of this model, and presents asymptotic properties of the estimated nonparametric instrumental regression function.","['Darolles, S.', 'Florens, J. P.', 'Renault, E.', 'Fan, Y.']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Multiple or Simultaneous Equation Models: Instrumental Variables (IV) Estimation']","['C26', 'C36']",Nonparametric Instrumental Regression,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"This paper studies the nonparametric identification of a contract model with adverse selection and moral hazard. Specifically, we consider the false moral hazard model developed by Laffont and Tirole (1986). We first extend this model to allow for general random demand and cost functions. We establish the nonparametric identification of the demand, cost, deterministic transfer, and effort disutility functions as well as the joint distribution of the random elements of the model, which are the firm's type and the demand, cost, and transfer shocks. The cost of public funds is identified with the help of an instrument. Testable restrictions of the model are characterized.","['Vuong, Quang', 'Perrigne, Isabelle']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Nonparametric Identification of a Contract Model with Adverse Selection and Moral Hazard,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"We examine the sales of French manufacturing firms in 113 destinations, including France itself. Several regularities stand out: (i) the number of French firms selling to a market, relative to French market share, increases systematically with market size; (ii) sales distributions are similar across markets of very different size and extent of French participation; (iii) average sales in France rise systematically with selling to less popular markets and to more markets. We adopt a model of firm heterogeneity and export participation which we estimate to match moments of the French data using the method of simulated moments. The results imply that over half the variation across firms in market entry can be attributed to a single dimension of underlying firm heterogeneity: efficiency. Conditional on entry, underlying efficiency accounts for much less of the variation in sales in any given market. We use our results to simulate the effects of a 10 percent counterfactual decline in bilateral trade barriers on French firms. While total French sales rise by around $16 billion (U.S.), sales by the top decile of firms rise by nearly $23 billion (U.S.). Every lower decile experiences a drop in sales, due to selling less at home or exiting altogether.","['Eaton, Jonathan', 'Kortum, Samuel', 'Kramarz, Francis']","['Model Construction and Estimation', 'Trade Policy; International Trade Organizations', 'Empirical Studies of Trade', 'Multinational Firms; International Business', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Industry Studies: Manufacturing: General']","['C51', 'F13', 'F14', 'F23', 'L11', 'L60']",An Anatomy of International Trade: Evidence from French Firms,1,0,0,0,0,2011,09,01
79,5,2011-09-01,"This paper studies whether removing barriers to trade induces efficiency gains for producers. Like almost all empirical work which relies on a production function to recover productivity measures, I do not observe physical output at the firm level. Therefore, it is imperative to control for unobserved prices and demand shocks. I develop an empirical model that combines a demand system with a production function to generate estimates of productivity. I rely on my framework to identify the productivity effects from reduced trade protection in the Belgian textile market. This trade liberalization provides me with observed demand shifters that are used to separate out the associated price, scale, and productivity effects. Using a matched plant-product level data set and detailed quota data, I find that correcting for unobserved prices leads to substantially lower productivity gains. More specifically, abolishing all quota protections increases firm-level productivity by only 2 percent as opposed to 8 percent when relying on standard measures of productivity. My results beg for a serious reevaluation of a long list of empirical studies that document productivity responses to major industry shocks and, in particular, to opening up to trade. My findings imply the need to study the impact of changes in the operating environment on productivity together with market power and prices in one integrated framework. The suggested method and identification strategy are quite general and can be applied whenever it is important to distinguish between revenue productivity and physical productivity.","['De Loecker, Jan']","['Model Construction and Estimation', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Trade Policy; International Trade Organizations', 'Other Consumer Nondurables: Clothing, Textiles, Shoes, and Leather Goods; Household Goods; Sports Equipment']","['C51', 'D24', 'F13', 'L67']","Product Differentiation, Multiproduct Firms, and Estimating the Impact of Trade Liberalization on Productivity",1,0,0,0,0,2011,09,01
79,5,2011-09-01,"This paper uses a structural model to understand, predict, and evaluate the impact of an exogenous microcredit intervention program, the Thai Million Baht Village Fund program. We model household decisions in the face of borrowing constraints, income uncertainty, and high-yield indivisible investment opportunities. After estimation of parameters using preprogram data, we evaluate the model's ability to predict and interpret the impact of the village fund intervention. Simulations from the model mirror the data in yielding a greater increase in consumption than credit, which is interpreted as evidence of credit constraints. A cost-benefit analysis using the model indicates that some households value the program much more than its per household cost, but overall the program costs 30 percent more than the sum of these benefits.","['Kaboski, Joseph P.', 'Townsend, Robert M.']","['Model Construction and Estimation', 'Allocative Efficiency; Cost-Benefit Analysis', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Microeconomic Analyses of Economic Development', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure']","['C51', 'D61', 'G21', 'O12', 'O16', 'O18']",A Structural Evaluation of Large-Scale Quasi-experimental Microfinance Initiative,0,0,0,0,0,2011,09,01
79,5,2011-09-01,"Postel-Vinay and Robin's (2002) sequential auction model is extended to allow for aggregate productivity shocks. Workers exhibit permanent differences in ability while firms are identical. Negative aggregate productivity shocks induce job destruction by driving the surplus of matches with low ability workers to negative values. Endogenous job destruction coupled with worker heterogeneity thus provides a mechanism for amplifying productivity shocks that offers an original solution to the unemployment volatility puzzle (Shimer (2005)). Moreover, positive or negative shocks may lead employers and employees to renegotiate low wages up and high wages down when agents' individual surpluses become negative. The model delivers rich business cycle dynamics of wage distributions and explains why both low wages and high wages are more procyclical than wages in the middle of the distribution.","['Robin, Jean-Marc']","['Model Construction and Estimation', 'Auctions', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Unemployment: Models, Duration, Incidence, and Job Search']","['C51', 'D44', 'E24', 'J31', 'J64']",On the Dynamics of Unemployment and Wage Distributions,0,0,1,0,0,2011,09,01
79,4,2011-07-01,"We present an algorithm to compute the set of perfect public equilibrium payoffs as the discount factor tends to 1 for stochastic games with observable states and public (but not necessarily perfect) monitoring when the limiting set of (long-run players') equilibrium payoffs is independent of the initial state. This is the case, for instance, if the Markov chain induced by any Markov strategy profile is irreducible. We then provide conditions under which a folk theorem obtains: if in each state the joint distribution over the public signal and next period's state satisfies some rank condition, every feasible payoff vector above the minmax payoff is sustained by a perfect public equilibrium with low discounting.","['Vieille, Nicolas', 'Sugaya, Takuo', 'Horner, Johannes', 'Takahashi, Satoru']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Recursive Methods in Discounted Stochastic Games: An Algorithm for Delta -> 1 and a Folk Theorem,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"This paper studies the design of optimal contracts in dynamic environments where agents have private information that is persistent. In particular, I focus on a continuous-time version of a benchmark insurance problem where a risk-averse agent would like to borrow from a risk-neutral lender to stabilize his utility. The agent privately observes a persistent state variable, typically either income or a taste shock, and he makes reports to the principal. I give verifiable sufficient conditions showing that incentive-compatible contracts can be written recursively, conditioning on the report and two additional state variables: the agent's promised utility and promised marginal utility of the private state. I then study two examples where the optimal contracts can be solved in closed form, showing how persistence alters the nature of the contract. Unlike the previous discrete-time models with independent and identically distributed (i.i.d.) private information, the agent's consumption under the contract may grow over time. Furthermore, in my setting the efficiency losses due to private information increase with the persistence of the private information, and the distortions vanish as I approximate an i.i.d. environment.","['Williams, Noah']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Persistent Private Information,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"In this paper, we introduce the extended method of moments (XMM) estimator. This estimator accommodates a more general set of moment restrictions than the standard generalized method of moments (GMM) estimator. More specifically, the XMM differs from the GMM in that it can handle not only uniform conditional moment restrictions (i.e., valid for any value of the conditioning variable), but also local conditional moment restrictions valid for a given fixed value of the conditioning variable. The local conditional moment restrictions are of special relevance in derivative pricing to reconstruct the pricing operator on a given day by using the information in a few cross sections of observed traded derivative prices and a time series of underlying asset returns. The estimated derivative prices are consistent for a large time series dimension, but a fixed number of cross sectionally observed derivative prices. The asymptotic properties of the XMM estimator are nonstandard, since the combination of uniform and local conditional moment restrictions induces different rates of convergence (parametric and nonparametric) for the parameters.","['Renault, E.', 'Gagliardini, P.', 'Gourieroux, C.']","['Financial Econometrics', 'Contingent Pricing; Futures Pricing; option pricing']","['C58', 'G13']",Efficient Derivative Pricing by the Extended Method of Moments,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"Golosov and Lucas recently argued that a menu-cost model, when made consistent with salient features of the microdata, predicts approximate monetary neutrality. I argue here that their model misses, in fact, two important features of the data. First, the distribution of the size of price changes in the data is very dispersed. Second, in the data many price changes are temporary. I study an extension of the simple menu-cost model to a multiproduct setting in which firms face economies of scope in adjusting posted and regular prices. The model, because of its ability to replicate this additional set of microeconomic facts, predicts real effects of monetary policy shocks that are much greater than those in Golosov and Lucas and nearly as large as those in the Calvo model. Although episodes of sales account for roughly 40% of all goods sold in retail stores, the model predicts that these episodes do not contribute much to the flexibility of the aggregate price level.","['Midrigan, Virgiliu']","['General Aggregative Models: Neoclassical', 'Price Level; Inflation; Deflation', 'Business Fluctuations; Cycles', 'Monetary Policy']","['E13', 'E31', 'E32', 'E52']","Menu Costs, Multiproduct Firms, and Aggregate Fluctuations",0,0,0,0,0,2011,07,01
79,4,2011-07-01,"One of the most dramatic economic transformations of the past century has been the entry of women into the labor force. While many theories explain why this change took place, we investigate the process of transition itself. We argue that local information transmission generates changes in participation that are geographically heterogeneous, locally correlated, and smooth in the aggregate, just like those observed in our data. In our model, women learn about the effects of maternal employment on children by observing nearby employed women. When few women participate in the labor force, data are scarce and participation rises slowly. As information accumulates in some regions, the effects of maternal employment become less uncertain and more women in that region participate. Learning accelerates, labor force participation rises faster, and regional participation rates diverge. Eventually, information diffuses throughout the economy, beliefs converge to the truth, participation flattens out, and regions become more similar again. To investigate the empirical relevance of our theory, we use a new county-level data set to compare our calibrated model to the time series and geographic patterns of participation.","['Fogli, Alessandra', 'Veldkamp, Laura']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['D83', 'J16', 'J22']",Nature or Nurture? Learning and the Geography of Female Labor Force Participation,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"The standard gravity model predicts that trade flows increase in proportion to importer and exporter total income, regardless of how income is divided into income per capita and population. Bilateral trade data, however, show that trade grows strongly with income per capita and is largely unresponsive to population. I develop a general equilibrium Ricardian model of trade that allows the elasticity of trade with respect to income per capita and with respect to population to diverge. Goods are of various types, which differ in their income elasticity of demand and in the extent to which there is heterogeneity in their production technologies. I estimate the model using bilateral trade data of 162 countries and compare it to a special case that delivers the gravity equation. The general model improves the restricted model's predictions regarding variations in trade due to size and income. I experiment with counterfactuals. A positive technology shock in China makes poor and rich countries better off and middle-income countries worse off.","['Fieler, Ana Cecilia']","['Neoclassical Models of Trade', 'Trade Policy; International Trade Organizations', 'Empirical Studies of Trade']","['F11', 'F13', 'F14']",Nonhomotheticity and Bilateral Trade: Evidence and a Quantitative Explanation,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"We study testable implications for the dynamics of consumption and income of models in which first-best allocations are not achieved because of a moral hazard problem with hidden saving. We show that in this environment, agents typically achieve more insurance than that obtained under self-insurance with a single asset. Consumption allocations exhibit ""excess smoothness,"" as found and defined by Campbell and Deaton (1989). We argue that excess smoothness, in this context, is equivalent to a violation of the intertemporal budget constraint considered in a Bewley economy (with a single asset). We also show parameterizations of our model in which we can obtain a closed-form solution for the efficient insurance contract and where the excess smoothness parameter has a structural interpretation in terms of the severity of the moral hazard problem. We present tests of excess smoothness, applied to U.K. microdata and constructed using techniques proposed by Hansen, Roberds, and Sargent (1991) to test the intertemporal budget constraint. Our theoretical model leads us to interpret them as tests of the market structure faced by economic agents. We also construct a test based on the dynamics of the cross-sectional variances of consumption and income that is, in a precise sense, complementary to that based on Hansen, Roberds, and Sargent (1991) and that allows us to estimate the same structural parameter. The results we report are consistent with the implications of the model and are internally coherent.","['Pavoni, Nicola', 'Attanasio, Orazio P.']","['Asymmetric and Private Information; Mechanism Design', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'General Aggregative Models: Neoclassical', 'Macroeconomics: Consumption; Saving; Wealth']","['D82', 'D15', 'E13', 'E21']",Risk Sharing in Private Information Models with Asset Accumulation: Explaining the Excess Smoothness of Consumption,0,0,0,0,0,2011,07,01
79,4,2011-07-01,"Rational herd behavior and informationally efficient security prices have long been considered to be mutually exclusive but for exceptional cases. In this paper we describe the conditions on the underlying information structure that are necessary and sufficient for informational herding and contrarianism. In a standard sequential security trading model, subject to sufficient noise trading, people herd if and only if, loosely, their information is sufficiently dispersed so that they consider extreme outcomes more likely than moderate ones. Likewise, people act as contrarians if and only if their information leads them to concentrate on middle values. Both herding and contrarianism generate more volatile prices, and they lower liquidity. They are also resilient phenomena, although by themselves herding trades are self-enforcing whereas contrarian trades are self-defeating. We complete the characterization by providing conditions for the absence of herding and contrarianism.","['Sabourian, Hamid', 'Park, Andreas']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D83', nan]",Herding and Contrarian Behavior in Financial Markets,0,0,0,0,0,2011,07,01
79,3,2011-05-01,ECONLIT None Found,[nan],[nan],[nan],2010 ELECTION OF FELLOWS TO THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2011,05,01
79,3,2011-05-01,ECONLIT None Found,"['LEVIN, JONATHAN']",[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"This paper studies the special case of the triangular system of equations in Vytlacil and Yildiz (2007), where both dependent variables are binary but without imposing the restrictive support condition required by Vytlacil and Yildiz (2007) for identification of the average structural function (ASF) and the average treatment effect (ATE). Under weak regularity conditions, we derive upper and lower bounds on the ASF and the ATE. We show further that the bounds on the ASF and ATE are sharp under some further regularity conditions and an additional restriction on the support of the covariates and the instrument.","['Vytlacil, Edward J.', 'Shaikh, Azeem M.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions']","['C21', 'C24', 'C25', 'C35']",Partial Identification in Triangular Systems of Equations with Binary Dependent Variables,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"We show that democratic change may be triggered by transitory economic shocks. Our approach uses within-country variation in rainfall as a source of transitory shocks to sub-Saharan African economies. We find that negative rainfall shocks are followed by significant improvement in democratic institutions. This result is consistent with the economic approach to political transitions, where transitory negative shocks can open a window of opportunity for democratic improvement. Instrumental variables estimates indicate that following a transitory negative income shock of 1 percent, democracy scores improve by 0.9 percentage points and the probability of a democratic transition increases by 1.3 percentage points.","['Ciccone, Antonio', 'Bruckner, Markus']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Renewable Resources and Conservation: Water']","['D72', 'O17', 'Q25']",Rain and the Democratic Window of Opportunity,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"We study the effects of deliberation on collective decisions. In a series of experiments, we vary groups' preference distributions (between common and conflicting interests) and the institutions by which decisions are reached (simple majority, two-thirds majority, and unanimity). Without deliberation, different institutions generate significantly different outcomes, tracking the theoretical comparative statics. Deliberation, however, significantly diminishes institutional differences and uniformly improves efficiency. Furthermore, communication protocols exhibit an array of stable attributes: messages are public, consistently reveal private information, provide a good predictor for ultimate group choices, and follow particular (endogenous) sequencing.","['Goeree, Jacob K.', 'Yariv, Leeat']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",An Experimental Study of Collective Deliberation,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"Repeated games with imperfect private monitoring have a wide range of applications, but a complete characterization of all equilibria in this class of games has yet to be obtained. The existing literature has identified a relatively tractable subset of equilibria. The present paper introduces the notion of weakly belief-free equilibria for repeated games with imperfect private monitoring. This is a tractable class which subsumes, as a special case, a major part of the existing literature (the belief-free equilibria). It is shown that this class can outperform the equilibria identified by the previous work.","['Kandori, Michihiro']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Weakly Belief-Free Equilibria in Repeated Games with Private Monitoring,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"We study reputation dynamics in continuous-time games in which a large player (e.g., government) faces a population of small players (e.g., households) and the large player's actions are imperfectly observable. The major part of our analysis examines the case in which public signals about the large player's actions are distorted by a Brownian motion and the large player is either a normal type, who plays strategically, or a behavioral type, who is committed to playing a stationary strategy. We obtain a clean characterization of sequential equilibria using ordinary differential equations and identify general conditions for the sequential equilibrium to be unique and Markovian in the small players' posterior belief. We find that a rich equilibrium dynamics arises when the small players assign positive prior probability to the behavioral type. By contrast, when it is common knowledge that the large player is the normal type, every public equilibrium of the continuous-time game is payoff-equivalent to one in which a static Nash equilibrium is played after every history. Finally, we examine variations of the model with Poisson signals and multiple behavioral types.","['Faingold, Eduardo', 'Sannikov, Yuliy']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Reputation in Continuous-Time Games,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"This paper proposes that idiosyncratic firm-level shocks can explain an important part of aggregate movements and provide a microfoundation for aggregate shocks. Existing research has focused on using aggregate shocks to explain business cycles, arguing that individual firm shocks average out in the aggregate. I show that this argument breaks down if the distribution of firm sizes is fat-tailed, as documented empirically. The idiosyncratic movements of the largest 100 firms in the United States appear to explain about one-third of variations in output growth. This ""granular"" hypothesis suggests new directions for macroeconomic research, in particular that macroeconomic questions can be clarified by looking at the behavior of large firms. This paper's ideas and analytical results may also be useful for thinking about the fluctuations of other economic aggregates, such as exports or the trade balance.","['Gabaix, Xavier']","['Macroeconomics: Production', 'Business Fluctuations; Cycles', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['E23', 'E32', 'L11']",The Granular Origins of Aggregate Fluctuations,1,0,0,0,0,2011,05,01
79,3,2011-05-01,"This paper provides an empirical analysis of the effects of employer-provided health insurance, Medicare, and Social Security on retirement behavior. Using data from the Health and Retirement Study, we estimate a dynamic programming model of retirement that accounts for both saving and uncertain medical expenses. Our results suggest that Medicare is important for understanding retirement behavior, and that uncertainty and saving are both important for understanding the labor supply responses to Medicare. Half the value placed by a typical worker on his employer-provided health insurance is the value of reduced medical expense risk. Raising the Medicare eligibility age from 65 to 67 leads individuals to work an additional 0.074 years over ages 60-69. In comparison, eliminating 2 years worth of Social Security benefits increases years of work by 0.076 years.","['French, Eric', 'Jones, John Bailey']","['Consumer Economics: Empirical Analysis', 'Social Security and Public Pensions', 'Health: Government Policy; Regulation; Public Health', 'Time Allocation and Labor Supply', 'Retirement; Retirement Policies', 'Nonwage Labor Costs and Benefits; Retirement Plans; Private Pensions']","['D12', 'H55', 'I18', 'J22', 'J26', 'J32']",The Effects of Health Insurance and Self-Insurance on Retirement Behavior,0,0,0,0,0,2011,05,01
79,3,2011-05-01,"This paper analyzes a tax enforcement field experiment in Denmark. In the base year, a stratified and representative sample of over 40,000 individual income tax filers was selected for the experiment. Half of the tax filers were randomly selected to be thoroughly audited, while the rest were deliberately not audited. The following year, threat-of-audit letters were randomly assigned and sent to tax filers in both groups. We present three main empirical findings. First, using baseline audit data, we find that the tax evasion rate is close to zero for income subject to third-party reporting, but substantial for self-reported income. Since most income is subject to third-party reporting, the overall evasion rate is modest. Second, using quasi-experimental variation created by large kinks in the income tax schedule, we find that marginal tax rates have a positive impact on tax evasion for self-reported income, but that this effect is small in comparison to legal avoidance and behavioral responses. Third, using the randomization of enforcement, we find that prior audits and threat-of-audit letters have significant effects on self-reported income, but no effect on third-party reported income. All these empirical results can be explained by extending the standard model of (rational) tax evasion to allow for the key distinction between self-reported and third-party reported income.","['Kreiner, Claus Thustrup', 'Saez, Emmanuel', 'Knudsen, Martin B.', 'Kleven, Henrik Jacobsen', 'Pedersen, Soren']","['Field Experiments', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Tax Evasion and Avoidance']","['C93', 'H24', 'H26']",Unwilling or Unable to Cheat? Evidence from a Tax Audit Experiment in Denmark,0,0,0,0,0,2011,05,01
87,4,2019-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2019,07,01
87,4,2019-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,07,01
87,4,2019-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 4.,0,0,0,0,0,2019,07,01
87,4,2019-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 4.,0,0,0,0,0,2019,07,01
87,3,2019-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,05,01
87,3,2019-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 3.,0,0,0,0,0,2019,05,01
87,3,2019-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 3.,0,0,0,0,0,2019,05,01
86,2,2018-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 2.,0,0,0,0,0,2018,03,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 1.,0,0,0,0,0,2018,01,01
85,5,2017-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 5.,0,0,0,0,0,2017,09,01
85,4,2017-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 4.,0,0,0,0,0,2017,07,01
85,3,2017-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 3.,0,0,0,0,0,2017,05,01
82,2,2014-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 2.,0,0,0,0,0,2014,03,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Annual Reports Report of the Editors of the Monograph Series.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 82 Iss. 1.,0,0,0,0,0,2014,01,01
79,2,2011-03-01,"Gul and Pesendorfer (2001) model the static behavior of an agent who ranks menus prior to the experience of temptation. This paper models the dynamic behavior of an agent whose ranking of menus itself is subject to temptation. The representation for the agent's dynamically inconsistent choice behavior views him as possessing a dynamically consistent view of what choices he ""should"" make (a normative preference) and being tempted by menus that contain tempting alternatives. Foundations for the model require a departure from Gul and Pesendorfer's idea that temptation creates a preference for commitment. Instead, it is hypothesized that distancing an agent from the consequences of his choices separates normative preference and temptation.","['Noor, Jawwad']",['Microeconomic Behavior: Underlying Principles'],['D01'],Temptation and Revealed Preference,0,0,0,0,0,2011,03,01
79,2,2011-03-01,"The majority of labor transactions throughout much of history and a significant fraction of such transactions in many developing countries today are ""coercive,"" in the sense that force or the threat of force plays a central role in convincing workers to accept employment or its terms. We propose a tractable principal-agent model of coercion, based on the idea that coercive activities by employers, or ""guns,"" affect the participation constraint of workers. We show that coercion and effort are complements, so that coercion increases effort, but coercion always reduces utilitarian social welfare. Better outside options for workers reduce coercion because of the complementarity between coercion and effort: workers with a better outside option exert lower effort in equilibrium and thus are coerced less. Greater demand for labor increases coercion because it increases equilibrium effort. We investigate the interaction between outside options, market prices, and other economic variables by embedding the (coercive) principal-agent relationship in a general equilibrium setup, and studying when and how labor scarcity encourages coercion. General (market) equilibrium interactions working through the price of output lead to a positive relationship between labor scarcity and coercion along the lines of ideas suggested by Domar, while interactions those working through the outside option lead to a negative relationship similar to ideas advanced in neo-Malthusian historical analyses of the decline of feudalism. In net, a decline in available labor increases coercion in general equilibrium if and only if its direct (partial equilibrium) effect is to increase the price of output by more than it increases outside options. Our model also suggests that markets in slaves make slaves worse off, conditional on enslavement, and that coercion is more viable in industries that do not require relationship-specific investment by workers.","['Wolitzky, Alexander', 'Acemoglu, Daron']","['Asymmetric and Private Information; Mechanism Design', 'Labor Contracts', 'Labor Standards: Working Conditions']","['D82', 'J41', 'J81']",The Economics of Labor Coercion,0,0,0,0,0,2011,03,01
79,2,2011-03-01,"We generalize Athey's (2001) and McAdams' (2003) results on the existence of monotone pure-strategy equilibria in Bayesian games. We allow action spaces to be compact locally complete metric semilattices and type spaces to be partially ordered probability spaces. Our proof is based on contractibility rather than convexity of best-reply sets. Several examples illustrate the scope of the result, including new applications to multi-unit auctions with risk-averse bidders.","['Reny, Philip J.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['C73', 'D44', 'D81']",On the Existence of Monotone Pure-Strategy Equilibria in Bayesian Games,0,0,1,0,0,2011,03,01
79,2,2011-03-01,"This paper introduces the model confidence set (MCS) and applies it to the selection of models. A MCS is a set of models that is constructed such that it will contain the best model with a given level of confidence. The MCS is in this sense analogous to a confidence interval for a parameter. The MCS acknowledges the limitations of the data, such that uninformative data yield a MCS with many models, whereas informative data yield a MCS with only a few models. The MCS procedure does not assume that a particular model is the true model; in fact, the MCS procedure can be used to compare more general objects, beyond the comparison of models. We apply the MCS procedure to two empirical problems. First, we revisit the inflation forecasting problem posed by Stock and Watson (1999), and compute the MCS for their set of inflation forecasts. Second, we compare a number of Taylor rule regressions and determine the MCS of the best regression in terms of in-sample likelihood criteria.","['Hansen, Peter R.', 'Lunde, Asger', 'Nason, James M.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Evaluation, Validation, and Selection']","['C30', 'C52']",The Model Confidence Set,0,0,0,0,0,2011,03,01
79,2,2011-03-01,"This paper shows that the semiparametric efficiency bound for a parameter identified by an unconditional moment restriction with data missing at random (MAR) coincides with that of a particular augmented moment condition problem. The augmented system consists of the inverse probability weighted (IPW) original moment restriction and an additional conditional moment restriction which exhausts all other implications of the MAR assumption. The paper also investigates the value of additional semiparametric restrictions on the conditional expectation function (CEF) of the original moment function given always observed covariates. In the program evaluation context, for example, such restrictions are implied by semiparametric models for the potential outcome CEFs given baseline covariates. The efficiency bound associated with this model is shown to also coincide with that of a particular moment condition problem. Some implications of these results for estimation are briefly discussed.","['Graham, Bryan S.']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C14', 'C21', 'C31']",Efficiency Bounds for Missing Data Models with Semiparametric Restrictions,0,0,0,0,0,2011,03,01
79,2,2011-03-01,"The asymptotic validity of tests is usually established by making appropriate primitive assumptions, which imply the weak convergence of a specific function of the data, and an appeal to the continuous mapping theorem. This paper, instead, takes the weak convergence of some function of the data to a limiting random element as the starting point and studies efficiency in the class of tests that remain asymptotically valid for all models that induce the same weak limit. It is found that efficient tests in this class are simply given by efficient tests in the limiting problem--that is, with the limiting random element assumed observed--evaluated at sample analogues. Efficient tests in the limiting problem are usually straightforward to derive, even in nonstandard testing problems. What is more, their evaluation at sample analogues typically yields tests that coincide with suitably robustified versions of optimal tests in canonical parametric versions of the model. This paper thus establishes an alternative and broader sense of asymptotic efficiency for many previously derived tests in econometrics, such as tests for unit roots, parameter stability tests, and tests about regression coefficients under weak instruments.","['Muller, Ulrich K.']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C12', 'C22']",Efficient Tests under a Weak Convergence Assumption,0,0,0,0,0,2011,03,01
79,2,2011-03-01,"Instrumental variables are widely used in applied econometrics to achieve identification and carry out estimation and inference in models that contain endogenous explanatory variables. In most applications, the function of interest (e.g., an Engel curve or demand function) is assumed to be known up to finitely many parameters (e.g., a linear model), and instrumental variables are used to identify and estimate these parameters. However, linear and other finite-dimensional parametric models make strong assumptions about the population being modeled that are rarely if ever justified by economic theory or other a priori reasoning and can lead to seriously erroneous conclusions if they are incorrect. This paper explores what can be learned when the function of interest is identified through an instrumental variable but is not assumed to be known up to finitely many parameters. The paper explains the differences between parametric and nonparametric estimators that are important for applied research, describes an easily implemented nonparametric instrumental variables estimator, and presents empirical examples in which nonparametric methods lead to substantive conclusions that are quite different from those obtained using standard, parametric estimators.","['Horowitz, Joel L.']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C14', 'C26']",Applied Nonparametric Instrumental Variables Estimation,0,0,0,0,0,2011,03,01
79,1,2011-01-01,ECONLIT None Found,[nan],[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS ECONOMETRICA REFEREES 2009-2010.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,ECONLIT None Found,"['STOCK, JAMES H.', 'SAMUELSON, LARRY', 'ACEMOGLU, DARON', 'UHLIG, HARALD', 'MORRIS, STEPHEN', 'ROBIN, JEAN-MARC', 'PESENDORFER, WOLFGANG']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE EDITORS 2009-2010.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],THE ECONOMETRIC SOCIETY REPORTS REPORT OF THE TREASURER.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE SECRETARY.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,"The rollout of Wal-Mart store openings followed a pattern that radiated from the center outward, with Wal-Mart maintaining high store density and a contiguous store network all along the way. This paper estimates the benefits of such a strategy to Wal-Mart, focusing on the savings in distribution costs afforded by a dense network of stores. The paper takes a revealed preference approach, inferring the magnitude of density economies from how much sales cannibalization of closely packed stores Wal-Mart is willing to suffer to achieve density economies. The model is dynamic with rich geographic detail on the locations of stores and distribution centers. Given the enormous number of possible combinations of store-opening sequences, it is difficult to directly solve Wal-Mart's problem, making conventional approaches infeasible. The moment inequality approach is used instead and works well. The estimates show the benefits to Wal-Mart of high store density are substantial and likely extend significantly beyond savings in trucking costs.","['Holmes, Thomas J.']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Retail and Wholesale Trade; e-Commerce', 'Production Management', 'Other Spatial Production and Pricing Analysis', 'Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise']","['D24', 'L81', 'M11', 'R32', 'R41']",The Diffusion of Wal-Mart and Economies of Density,1,0,0,0,0,2011,01,01
79,1,2011-01-01,"This paper develops a tractable econometric model of optimal migration, focusing on expected income as the main economic influence on migration. The model improves on previous work in two respects: it covers optimal sequences of location decisions (rather than a single once-for-all choice) and it allows for many alternative location choices. The model is estimated using panel data from the National Longitudinal Survey of Youth on white males with a high-school education. Our main conclusion is that interstate migration decisions are influenced to a substantial extent by income prospects. The results suggest that the link between income and migration decisions is driven both by geographic differences in mean wages and by a tendency to move in search of a better locational match when the income realization in the current location is unfavorable.","['Walker, James R.', 'Kennan, John']","['Geographic Labor Mobility; Immigrant Workers', 'Unemployment: Models, Duration, Incidence, and Job Search', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration; Regional Labor Markets; Population; Neighborhood Characteristics']","['J61', 'J64', 'R23']",The Effect of Expected Income on Individual Migration Decisions,0,0,0,0,0,2011,01,01
79,1,2011-01-01,"This paper investigates an empirical puzzle in technology adoption for developing countries: the low adoption rates of technologies like hybrid maize that increase average farm profits dramatically. I offer a simple explanation for this: benefits and costs of technologies are heterogeneous, so that farmers with low net returns do not adopt the technology. I examine this hypothesis by estimating a correlated random coefficient model of yields and the corresponding distribution of returns to hybrid maize. This distribution indicates that the group of farmers with the highest estimated gross returns does not use hybrid, but their returns are correlated with high costs of acquiring the technology (due to poor infrastructure). Another group of farmers has lower returns and adopts, while the marginal farmers have zero returns and switch in and out of use over the sample period. Overall, adoption decisions appear to be rational and well explained by (observed and unobserved) variation in heterogeneous net benefits to the technology.","['Suri, Tavneet']","['Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Agricultural R&D; Agricultural Technology; Biofuels; Agricultural Extension Services']","['O13', 'O18', 'O33', 'Q16']",Selection and Comparative Advantage in Technology Adoption,0,0,0,1,0,2011,01,01
79,1,2011-01-01,"We study the dynamics of the distribution of wealth in an overlapping generation economy with finitely lived agents and intergenerational transmission of wealth. Financial markets are incomplete, exposing agents to both labor and capital income risk. We show that the stationary wealth distribution is a Pareto distribution in the right tail and that it is capital income risk, rather than labor income, that drives the properties of the right tail of the wealth distribution. We also study analytically the dependence of the distribution of wealth--of wealth inequality in particular--on various fiscal policy instruments like capital income taxes and estate taxes, and on different degrees of social mobility. We show that capital income and estate taxes can significantly reduce wealth inequality, as do institutions favoring social mobility. Finally, we calibrate the economy to match the Lorenz curve of the wealth distribution of the U.S. economy.","['Benhabib, Jess', 'Bisin, Alberto', 'Zhu, Shenghao']","['Personal Income, Wealth, and Their Distributions', 'Incomplete Markets', 'General Equilibrium and Disequilibrium: Financial Markets', 'Fiscal Policy', 'Fiscal Policies and Behavior of Economic Agents: Household']","['D31', 'D52', 'D53', 'E62', 'H31']",The Distribution of Wealth and Fiscal Policy in Economies with Finitely Lived Agents,0,0,0,0,0,2011,01,01
79,1,2011-01-01,"This paper develops a tractable version of the Lucas and Prescott (1974) search model. Each of a continuum of industries produces a heterogeneous good using a production technology that is continually hit by idiosyncratic shocks. In response to adverse shocks, some workers search for new industries while others are rest unemployed, waiting for their industry's condition to improve. We obtain closed-form expressions for key aggregate variables and use them to evaluate the model's quantitative predictions for unemployment and wages. Both search and rest unemployment are important for understanding the behavior of wages at the industry level.","['Shimer, Robert', 'Alvarez, Fernando']","['Model Construction and Estimation', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Unemployment: Models, Duration, Incidence, and Job Search']","['C51', 'E24', 'J31', 'J64']",Search and Rest Unemployment,0,0,0,0,0,2011,01,01
79,1,2011-01-01,"This paper axiomatizes the robust control criterion of multiplier preferences introduced by Hansen and Sargent (2001). The axiomatization relates multiplier preferences to other classes of preferences studied in decision theory, in particular, the variational preferences recently introduced by Maccheroni, Marinacci, and Rustichini (2006a). This paper also establishes a link between the parameters of the multiplier criterion and the observable behavior of the agent. This link enables measurement of the parameters on the basis of observable choice data and provides a useful tool for applications.","['Strzalecki, Tomasz']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Axiomatic Foundations of Multiplier Preferences,0,0,0,0,0,2011,01,01
79,1,2011-01-01,"We study the evolution of market-oriented policies over time and across countries. We consider a model in which own and neighbors' past experiences influence policy choices through their effect on policymakers' beliefs. We estimate the model using a large panel of countries and find that it fits a large fraction of the policy choices observed in the postwar data, including the slow adoption of liberal policies. Our model also predicts that there would be reversals to state intervention if nowadays the world was hit by a shock of the size of the Great Depression.","['Primiceri, Giorgio E.', 'Buera, Francisco J.', 'Monge-Naranjo, Alexander']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Macroeconomic Policy, Macroeconomic Aspects of Public Finance, and General Outlook: General', 'Development Planning and Policy: General']","['D83', 'E60', 'O20']",Learning the Wealth of Nations,0,0,0,0,0,2011,01,01
87,2,2019-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,03,01
87,2,2019-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 2.,0,0,0,0,0,2019,03,01
87,2,2019-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 2.,0,0,0,0,0,2019,03,01
81,6,2013-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 81 Iss. 6.,0,0,0,0,0,2013,11,01
81,5,2013-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 81 Iss. 5.,0,0,0,0,0,2013,09,01
78,6,2010-11-01,"Two Ellsberg-style thought experiments are described that reflect on the smooth ambiguity decision model developed by Klibanoff, Marinacci, and Mukerji (2005). The first experiment poses difficulties for the model's axiomatic foundations and, as a result, also for its interpretation, particularly for the claim that the model achieves a separation between ambiguity and the attitude toward ambiguity. Given the problematic nature of its foundations, the behavioral content of the model and how it differs from multiple priors, for example, are not clear. The second thought experiment casts some light on these questions.","['Epstein, Larry G.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Paradox for the 'Smooth Ambiguity' Model of Preference,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"We study optimal taxation when consumers have temptation and self-control problems. Embedding the class of preferences developed by Gul and Pesendorfer into a standard macroeconomic setting, we first prove, in a two-period model, that the optimal policy is to subsidize savings when consumers are tempted by ""excessive"" impatience. The savings subsidy improves welfare because it makes succumbing to temptation less attractive. We then study an economy with a long but finite horizon which nests, as a special case, the Phelps-Pollak-Laibson multiple-selves model (thereby providing guidance on how to evaluate welfare in this model). We prove that when period utility is logarithmic, the optimal savings subsidies increase over time for any finite horizon. Moreover, as the horizon grows large, the optimal policy prescribes a constant subsidy, in contrast to the well known Chamley-Judd result.","['Kuruscu, Burhanettin', 'Smith, Anthony A., Jr.', 'Krusell, Per']",['Taxation and Subsidies: Efficiency; Optimal Taxation'],['H21'],Temptation and Taxation,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"A unifying framework to test for causal effects in nonlinear models is proposed. We consider a generalized linear-index regression model with endogenous regressors and no parametric assumptions on the error disturbances. To test the significance of the effect of an endogenous regressor, we propose a statistic that is a kernel-weighted version of the rank correlation statistic (tau) of Kendall (1938). The semiparametric model encompasses previous cases considered in the literature [continuous endogenous regressors (Blundell and Powell (2003)] and a single binary endogenous regressor [Vytlacil and Yildiz (2007)], but the testing approach is the first to allow for (i) multiple discrete endogenous regressors, (ii) endogenous regressors that are neither discrete nor continuous (e.g., a censored variable), and (iii) an arbitrary ""mix"" of endogenous regressors (e.g., one binary regressor and one continuous regressor).","['Hausman, Jerry A.', 'Abrevaya, Jason', 'Khan, Shakeeb']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Model Construction and Estimation', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['C21', 'C26', 'C51', 'J16', 'J22']",Testing for Causal Effects in a Generalized Regression Model with Endogenous Regressors,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"In weighted moment condition models, we show a subtle link between identification and estimability that limits the practical usefulness of estimators based on these models. In particular, if it is necessary for (point) identification that the weights take arbitrarily large values, then the parameter of interest, though point identified, cannot be estimated at the regular (parametric) rate and is said to be irregularly identified. This rate depends on relative tail conditions and can be as slow in some examples as n[superscript -1/4]. This nonstandard rate of convergence can lead to numerical instability and/or large standard errors. We examine two weighted model examples: (i) the binary response model under mean restriction introduced by Lewbel (1997) and further generalized to cover endogeneity and selection, where the estimator in this class of models is weighted by the density of a special regressor, and (ii) the treatment effect model under exogenous selection [Rosenbaum and Rubin (1983)], where the resulting estimator of the average treatment effect is one that is weighted by a variant of the propensity score. Without strong relative support conditions, these models, similar to well known ""identified at infinity"" models, lead to estimators that converge at slower than parametric rate, since essentially, to ensure point identification, one requires some variables to take values on sets with arbitrarily small probabilities, or thin sets. For the two models above, we derive some rates of convergence and propose that one conducts inference using rate adaptive procedures that are analogous to Andrews and Schafgans (1998) for the sample selection model.","['Tamer, Elie', 'Khan, Shakeeb']","['Estimation: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C13', 'C21', 'C24', 'C25']","Irregular Identification, Support Conditions, and Inverse Weight Estimation",0,0,0,0,0,2010,11,01
78,6,2010-11-01,"Simple exchange experiments have revealed that participants trade their endowment less frequently than standard demand theory would predict. List (2003a) found that the most experienced dealers acting in a well functioning market are not subject to this exchange asymmetry, suggesting that a significant amount of market experience is required to overcome it. To understand this market-experience effect, we introduce a distinction between two types of uncertainty--choice uncertainty and trade uncertainty--both of which could lead to exchange asymmetry. We conjecture that trade uncertainty is most important for exchange asymmetry. To test this conjecture, we design an experiment where the two treatments impact differently on trade uncertainty, while controlling for choice uncertainty. Supporting our conjecture, we find that ""forcing"" subjects to give away their endowment in a series of exchanges eliminates exchange asymmetry in a subsequent test. We discuss why markets might not provide sufficient incentives for learning to overcome exchange asymmetry.","['Engelmann, Dirk', 'Hollard, Guillaume']","['Design of Experiments: Laboratory, Individual', 'Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty']","['C91', 'D12', 'D81']",Reconsidering the Effect of Market Experience on the 'Endowment Effect',0,0,0,0,0,2010,11,01
78,6,2010-11-01,"Experimental evidence suggests that individuals are more risk averse when they perceive risk that is gradually resolved over time. We address these findings by studying a decision maker who has recursive, nonexpected utility preferences over compound lotteries. The decision maker has preferences for one-shot resolution of uncertainty if he always prefers any compound lottery to be resolved in a single stage. We establish an equivalence between dynamic preferences for one-shot resolution of uncertainty and static preferences that are identified with commonly observed behavior in Allais-type experiments. The implications of this equivalence on preferences over information systems are examined. We define the gradual resolution premium and demonstrate its magnifying effect when combined with the usual risk premium.","['Dillenberger, David']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Preferences for One-Shot Resolution of Uncertainty and Allais-Type Behavior,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"Harsanyi's impartial observer must consider two types of lotteries: imaginary identity lotteries (""accidents of birth"") that she faces as herself and the real outcome lotteries (""life chances"") to be faced by the individuals she imagines becoming. If we maintain a distinction between identity and outcome lotteries, then Harsanyi-like axioms yield generalized utilitarianism, and allow us to accommodate concerns about different individuals' risk attitudes and concerns about fairness. Requiring an impartial observer to be indifferent as to which individual should face similar risks restricts her social welfare function, but still allows her to accommodate fairness. Requiring an impartial observer to be indifferent between identity and outcome lotteries, however, forces her to ignore both fairness and different risk attitudes, and yields a new axiomatization of Harsanyi's utilitarianism.","['Safra, Zvi', 'Kajii, Atsushi', 'Polak, Ben', 'Grant, Simon']","['Auctions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Social Choice; Clubs; Committees; Associations']","['D44', 'D63', 'D71']",Generalized Utilitarianism and Harsanyi's Impartial Observer Theorem,0,0,1,0,0,2010,11,01
78,6,2010-11-01,"We prove--in the standard independent private-values model--that the outcome, in terms of interim expected probabilities of trade and interim expected transfers, of any Bayesian mechanism can also be obtained with a dominant-strategy mechanism.","['Manelli, Alejandro M.', 'Vincent, Daniel R.']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Bayesian and Dominant-Strategy Implementation in the Independent Private-Values Model,0,0,1,0,0,2010,11,01
78,6,2010-11-01,"This study utilizes regression discontinuity to examine the long-run impacts of the mita, an extensive forced mining labor system in effect in Peru and Bolivia between 1573 and 1812. Results indicate that a mita effect lowers household consumption by around 25% and increases the prevalence of stunted growth in children by around 6 percentage points in subjected districts today. Using data from the Spanish Empire and Peruvian Republic to trace channels of institutional persistence, I show that the mita's influence has persisted through its impacts on land tenure and public goods provision. Mita districts historically had fewer large landowners and lower educational attainment. Today, they are less integrated into road networks and their residents are substantially more likely to be subsistence farmers.","['Dell, Melissa']","['Public Goods', 'Labor Standards: Labor Force Composition', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: Latin America; Caribbean', 'Economic History: Agriculture, Natural Resources, Environment, and Extractive Industries: Latin America; Caribbean', 'Economic Development: Agriculture; Natural Resources; Energy; Environment; Other Primary Products', 'Land Ownership and Tenure; Land Reform; Land Use; Irrigation; Agriculture and Environment']","['H41', 'J82', 'N36', 'N56', 'O13', 'Q15']",The Persistent Effects of Peru's Mining Mita,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"We study economies with adverse selection, plus the frictions in competitive search theory. With competitive search, principals post terms of trade (contracts), then agents choose where to apply, and they match bilaterally. Search allows us to analyze the effects of private information on both the intensive and extensive margins (the terms and probability of trade). There always exists a separating equilibrium where each type applies to a different contract. The equilibrium is unique in terms of payoffs. It is not generally efficient. We provide an algorithm for constructing equilibrium. Three applications illustrate the usefulness of the approach, and contrast our results with those in standard contract and search theory.","['Shimer, Robert', 'Wright, Randall', 'Guerrieri, Veronica']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Adverse Selection in Competitive Search Equilibrium,0,0,0,0,0,2010,11,01
78,6,2010-11-01,"Behavioral choice models generate inequalities which, when combined with additional assumptions, can be used as a basis for estimation. This paper considers two sets of such assumptions and uses them in two empirical examples. The second example examines the structure of payments resulting from the upstream interactions in a vertical market. I then mimic the empirical setting for this example in a numerical analysis which computes actual equilibria, examines how their characteristics vary with the market setting, and compares them to the empirical results. The final section uses the numerical results in a Monte Carlo analysis of the robustness of the two approaches to estimation to their underlying assumptions.","['Pakes, A.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Analysis of Health Care Markets', 'Retail and Wholesale Trade; e-Commerce']","['C21', 'C25', 'C51', 'D12', 'I11', 'L81']",Alternative Models for Moment Inequalities,1,0,0,0,0,2010,11,01
78,5,2010-09-01,"Consider an environment with a finite number of alternatives, and agents with private values and quasilinear utility functions. A domain of valuation functions for an agent is a monotonicity domain if every finite-valued monotone randomized allocation rule defined on it is implementable in dominant strategies. We fully characterize the set of all monotonicity domains.","['Ashlagi, Itai', 'Hassidim, Avinatan', 'Monderer, Dov', 'Braverman, Mark']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",Monotonicity and Implementability,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"We offer an axiomatization of the serial cost-sharing method of Friedman and Moulin (1999). The key property in our axiom system is Group Demand Monotonicity, asking that when a group of agents raise their demands, not all of them should pay less.","['Sprumont, Yves']","['Cooperative Games', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['C71', 'D63']",An Axiomatization of the Serial Cost-Sharing Method,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"This paper studies repeated games with imperfect public monitoring where the players are uncertain both about the payoff functions and about the relationship between the distribution of signals and the actions played. We introduce the concept of perfect public ex post equilibrium (PPXE), and show that it can be characterized with an extension of the techniques used to study perfect public equilibria. We develop identifiability conditions that are sufficient for a folk theorem; these conditions imply that there are PPXE in which the payoffs are approximately the same as if the monitoring structure and payoff functions were known. Finally, we define perfect type-contingently public ex post equilibria (PTXE), which allows players to condition their actions on their initial private information, and we provide its linear programming characterization.","['Fudenberg, Drew', 'Yamamoto, Yuichi']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Repeated Games Where the Payoffs and Monitoring Structure Are Unknown,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"The random priority (random serial dictatorship) mechanism is a common method for assigning objects. The mechanism is easy to implement and strategy-proof. However, this mechanism is inefficient, because all agents may be made better off by another mechanism that increases their chances of obtaining more preferred objects. This form of inefficiency is eliminated by a mechanism called probabilistic serial, but this mechanism is not strategy-proof. Thus, which mechanism to employ in practical applications is an open question. We show that these mechanisms become equivalent when the market becomes large. More specifically, given a set of object types, the random assignments in these mechanisms converge to each other as the number of copies of each object type approaches infinity. Thus, the inefficiency of the random priority mechanism becomes small in large markets. Our result gives some rationale for the common use of the random priority mechanism in practical problems such as student placement in public schools.","['Che, Yeon-Koo', 'Kojima, Fuhito']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",Asymptotic Equivalence of Probabilistic Serial and Random Priority Mechanisms,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"The coalitional Nash bargaining solution is defined to be the core allocation for which the product of players' payoffs is maximal. We consider a non-cooperative model with discounting in which one team may form and every player is randomly selected to make a proposal in every period. The grand team, consisting of all players, generates the largest surplus. But a smaller team may form. We show that as players get more patient if an efficient and stationary equilibrium exists, it must deliver payoffs that correspond to the coalitional Nash bargaining solution. We also characterize when an efficient and stationary equilibrium exists, which requires conditions that go beyond the nonemptiness of the core.","['Compte, Olivier', 'Jehiel, Philippe']","['Noncooperative Games', 'Bargaining Theory; Matching Theory']","['C72', 'C78']",The Coalitional Nash Bargaining Solution,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"This paper studies the identification and estimation of preferences and technologies in equilibrium hedonic models. In it, we identify nonparametric structural relationships with nonadditive heterogeneity. We determine what features of hedonic models can be identified from equilibrium observations in a single market under weak assumptions about the available information. We then consider use of additional information about structural functions and heterogeneity distributions. Separability conditions facilitate identification of consumer marginal utility and firm marginal product functions. We also consider how identification is facilitated using multimarket data.","['Nesheim, Lars', 'Matzkin, Rosa L.', 'Heckman, James J.']","['Semiparametric and Nonparametric Methods: General', 'Model Construction and Estimation', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['C14', 'C51', 'L11']",Nonparametric Identification and Estimation of Nonadditive Hedonic Models,1,0,0,0,0,2010,09,01
78,5,2010-09-01,"We discuss the identification and estimation of discrete games of complete information. Following Bresnahan and Reiss (1990, 1991), a discrete game is a generalization of a standard discrete choice model where utility depends on the actions of other players. Using recent algorithms to compute all of the Nash equilibria to a game, we propose simulation-based estimators for static, discrete games. We demonstrate that the model is identified under weak functional form assumptions using exclusion restrictions and an identification at infinity approach. Monte Carlo evidence demonstrates that the estimator can perform well in moderately sized samples. As an application, we study entry decisions by construction contractors to bid on highway projects in California. We find that an equilibrium is more likely to be observed if it maximizes joint profits, has a higher Nash product, uses mixed strategies, and is not Pareto dominated by another equilibrium.","['Hong, Han', 'Bajari, Patrick', 'Ryan, Stephen P.']","['Model Construction and Estimation', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C51', 'C73', 'D83']",Identification and Estimation of a Discrete Game of Complete Information,0,0,0,0,0,2010,09,01
78,5,2010-09-01,"This paper extends the static analysis of oligopoly structure into an infinite-horizon setting with sunk costs and demand uncertainty. The observation that exit rates decline with firm age motivates the assumption of last-in first-out dynamics: An entrant expects to produce no longer than any incumbent. This selects an essentially unique Markov-perfect equilibrium. With mild restrictions on the demand shocks, sequences of thresholds describe firms' equilibrium entry and survival decisions. Bresnahan and Reiss' (1993) empirical analysis of oligopolists' entry and exit assumes that such thresholds govern the evolution of the number of competitors. Our analysis provides an infinite-horizon game-theoretic foundation for that structure.","['Abbring, Jaap H.', 'Campbell, Jeffrey R.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Criteria for Decision-Making under Risk and Uncertainty', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Oligopoly and Other Imperfect Markets']","['D43', 'D81', 'L11', 'L13']",Last-In First-Out Oligopoly Dynamics,1,0,1,0,0,2010,09,01
78,3,2010-05-01,ECONLIT None Found,[nan],[nan],[nan],2009 Election of Fellows to the Econometric Society.,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"Sannikov (2007) investigated properties of perfect public equilibria in continuous-time repeated games. This note points out that the proof of Lemma 6, required for the proof of the main theorem (Theorem 2), contains an error in computing a Hessian matrix. A correct proof of Lemma 6 is provided using an additional innocuous assumption and a generalized version of Lemma 5.","['Hashimoto, Tadashi']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Games with Imperfectly Observable Actions in Continuous Time: Corrigendum,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"Does expertise in strategic behavior obtained in the field transfer to the abstract setting of the laboratory? Palacios-Huerta and Volij (2008) argued that the behavior of professional soccer players in mixed-strategy games conforms closely to minimax play, while the behavior of students (who are presumably novices in strategic situations requiring unpredictability) does not. We reexamine their data, showing that the play of professionals is inconsistent with the minimax hypothesis in several respects: (i) professionals follow nonstationary mixtures, with action frequencies that are negatively correlated between the first and the second half of the experiment, (ii) professionals tend to switch between under- and overplaying an action relative to its equilibrium frequency, and (iii) the distribution of action frequencies across professionals is far from the distribution implied by minimax. In each respect, the behavior of students conforms more closely to the minimax hypothesis.","['Wooders, John']","['Noncooperative Games', 'Design of Experiments: Laboratory, Individual']","['C72', 'C91']",Does Experience Teach? Professionals and Minimax Play in the Lab,0,0,0,0,0,2010,05,01
78,3,2010-05-01,This paper proves the existence and uniqueness of a fixed point for local contractions without assuming the family of contraction coefficients to be uniformly bounded away from 1. More importantly it shows how this fixed-point result can apply to study the existence and uniqueness of solutions to some recursive equations that arise in economic dynamics.,"['Vailakis, Yiannis', 'Martins-da-Rocha, V. Filipe']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'Existence and Stability Conditions of Equilibrium']","['C61', 'C62']",Existence and Uniqueness of a Fixed Point for Local Contractions,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"This paper proposes a method to address the longstanding problem of lack of monotonicity in estimation of conditional and structural quantile functions, also known as the quantile crossing problem (Bassett and Koenker (1982)). The method consists in sorting or monotone rearranging the original estimated non-monotone curve into a monotone rearranged curve. We show that the rearranged curve is closer to the true quantile curve than the original curve in finite samples, establish a functional delta method for rearrangement-related operators, and derive functional limit theory for the entire rearranged curve and its functionals. We also establish validity of the bootstrap for estimating the limit law of the entire rearranged curve and its functionals. Our limit results are generic in that they apply to every estimator of a monotone function, provided that the estimator satisfies a functional central limit theorem and the function satisfies some smoothness conditions. Consequently, our results apply to estimation of other econometric functions with monotonicity restrictions, such as demand, production, distribution, and structural distribution functions. We illustrate the results with an application to estimation of structural distribution and quantile functions using data on Vietnam veteran status and earnings.","['Chernozhukov, Victor', 'Fernandez-Val, Ivan', 'Galichon, Alfred']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Quantile and Probability Curves without Crossing,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"Much of the extensive empirical literature on insurance markets has focused on whether adverse selection can be detected. Once detected, however, there has been little attempt to quantify its welfare cost or to assess whether and what potential government interventions may reduce these costs. To do so, we develop a model of annuity contract choice and estimate it using data from the U.K. annuity market. The model allows for private information about mortality risk as well as heterogeneity in preferences over different contract options. We focus on the choice of length of guarantee among individuals who are required to buy annuities. The results suggest that asymmetric information along the guarantee margin reduces welfare relative to a first-best symmetric information benchmark by about 127 million pounds per year or about 2 percent of annuitized wealth. We also find that by requiring that individuals choose the longest guarantee period allowed, mandates could achieve the first-best allocation. However, we estimate that other mandated guarantee lengths would have detrimental effects on welfare. Since determining the optimal mandate is empirically difficult, our findings suggest that achieving welfare gains through mandatory social insurance may be harder in practice than simple theory may suggest.","['Finkelstein, Amy', 'Einav, Liran', 'Schrimpf, Paul']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Insurance; Insurance Companies; Actuarial Studies']","['D82', 'D86', 'G22']",Optimal Mandates and the Welfare Cost of Asymmetric Information: Evidence from the U.K. Annuity Market,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"This paper provides a novel approach to ordering signals based on the property that more informative signals lead to greater variability of conditional expectations. We define two nested information criteria (supermodular precision and integral precision) by combining this approach with two variability orders (dispersive and convex orders). We relate precision criteria with orderings based on the value of information to a decision maker. We then use precision to study the incentives of an auctioneer to supply private information. Using integral precision, we obtain two results: (i) a more precise signal yields a more efficient allocation; (ii) the auctioneer provides less than the efficient level of information. Supermodular precision allows us to extend the previous analysis to the case in which supplying information is costly and to obtain an additional finding; (iii) there is a complementarity between information and competition, so that both the socially efficient and the auctioneer's optimal choice of precision increase with the number of bidders.","['Ganuza, Juan-Jose', 'Penalva, Jose S.']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Signal Orderings Based on Dispersion and the Supply of Private Information in Auctions,0,0,1,0,0,2010,05,01
78,3,2010-05-01,"This paper develops a framework to assess how fear of miscoordination affects the sustainability of cooperation. Building on theoretical insights from Carlsson and van Damme (1993), it explores the effect of small amounts of private information on a class of dynamic cooperation games with exit. Lack of common knowledge leads players to second guess each other's behavior and makes coordination difficult. This restricts the range of equilibria and highlights the role of miscoordination payoffs in determining whether cooperation is sustainable or not. The paper characterizes the range of perfect Bayesian equilibria as the players' information becomes arbitrarily precise. Unlike in one-shot two-by-two games, the global games information structure does not yield equilibrium uniqueness.","['Chassang, Sylvain']","['Cooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C71', 'C73', 'D83']",Fear of Miscoordination and the Robustness of Cooperation in Dynamic Global Games with Exit,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"This paper combines dynamic social choice and strategic experimentation to study the following question: how does a society, a committee, or, more generally, a group of individuals with potentially heterogeneous preferences, experiment with new opportunities? Each voter recognizes that, during experimentation, other voters also learn about their preferences. As a result, pivotal voters today are biased against experimentation because it reduces their likelihood of remaining pivotal. This phenomenon reduces equilibrium experimentation below the socially efficient level, and may even result in a negative option value of experimentation. However, one can restore efficiency by designing a voting rule that depends deterministically on time. Another main result is that even when payoffs of a reform are independently distributed across the population, good news about any individual's payoff increases other individuals' incentives to experiment with that reform, due to a positive voting externality.","['Strulovici, Bruno']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D71', 'D72', 'D83']",Learning While Voting: Determinants of Collective Experimentation,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"This paper formulates and estimates multistage production functions for children's cognitive and noncognitive skills. Skills are determined by parental environments and investments at different stages of childhood. We estimate the elasticity of substitution between investments in one period and stocks of skills in that period to assess the benefits of early investment in children compared to later remediation. We establish nonparametric identification of a general class of production technologies based on nonlinear factor models with endogenous inputs. A by-product of our approach is a framework for evaluating childhood and schooling interventions that does not rely on arbitrarily scaled test scores as outputs and recognizes the differential effects of the same bundle of skills in different tasks. Using the estimated technology, we determine optimal targeting of interventions to children with different parental and personal birth endowments. Substitutability decreases in later stages of the life cycle in the production of cognitive skills. It is roughly constant across stages of the life cycle in the production of noncognitive skills. This finding has important implications for the design of policies that target the disadvantaged. For most configurations of disadvantage it is optimal to invest relatively more in the early stages of childhood than in later stages.","['Cunha, Flavio', 'Heckman, James J.', 'Schennach, Susanne M.']","['Model Construction and Estimation', 'Analysis of Education', 'Fertility; Family Planning; Child Care; Children; Youth']","['C51', 'I21', 'J13']",Estimating the Technology of Cognitive and Noncognitive Skill Formation,0,0,0,0,0,2010,05,01
78,3,2010-05-01,"We show that in repeated interactions the avenues for effective provision of incentives depend crucially on the type of information players observe. We establish this conclusion for general repeated two-player games in which information arrives via a continuous-time stationary process that has a continuous multidimensional Brownian component and a Poisson component, and in which the players act frequently. The Poisson jumps can be used to effectively provide incentives both with transfers and value burning, while continuous Brownian information can be used to provide incentives only with transfers.","['Skrzypacz, Andrzej', 'Sannikov, Yuliy']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",The Role of Information in Repeated Games with Frequent Actions,0,0,0,0,0,2010,05,01
78,2,2010-03-01,Recursive procedures which are based on iterating on the best response mapping have difficulties converging to all equilibria in multi-player games. We illustrate these difficulties by revisiting the asymptotic properties of the iterative nested pseudo maximum likelihood method for estimating dynamic games introduced by Aguirregabiria and Mira (2007). An example shows that the iterative method may not be consistent.,"['Pesendorfer, Martin', 'Schmidt-Dengler, Philipp']","['Model Construction and Estimation', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C51', 'C73', 'D43']",Sequential Estimation of Dynamic Discrete Games: A Comment,0,0,1,0,0,2010,03,01
78,2,2010-03-01,"Fudenberg and Levine (1993a) introduced the notion of self-confirming equilibrium, which is generally less restrictive than Nash equilibrium. Fudenberg and Levine also defined a concept of consistency, and claimed in their Theorem 4 that with consistency and other conditions on beliefs, a self-confirming equilibrium has a Nash equilibrium outcome. We provide a counterexample that disproves Theorem 4 and prove an alternative by replacing consistency with a more restrictive concept, which we call strong consistency. In games with observed deviators, self-confirming equilibria are strongly consistent self-confirming equilibria. Hence, our alternative theorem ensures that despite the counterexample, the corollary of Theorem 4 is still valid.","['Kamada, Yuichiro']",['Noncooperative Games'],['C72'],Strongly Consistent Self-Confirming Equilibrium,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"We present a comprehensive framework for Bayesian estimation of structural nonlinear dynamic economic models on sparse grids to overcome the curse of dimensionality for approximations. We apply sparse grids to a global polynomial approximation of the model solution, to the quadrature of integrals arising as rational expectations, and to three new nonlinear state space filters which speed up the sequential importance resampling particle filter. The posterior of the structural parameters is estimated by a new Metropolis-Hastings algorithm with mixing parallel sequences. The parallel extension improves the global maximization property of the algorithm, simplifies the parameterization for an appropriate acceptance ratio, and allows a simple implementation of the estimation on parallel computers. Finally, we provide all algorithms in the open source software JBendge for the solution and estimation of a general class of models.","['Winschel, Viktor', 'Kratzig, Markus']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Model Construction and Estimation']","['C22', 'C32', 'C51']","Solving, Estimating, and Selecting Nonlinear Dynamic Models without the Curse of Dimensionality",0,0,0,0,0,2010,03,01
78,2,2010-03-01,"We consider a class of mechanism games in which there are multiple principals and three or more agents. For a mechanism game in this class, a sort of folk theorem holds: there is a threshold value for each of the principals such that an allocation is achieved at a pure-strategy sequential equilibrium of the game if and only if (i) it is incentive compatible and (ii) it attains an expected utility for each principal that is greater than or equal to the threshold value for the principal.","['Yamashita, Takuro']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Mechanism Games with Multiple Principals and Three or More Agents,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"We consider truthful implementation of the socially efficient allocation in an independent private-value environment in which agents receive private information over time. We propose a suitable generalization of the pivot mechanism, based on the marginal contribution of each agent. In the dynamic pivot mechanism, the ex post incentive and ex post participation constraints are satisfied for all agents after all histories. In an environment with diverse preferences it is the unique mechanism satisfying ex post incentive, ex post participation, and efficient exit conditions. We develop the dynamic pivot mechanism in detail for a repeated auction of a single object in which each bidder learns over time her true valuation of the object. The dynamic pivot mechanism here is equivalent to a modified second price auction.","['Bergemann, Dirk', 'Valimaki, Juuso']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",The Dynamic Pivot Mechanism,0,0,1,0,0,2010,03,01
78,2,2010-03-01,"A decision maker (DM) is characterized by two binary relations. The first reflects choices that are rational in an ""objective"" sense: the DM can convince others that she is right in making them. The second relation models choices that are rational in a ""subjective"" sense: the DM cannot be convinced that she is wrong in making them. In the context of decision under uncertainty, we propose axioms that the two notions of rationality might satisfy. These axioms allow a joint representation by a single set of prior probabilities and a single utility index. It is ""objectively rational"" to choose f in the presence of g if and only if the expected utility of f is at least as high as that of g given each and every prior in the set. It is ""subjectively rational"" to choose f rather than g if and only if the minimal expected utility of f (with respect to all priors in the set) is at least as high as that of g. In other words, the objective and subjective rationality relations admit, respectively, a representation a la Bewley (2002) and a la Gilboa and Schmeidler (1989). Our results thus provide a bridge between these two classic models, as well as a novel foundation for the latter.","['Maccheroni, Fabio', 'Gilboa, Itzhak', 'Schmeidler, David', 'Marinacci, Massimo']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Objective and Subjective Rationality in a Multiple Prior Model,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"This paper introduces a novel bootstrap procedure to perform inference in a wide class of partially identified econometric models. We consider econometric models defined by finitely many weak moment inequalities, which encompass many applications of economic interest. The objective of our inferential procedure is to cover the identified set with a prespecified probability. We compare our bootstrap procedure, a competing asymptotic approximation, and subsampling procedures in terms of the rate at which they achieve the desired coverage level, also known as the error in the coverage probability. Under certain conditions, we show that our bootstrap procedure and the asymptotic approximation have the same order of error in the coverage probability, which is smaller than that obtained by using subsampling. This implies that inference based on our bootstrap and asymptotic approximation should eventually be more precise than inference based on subsampling. A Monte Carlo study confirms this finding in a small sample simulation.","['Bugni, Federico A.']","['Statistical Simulation Methods: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C15', 'C20', 'C30']",Bootstrap Inference in Partially Identified Models Defined by Moment Inequalities: Coverage of the Identified Set,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"A model for binary panel data is introduced which allows for state dependence and unobserved heterogeneity beyond the effect of available covariates. The model is of quadratic exponential type and its structure closely resembles that of the dynamic logit model. However, it has the advantage of being easily estimable via conditional likelihood with at least two observations (further to an initial observation) and even in the presence of time dummies among the regressors.","['Bartolucci, Francesco', 'Nigro, Valentina']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",A Dynamic Model for Binary Panel Data with Unobserved Heterogeneity Admitting a Square-Root-of-n-Consistent Conditional Estimator,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"This paper considers model averaging as a way to construct optimal instruments for the two-stage least squares (2SLS), limited information maximum likelihood (LIML), and Fuller estimators in the presence of many instruments. We propose averaging across least squares predictions of the endogenous variables obtained from many different choices of instruments and then use the average predicted value of the endogenous variables in the estimation stage. The weights for averaging are chosen to minimize the asymptotic mean squared error of the model averaging version of the 2SLS, LIML, or Fuller estimator. This can be done by solving a standard quadratic programming problem.","['Okui, Ryo', 'Kuersteiner, Guido']","['Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation', 'Multiple or Simultaneous Equation Models: Instrumental Variables (IV) Estimation']","['C26', 'C36']",Constructing Optimal Instruments by First-Stage Prediction Averaging,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"The subjective likelihood of a contingency often depends on the manner in which it is described to the decision maker. To accommodate this dependence, we introduce a model of decision making under uncertainty that takes as primitive a family of preferences indexed by partitions of the state space. Each partition corresponds to a description of the state space. We characterize the following partition-dependent expected utility representation. The decision maker has a nonadditive set function nu over events. Given a partition of the state space, she computes expected utility with respect to her partition-dependent belief, which weights each cell in the partition by nu. Nonadditivity of nu allows the probability of an event to depend on the way in which the state space is described. We propose behavioral definitions for those events that are transparent to the decision maker and those that are completely overlooked, and connect these definitions to conditions on the representation.","['Ergin, Haluk', 'Ahn, David S.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Framing Contingencies,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"The deferred acceptance algorithm is often used to allocate indivisible objects when monetary transfers are not allowed. We provide two characterizations of agent-proposing deferred acceptance allocation rules. Two new axioms--individually rational monotonicity and weak Maskin monotonicity--are essential to our analysis. An allocation rule is the agent-proposing deferred acceptance rule for some acceptant substitutable priority if and only if it satisfies non-wastefulness and individually rational monotonicity. An alternative characterization is in terms of non-wastefulness, population monotonicity, and weak Maskin monotonicity. We also offer an axiomatization of the deferred acceptance rule generated by an exogenously specified priority structure. We apply our results to characterize efficient deferred acceptance rules.","['Kojima, Fuhito', 'Manea, Mihai']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",Axioms for Deferred Acceptance,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"Unlike the prediction of a frictionless open economy model, long-term average savings and investment rates are highly correlated across countries--a puzzle first identified by Feldstein and Horioka (1980). We quantitatively investigate the impact of two types of financial frictions on this correlation. One is limited enforcement, where contracts are enforced by the threat of default penalties. The other is limited spanning, where the only asset available is noncontingent bonds. We find that the calibrated model with both frictions produces a savings-investment correlation and a volume of capital flows close to the data. To solve the puzzle, the limited enforcement friction needs low default penalties under which capital flows are much lower than those in the data, and the limited spanning friction needs to exogenously restrict capital flows to the observed level. When combined, the two frictions interact to endogenously restrict capital flows and thereby solve the Feldstein-Horioka puzzle.","['Zhang, Jing', 'Bai, Yan']","['Macroeconomics: Consumption; Saving; Wealth', 'Investment; Capital; Intangible Capital; Capacity', 'Current Account Adjustment; Short-term Capital Movements', 'Open Economy Macroeconomics']","['E21', 'E22', 'F32', 'F41']",Solving the Feldstein-Horioka Puzzle with Financial Frictions,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"Single equation instrumental variable models for discrete outcomes are shown to be set identifying, not point identifying, for the structural functions that deliver the values of the discrete outcome. Bounds on identified sets are derived for a general nonparametric model and sharp set identification is demonstrated in the binary outcome case. Point identification is typically not achieved by imposing parametric restrictions. The extent of an identified set varies with the strength and support of instruments, and typically shrinks as the support of a discrete outcome grows. The paper extends the analysis of structural quantile functions with endogenous arguments to cases in which there are discrete outcomes.","['Chesher, Andrew']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Single Equation Models: Single Variables: Instrumental Variables (IV) Estimation']","['C25', 'C26']",Instrumental Variable Models for Discrete Outcomes,0,0,0,0,0,2010,03,01
78,2,2010-03-01,"We investigate the role of search frictions in markets with price competition and how it leads to sorting of heterogeneous agents. There are two aspects of value creation: the match value when two agents actually trade and the probability of trading governed by the search technology. We show that positive assortative matching obtains when complementarities in the former outweigh complementarities in the latter. This happens if and only if the match-value function is root-supermodular, that is, its nth root is supermodular, where n reflects the elasticity of substitution of the search technology. This condition is weaker than the condition required for positive assortative matching in markets with random search.","['Eeckhout, Jan', 'Kircher, Philipp']","['Bargaining Theory; Matching Theory', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'D43', 'D83']",Sorting and Decentralized Price Competition,0,0,1,0,0,2010,03,01
78,2,2010-03-01,"We examine the labor market effects of incomplete information about the workers' own job-finding process. Search outcomes convey valuable information, and learning from search generates endogenous heterogeneity in workers' beliefs about their job-finding probability. We characterize this process and analyze its interactions with job creation and wage determination. Our theory sheds new light on how unemployment can affect workers' labor market outcomes and wage determination, providing a rational explanation for discouragement as the consequence of negative search outcomes. In particular, longer unemployment durations are likely to be followed by lower reemployment wages because a worker's beliefs about his job-finding process deteriorate with unemployment duration. Moreover, our analysis provides a set of useful results on dynamic programming with optimal learning.","['Shi, Shouyong', 'Gonzalez, Francisco M.']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['D82', 'D83', 'J22', 'J31', 'J41', 'J64']","An Equilibrium Theory of Learning, Search, and Wages",0,0,0,0,0,2010,03,01
78,2,2010-03-01,"Learning-by-doing and organizational forgetting are empirically important in a variety of industrial settings. This paper provides a general model of dynamic competition that accounts for these fundamentals and shows how they shape industry structure and dynamics. We show that forgetting does not simply negate learning. Rather, they are distinct economic forces that interact in subtle ways to produce a great variety of pricing behaviors and industry dynamics. In particular, a model with learning and forgetting can give rise to aggressive pricing behavior, varying degrees of long-run industry concentration ranging from moderate leadership to absolute dominance, and multiple equilibria.","['Satterthwaite, Mark', 'Besanko, David', 'Kryukov, Yaroslav', 'Doraszelski, Ulrich']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Organizational Behavior; Transaction Costs; Property Rights', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Oligopoly and Other Imperfect Markets']","['C73', 'D23', 'D43', 'D83', 'L13']","Learning-by-Doing, Organizational Forgetting, and Industry Dynamics",1,0,1,0,0,2010,03,01
78,1,2010-01-01,ECONLIT None Found,"['Acemoglu, Daron', 'Berry, Steve', 'Pesendorfer, Wolfgang', 'Samuelson, Larry', 'Morris, Stephen', 'Uhlig, Harald', 'Newey, Whitney']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE EDITORS 2008-2009.,0,0,0,0,0,2010,01,01
78,1,2010-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],THE ECONOMETRIC SOCIETY REPORTS: REPORT OF THE TREASURER.,0,0,0,0,0,2010,01,01
78,1,2010-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE SECRETARY.,0,0,0,0,0,2010,01,01
78,1,2010-01-01,An emerging literature in time series econometrics concerns the modeling of potentially nonlinear temporal dependence in stationary Markov chains using copula functions. We obtain sufficient conditions for a geometric rate of mixing in models of this kind. Geometric beta-mixing is established under a rather strong sufficient condition that rules out asymmetry and tail dependence in the copula function. Geometric rho-mixing is obtained under a weaker condition that permits both asymmetry and tail dependence. We verify one or both of these conditions for a range of parametric copula functions that are popular in applied work.,"['Beare, Brendan K.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Copulas and Temporal Dependence,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"This paper develops methods for evaluating marginal policy changes. We characterize how the effects of marginal policy changes depend on the direction of the policy change, and show that marginal policy effects are fundamentally easier to identify and to estimate than conventional treatment parameters. We develop the connection between marginal policy effects and the average effect of treatment for persons on the margin of indifference between participation in treatment and nonparticipation, and use this connection to analyze both parameters. We apply our analysis to estimate the effect of marginal changes in tuition on the return to going to college.","['Heckman, James J.', 'Carneiro, Pedro', 'Vytlacil, Edward']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials']","['C21', 'J24', 'J31']",Evaluating Marginal Policy Changes and the Average Effect of Treatment for Individuals at the Margin,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"We use a preference-over-menus framework to model a decision maker who is affected by multiple temptations. Our two main axioms on preference--exclusion and inclusion--identify when the agent would want to restrict his choice set and when he would want to expand his choice set. An agent who is tempted would want to restrict his choice set by excluding the normatively worst alternative of that choice set. Simultaneously, he would want to expand his choice set by including a normatively superior alternative. Our representation identifies the agent's normative preference and temptations, and suggests the agent is uncertain which of these temptations will affect him. We provide examples to illustrate how our model improves on those of Gul and Pesendorfer (2001) and Dekel, Lipman, and Rustichini (2009).","['Stovall, John E.']",['Consumer Economics: Theory'],['D11'],Multiple Temptations,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"We prove the generic existence of a recursive equilibrium for overlapping-generations economies with uncertainty. ""Generic"" here means in a residual set of utilities and endowments. The result holds provided there is a sufficient number of potentially different individuals within each cohort.","['Citanna, Alessandro', 'Siconolfi, Paolo']",['General Aggregative Models: Neoclassical'],['E13'],Recursive Equilibrium in Stochastic Overlapping-Generations Economies,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"This paper studies partnerships that employ a mediator to improve their contractual ability. Intuitively, profitable deviations must be attributable, that is, there must be some group behavior such that an individual can be statistically identified as innocent, to provide incentives in partnerships. Mediated partnerships add value by effectively using different behavior to attribute different deviations. As a result, mediated partnerships are necessary to provide the right incentives in a wide range of economic environments.","['Rahman, David', 'Obara, Ichiro']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Mediated Partnerships,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"We consider a model of strategic trading with asymmetric information of an asset whose value follows a Brownian motion. An insider continuously observes a signal that tracks the evolution of the asset's fundamental value. The value of the asset is publicly revealed at a random time. The equilibrium has two regimes separated by an endogenously determined time T. In [0, T), the insider gradually transfers her information to the market. By time T, all her information has been transferred and the price agrees with the market value of the asset. In the interval [T, infinity), the insider trades large volumes and reveals her information immediately, so market prices track the market value perfectly. Despite this market efficiency, the insider is able to collect strictly positive rents after T.","['Caldentey, Rene', 'Stacchetti, Ennio']","['Asymmetric and Private Information; Mechanism Design', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D82', 'G11', nan]",Insider Trading with a Random Deadline,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"We present a model in which a principal delegates the choice of project to an agent with different preferences. The principal determines the set of projects from which the agent may choose. The principal can verify the characteristics of the project chosen by the agent, but does not know which other projects were available to the agent. We consider situations where the collection of available projects is exogenous to the agent but uncertain, where the agent must invest effort to discover a project, where the principal can pay the agent to choose a desirable project, and where the principal can adopt more complex schemes than simple permission sets.","['Vickers, John', 'Armstrong, Mark']","['Asymmetric and Private Information; Mechanism Design', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance']","['D82', 'G34']",A Model of Delegated Project Choice,0,0,0,0,1,2010,01,01
78,1,2010-01-01,"This paper provides computationally intensive, yet feasible methods for inference in a very general class of partially identified econometric models. Let P denote the distribution of the observed data. The class of models we consider is defined by a population objective function Q(theta, P) for theta element of Theta. The point of departure from the classical extremum estimation framework is that it is not assumed that Q(theta, P) has a unique minimizer in the parameter space Theta. The goal may be either to draw inferences about some unknown point in the set of minimizers of the population objective function or to draw inferences about the set of minimizers itself. In this paper, the object of interest is Theta[subscript 0](P)=arg min[subscript theta element of Theta]Q(theta, P), and so we seek random sets that contain this set with at least some prespecified probability asymptotically. We also consider situations where the object of interest is the image of Theta[subscript 0](P) under a known function. Random sets that satisfy the desired coverage property are constructed under weak assumptions. Conditions are provided under which the confidence regions are asymptotically valid not only pointwise in P, but also uniformly in P. We illustrate the use of our methods with an empirical study of the impact of top-coding outcomes on inferences about the parameters of a linear regression. Finally, a modest simulation study sheds some light on the finite-sample behavior of our procedure.","['Romano, Joseph P.', 'Shaikh, Azeem M.']","['Hypothesis Testing: General', 'Estimation: General']","['C12', 'C13']",Inference for the Identified Set in Partially Identified Econometric Models,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"This paper considers a panel data model for predicting a binary outcome. The conditional probability of a positive response is obtained by evaluating a given distribution function (F) at a linear combination of the predictor variables. One of the predictor variables is unobserved. It is a random effect that varies across individuals but is constant over time. The semiparametric aspect is that the conditional distribution of the random effect, given the predictor variables, is unrestricted. This paper has two results. If the support of the observed predictor variables is bounded, then identification is possible only in the logistic case. Even if the support is unbounded, so that (from Manski (1987)) identification holds quite generally, the information bound is zero unless F is logistic. Hence consistent estimation at the standard pn rate is possible only in the logistic case.","['Chamberlain, Gary']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",Binary Response Models for Panel Data: Identification and Information,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"The topic of this paper is inference in models in which parameters are defined by moment inequalities and/or equalities. The parameters may or may not be identified. This paper introduces a new class of confidence sets and tests based on generalized moment selection (GMS). GMS procedures are shown to have correct asymptotic size in a uniform sense and are shown not to be asymptotically conservative. The power of GMS tests is compared to that of subsampling, m out of n bootstrap, and ""plug-in asymptotic"" (PA) tests. The latter three procedures are the only general procedures in the literature that have been shown to have correct asymptotic size (in a uniform sense) for the moment inequality/equality model. GMS tests are shown to have asymptotic power that dominates that of subsampling, m out of n bootstrap, and PA tests. Subsampling and m out of n bootstrap tests are shown to have asymptotic power that dominates that of PA tests.","['Soares, Gustavo', 'Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Estimation: General']","['C12', 'C13']",Inference for Parameters Defined by Moment Inequalities Using Generalized Moment Selection,0,0,0,0,0,2010,01,01
78,1,2010-01-01,"We study a continuous-time principal-agent model in which a risk-neutral agent with limited liability must exert unobservable effort to reduce the likelihood of large but relatively infrequent losses. Firm size can be decreased at no cost or increased subject to adjustment costs. In the optimal contract, investment takes place only if a long enough period of time elapses with no losses occurring. Then, if good performance continues, the agent is paid. As soon as a loss occurs, payments to the agent are suspended, and so is investment if further losses occur. Accumulated bad performance leads to downsizing. We derive explicit formulae for the dynamics of firm size and its asymptotic growth rate, and we provide conditions under which firm size eventually goes to zero or grows without bounds.","['Villeneuve, Stephane', 'Mariotti, Thomas', 'Biais, Bruno', 'Rochet, Jean-Charles']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Firm Performance: Size, Diversification, and Scope']","['D81', 'D82', 'D25', 'G31', 'L25']","Large Risks, Limited Liability, and Dynamic Moral Hazard",1,0,0,0,0,2010,01,01
78,1,2010-01-01,"We construct a new index of media slant that measures the similarity of a news outlet's language to that of a congressional Republican or Democrat. We estimate a model of newspaper demand that incorporates slant explicitly, estimate the slant that would be chosen if newspapers independently maximized their own profits, and compare these profit-maximizing points with firms' actual choices. We find that readers have an economically significant preference for like-minded news. Firms respond strongly to consumer preferences, which account for roughly 20 percent of the variation in measured slant in our sample. By contrast, the identity of a newspaper's owner explains far less of the variation in slant.","['Shapiro, Jesse M.', 'Gentzkow, Matthew']","['Model Construction and Estimation', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Entertainment; Media']","['C51', 'D72', 'L82']",What Drives Media Slant? Evidence from U.S. Daily Newspapers,1,0,0,0,0,2010,01,01
78,1,2010-01-01,"The absence of state capacities to raise revenue and to support markets is a key factor in explaining the persistence of weak states. This paper reports on an ongoing project to investigate the incentive to invest in such capacities. The paper sets out a simple analytical structure in which state capacities are modeled as forward looking investments by government. The approach highlights some determinants of state building including the risk of external or internal conflict, the degree of political instability, and dependence on natural resources. Throughout, we link these state capacity investments to patterns of development and growth.","['Besley, Timothy', 'Persson, Torsten']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Structure, Scope, and Performance of Government', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements']","['D74', 'H11', 'O17']","State Capacity, Conflict, and Development",0,0,0,0,0,2010,01,01
77,6,2009-11-01,"We show by counterexample that Proposition 2 in Fernandez-Villaverde, Rubio-Ramirez, and Santos (Econometrica (2006), 74, 93-119) is false. We also show that even if their Proposition 2 were corrected, it would be irrelevant for parameter estimates. As a more constructive contribution, we consider the effects of approximation error on parameter estimation, and conclude that second order approximation errors in the policy function have at most second order effects on parameter estimates.","['Ackerberg, Daniel', 'Hahn, Jinyong', 'Geweke, John']",['Model Construction and Estimation'],['C51'],Comments on 'Convergence Properties of the Likelihood of Computed Dynamic Models',0,0,0,0,0,2009,11,01
77,6,2009-11-01,"Information asymmetries are important in theory but difficult to identify in practice. We estimate the presence and importance of hidden information and hidden action problems in a consumer credit market using a new field experiment methodology. We randomized 58,000 direct mail offers to former clients of a major South African lender along three dimensions: (i) an initial ""offer interest rate"" featured on a direct mail solicitation; (ii) a ""contract interest rate"" that was revealed only after a borrower agreed to the initial offer rate; and (ii) a dynamic repayment incentive that was also a surprise and extended preferential pricing on future loans to borrowers who remained in good standing. These three randomizations, combined with complete knowledge of the lender's information set, permit identification of specific types of private information problems. Our setup distinguishes hidden information effects from selection on the offer rate (via unobservable risk and anticipated effort), from hidden action effects (via moral hazard in effort) induced by actual contract terms. We find strong evidence of moral hazard and weaker evidence of hidden information problems. A rough estimate suggests that perhaps 13% to 21% of default is due to moral hazard. Asymmetric information thus may help explain the prevalence of credit constraints even in a market that specializes in financing high-risk borrowers.","['Zinman, Jonathan', 'Karlan, Dean']","['Asymmetric and Private Information; Mechanism Design', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Economic Development: Financial Markets; Saving and Capital Investment; Corporate Finance and Governance']","['D82', 'G21', 'O16']",Observing Unobservables: Identifying Information Asymmetries with a Consumer Credit Field Experiment,0,0,0,0,0,2009,11,01
77,6,2009-11-01,"We identify a new way to order functions, called the interval dominance order, that generalizes both the single crossing property and a standard condition used in statistical decision theory. This allows us to provide a unified treatment of the major theorems on monotone comparative statics with and without uncertainty, the comparison of signal informativeness, and a non-Bayesian theorem on the completeness of increasing decision rules. We illustrate the concept and results with various applications, including an application to optimal stopping time problems where the single crossing property is typically violated.","['Quah, John K.-H.', 'Strulovici, Bruno']","['Operations Research; Statistical Decision Theory', 'Miscellaneous Mathematical Tools', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C44', 'C65', 'D83']","Comparative Statics, Informativeness, and the Interval Dominance Order",0,0,0,0,0,2009,11,01
77,6,2009-11-01,"Nonparametric estimation of a structural cointegrating regression model is studied. As in the standard linear cointegrating regression model, the regressor and the dependent variable are jointly dependent and contemporaneously correlated. In nonparametric estimation problems, joint dependence is known to be a major complication that affects identification, induces bias in conventional kernel estimates, and frequently leads to ill-posed inverse problems. In functional cointegrating regressions where the regressor is an integrated or near-integrated time series, it is shown here that inverse and ill-posed inverse problems do not arise. Instead, simple nonparametric kernel estimation of a structural nonparametric cointegrating regression is consistent and the limit distribution theory is mixed normal, giving straightforward asymptotics that are useable in practical work. It is further shown that use of augmented regression, as is common in linear cointegration modeling to address endogeneity, does not lead to bias reduction in nonparametric regression, but there is an asymptotic gain in variance reduction. The results provide a convenient basis for inference in structural nonparametric regression with nonstationary time series when there is a single integrated or near-integrated regressor. The methods may be applied to a range of empirical models where functional estimation of cointegrating relations is required.","['Phillips, Peter C. B.', 'Wang, Qiying']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Structural Nonparametric Cointegrating Regression,0,0,0,0,0,2009,11,01
77,6,2009-11-01,"We propose a new methodology for structural estimation of infinite horizon dynamic discrete choice models. We combine the dynamic programming (DP) solution algorithm with the Bayesian Markov chain Monte Carlo algorithm into a single algorithm that solves the DP problem and estimates the parameters simultaneously. As a result, the computational burden of estimating a dynamic model becomes comparable to that of a static model. Another feature of our algorithm is that even though the number of grid points on the state variable is small per solution-estimation iteration, the number of effective grid points increases with the number of estimation iterations. This is how we help ease the ""curse of dimensionality."" We simulate and estimate several versions of a simple model of entry and exit to illustrate our methodology. We also prove that under standard conditions, the parameters converge in probability to the true posterior distribution, regardless of the starting values.","['Ching, Andrew', 'Jain, Neelam', 'Imai, Susumu']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],Bayesian Estimation of Dynamic Discrete Choice Models,0,0,0,0,0,2009,11,01
77,6,2009-11-01,Conventional wisdom suggests that increased life expectancy had a key role in causing a rise in investment in human capital. I incorporate the retirement decision into a version of Ben-Porath's (1967) model and find that a necessary condition for this causal relationship to hold is that increased life expectancy will also increase lifetime labor supply. I then show that this condition does not hold for American men born between 1840 and 1970 and for the American population born between 1890 and 1970. The data suggest similar patterns in Western Europe. I end by discussing the implications of my findings for the debate on the fundamental causes of long-run growth.,"['Hazan, Moshe']","['Health Behavior', 'Time Allocation and Labor Supply', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Retirement; Retirement Policies', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S.; Canada: Pre-1913', 'Economic History: Labor and Consumers, Demography, Education, Health, Welfare, Income, Wealth, Religion, and Philanthropy: U.S.; Canada: 1913-']","['I12', 'J22', 'J24', 'J26', 'N31', 'N32']",Longevity and Lifetime Labor Supply: Evidence and Implications,0,0,0,0,0,2009,11,01
77,6,2009-11-01,"We provide a practical method to estimate the payoff functions of players in complete information, static, discrete games. With respect to the empirical literature on entry games originated by Bresnahan and Reiss (1990) and Berry (1992), the main novelty of our framework is to allow for general forms of heterogeneity across players without making equilibrium selection assumptions. We allow the effects that the entry of each individual airline has on the profits of its competitors, its ""competitive effects,"" to differ across airlines. The identified features of the model are sets of parameters (partial identification) such that the choice probabilities predicted by the econometric model are consistent with the empirical choice probabilities estimated from the data. We apply this methodology to investigate the empirical importance of firm heterogeneity as a determinant of market structure in the U.S. airline industry. We find evidence of heterogeneity across airlines in their profit functions. The competitive effects of large airlines (American, Delta, United) are different from those of low cost carriers and Southwest. Also, the competitive effect of an airline is increasing in its airport presence, which is an important measure of observable heterogeneity in the airline industry. Then we develop a policy experiment to estimate the effect of repealing the Wright Amendment on competition in markets out of the Dallas airports. We find that repealing the Wright Amendment would increase the number of markets served out of Dallas Love.","['Tamer, Elie', 'Ciliberto, Federico']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Oligopoly and Other Imperfect Markets', 'Firm Performance: Size, Diversification, and Scope', 'Air Transportation']","['D24', 'L11', 'L13', 'L25', 'L93']",Market Structure and Multiple Equilibria in Airline Markets,1,0,0,0,0,2009,11,01
77,6,2009-11-01,"In this paper, we build a model where the presence of liquidity constraints tends to magnify the economy's response to aggregate shocks. We consider a decentralized model of trade, where agents may use money or credit to buy goods. When agents do not have access to credit and the real value of money balances is low, agents are more likely to be liquidity constrained. This makes them more concerned about their short-term earning prospects when making their consumption decisions and about their short-term spending opportunities when making their production decisions. This generates a coordination element in spending and production which leads to greater aggregate volatility and greater comovement across producers.","['Lorenzoni, Guido', 'Guerrieri, Veronica']","['Macroeconomics: Consumption; Saving; Wealth', 'Business Fluctuations; Cycles', 'Demand for Money']","['E21', 'E32', 'E41']",Liquidity and Trading Dynamics,0,0,0,0,0,2009,11,01
77,6,2009-11-01,"I study asset prices in a two-agent macroeconomic model with two key features: limited stock market participation and heterogeneity in the elasticity of intertemporal substitution in consumption (EIS). The model is consistent with some prominent features of asset prices, such as a high equity premium, relatively smooth interest rates, procyclical stock prices, and countercyclical variation in the equity premium, its volatility, and in the Sharpe ratio. In this model, the risk-free asset market plays a central role by allowing non-stockholders (with low EIS) to smooth the fluctuations in their labor income. This process concentrates non-stockholders' labor income risk among a small group of stockholders, who then demand a high premium for bearing the aggregate equity risk. Furthermore, this mechanism is consistent with the very small share of aggregate wealth held by non-stockholders in the U.S. data, which has proved problematic for previous models with limited participation. I show that this large wealth inequality is also important for the model's ability to generate a countercyclical equity premium. When it comes to business cycle performance, the model's progress has been more limited: consumption is still too volatile compared to the data, whereas investment is still too smooth. These are important areas for potential improvement in this framework.","['Guvenen, Fatih']","['Business Fluctuations; Cycles', 'Financial Markets and the Macroeconomy', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['E32', 'E44', nan]",A Parsimonious Macroeconomic Model for Asset Pricing,0,0,0,0,0,2009,11,01
77,5,2009-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"This paper develops asymptotic optimality theory for statistical treatment rules in smooth parametric and semiparametric models. Manski (2000, 2002, 2004) and Dehejia (2005) have argued that the problem of choosing treatments to maximize social welfare is distinct from the point estimation and hypothesis testing problems usually considered in the treatment effects literature, and advocate formal analysis of decision procedures that map empirical data into treatment choices. We develop large-sample approximations to statistical treatment assignment problems using the limits of experiments framework. We then consider some different loss functions and derive treatment assignment rules that are asymptotically optimal under average and minmax risk criteria.","['Porter, Jack R.', 'Hirano, Keisuke']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Asymptotics for Statistical Treatment Rules,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"This paper develops a method for inference in dynamic discrete choice models with serially correlated unobserved state variables. Estimation of these models involves computing high-dimensional integrals that are present in the solution to the dynamic program and in the likelihood function. First, the paper proposes a Bayesian Markov chain Monte Carlo estimation procedure that can handle the problem of multidimensional integration in the likelihood function. Second, the paper presents an efficient algorithm for solving the dynamic program suitable for use in conjunction with the proposed estimation procedure.","['Norets, Andriy']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C22', 'C25']",Inference in Dynamic Discrete Choice Models with Serially Correlated Unobserved State Variables,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"We use a controlled experiment to explore whether there are gender differences in selecting into competitive environments across two distinct societies: the Maasai in Tanzania and the Khasi in India. One unique aspect of these societies is that the Maasai represent a textbook example of a patriarchal society, whereas the Khasi are matrilineal. Similar to the extant evidence drawn from experiments executed in Western cultures, Maasai men opt to compete at roughly twice the rate as Maasai women. Interestingly, this result is reversed among the Khasi, where women choose the competitive environment more often than Khasi men, and even choose to compete weakly more often than Maasai men. These results provide insights into the underpinnings of the factors hypothesized to be determinants of the observed gender differences in selecting into competitive environments.","['List, John A.', 'Leonard, Kenneth L.', 'Gneezy, Uri']","['Economics of Gender; Non-labor Discrimination', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['J16', 'O15', 'Z13']",Gender Differences in Competition: Evidence from a Matrilineal and a Patriarchal Society,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"A norm of 50-50 division appears to have considerable force in a wide range of economic environments, both in the real world and in the laboratory. Even in settings where one party unilaterally determines the allocation of a prize (the dictator game), many subjects voluntarily cede exactly half to another individual. The hypothesis that people care about fairness does not by itself account for key experimental patterns. We consider an alternative explanation, which adds the hypothesis that people like to be perceived as fair. The properties of equilibria for the resulting signaling game correspond closely to laboratory observations. The theory has additional testable implications, the validity of which we confirm through new experiments.","['Andreoni, James', 'Bernheim, B. Douglas']","['Noncooperative Games', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['C72', 'D63']",Social Image and the Fifty-Fifty Norm: A Theoretical and Experimental Analysis of Audience Effects,0,0,0,0,0,2009,09,01
77,5,2009-09-01,Anscombe and Aumann (1963) wrote a classic characterization of subjective expected utility theory. This paper employs the same domain for preference and a closely related (but weaker) set of axioms to characterize preferences that use second-order beliefs (beliefs over probability measures). Such preferences are of interest because they accommodate Ellsberg-type behavior.,"['Seo, Kyoungwon']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D83']",Ambiguity and Second-Order Belief,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"We solve for the equilibrium dynamics of information sharing in a large population. Each agent is endowed with signals regarding the likely outcome of a random variable of common concern. Individuals choose the effort with which they search for others from whom they can gather additional information. When two agents meet, they share their information. The information gathered is further shared at subsequent meetings, and so on. Equilibria exist in which agents search maximally until they acquire sufficient information precision and then search minimally. A tax whose proceeds are used to subsidize the costs of search improves information sharing and can, in some cases, increase welfare. On the other hand, endowing agents with public signals reduces information sharing and can, in some cases, decrease welfare.","['Duffie, Darrell', 'Malamud, Semyon', 'Manso, Gustavo']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Information Percolation with Equilibrium Search Dynamics,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"This paper uses control variables to identify and estimate models with nonseparable, multidimensional disturbances. Triangular simultaneous equations models are considered, with instruments and disturbances that are independent and a reduced form that is strictly monotonic in a scalar disturbance. Here it is shown that the conditional cumulative distribution function of the endogenous variable given the instruments is a control variable. Also, for any control variable, identification results are given for quantile, average, and policy effects. Bounds are given when a common support assumption is not satisfied. Estimators of identified objects and bounds are provided, and a demand analysis empirical example is given.","['Imbens, Guido W.', 'Newey, Whitney K.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Identification and Estimation of Triangular Simultaneous Equations Models without Additivity,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"In this paper we study high-dimensional time series that have the generalized dynamic factor structure. We develop a test of the null of k[subscript 0] factors against the alternative that the number of factors is larger than k[subscript 0] but no larger than k[subscript 1] > k[subscript 0]. Our test statistic equals max[subscript k[subscript 0] < k <= k[subscript 1]] (gamma[subscript k] - gamma[subscript k + 1])/(gamma[subscript k + 1] - gamma[subscript k + 2]), where gamma[subscript i] is the ith largest eigenvalue of the smoothed periodogram estimate of the spectral density matrix of data at a prespecified frequency. We describe the asymptotic distribution of the statistic, as the dimensionality and the number of observations rise, as a function of the Tracy-Widom distribution and tabulate the critical values of the test. As an application, we test different hypotheses about the number of dynamic factors in macroeconomic time series and about the number of dynamic factors driving excess stock returns.","['Onatski, Alexei']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C32', 'C58', nan]",Testing Hypotheses about the Number of Factors in Large Factor Models,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"The econometric literature of high frequency data often relies on moment estimators which are derived from assuming local constancy of volatility and related quantities. We here study this local-constancy approximation as a general approach to estimation in such data. We show that the technique yields asymptotic properties (consistency, normality) that are correct subject to an ex post adjustment involving asymptotic likelihood ratios. These adjustments are derived and documented. Several examples of estimation are provided: powers of volatility, leverage effect, and integrated betas. The first order approximations based on local constancy can be over the period of one observation or over blocks of successive observations. It has the advantage of gaining in transparency in defining and analyzing estimators. The theory relies heavily on the interplay between stable convergence and measure change, and on asymptotic expansions for martingales.","['Zhang, Lan', 'Mykland, Per A.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Financial Econometrics', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C58', nan]",Inference for Continuous Semimartingales Observed at High Frequency,0,0,0,0,0,2009,09,01
77,5,2009-09-01,"I study individuals who use frequentist models to draw uniform inferences from independent and identically distributed data. The main contribution of this paper is to show that distinct models may be consistent with empirical evidence, even in the limit when data increases without bound. Decision makers may then hold different beliefs and interpret their environment differently even though they know each other's model and base their inferences on the same evidence. The behavior modeled here is that of rational individuals confronting an environment in which learning is hard, rather than individuals beset by cognitive limitations or behavioral biases.","['Al-Najjar, Nabil I.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D83']","Decision Makers as Statisticians: Diversity, Ambiguity, and Learning",0,0,0,0,0,2009,09,01
77,5,2009-09-01,"I discuss the failure of the canonical search and matching model to match the cyclical volatility in the job finding rate. I show that job creation in the model is influenced by wages in new matches. I summarize microeconometric evidence and find that wages in new matches are volatile and consistent with the model's key predictions. Therefore, explanations of the unemployment volatility puzzle have to preserve the cyclical volatility of wages. I discuss a modification of the model, based on fixed matching costs, that can increase cyclical unemployment volatility and is consistent with wage flexibility in new matches.","['Pissarides, Christopher A.']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['E24', 'E32', 'J31', 'J41', 'J64']",The Unemployment Volatility Puzzle: Is Wage Stickiness the Answer?,0,0,0,0,0,2009,09,01
77,3,2009-05-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS: 2009 AUSTRALASIAN MEETING.,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"Two key issues in the literature on female labor supply are (i) whether persistence in employment status is due to unobserved heterogeneity or state dependence, and (ii) whether fertility is exogenous to labor supply. Until recently, the consensus was that unobserved heterogeneity is very important and fertility is endogenous. Hyslop (1999) challenged this. Using a dynamic panel probit model of female labor supply including heterogeneity and state dependence, he found that adding autoregressive errors led to a substantial diminution in the importance of heterogeneity. This, in turn, meant he could not reject that fertility is exogenous. Here, we extend Hyslop (1999) to allow classification error in employment status, using an estimation procedure developed by Keane and Wolpin (2001) and Keane and Sauer (2005). We find that a fairly small amount of classification error is enough to overturn Hyslop's conclusions, leading to overwhelming rejection of the hypothesis of exogenous fertility.","['Sauer, Robert M.', 'Keane, Michael P.']","['Model Construction and Estimation', 'Fertility; Family Planning; Child Care; Children; Youth', 'Economics of Gender; Non-labor Discrimination', 'Time Allocation and Labor Supply']","['C51', 'J13', 'J16', 'J22']",Classification Error in Dynamic Discrete Choice Models: Implications for Female Labor Supply Behavior,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"We propose a new regression method to evaluate the impact of changes in the distribution of the explanatory variables on quantiles of the unconditional (marginal) distribution of an outcome variable. The proposed method consists of running a regression of the (recentered) influence function (RIF) of the unconditional quantile on the explanatory variables. The influence function, a widely used tool in robust estimation, is easily computed for quantiles, as well as for other distributional statistics. Our approach, thus, can be readily generalized to other distributional statistics.","['Firpo, Sergio', 'Fortin, Nicole M.', 'Lemieux, Thomas']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Model Construction and Estimation', 'Wage Level and Structure; Wage Differentials', 'Trade Unions: Objectives, Structure, and Effects']","['C21', 'C51', 'J31', 'J51']",Unconditional Quantile Regressions,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"We propose a new Walrasian tatonnement process called a double-track procedure for efficiently allocating multiple heterogeneous indivisible items in two distinct sets to many buyers who view items in the same set as substitutes but items across the two sets as complements. In each round of the process, a Walrasian auctioneer first announces the current prices for all items, buyers respond by reporting their demands at these prices, and then the auctioneer adjusts simultaneously the prices of items in one set upward but those of items in the other set downward. It is shown that this procedure converges globally to a Walrasian equilibrium in finitely many rounds.","['Sun, Ning', 'Yang, Zaifu']","['Market Structure, Pricing, and Design: General', 'Auctions']","['D40', 'D44']",A Double-Track Adjustment Process for Discrete Markets with Substitutes and Complements,0,0,1,0,0,2009,05,01
77,3,2009-05-01,"Can incentives be effective in encouraging the development of good habits? We investigate the post-intervention effects of paying people to attend a gym a number of times during one month. In two studies we find marked attendance increases after the intervention relative to attendance changes for the respective control groups. This is entirely driven by people who did not previously attend the gym on a regular basis. In our second study, we find improvements on health indicators such as weight, waist size, and pulse rate, suggesting the intervention led to a net increase in total physical activity rather than to a substitution away from nonincentivized ones. We argue that there is scope for financial intervention in habit formation, particularly in the area of health.","['Charness, Gary', 'Gneezy, Uri']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Health Behavior']","['D83', 'I12']",Incentives to Exercise,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"We develop a theory of optimal stopping under Knightian uncertainty. A suitable martingale theory for multiple priors is derived that extends the classical dynamic programming or Snell envelope approach to multiple priors. We relate the multiple prior theory to the classical setup via a minimax theorem. In a multiple prior version of the classical model of independent and identically distributed random variables, we discuss several examples from microeconomics, operation research, and finance. For monotone payoffs, the worst-case prior can be identified quite easily with the help of stochastic dominance arguments. For more complex payoff structures like barrier options, model ambiguity leads to stochastic changes in the worst-case beliefs.","['Riedel, Frank']","['Operations Research; Statistical Decision Theory', 'Optimization Techniques; Programming Models; Dynamic Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Contingent Pricing; Futures Pricing; option pricing']","['C44', 'C61', 'D81', 'G13']",Optimal Stopping with Multiple Priors,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"This paper proposes a model of decision under ambiguity deemed vector expected utility, or VEU. In this model, an uncertain prospect, or Savage act, is assessed according to (a) a baseline expected-utility evaluation, and (b) an adjustment that reflects the individual's perception of ambiguity and her attitudes toward it. The adjustment is itself a function of the act's exposure to distinct sources of ambiguity, as well as its variability. The key elements of the VEU model are a baseline probability and a collection of random variables, or adjustment factors, which represent acts exposed to distinct ambiguity sources and also reflect complementarities among ambiguous events. The adjustment to the baseline expected-utility evaluation of an act is a function of the covariance of its utility profile with each adjustment factor, which reflects exposure to the corresponding ambiguity source. A behavioral characterization of the VEU model is provided. Furthermore, an updating rule for VEU preferences is proposed and characterized. The suggested updating rule facilitates the analysis of sophisticated dynamic choice with VEU preferences.","['Siniscalchi, Marciano']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Vector Expected Utility and Attitudes toward Variation,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"Consider a group consisting of S members facing a common budget constraint p' xi = 1: any demand vector belonging to the budget set can be (privately or publicly) consumed by the members. Although the intragroup decision process is not known, it is assumed to generate Pareto-efficient outcomes; neither individual consumptions nor intragroup transfers are observable. The paper analyzes when, to what extent, and under which conditions it is possible to recover the underlying structure--individual preferences and the decision process--from the group's aggregate behavior. We show that the general version of the model is not identified. However, a simple exclusion assumption (whereby each member does not consume at least one good) is sufficient to guarantee generic identifiability of the welfare-relevant structural concepts.","['Chiappori, P.-A.', 'Ekeland, I.']","['Consumer Economics: Theory', 'Social Choice; Clubs; Committees; Associations', 'Time Allocation and Labor Supply']","['D11', 'D71', 'J22']",The Microeconomics of Efficient Group Behavior: Identification,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"This paper considers inference in a broad class of nonregular models. The models considered are nonregular in the sense that standard test statistics have asymptotic distributions that are discontinuous in some parameters. It is shown in Andrews and Guggenberger (2009a) that standard fixed critical value, subsampling, and m out of n bootstrap methods often have incorrect asymptotic size in such models. This paper introduces general methods of constructing tests and confidence intervals that have correct asymptotic size. In particular, we consider a hybrid subsampling/fixed-critical-value method and size-correction methods. The paper discusses two examples in detail. They are (i) confidence intervals in an autoregressive model with a root that may be close to unity and conditional heteroskedasticity of unknown form and (ii) tests and confidence intervals based on a post-conservative model selection estimator.","['Guggenberger, Patrik', 'Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Evaluation, Validation, and Selection']","['C12', 'C13', 'C22', 'C52']",Hybrid and Size-Corrected Subsampling Methods,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"Using many moment conditions can improve efficiency but makes the usual generalized method of moments (GMM) inferences inaccurate. Two-step GMM is biased. Generalized empirical likelihood (GEL) has smaller bias, but the usual standard errors are too small in instrumental variable settings. In this paper, we give a new variance estimator for GEL that addresses this problem. It is consistent under the usual asymptotics and, under many weak moment asymptotics, is larger than usual and is consistent. We also show that the Kleibergen (2005) Lagrange multiplier and conditional likelihood ratio statistics are valid under many weak moments. In addition, we introduce a jackknife GMM estimator, but find that GEL is asymptotically more efficient under many weak moments. In Monte Carlo examples we find that t-statistics based on the new variance estimator have nearly correct size in a wide range of cases.","['Windmeijer, Frank', 'Newey, Whitney K.']","['Estimation: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C13', 'C20', 'C30']",Generalized Method of Moments with Many Weak Moment Conditions,0,0,0,0,0,2009,05,01
77,3,2009-05-01,"Uncertainty appears to jump up after major shocks like the Cuban Missile crisis, the assassination of JFK, the OPEC I oil-price shock, and the 9/11 terrorist attacks. This paper offers a structural framework to analyze the impact of these uncertainty shocks. I build a model with a time-varying second moment, which is numerically solved and estimated using firm-level data. The parameterized model is then used to simulate a macro uncertainty shock, which produces a rapid drop and rebound in aggregate output and employment. This occurs because higher uncertainty causes firms to temporarily pause their investment and hiring. Productivity growth also falls because this pause in activity freezes reallocation across units. In the medium term, the increased volatility from the shock induces an overshoot in output, employment, and productivity. Thus, uncertainty shocks generate short sharp recessions and recoveries. This simulated impact of an uncertainty shock is compared to vector autoregression estimations on actual data, showing a good match in both magnitude and timing. The paper also jointly estimates labor and capital adjustment costs (both convex and nonconvex). Ignoring capital adjustment costs is shown to lead to substantial bias, while ignoring labor adjustment costs does not.","['Bloom, Nicholas']","['Model Construction and Estimation', 'Criteria for Decision-Making under Risk and Uncertainty', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Macroeconomics: Production', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Business Fluctuations; Cycles', 'Information and Market Efficiency; Event Studies; Insider Trading']","['C51', 'D81', 'D25', 'E23', 'E24', 'E32', 'G14']",The Impact of Uncertainty Shocks,0,0,0,0,0,2009,05,01
77,2,2009-03-01,This paper describes a direct revelation mechanism for eliciting agents' subjective probabilities. The game induced by the mechanism has a dominant strategy equilibrium in which the players reveal their subjective probabilities.,"['Karni, Edi']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Mechanism for Eliciting Probabilities,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"We propose a test of the hypothesis of stochastic monotonicity. This hypothesis is of interest in many applications in economics. Our test is based on the supremum of a rescaled U-statistic. We show that its asymptotic distribution is Gumbel. The proof is difficult because the approximating Gaussian stochastic process contains both a stationary and a nonstationary part, and so we have to extend existing results that only apply to either one or the other case. We also propose a refinement to the asymptotic approximation that we show works much better in finite samples. We apply our test to the study of intergenerational income mobility.","['Linton, Oliver', 'Lee, Sokbae', 'Whang, Yoon-Jae']","['Specific Distributions; Specific Statistics', 'Model Construction and Estimation', 'Job, Occupational, and Intergenerational Mobility; Promotion']","['C46', 'C51', 'J62']",Testing for Stochastic Monotonicity,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"I construct a theoretical framework in which firms offer wage-tenure contracts to direct the search by risk-averse workers. All workers can search, on or off the job. I characterize an equilibrium and prove its existence. The equilibrium generates a nondegenerate, continuous distribution of employed workers over the values of contracts, despite that all matches are identical and workers observe all offers. A striking property is that the equilibrium is block recursive; that is, individuals' optimal decisions and optimal contracts are independent of the distribution of workers. This property makes the equilibrium analysis tractable. Consistent with stylized facts, the equilibrium predicts that (i) wages increase with tenure, (ii) job-to-job transitions decrease with tenure and wages, and (iii) wage mobility is limited in the sense that the lower the worker's wage, the lower the future wage a worker will move to in the next job transition. Moreover, block recursivity implies that changes in the unemployment benefit and the minimum wage have no effect on an employed worker's job-to-job transitions and contracts.","['Shi, Shouyong']","['Criteria for Decision-Making under Risk and Uncertainty', 'Economics of Contract: Theory', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts']","['D81', 'D86', 'J31', 'J41']",Directed Search for Equilibrium Wage-Tenure Contracts,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"This paper analyzes the general nonlinear optimal income tax for couples, a multidimensional screening problem. Each couple consists of a primary earner who always participates in the labor market, but makes an hours-of-work choice, and a secondary earner who chooses whether or not to work. If second-earner participation is a signal of the couple being better (worse) off, we prove that optimal tax schemes display a positive tax (subsidy) on secondary earnings and that the tax (subsidy) on secondary earnings decreases with primary earnings and converges to zero asymptotically. We present calibrated microsimulations for the United Kingdom showing that decreasing tax rates on secondary earnings is quantitatively significant and consistent with actual income tax and transfer programs.","['Kleven, Henrik Jacobsen', 'Kreiner, Claus Thustrup', 'Saez, Emmanuel']","['Taxation and Subsidies: Efficiency; Optimal Taxation', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials']","['H21', 'H24', 'H31', 'J22', 'J31']",The Optimal Income Taxation of Couples,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"Many approaches to estimation of panel models are based on an average or integrated likelihood that assigns weights to different values of the individual effects. Fixed effects, random effects, and Bayesian approaches all fall into this category. We provide a characterization of the class of weights (or priors) that produce estimators that are first-order unbiased. We show that such bias-reducing weights will depend on the data in general unless an orthogonal reparameterization or an essentially equivalent condition is available. Two intuitively appealing weighting schemes are discussed. We argue that asymptotically valid confidence intervals can be read from the posterior distribution of the common parameters when N and T grow at the same rate. Next, we show that random effects estimators are not bias reducing in general and we discuss important exceptions. Moreover, the bias depends on the Kullback-Leibler distance between the population distribution of the effects and its best approximation in the random effects family. Finally, we show that, in general, standard random effects estimation of marginal effects is inconsistent for large T, whereas the posterior mean of the marginal effect is large-T consistent, and we provide conditions for bias reduction. Some examples and Monte Carlo experiments illustrate the results.","['Bonhomme, Stephane', 'Arellano, Manuel']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",Robust Priors in Nonlinear Panel Data Models,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"We define belief-free equilibria in two-player games with incomplete information as sequential equilibria for which players' continuation strategies are best replies after every history, independently of their beliefs about the state of nature. We characterize a set of payoffs that includes all belief-free equilibrium payoffs. Conversely, any payoff in the interior of this set is a belief-free equilibrium payoff. The characterization is applied to the analysis of reputations.","['Lovo, Stefano', 'Horner, Johannes']","['Existence and Stability Conditions of Equilibrium', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C62', 'C73', 'D82', 'D83']",Belief-Free Equilibria in Games with Incomplete Information,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"We examine the competition between a group of Internet retailers who operate in an environment where a price search engine plays a dominant role. We show that for some products in this environment, the easy price search makes demand tremendously price-sensitive. Retailers, though, engage in obfuscation--practices that frustrate consumer search or make it less damaging to firms--resulting in much less price sensitivity on some other products. We discuss several models of obfuscation and examine its effects on demand and markups empirically.","['Ellison, Sara Fisher', 'Ellison, Glenn']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Retail and Wholesale Trade; e-Commerce']","['D82', 'D83', 'L11', 'L81']","Search, Obfuscation, and Price Elasticities on the Internet",1,0,0,0,0,2009,03,01
77,2,2009-03-01,"We develop a search-theoretic model of financial intermediation in an over-the-counter market and study how trading frictions affect the distribution of asset holdings and standard measures of liquidity. A distinctive feature of our theory is that it allows for unrestricted asset holdings, so market participants can accommodate trading frictions by adjusting their asset positions. We show that these individual responses of asset demands constitute a fundamental feature of illiquid markets: they are a key determinant of trade volume, bid-ask spreads, and trading delays--the dimensions of market liquidity that search-based theories seek to explain.","['Lagos, Ricardo', 'Rocheteau, Guillaume']","['Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['G11', nan]",Liquidity in Asset Markets with Search Frictions,0,0,0,0,0,2009,03,01
77,2,2009-03-01,"We document cash management patterns for households that are at odds with the predictions of deterministic inventory models that abstract from precautionary motives. We extend the Baumol-Tobin cash inventory model to a dynamic environment that allows for the possibility of withdrawing cash at random times at a low cost. This modification introduces a precautionary motive for holding cash and naturally captures developments in withdrawal technology, such as the increasing diffusion of bank branches and ATM terminals. We characterize the solution of the model, which qualitatively reproduces several empirical patterns. We estimate the structural parameters using micro data and show that quantitatively the model captures important economic patterns. The estimates are used to quantify the expenditure and interest rate elasticity of money demand, the impact of financial innovation on money demand, the welfare cost of inflation, and the benefit of ATM ownership.","['Alvarez, Fernando', 'Lippi, Francesco']","['Household Saving; Personal Finance', 'Demand for Money', 'Banks; Depository Institutions; Micro Finance Institutions; Mortgages']","['D14', 'E41', 'G21']",Financial Innovation and the Transactions Demand for Cash,0,0,0,0,0,2009,03,01
77,1,2009-01-01,ECONLIT None Found,"['SAMUELSON, LARRY', 'ACEMOGLU, DARON', 'UHLIG, HARALD', 'NEWEY, WHITNEY', 'LEVINE, DAVID', 'MORRIS, STEPHEN', 'BERRY, STEVE']",[nan],[nan],REPORT OF THE EDITORS 2007-2008.,0,0,0,0,0,2009,01,01
77,1,2009-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],REPORT OF THE TREASURER.,0,0,0,0,0,2009,01,01
77,1,2009-01-01,ECONLIT None Found,"['REPULLO, RAFAEL']",[nan],[nan],REPORT OF THE SECRETARY.,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"The property of an allocation rule to be implementable in dominant strategies by a unique payment scheme is called revenue equivalence. We give a characterization of revenue equivalence based on a graph theoretic interpretation of the incentive compatibility constraints. The characterization holds for any (possibly infinite) outcome space and many of the known results are immediate consequences. Moreover, revenue equivalence can be identified in cases where existing theorems are silent.","['Heydenreich, Birgit', 'Vohra, Rakesh V.', 'Muller, Rudolf', 'Uetz, Marc']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Characterization of Revenue Equivalence,0,0,1,0,0,2009,01,01
77,1,2009-01-01,"We propose bootstrap methods for a general class of nonlinear transformations of realized volatility which includes the raw version of realized volatility and its logarithmic transformation as special cases. We consider the independent and identically distributed (i.i.d.) bootstrap and the wild bootstrap (WB), and prove their first-order asymptotic validity under general assumptions on the log-price process that allow for drift and leverage effects. We derive Edgeworth expansions in a simpler model that rules out these effects. The i.i.d. bootstrap provides a second-order asymptotic refinement when volatility is constant, but not otherwise. The WB yields a second-order asymptotic refinement under stochastic volatility provided we choose the external random variable used to construct the WB data appropriately. None of these methods provides third-order asymptotic refinements. Both methods improve upon the first-order asymptotic theory in finite samples.","['Goncalves, Silvia', 'Meddahi, Nour']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', nan]",Bootstrapping Realized Volatility,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"This paper presents simple new multisignal generalizations of the two classic methods used to justify the first-order approach to moral hazard principal-agent problems, and compares these two approaches with each other. The paper first discusses limitations of previous generalizations. Then a state-space formulation is used to obtain a new multisignal generalization of the Jewitt (1988) conditions. Next, using the Mirrlees formulation, new multisignal generalizations of the convexity of the distribution function condition (CDFC) approach of Rogerson (1985) and Sinclair-Desgagne (1994) are obtained. Vector calculus methods are used to derive easy-to-check local conditions for our generalization of the CDFC. Finally, we argue that the Jewitt conditions may generalize more flexibly than the CDFC to the multisignal case. This is because, with many signals, the principal can become very well informed about the agent's action and, even in the one-signal case, the CDFC must fail when the signal becomes very accurate.","['Conlon, John R.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Two New Conditions Supporting the First-Order Approach to Multisignal Principal-Agent Problems,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"We reappraise the significance and robustness of indeterminacy in overlapping-generations models. In any of Gale's example economies with an equilibrium that is not locally unique, for instance, perturbing the economy by judiciously splitting each of Gale's goods into two close substitutes restricts that indeterminacy to each period's allocation of consumption between those substitutes. In particular, prices, interest rates, the commodity value of nominal savings (including money), and utility levels become determinate. Any indeterminacy of equilibrium consumption in the perturbed economy is thus insignificant to consumers, and some forecasting and comparative-statics policy exercises become possible.","['Burke, Jonathan L.']",['General Aggregative Models: Neoclassical'],['E13'],Virtual Determinacy in Overlapping Generations Models,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"We create an analytical structure that reveals the long-run risk-return relationship for nonlinear continuous-time Markov environments. We do so by studying an eigenvalue problem associated with a positive eigenfunction for a conveniently chosen family of valuation operators. The members of this family are indexed by the elapsed time between payoff and valuation dates, and they are necessarily related via a mathematical structure called a semigroup. We represent the semigroup using a positive process with three components: an exponential term constructed from the eigenvalue, a martingale, and a transient eigenfunction term. The eigenvalue encodes the risk adjustment, the martingale alters the probability measure to capture long-run approximation, and the eigenfunction gives the long-run dependence on the Markov state. We discuss sufficient conditions for the existence and uniqueness of the relevant eigenvalue and eigenfunction. By showing how changes in the stochastic growth components of cash flows induce changes in the corresponding eigenvalues and eigenfunctions, we reveal a long-run risk-return trade-off.","['Hansen, Lars Peter', 'Scheinkman, Jose A.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', nan]",Long-Term Risk: An Operator Approach,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"In dynamic discrete choice analysis, controlling for unobserved heterogeneity is an important issue, and finite mixture models provide flexible ways to account for it. This paper studies nonparametric identifiability of type probabilities and type-specific component distributions in finite mixture models of dynamic discrete choices. We derive sufficient conditions for nonparametric identification for various finite mixture models of dynamic discrete choices used in applied work under different assumptions on the Markov property, stationarity, and type-invariance in the transition process. Three elements emerge as the important determinants of identification: the time-dimension of panel data, the number of values the covariates can take, and the heterogeneity of the response of different types to changes in the covariates. For example, in a simple case where the transition function is type-invariant, a time-dimension of T=3 is sufficient for identification, provided that the number of values the covariates can take is no smaller than the number of types and that the changes in the covariates induce sufficiently heterogeneous variations in the choice probabilities across types. Identification is achieved even when state dependence is present if a model is stationary first-order Markovian and the panel has a moderate time-dimension (T>=6).","['Kasahara, Hiroyuki', 'Shimotsu, Katsumi']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions']","['C22', 'C25', 'C32', 'C35']",Nonparametric Identification of Finite Mixture Models of Dynamic Discrete Choices,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"This paper applies some general concepts in decision theory to a linear panel data model. A simple version of the model is an autoregression with a separate intercept for each unit in the cross section, with errors that are independent and identically distributed with a normal distribution. There is a parameter of interest gamma and a nuisance parameter tau, a NxK matrix, where N is the cross-section sample size. The focus is on dealing with the incidental parameters problem created by a potentially high-dimension nuisance parameter. We adopt a ""fixed-effects"" approach that seeks to protect against any sequence of incidental parameters. We transform tau to (delta, rho, omega), where delta is a JxK matrix of coefficients from the least-squares projection of tau on a NxJ matrix x of strictly exogenous variables, rho is a KxK symmetric, positive semidefinite matrix obtained from the residual sums of squares and cross-products in the projection of tau on x, and omega is a (N-J)xK matrix whose columns are orthogonal and have unit length. The model is invariant under the actions of a group on the sample space and the parameter space, and we find a maximal invariant statistic. The distribution of the maximal invariant statistic does not depend upon omega. There is a unique invariant distribution for omega. We use this invariant distribution as a prior distribution to obtain an integrated likelihood function. It depends upon the observation only through the maximal invariant statistic. We use the maximal invariant statistic to construct a marginal likelihood function, so we can eliminate omega by integration with respect to the invariant prior distribution or by working with the marginal likelihood function. The two approaches coincide. Decision rules based on the invariant distribution for omega have a minimax property. Given a loss function that does not depend upon omega and given a prior distribution for (gamma, delta, rho), we show how to minimize the average--with respect to the prior distribution for (gamma,delta, rho)--of the maximum risk, where the maximum is with respect to omega. There is a family of prior distributions for (delta, rho) that leads to a simple closed form for the integrated likelihood function. This integrated likelihood function coincides with the likelihood function for a normal, correlated random-effects model. Under random sampling, the corresponding quasi maximum likelihood estimator is consistent for gamma as N to infinity, with a standard limiting distribution. The limit results do not require normality or homoskedasticity (conditional on x) assumptions.","['Chamberlain, Gary', 'Moreira, Marcelo J.']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Decision Theory Applied to a Linear Panel Data Model,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"Consider a weather forecaster predicting a probability of rain for the next day. We consider tests that, given a finite sequence of forecast predictions and outcomes, will either pass or fail the forecaster. Sandroni showed that any test which passes a forecaster who knows the distribution of nature can also be probabilistically passed by a forecaster with no knowledge of future events. We look at the computational complexity of such forecasters and exhibit a linear-time test and distribution of nature such that any forecaster without knowledge of the future who can fool the test must be able to solve computationally difficult problems. Thus, unlike Sandroni's work, a computationally efficient forecaster cannot always fool this test independently of nature.","['Fortnow, Lance', 'Vohra, Rakesh V.']","['Survey Methods; Sampling Methods', 'Criteria for Decision-Making under Risk and Uncertainty']","['C83', 'D81']",The Complexity of Forecast Testing,0,0,0,0,0,2009,01,01
77,1,2009-01-01,"This paper studies a class of games, ""all-pay contests,"" which capture general asymmetries and sunk investments inherent in scenarios such as lobbying, competition for market power, labor-market tournaments, and R&D races. Players compete for one of several identical prizes by choosing a score. Conditional on winning or losing, it is weakly better to do so with a lower score. This formulation allows for differing production technologies, costs of capital, prior investments, attitudes toward risk, and conditional and unconditional investments, among others. I provide a closed-form formula for players' equilibrium payoffs and analyze player participation. A special case of contests is multiprize, complete-information all-pay auctions.","['Siegel, Ron']","['Auctions', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D82', 'D83']",All-Pay Contests,0,0,1,0,0,2009,01,01
77,1,2009-01-01,"We study the role of observability in bargaining with correlated values. Short-run buyers sequentially submit offers to one seller. When previous offers are observable, bargaining is likely to end up in an impasse. In contrast, when offers are hidden, agreement is always reached, although with delay.","['Vieille, Nicolas', 'Horner, Johannes']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Information and Product Quality; Standardization and Compatibility']","['C78', 'D82', 'D83', 'L15']",Public vs. Private Offers in the Market for Lemons,1,0,0,0,0,2009,01,01
77,1,2009-01-01,"A player's pure strategy is called relevant for an outcome of a game in extensive form with perfect recall if there exists a weakly sequential equilibrium with that outcome for which the strategy is an optimal reply at every information set it does not exclude. The outcome satisfies forward induction if it results from a weakly sequential equilibrium in which players' beliefs assign positive probability only to relevant strategies at each information set reached by a profile of relevant strategies. We prove that if there are two players and payoffs are generic, then an outcome satisfies forward induction if every game with the same reduced normal form after eliminating redundant pure strategies has a sequential equilibrium with an equivalent outcome. Thus in this case forward induction is implied by decision-theoretic criteria.","['Wilson, Robert', 'Govindan, Srihari']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D83']",On Forward Induction,0,0,0,0,0,2009,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 87 Iss. 1.,0,0,0,0,0,2019,01,01
87,1,2019-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 87 Iss. 1.,0,0,0,0,0,2019,01,01
76,6,2008-11-01,ECONLIT None Found,"['Teague, Vanessa']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D83']",Problems with Coordination in Two-Player Games: Comment on 'Computational Complexity and Communication',0,0,0,0,0,2008,11,01
76,6,2008-11-01,"Matching estimators are widely used in empirical economics for the evaluation of programs or treatments. Researchers using matching methods often apply the bootstrap to calculate the standard errors. However, no formal justification has been provided for the use of the bootstrap in this setting. In this article, we show that the standard bootstrap is, in general, not valid for matching estimators, even in the simple case with a single continuous covariate where the estimator is root-N consistent and asymptotically normally distributed with zero asymptotic bias. Valid inferential methods in this setting are the analytic asymptotic variance estimator of Abadie and Imbens (2006) as well as certain modifications of the standard bootstrap, like the subsampling methods in Politis and Romano (1994).","['Abadie, Alberto', 'Imbens, Guido W.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],On the Failure of the Bootstrap for Matching Estimators,0,0,0,0,0,2008,11,01
76,6,2008-11-01,"This paper shows how to use realized kernels to carry out efficient feasible inference on the ex post variation of underlying equity prices in the presence of simple models of market frictions. The weights can be chosen to achieve the best possible rate of convergence and to have an asymptotic variance which equals that of the maximum likelihood estimator in the parametric version of this problem. Realized kernels can also be selected to (i) be analyzed using endogenously spaced data such as that in data bases on transactions, (ii) allow for market frictions which are endogenous, and (iii) allow for temporally dependent noise. The finite sample performance of our estimators is studied using simulation, while empirical work illustrates their use in practice.","['Shephard, Neil', 'Hansen, Peter Reinhard', 'Lunde, Asger', 'Barndorff-Nielsen, Ole E.']","['Model Construction and Estimation', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', nan]",Designing Realized Kernels to Measure the Ex Post Variation of Equity Prices in the Presence of Noise,0,0,0,0,0,2008,11,01
76,6,2008-11-01,"Numerous psychological and economic experiments have shown that the exchange of promises greatly enhances cooperative behavior in experimental games. This paper seeks to test two theories to explain this effect. The first posits that individuals have a preference for keeping their word. The second assumes that people dislike letting down others' payoff expectations. According to the latter account, promises affect behavior only indirectly, because they lead to changes in the payoff expectations attributed to others. I conduct an experiment designed to distinguish between and test these alternative explanations. The results demonstrate that the effects of promises cannot be accounted for by changes in payoff expectations. This suggests that people have a preference for promise keeping per se.","['Vanberg, Christoph']","['Cooperative Games', 'Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C71', 'C72', 'D83']",Why Do People Keep Their Promises? An Experimental Test of Two Explanations,0,0,0,0,0,2008,11,01
76,6,2008-11-01,"The difficulties in properly anticipating key economic variables may encourage decision makers to rely on experts' forecasts. Professional forecasters, however, may not be reliable and so their forecasts must be empirically tested. This may induce experts to forecast strategically in order to pass the test. A test can be ignorantly passed if a false expert, with no knowledge of the data-generating process, can pass the test. Many tests that are unlikely to reject correct forecasts can be ignorantly passed. Tests that cannot be ignorantly passed do exist, but these tests must make use of predictions contingent on data not yet observed at the time the forecasts are rejected. Such tests cannot be run if forecasters report only the probability of the next period's events on the basis of the actually observed data. This result shows that it is difficult to dismiss false, but strategic, experts who know how theories are tested. This result also shows an important role that can be played by predictions contingent on data not yet observed.","['Olszewski, Wojciech', 'Sandroni, Alvaro']","['Forecasting Models; Simulation Methods', 'Criteria for Decision-Making under Risk and Uncertainty', 'Expectations; Speculations']","['C53', 'D81', 'D84']",Manipulability of Future-Independent Tests,0,0,0,0,0,2008,11,01
76,6,2008-11-01,"Our concern is the extension of the theory of the Shapley value to problems involving externalities. Using the standard axiom systems behind the Shapley value leads to the identification of bounds on players' payoffs around an ""externality-free"" value. The approach determines the direction and maximum size of Pigouvian-like transfers among players, transfers based on the specific nature of externalities that are compatible with basic normative principles. Examples are provided to illustrate the approach and to draw comparisons with previous literature.","['de Clippel, Geoffroy', 'Serrano, Roberto']","['Cooperative Games', 'Externalities']","['C71', 'D62']",Marginal Contributions and Externalities in the Value,0,0,0,0,0,2008,11,01
76,6,2008-11-01,"We propose an approximation method for analyzing Ericson and Pakes (1995)-style dynamic models of imperfect competition. We define a new equilibrium concept that we call oblivious equilibrium, in which each firm is assumed to make decisions based only on its own state and knowledge of the long-run average industry state, but where firms ignore current information about competitors' states. The great advantage of oblivious equilibria is that they are much easier to compute than are Markov perfect equilibria. Moreover, we show that, as the market becomes large, if the equilibrium distribution of firm states obeys a certain ""light-tail"" condition, then oblivious equilibria closely approximate Markov perfect equilibria. This theorem justifies using oblivious equilibria to analyze Markov perfect industry dynamics in Ericson and Pakes (1995)-style models with many firms.","['Van Roy, Benjamin', 'Weintraub, Gabriel Y.', 'Benkard, C. Lanier']","['Existence and Stability Conditions of Equilibrium', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Exchange and Production Economies', 'Oligopoly and Other Imperfect Markets']","['C62', 'D43', 'D51', 'L13']",Markov Perfect Industry Dynamics with Many Firms,1,0,1,0,0,2008,11,01
76,6,2008-11-01,"Productivity differences across firms are large and persistent, but the evidence for worker reallocation as an important source of aggregate productivity growth is mixed. The purpose of this paper is to estimate the structure of an equilibrium model of growth through innovation designed to identify and quantify the role of resource reallocation in the growth process. The model is a version of the Schumpeterian theory of firm evolution and growth developed by Klette and Kortum (2004) extended to allow for firm heterogeneity. The data set is a panel of Danish firms that includes information on value added, employment, and wages. The model's fit is good. The estimated model implies that more productive firms in each cohort grow faster and consequently crowd out less productive firms in steady state. This selection effect accounts for 53% of aggregate growth in the estimated version of the model.","['Lentz, Rasmus', 'Mortensen, Dale T.']","['Model Construction and Estimation', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Innovation and Invention: Processes and Incentives', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['C51', 'D24', 'D25', 'G32', 'L11', 'O31', 'O47']",An Empirical Model of Growth through Product Innovation,1,0,0,1,0,2008,11,01
76,6,2008-11-01,"In the past few decades, multistore retailers, especially those with 100 or more stores, have experienced substantial growth. At the same time, there is widely reported public outcry over the impact of these chain stores on other retailers and local communities. This paper develops an empirical model to assess the impact of chain stores on other discount retailers and to quantify the size of the scale economies within a chain. The model has two key features. First, it allows for flexible competition patterns among all players. Second, for chains, it incorporates the scale economies that arise from operating multiple stores in nearby regions. In doing so, the model relaxes the commonly used assumption that entry in different markets is independent. The lattice theory is exploited to solve this complicated entry game among chains and other discount retailers in a large number of markets. It is found that the negative impact of Kmart's presence on Wal-Mart's profit was much stronger in 1988 than in 1997, while the opposite is true for the effect of Wal-Mart's presence on Kmart's profit. Having a chain store in a market makes roughly 50% of the discount stores unprofitable. Wal-Mart's expansion from the late 1980s to the late 1990s explains about 40-50% of the net change in the number of small discount stores and 30-40% for all other discount stores. Scale economies were important for Wal-Mart, but less so for Kmart, and the magnitude did not grow proportionately with the chains' sizes.","['Jia, Panle']","['Production, Pricing, and Market Structure; Size Distribution of Firms', 'Firm Performance: Size, Diversification, and Scope', 'Retail and Wholesale Trade; e-Commerce', 'Other Spatial Production and Pricing Analysis']","['L11', 'L25', 'L81', 'R32']",What Happens When Wal-Mart Comes to Town: An Empirical Analysis of the Discount Retailing Industry,1,0,0,0,0,2008,11,01
76,6,2008-11-01,This paper uses revealed preference inequalities to provide the tightest possible (best) nonparametric bounds on predicted consumer responses to price changes using consumer-level data over a finite set of relative price changes. These responses are allowed to vary nonparametrically across the income distribution. This is achieved by combining the theory of revealed preference with the semiparametric estimation of consumer expansion paths (Engel curves). We label these expansion path based bounds on demand responses as E-bounds. Deviations from revealed preference restrictions are measured by preference perturbations which are shown to usefully characterize taste change and to provide a stochastic environment within which violations of revealed preference inequalities can be assessed.,"['Browning, Martin', 'Crawford, Ian', 'Blundell, Richard']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Personal Income, Wealth, and Their Distributions']","['C51', 'D12', 'D31']",Best Nonparametric Bounds on Demand Responses,0,0,0,0,0,2008,11,01
76,5,2008-09-01,"In this paper we revisit the results in Caner and Hansen (2001), where the authors obtained novel limiting distributions of Wald type test statistics for testing for the presence of threshold nonlinearities in autoregressive models containing unit roots. Using the same framework, we obtain a new formulation of the limiting distribution of the Wald statistic for testing for threshold effects, correcting an expression that appeared in the main theorem presented by Caner and Hansen. Subsequently, we show that under a particular scenario that excludes stationary regressors such as lagged dependent variables and despite the presence of a unit root, this same limiting random variable takes a familiar form that is free of nuisance parameters and already tabulated in the literature, thus removing the need to use bootstrap based inferences. This is a novel and unusual occurrence in this literature on testing for the presence of nonlinear dynamics.","['Pitarakis, Jean-Yves']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Comment On: Threshold Autoregressions with a Unit Root,0,0,0,0,0,2008,09,01
76,5,2008-09-01,"We use the control function approach to identify the average treatment effect and the effect of treatment on the treated in models with a continuous endogenous regressor whose impact is heterogeneous. We assume a stochastic polynomial restriction on the form of the heterogeneity, but unlike alternative nonparametric control function approaches, our approach does not require large support assumptions.","['Vytlacil, E.', 'Heckman, J. J.', 'Meghir, C.', 'Florens, J. P.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],"Identification of Treatment Effects Using Control Functions in Models with Continuous, Endogenous Treatment and Heterogeneous Effects",0,0,0,0,0,2008,09,01
76,5,2008-09-01,"We study a definition of subjective beliefs applicable to preferences that allow for the perception of ambiguity, and provide a characterization of such beliefs in terms of market behavior. Using this definition, we derive necessary and sufficient conditions for the efficiency of ex ante trade and show that these conditions follow from the fundamental welfare theorems. When aggregate uncertainty is absent, our results show that full insurance is efficient if and only if agents share some common subjective beliefs. Our results hold for a general class of convex preferences, which contains many functional forms used in applications involving ambiguity and ambiguity aversion. We show how our results can be articulated in the language of these functional forms, confirming results existing in the literature, generating new results, and providing a useful tool for applications.","['Rigotti, Luca', 'Strzalecki, Tomasz', 'Shannon, Chris']","['Exchange and Production Economies', 'Allocative Efficiency; Cost-Benefit Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D51', 'D61', 'D81', 'D83']",Subjective Beliefs and Ex Ante Trade,0,0,0,0,0,2008,09,01
76,5,2008-09-01,"Rabin (2000) proved that a low level of risk aversion with respect to small gambles leads to a high, and absurd, level of risk aversion with respect to large gambles. Rabin's arguments strongly depend on expected utility theory, but we show that similar arguments apply to general non-expected utility theories.","['Safra, Zvi', 'Segal, Uzi']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Calibration Results for Non-expected Utility Theories,0,0,0,0,0,2008,09,01
76,5,2008-09-01,"This paper derives asymptotic power envelopes for tests of the unit root hypothesis in a zero-mean AR(1) model. The power envelopes are derived using the limits of experiments approach and are semiparametric in the sense that the underlying error distribution is treated as an unknown infinite-dimensional nuisance parameter. Adaptation is shown to be possible when the error distribution is known to be symmetric and to be impossible when the error distribution is unrestricted. In the latter case, two conceptually distinct approaches to nuisance parameter elimination are employed in the derivation of the semiparametric power bounds. One of these bounds, derived under an invariance restriction, is shown by example to be sharp, while the other, derived under a similarity restriction, is conjectured not to be globally attainable.","['Jansson, Michael']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Semiparametric Power Envelopes for Tests of the Unit Root Hypothesis,0,0,0,0,0,2008,09,01
76,5,2008-09-01,"We analyze tender offers where privately informed shareholders are uncertain about the raider's ability to improve firm value. The raider suffers a ""lemons problem"" in that, for any price offered, only shareholders who are relatively pessimistic about the value of the firm tender their shares. Consequently, the raider finds it too costly to induce shareholders to tender when their information is positive. In the limit as the number of shareholders gets arbitrarily large, when private benefits are relatively low, the tender offer is unsuccessful if the takeover has the potential to create value. The takeover market is therefore inefficient. In contrast, when private benefits of control are high, the tender offer allocates the firm to any value-increasing raider, but may also allow inefficient takeovers to occur. Unlike the case where all information is symmetric, shareholders cannot always extract the entire surplus from the acquisition.","['Marquez, Robert', 'Yilmaz, Bilge']","['Asymmetric and Private Information; Mechanism Design', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance']","['D82', 'G32', 'G34']",Information and Efficiency in Tender Offers,0,0,0,0,1,2008,09,01
76,5,2008-09-01,"Traditional discrete-choice models assume buyers are aware of all products for sale. In markets where products change rapidly, the full information assumption is untenable. I present a discrete-choice model of limited consumer information, where advertising influences the set of products from which consumers choose to purchase. I apply the model to the U.S. personal computer market where top firms spend over $2 billion annually on advertising. I find estimated markups of 19% over production costs, where top firms advertise more than average and earn higher than average markups. High markups are explained to a large extent by informational asymmetries across consumers, where full information models predict markups of one-fourth the magnitude. I find that estimated product demand curves are biased toward being too elastic under traditional models. I show how to use data on media exposure to improve estimated price elasticities in the absence of micro ad data.","['Goeree, Michelle Sovinsky']","['Model Construction and Estimation', 'Microelectronics; Computers; Communications Equipment', 'Advertising']","['C51', 'L63', 'M37']",Limited Information and Advertising in the U.S. Personal Computer Industry,1,0,0,0,0,2008,09,01
76,5,2008-09-01,"We develop a framework to assess how successfully standard time series models explain low-frequency variability of a data series. The low-frequency information is extracted by computing a finite number of weighted averages of the original data, where the weights are low-frequency trigonometric series. The properties of these weighted averages are then compared to the asymptotic implications of a number of common time series models. We apply the framework to twenty U.S. macroeconomic and financial time series using frequencies lower than the business cycle.","['Watson, Mark W.', 'Muller, Ulrich K.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Business Fluctuations; Cycles', 'Prices, Business Fluctuations, and Cycles: Forecasting and Simulation: Models and Applications', 'Interest Rates: Determination, Term Structure, and Effects', 'Money and Interest Rates: Forecasting and Simulation: Models and Applications']","['C22', 'E32', 'E37', 'E43', 'E47']",Testing Models of Low-Frequency Variability,0,0,0,0,0,2008,09,01
76,5,2008-09-01,"This paper provides conditions for identification of functionals in nonparametric simultaneous equations models with nonadditive unobservable random terms. The conditions are derived from a characterization of observational equivalence between models. We show that, in the models considered, observational equivalence can be characterized by a restriction on the rank of a matrix. The use of the new results is exemplified by deriving previously known results about identification in parametric and nonparametric models as well as new results. A stylized method for analyzing identification, which is useful in some situations, is also presented.","['Matzkin, Rosa L.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Identification in Nonparametric Simultaneous Equations Models,0,0,0,0,0,2008,09,01
76,4,2008-07-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"Consider two agents who learn the value of an unknown parameter by observing a sequence of private signals. The signals are independent and identically distributed across time but not necessarily across agents. We show that when each agent's signal space is finite, the agents will commonly learn the value of the parameter, that is, that the true value of the parameter will become approximate common knowledge. The essential step in this argument is to express the expectation of one agent's signals, conditional on those of the other agent, in terms of a Markov chain. This allows us to invoke a contraction mapping principle ensuring that if one agent's signals are close to those expected under a particular value of the parameter, then that agent expects the other agent's signals to be even closer to those expected under the parameter value. In contrast, if the agents' observations come from a countably infinite signal space, then this contraction mapping property fails. We show by example that common learning can fail in this case.","['Ely, Jeffrey C.', 'Cripps, Martin W.', 'Mailath, George J.', 'Samuelson, Larry']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Common Learning,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"We prove existence of equilibrium in a continuous-time securities market in which the securities are potentially dynamically complete: the number of securities is at least one more than the number of independent sources of uncertainty. We prove that dynamic completeness of the candidate equilibrium price process follows from mild exogenous assumptions on the economic primitives of the model. Our result is universal, rather than generic: dynamic completeness of the candidate equilibrium price process and existence of equilibrium follow from the way information is revealed in a Brownian filtration, and from a mild exogenous nondegeneracy condition on the terminal security dividends. The nondegeneracy condition, which requires that finding one point at which a determinant of a Jacobian matrix of dividends is nonzero, is very easy to check. We find that the equilibrium prices, consumptions, and trading strategies are well-behaved functions of the stochastic process describing the evolution of information. We prove that equilibria of discrete approximations converge to equilibria of the continuous-time economy.","['Raimondo, Roberto C.', 'Anderson, Robert M.']",['General Equilibrium and Disequilibrium: Financial Markets'],['D53'],Equilibrium in Continuous-Time Financial Markets: Endogenously Dynamically Complete Markets,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"We combine choice data in the ultimatum game with the expectations of proposers elicited by subjective probability questions to estimate a structural model of decision making under uncertainty. The model, estimated using a large representative sample of subjects from the Dutch population, allows both nonlinear preferences for equity and expectations to vary across socioeconomic groups. Our results indicate that inequity aversion to one's own disadvantage is an increasing and concave function of the payoff difference. We also find considerable heterogeneity in the population. Young and highly educated subjects have lower aversion for inequity than other groups. Moreover, the model that uses subjective data on expectations generates much better in- and out-of-sample predictions than a model which assumes that players have rational expectations.","['Kroger, Sabine', 'Bellemare, Charles', 'van Soest, Arthur']","['Design of Experiments: Laboratory, Individual', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C91', 'D63', 'D81', 'D83']",Measuring Inequity Aversion in a Heterogeneous Population Using Experimental Decisions and Subjective Probabilities,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"We propose inference procedures for partially identified population features for which the population identification region can be written as a transformation of the Aumann expectation of a properly defined set valued random variable (SVRV). An SVRV is a mapping that associates a set (rather than a real number) with each element of the sample space. Examples of population features in this class include interval-identified scalar parameters, best linear predictors with interval outcome data, and parameters of semiparametric binary models with interval regressor data. We extend the analogy principle to SVRVs and show that the sample analog estimator of the population identification region is given by a transformation of a Minkowski average of SVRVs. Using the results of the mathematics literature on SVRVs, we show that this estimator converges in probability to the population identification region with respect to the Hausdorff distance. We then show that the Hausdorff distance and the directed Hausdorff distance between the population identification region and the estimator, when properly normalized by the square root of n, converge in distribution to functions of a Gaussian process whose covariance kernel depends on parameters of the population identification region. We provide consistent bootstrap procedures to approximate these limiting distributions. Using similar arguments as those applied for vector valued random variables, we develop a methodology to test assumptions about the true identification region and its subsets. We show that these results can be used to construct a confidence collection and a directed confidence collection. Those are (respectively) collection of sets that, when specified as a null hypothesis for the true value (a subset of values) of the population identification region, cannot be rejected by our tests.","['Beresteanu, Arie', 'Molinari, Francesca']","['Econometric and Statistical Methods and Methodology: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C10', 'C20', 'C30']",Asymptotic Properties for a Class of Partially Identified Models,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"This paper studies the asymptotic behavior of Fisher's information for a Levy process discretely sampled at an increasing frequency. As a result, we derive the optimal rates of convergence of efficient estimators of the different parameters of the process and show that the rates are often nonstandard and differ across parameters. We also show that it is possible to distinguish the continuous part of the process from its jumps part, and even different types of jumps from one another.","['Jacod, Jean', 'Ait-Sahalia, Yacine']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C51', nan]",Fisher's Information for Discretely Sampled Levy Processes,0,0,0,0,0,2008,07,01
76,4,2008-07-01,"We develop and estimate a model of dynamic interactions in which commitment is limited and contracts are incomplete to explain the patterns of income and consumption growth in village economies of less developed countries. Households can insure each other through both formal contracts and informal agreements, that is, self-enforcing agreements specifying voluntary transfers. This theoretical setting nests the case of complete markets and the case where only informal agreements are available. We derive a system of nonlinear equations for income and consumption growth. A key prediction of our model is that both variables are affected by lagged consumption as a consequence of the interplay of formal and informal contracting possibilities. In a semiparametric setting, we prove identification, derive testable restrictions, and estimate the model with the use of data from Pakistani villages. Empirical results are consistent with the economic arguments. Incentive constraints due to self-enforcement bind with positive probability and formal contracts are used to reduce this probability.","['Dubois, Pierre', 'Jullien, Bruno', 'Magnac, Thierry']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Economics of Contract: Theory', 'Microeconomic Analyses of Economic Development', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure']","['C51', 'D12', 'D81', 'D86', 'O12', 'O18']",Formal and Informal Risk Sharing in LDCs: Theory and Empirical Evidence,0,0,0,0,0,2008,07,01
76,3,2008-05-01,ECONLIT None Found,[nan],[nan],[nan],2007 ELECTION OF FELLOWS TO THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2008,05,01
76,3,2008-05-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"This paper proposes a new method for identifying social interactions using conditional variance restrictions. The method provides a consistent estimate of the social multiplier when social interactions take the ""linear-in-means"" form (Manski (1993)). When social interactions are not of the linear-in-means form, the estimator, under certain conditions, continues to form the basis of a consistent test of the no social interactions null with correct large sample size. The methods are illustrated using data from the Tennessee class size reduction experiment Project STAR. The application suggests that differences in peer group quality were an important source of individual-level variation in the academic achievement of Project STAR kindergarten students.","['Graham, Bryan S.']","['Model Construction and Estimation', 'Analysis of Education']","['C51', 'I21']",Identifying Social Interactions through Conditional Variance Restrictions,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"We study the provision of dynamic incentives to self-interested politicians who control the allocation of resources in the context of the standard neoclassical growth model. Citizens discipline politicians using elections. We show that the need to provide incentives to the politician in power creates political economy distortions in the structure of production, which resemble aggregate tax distortions. We provide conditions under which the political economy distortions persist or disappear in the long run. If the politicians are as patient as the citizens, the best subgame perfect equilibrium leads to an asymptotic allocation where the aggregate distortions arising from political economy disappear. In contrast, when politicians are less patient than the citizens, political economy distortions remain asymptotically and lead to positive aggregate labor and capital taxes.","['Acemoglu, Daron', 'Tsyvinski, Aleh', 'Golosov, Michael']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Asymmetric and Private Information; Mechanism Design', 'Taxation, Subsidies, and Revenue: General', 'Capitalist Systems: Political Economy']","['D72', 'D82', 'H20', 'P16']",Political Economy of Mechanisms,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"We design experiments to jointly elicit risk and time preferences for the adult Danish population. Since subjects are generally risk averse, we find that joint elicitation provides estimates of discount rates that are significantly lower than those found in previous studies and more in line with what would be considered as a priori reasonable rates. The statistical specification relies on a theoretical framework that involves a latent trade-off between long-run optimization and short-run temptation. Estimation of this specification is undertaken using structural, maximum likelihood methods. Our main results based on exponential discounting are robust to alternative specifications such as hyperbolic discounting. These results have direct implications for attempts to elicit time preferences, as well as debates over the appropriate domain of the utility function when characterizing risk aversion and time consistency.","['Lau, Morten I.', 'Andersen, Steffen', 'Rutstrom, E. Elisabet', 'Harrison, Glenn W.']","['Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D12', 'D81', 'D15']",Eliciting Risk and Time Preferences,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"We consider a cross-calibration test of predictions by multiple potential experts in a stochastic environment. This test checks whether each expert is calibrated conditional on the predictions made by other experts. We show that this test is good in the sense that a true expert--one informed of the true distribution of the process--is guaranteed to pass the test no matter what the other potential experts do, and false experts will fail the test on all but a small (category I) set of true distributions. Furthermore, even when there is no true expert present, a test similar to cross-calibration cannot be simultaneously manipulated by multiple false experts, but at the cost of failing some true experts.","['Stewart, Colin', 'Feinberg, Yossi']",['Forecasting Models; Simulation Methods'],['C53'],Testing Multiple Forecasters,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"We show that a simple ""reputation-style"" test can always identify which of two experts is informed about the true distribution. The test presumes no prior knowledge of the true distribution, achieves any desired degree of precision in some fixed finite time, and does not use ""counterfactual"" predictions. Our analysis capitalizes on a result of Fudenberg and Levine (1992) on the rate of convergence of supermartingales. We use our setup to shed some light on the apparent paradox that a strategically motivated expert can ignorantly pass any test. We point out that this paradox arises because in the single-expert setting, any mixed strategy for Nature over distributions is reducible to a pure strategy. This eliminates any meaningful sense in which Nature can randomize. Comparative testing reverses the impossibility result because the presence of an expert who knows the realized distribution eliminates the reducibility of Nature's compound lotteries.","['Weinstein, Jonathan', 'Al-Najjar, Nabil I.']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Comparative Testing of Experts,0,0,0,0,0,2008,05,01
76,3,2008-05-01,"We consider a dynamic Bertrand game in which prices are publicly observed and each firm receives a privately observed cost shock in each period. Although cost shocks are independent across firms, within a firm costs follow a first-order Markov process. We analyze the set of collusive equilibria available to firms, emphasizing the best collusive scheme for the firms at the start of the game. In general, there is a trade-off between productive efficiency, whereby the low-cost firm serves the market in a given period, and high prices. We show that when costs are perfectly correlated over time within a firm, if the distribution of costs is log-concave and firms are sufficiently patient, then the optimal collusive scheme entails price rigidity: firms set the same price and share the market equally, regardless of their respective costs. When serial correlation of costs is imperfect, partial productive efficiency is optimal. For the case of two cost types, first-best collusion is possible if the firms are patient relative to the persistence of cost shocks, but not otherwise. We present numerical examples of first-best collusive schemes.","['Athey, Susan', 'Bagwell, Kyle']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Asymmetric and Private Information; Mechanism Design', 'Monopoly; Monopolization Strategies', 'Oligopoly and Other Imperfect Markets']","['C73', 'D43', 'D82', 'L12', 'L13']",Collusion with Persistent Cost Shocks,1,0,1,0,0,2008,05,01
76,3,2008-05-01,"This paper studies a general model of holdup in a setting encompassing the models of Segal (1999) and Che and Hausch (1999) among others. It is shown that if renegotiation is modeled as an infinite-horizon noncooperative bargaining game, then, with a simple initial contract, an efficient equilibrium will generally exist. The contract is robust in the sense that it does not depend on fine details of the model. The contract gives authority to one party to set the terms of trade and gives the other party a nonexpiring option to trade at these terms. The difference from standard results arises because the initial contract ensures that the renegotiation game has multiple equilibria; the multiplicity of continuation equilibria can be used to enforce efficient investment.","['Evans, Robert']","['Bargaining Theory; Matching Theory', 'Economics of Contract: Theory']","['C78', 'D86']",Simple Efficient Contracts in Complex Environments,0,0,0,0,0,2008,05,01
76,2,2008-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"We study a Monte Carlo algorithm for computing marginal and stationary densities of stochastic models with the Markov property, establishing global asymptotic normality and OP(n-1/2) convergence. Asymptotic normality is used to derive error bounds in terms of the distribution of the norm deviation.","['Stachurski, John', 'Martin, Vance']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Computing the Distributions of Economic Models via Simulation,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"Previous research has argued that debt financing affects equity-holders' investment decisions, producing substantial inefficiency. This paper shows that the size of this inefficiency depends on the degree of investment reversibility. In a dynamic model of financing and investment, the paper provides an upper bound for the inefficiency produced by debt financing. The upper bound is decreasing in the degree of investment reversibility and is zero when investment is perfectly reversible.","['Manso, Gustavo']","['Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['G31', 'G32']",Investment Reversibility and Agency Cost of Debt,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"We study a model of lumpy investment wherein establishments face persistent shocks to common and plant-specific productivity, and nonconvex adjustment costs lead them to pursue generalized (S, s) investment rules. We allow persistent heterogeneity in both capital and total factor productivity alongside low-level investments exempt from adjustment costs to develop the first model consistent with the cross-sectional distribution of establishment investment rates. Examining the implications of lumpy investment for aggregate dynamics in this setting, we find that they remain substantial when factor supply considerations are ignored, but are quantitatively irrelevant in general equilibrium. The substantial implications of general equilibrium extend beyond the dynamics of aggregate series. While the presence of idiosyncratic shocks makes the time-averaged distribution of plant-level investment rates largely invariant to market-clearing movements in real wages and interest rates, we show that the dynamics of plants' investments differ sharply in their presence. Thus, model-based estimations of capital adjustment costs involving panel data may be quite sensitive to the assumption about equilibrium. Our analysis also offers new insights about how nonconvex adjustment costs influence investment at the plant. When establishments face idiosyncratic productivity shocks consistent with existing estimates, we find that nonconvex costs do not cause lumpy investments, but act to eliminate them.","['Khan, Aubhik', 'Thomas, Julia K.']","['Firm Behavior: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Business Fluctuations; Cycles', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['D21', 'D15', 'D25', 'E32', 'G31']",Idiosyncratic Shocks and the Role of Nonconvexities in Plant and Aggregate Investment Dynamics,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"Much evidence suggests that people are heterogeneous with regard to their abilities to make rational, forward-looking decisions. This raises the question as to when the rational types are decisive for aggregate outcomes and when the boundedly rational types shape aggregate results. We examine this question in the context of a long-standing and important economic problem: the adjustment of nominal prices after an anticipated monetary shock. Our experiments suggest that two types of bounded rationality--money illusion and anchoring--are important behavioral forces behind nominal inertia. However, depending on the strategic environment, bounded rationality has vastly different effects on aggregate price adjustment. If agents' actions are strategic substitutes, adjustment to the new equilibrium is extremely quick, whereas under strategic complementarity, adjustment is both very slow and associated with relatively large real effects. This adjustment difference is driven by price expectations, which are very flexible and forward-looking under substitutability but adaptive and sticky under complementarity. Moreover, subjects' expectations are also considerably more rational under substitutability.","['Fehr, Ernst', 'Tyran, Jean-Robert']","['Microeconomic Behavior: Underlying Principles', 'Consumer Economics: Theory', 'Price Level; Inflation; Deflation', 'Money Supply; Credit; Money Multipliers']","['D01', 'D11', 'E31', 'E51']",Limited Rationality and Strategic Interaction: The Impact of the Strategic Environment on Nominal Inertia,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"Suppose that each player in a game is rational, each player thinks the other players are rational, and so on. Also, suppose that rationality is taken to incorporate an admissibility requirement--that is, the avoidance of weakly dominated strategies. Which strategies can be played? We provide an epistemic framework in which to address this question. Specifically, we formulate conditions of rationality and mth-order assumption of rationality (RmAR) and rationality and common assumption of rationality (RCAR). We show that (i) RCAR is characterized by a solution concept we call a ""self-admissible set""; (ii) in a ""complete"" type structure, RmAR is characterized by the set of strategies that survive m+1 rounds of elimination of inadmissible strategies; (iii) under certain conditions, RCAR is impossible in a complete structure.","['Friedenberg, Amanda', 'Brandenburger, Adam', 'Keisler, H. Jerome']",['Game Theory and Bargaining Theory: General'],['C70'],Admissibility in Games,0,0,0,0,0,2008,03,01
76,2,2008-03-01,"We study preferences over menus which can be represented as if the agent selects an alternative from a menu and experiences regret if her choice is ex post inferior. Since regret arises from comparisons between the alternative selected and the other available alternatives, our axioms reflect the agent's desire to limit her options. We prove that our representation is essentially unique. We also introduce two measures of comparative regret attitudes and relate them to our representation. Finally, we explore the formal connection between the present work and the literature on temptation.","['Sarver, Todd']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Anticipating Regret: Why Fewer Options May Be Better,0,0,0,0,0,2008,03,01
76,1,2008-01-01,ECONLIT None Found,[nan],[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: ECONOMETRICA REFEREES 2006-2007.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,ECONLIT None Found,"['Berry, Steve', 'Samuelson, Larry', 'Dekel, Eddie', 'Uhlig, Harald', 'Levine, David', 'Newey, Whitney']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE EDITORS 2006-2007.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE TREASURER.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE SECRETARY.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"While the literature on nonclassical measurement error traditionally relies on the availability of an auxiliary data set containing correctly measured observations, we establish that the availability of instruments enables the identification of a large class of nonclassical nonlinear errors-in-variables models with continuously distributed variables. Our main identifying assumption is that, conditional on the value of the true regressors, some ""measure of location"" of the distribution of the measurement error (e.g., its mean, mode, or median) is equal to zero. The proposed approach relies on the eigenvalue-eigenfunction decomposition of an integral operator associated with specific joint probability densities. The main identifying assumption is used to ""index"" the eigenfunctions so that the decomposition is unique. We propose a convenient sieve-based estimator, derive its asymptotic properties, and investigate its finite-sample behavior through Monte Carlo simulations.","['Hu, Yingyao', 'Schennach, Susanne M.']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Instrumental Variable Treatment of Nonclassical Measurement Error Models,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"This paper considers studentized tests in time series regressions with nonparametrically autocorrelated errors. The studentization is based on robust standard errors with truncation lag M = bT for some constant b element of (0, 1] and sample size T. It is shown that the nonstandard fixed-b limit distributions of such nonparametrically studentized tests provide more accurate approximations to the finite sample distributions than the standard small-b limit distribution. We further show that, for typical economic time series, the optimal bandwidth that minimizes a weighted average of type I and type II errors is larger by an order of magnitude than the bandwidth that minimizes the asymptotic mean squared error of the corresponding long-run variance estimator. A plug-in procedure for implementing this optimal bandwidth is suggested and simulations (not reported here) confirm that the new plug-in procedure works well in finite samples.","['Phillips, Peter C. B.', 'Sun, Yixiao', 'Jin, Sainan']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Optimal Bandwidth Selection in Heteroskedasticity-Autocorrelation Robust Testing,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"The conventional heteroskedasticity-robust (HR) variance matrix estimator for cross-sectional regression (with or without a degrees-of-freedom adjustment), applied to the fixed-effects estimator for panel data with serially uncorrelated errors, is inconsistent if the number of time periods T is fixed (and greater than 2) as the number of entities n increases. We provide a bias-adjusted HR estimator that is square-root-of-nT-consistent under any sequences (n, T) in which n and/or T increase to infinity. This estimator can be extended to handle serial correlation of fixed order.","['Stock, James H.', 'Watson, Mark W.']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Heteroskedasticity-Robust Standard Errors for Fixed Effects Panel Data Regression,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"Experimental studies have found that a decision maker prefers spreading good and bad outcomes evenly over time. We propose, in an axiomatic framework, a new model of discount factors that captures this preference for spread. The model provides a refinement of the discounted utility model while maintaining dynamic consistency. The derived discount factors incorporate gain/loss asymmetry recursively: the difference between average future utility and current utility defines a gain or a loss, and gains are discounted more than losses. This notion of utility smoothing can induce a preference for spread: if bad outcomes are concentrated on future periods, moving one of the bad outcomes to today would be beneficial because such an operation eliminates a large loss and replaces it with a small gain.","['Wakai, Katsutoshi']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Model of Utility Smoothing,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"There are typically multiple equilibrium outcomes in the Crawford-Sobel (CS) model of strategic information transmission. This paper identifies a simple condition on equilibrium payoffs, called NITS (no incentive to separate), that selects among CS equilibria. Under a commonly used regularity condition, only the equilibrium with the maximal number of induced actions satisfies NITS. We discuss various justifications for NITS, including perturbed cheap-talk games with nonstrategic players or costly lying. We also apply NITS to other models of cheap talk, illustrating its potential beyond the CS framework.","['Sobel, Joel', 'Chen, Ying', 'Kartik, Navin']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']",Selecting Cheap-Talk Equilibria,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"We study how professional players and college students play zero-sum two-person strategic games in a laboratory setting. We first ask professionals to play a 2 x 2 game that is formally identical to a strategic interaction situation that they face in their natural environment. Consistent with their behavior in the field, they play very close to the equilibrium of the game. In particular, (i) they equate their strategies' payoffs to the equilibrium ones and (ii) they generate sequences of choices that are serially independent. In sharp contrast, however, we find that college students play the game far from the equilibrium predictions. We then study the behavior of professional players and college students in the classic O'Neill 4 x 4 zero-sum game, a game that none of the subjects has encountered previously, and find the same differences in the behavior of these two pools of subjects. The transfer of skills and experience from the familiar field to the unfamiliar laboratory observed for professional players is relevant to evaluate the circumstances under which behavior in a laboratory setting may be a reliable indicator of behavior in a naturally occurring setting. From a cognitive perspective, it is useful for research on recognition processes, intuition, and similarity as a basis for inductive reasoning.","['Volij, Oscar', 'Palacios-Huerta, Ignacio']","['Noncooperative Games', 'Design of Experiments: Laboratory, Individual', 'Sports; Gambling; Restaurants; Recreation; Tourism']","['C72', 'C91', 'L83']",Experientia Docet: Professionals Play Minimax in Laboratory Experiments,1,0,0,0,0,2008,01,01
76,1,2008-01-01,"This paper develops a nonparametric theory of preferences over one's own and others' monetary payoffs. We introduce ""more altruistic than"" (MAT), a partial ordering over such preferences, and interpret it with known parametric models. We also introduce and illustrate ""more generous than"" (MGT), a partial ordering over opportunity sets. Several recent studies focus on two-player extensive form games of complete information in which the first mover (FM) chooses a more or less generous opportunity set for the second mover (SM). Here reciprocity can be formalized as the assertion that an MGT choice by the FM will elicit MAT preferences in the SM. A further assertion is that the effect on preferences is stronger for acts of commission by FM than for acts of omission. We state and prove propositions on the observable consequences of these assertions. Finally, empirical support for the propositions is found in existing data from investment and dictator games, the carrot and stick game, and the Stackelberg duopoly game and in new data from Stackelberg mini-games.","['Cox, James C.', 'Friedman, Daniel', 'Sadiraj, Vjollca']",['Altruism; Philanthropy; Intergenerational Transfers'],['D64'],Revealed Altruism,0,0,0,0,0,2008,01,01
76,1,2008-01-01,"A general equilibrium search model makes layoff costs affect the aggregate unemployment rate in ways that depend on equilibrium proportions of frictional and structural unemployment that in turn depend on the generosity of government unemployment benefits and skill losses among newly displaced workers. The model explains how, before the 1970s, lower flows into unemployment gave Europe lower unemployment rates than the United States and also how, after 1980, higher durations have kept unemployment rates in Europe persistently higher than in the United States. These outcomes arise from the way Europe's higher firing costs and more generous unemployment compensation make its unemployment rate respond to bigger skill losses among newly displaced workers. Those bigger skill losses also explain why U.S. workers have experienced more earnings volatility since 1980 and why, especially among older workers, hazard rates of gaining employment in Europe now fall sharply with increases in the duration of unemployment.","['Ljungqvist, Lars', 'Sargent, Thomas J.']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Unemployment: Models, Duration, Incidence, and Job Search', 'Unemployment Insurance; Severance Pay; Plant Closings']","['E24', 'J64', 'J65']",Two Questions about European Unemployment,0,0,0,0,0,2008,01,01
86,6,2018-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,11,01
86,6,2018-11-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 6.,0,0,0,0,0,2018,11,01
86,6,2018-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 6.,0,0,0,0,0,2018,11,01
75,6,2007-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2007,11,01
75,6,2007-11-01,ECONLIT None Found,"['Solan, Eilon', 'Rosenberg, Dinah', 'Vieille, Nicolas']",[nan],[nan],SOCIAL LEARNING IN ONE-ARM BANDIT PROBLEMS.,0,0,0,0,0,2007,11,01
75,6,2007-11-01,ECONLIT None Found,"['Corbae, Dean', 'Nakajima, Makoto', 'Ríos-Rull, José-Víctor', 'Chatterjee, Satyajit']",[nan],[nan],A QUANTITATIVE THEORY OF UNSECURED CONSUMER CREDIT WITH RISK OF DEFAULT.,0,0,0,0,0,2007,11,01
75,6,2007-11-01,"A new panel data model is proposed to represent the behavior of economies in transition, allowing for a wide range of possible time paths and individual heterogeneity. The model has both common and individual specific components, and is formulated as a nonlinear time varying factor model. When applied to a micro panel, the decomposition provides flexibility in idiosyncratic behavior over time and across section, while retaining some commonality across the panel by means of an unknown common growth component. This commonality means that when the heterogeneous time varying idiosyncratic components converge over time to a constant, a form of panel convergence holds, analogous to the concept of conditional sigma convergence. The paper provides a framework of asymptotic representations for the factor components that enables the development of econometric procedures of estimation and testing. In particular, a simple regression based convergence test is developed, whose asymptotic properties are analyzed under both null and local alternatives, and a new method of clustering panels into club convergence groups is constructed. These econometric methods are applied to analyze convergence in cost of living indices among 19 U.S. metropolitan cities.","['Phillips, Peter C. B.', 'Sul, Donggyu']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Price Level; Inflation; Deflation', 'General Regional Economics: Econometric and Input-Output Models; Other Models']","['C23', 'C33', 'E31', 'R15']",Transition Modeling and Econometric Convergence Tests,0,0,0,0,0,2007,11,01
75,6,2007-11-01,"This paper proposes a structural nonequilibrium model of initial responses to incomplete-information games based on ""level-k"" thinking, which describes behavior in many experiments with complete-information games. We derive the model's implications in first- and second-price auctions with general information structures, compare them to equilibrium and Eyster and Rabin's (2005) ""cursed equilibrium,"" and evaluate the model's potential to explain nonequilibrium bidding in auction experiments. The level-k model generalizes many insights from equilibrium auction theory. It allows a unified explanation of the winner's curse in common-value auctions and overbidding in those independent-private-value auctions without the uniform value distributions used in most experiments.","['Iriberri, Nagore', 'Crawford, Vincent P.']",['Auctions'],['D44'],Level-k Auctions: Can a Nonequilibrium Model of Strategic Thinking Explain the Winner's Curse and Overbidding in Private-Value Auctions?,0,0,1,0,0,2007,11,01
75,6,2007-11-01,"We analyze use of a quasi-likelihood ratio statistic for a mixture model to test the null hypothesis of one regime versus the alternative of two regimes in a Markov regime-switching context. This test exploits mixture properties implied by the regime-switching process, but ignores certain implied serial correlation properties. When formulated in the natural way, the setting is nonstandard, involving nuisance parameters on the boundary of the parameter space, nuisance parameters identified only under the alternative, or approximations using derivatives higher than second order. We exploit recent advances by Andrews (2001) and contribute to the literature by extending the scope of mixture models, obtaining asymptotic null distributions different from those in the literature. We further provide critical values for popular models or bounds for tail probabilities that are useful in constructing conservative critical values for regime-switching tests. We compare the size and power of our statistics to other useful tests for regime switching via Monte Carlo methods and find relatively good performance. We apply our methods to reexamine the classic cartel study of Porter (1983) and reaffirm Porter's findings.","['Cho, Jin Seo', 'White, Halbert']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Testing for Regime Switching,0,0,0,0,0,2007,11,01
75,6,2007-11-01,"This paper studies a shape-invariant Engel curve system with endogenous total expenditure, in which the shape-invariant specification involves a common shift parameter for each demographic group in a pooled system of nonparametric Engel curves. We focus on the identification and estimation of both the nonparametric shapes of the Engel curves and the parametric specification of the demographic scaling parameters. The identification condition relates to the bounded completeness and the estimation procedure applies the sieve minimum distance estimation of conditional moment restrictions, allowing for endogeneity. We establish a new root mean squared convergence rate for the nonparametric instrumental variable regression when the endogenous regressor could have unbounded support. Root-n asymptotic normality and semiparametric efficiency of the parametric components are also given under a set of ""low-level"" sufficient conditions. Our empirical application using the U.K. Family Expenditure Survey shows the importance of adjusting for endogeneity in terms of both the nonparametric curvatures and the demographic parameters of systems of Engel curves.","['Blundell, Richard', 'Kristensen, Dennis', 'Chen, Xiaohong']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis']","['C51', 'D12']",Semi-nonparametric IV Estimation of Shape-Invariant Engel Curves,0,0,0,0,0,2007,11,01
75,5,2007-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2007,09,01
75,5,2007-09-01,"Nonseparable models do not impose any type of additivity between the unobserved part and the observable regressors, and are therefore ideal for many economic applications. To identify these models using the entire joint distribution of the data as summarized in regression quantiles, monotonicity in unobservables has frequently been assumed. This paper establishes that in the absence of monotonicity, the quantiles identify local average structural derivatives of nonseparable models.","['Hoderlein, Stefan', 'Mammen, Enno']",['Single Equation Models; Single Variables: General'],['C20'],Identification of Marginal Effects in Nonseparable Models without Monotonicity,0,0,0,0,0,2007,09,01
75,5,2007-09-01,"This study reports evidence from a field experiment that was conducted to investigate the relevance of gift exchange in a natural setting. In collaboration with a charitable organization, we sent roughly 10,000 solicitation letters to potential donors. One-third of the letters contained no gift, one-third contained a small gift, and one-third contained a large gift. Treatment assignment was random. The results confirm the economic importance of gift exchange. Compared to the no gift condition, the relative frequency of donations increased by 17 percent if a small gift was included and by 75 percent for a large gift. The study extends the current body of research on gift exchange, which is almost exclusively confined to laboratory studies.","['Falk, Armin']",['Altruism; Philanthropy; Intergenerational Transfers'],['D64'],Gift Exchange in the Field,0,0,0,0,0,2007,09,01
75,5,2007-09-01,"This paper takes steps toward integrating firm theory in the spirit of Alchian and Demsetz (1972) and Grossman and Hart (1986), contract theory in the spirit of Holmstrom (1979), and general equilibrium theory in the spirit of Arrow and Debreu (1954) and McKenzie (1959). In the model presented here, the set of firms that form and the contractual arrangements that appear, the assignments of agents to firms, the prices faced by firms for inputs and outputs, and the incentives to agents are all determined endogenously at equilibrium. Agents choose consumption--but they also choose which firms to join, which roles to occupy in those firms, and which actions to take in those roles. Agents interact anonymously with the (large) market, but strategically within the (small) firms they join. The model accommodates moral hazard, adverse selection, signaling, and insurance. Equilibria may be Pareto ranked.","['Zame, William R.']","['Firm Behavior: Theory', 'General Equilibrium and Disequilibrium: Other', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D21', 'D59', 'D82', 'D86']","Incentives, Contracts, and Markets: A General Equilibrium Theory of Firms",0,0,0,0,0,2007,09,01
75,5,2007-09-01,"The purpose of this paper is to provide theoretical justification for some existing methods for constructing confidence intervals for the sum of coefficients in autoregressive models. We show that the methods of Stock (1991), Andrews (1993), and Hansen (1999) provide asymptotically valid confidence intervals, whereas the subsampling method of Romano and Wolf (2001) does not. In addition, we generalize the three valid methods to a larger class of statistics. We also clarify the difference between uniform and pointwise asymptotic approximations, and show that a pointwise convergence of coverage probabilities for all values of the parameter does not guarantee the validity of the confidence set.","['Mikusheva, Anna']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Uniform Inference in Autoregressive Models,0,0,0,0,0,2007,09,01
75,5,2007-09-01,"This paper presents three sets of results about equilibrium bias of technology. First, I show that when the menu of technological possibilities only allows for factor-augmenting technologies, the increase in the supply of a factor induces technological change relatively biased toward that factor--meaning that the induced technological change increases the relative marginal product of the factor becoming more abundant. Moreover, this induced bias can be strong enough to make the relative marginal product of a factor increasing in response to an increase in its supply, thus leading to an upward-sloping relative demand curve. I also show that these results about relative bias do not generalize when more general menus of technological possibilities are considered. Second, I prove that under mild assumptions, the increase in the supply of a factor induces technological change that is absolutely biased toward that factor--meaning that it increases its marginal product at given factor proportions. The third and most important result in the paper establishes the possibility of and conditions for strong absolute equilibrium bias--whereby the price (marginal product) of a factor increases in response to an increase in its supply. I prove that, under some regularity conditions, there will be strong absolute equilibrium bias if and only if the aggregate production function of the economy fails to be jointly concave in factors and technology. This type of failure of joint concavity is possible in economies where equilibrium factor demands and technologies result from the decisions of different agents.","['Acemoglu, Daron']","['Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Technological Change: Choices and Consequences; Diffusion Processes', 'One, Two, and Multisector Growth Models']","['L16', 'O33', 'O41']",Equilibrium Bias of Technology,1,0,0,1,0,2007,09,01
75,5,2007-09-01,"We describe a two-step algorithm for estimating dynamic games under the assumption that behavior is consistent with Markov perfect equilibrium. In the first step, the policy functions and the law of motion for the state variables are estimated. In the second step, the remaining structural parameters are estimated using the optimality conditions for equilibrium. The second step estimator is a simple simulated minimum distance estimator. The algorithm applies to a broad class of models, including industry competition models with both discrete and continuous controls such as the Ericson and Pakes (1995) model. We test the algorithm on a class of dynamic discrete choice models with normally distributed errors and a class of dynamic oligopoly models similar to that of Pakes and McGuire (1994).","['Levin, Jonathan', 'Bajari, Patrick', 'Benkard, C. Lanier']","['Model Construction and Estimation', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['C51', 'D43', 'L13']",Estimating Dynamic Models of Imperfect Competition,1,0,1,0,0,2007,09,01
75,5,2007-09-01,"This paper investigates a new class of two-player games in continuous time, in which the players' observations of each other's actions are distorted by Brownian motions. These games are analogous to repeated games with imperfect monitoring in which the players take actions frequently. Using a differential equation, we find the set epsilon(r) of payoff pairs achievable by all public perfect equilibria of the continuous-time game, where r is the discount rate. The same differential equation allows us to find public perfect equilibria that achieve any value pair on the boundary of the set epsilon(r). These public perfect equilibria are based on a pair of continuation values as a state variable, which moves along the boundary of epsilon(r) during the course of the game. In order to give players incentives to take actions that are not static best responses, the pair of continuation values is stochastically driven by the players' observations of each other's actions along the boundary of the set epsilon(r).","['Sannikov, Yuliy']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Games with Imperfectly Observable Actions in Continuous Time,0,0,0,0,0,2007,09,01
75,5,2007-09-01,"This paper develops a framework for performing estimation and inference in econometric models with partial identification, focusing particularly on models characterized by moment inequalities and equalities. Applications of this framework include the analysis of game-theoretic models, revealed preference restrictions, regressions with missing and corrupted data, auction models, structural quantile regressions, and asset pricing models. Specifically, we provide estimators and confidence regions for the set of minimizers Theta[subscript I] of an econometric criterion function Q(theta). In applications, the criterion function embodies testable restrictions on economic models. A parameter value theta that describes an economic model satisfies these restrictions if Q(theta) attains its minimum at this value. Interest therefore focuses on the set of minimizers, called the identified set. We use the inversion of the sample analog, Q[subscript n](theta), of the population criterion, Q(theta), to construct estimators and confidence regions for the identified set, and develop consistency, rates of convergence, and inference results for these estimators and regions. To derive these results, we develop methods for analyzing the asymptotic properties of sample criterion functions under set identification.","['Chernozhukov, Victor', 'Hong, Han', 'Tamer, Elie']","['Estimation: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C13', 'C20', 'C30']",Estimation and Confidence Regions for Parameter Sets in Econometric Models,0,0,0,0,0,2007,09,01
75,4,2007-07-01,"We consider nonparametric estimation of a regression function that is identified by requiring a specified quantile of the regression ""error"" conditional on an instrumental variable to be zero. The resulting estimating equation is a nonlinear integral equation of the first kind, which generates an ill-posed inverse problem. The integral operator and distribution of the instrumental variable are unknown and must be estimated nonparametrically. We show that the estimator is mean-square consistent, derive its rate of convergence in probability, and give conditions under which this rate is optimal in a minimax sense. The results of Monte Carlo experiments show that the estimator behaves well in finite samples.","['Linton, Oliver', 'Lewbel, Arthur']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Nonparametric Matching and Efficient Estimators of Homothetically Separable Functions,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"We consider nonparametric estimation of a regression function that is identified by requiring a specified quantile of the regression ""error"" conditional on an instrumental variable to be zero. The resulting estimating equation is a nonlinear integral equation of the first kind, which generates an ill-posed inverse problem. The integral operator and distribution of the instrumental variable are unknown and must be estimated nonparametrically. We show that the estimator is mean-square consistent, derive its rate of convergence in probability, and give conditions under which this rate is optimal in a minimax sense. The results of Monte Carlo experiments show that the estimator behaves well in finite samples.","['Lee, Sokbae', 'Horowitz, Joel L.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C21', 'C31']",Nonparametric Instrumental Variables Estimation of a Quantile Regression Model,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"This paper considers the problem of selection of weights for averaging across least squares estimates obtained from a set of models. Existing model average methods are based on exponential Akaike information criterion (AIC) and Bayesian information criterion (BIC) weights. In distinction, this paper proposes selecting the weights by minimizing a Mallows criterion, the latter an estimate of the average squared error from the model average fit. We show that our new Mallows model average (MMA) estimator is asymptotically optimal in the sense of achieving the lowest possible squared error in a class of discrete model average estimators. In a simulation experiment we show that the MMA estimator compares favorably with those based on AIC and BIC weights. The proof of the main result is an application of the work of Li (1987).","['Hansen, Bruce E.']","['Single Equation Models; Single Variables: General', 'Model Evaluation, Validation, and Selection']","['C20', 'C52']",Notes and Comments: Least Squares Model Averaging,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"We study how to evaluate allocations independently of individual preferences over unavailable commodities. We prove impossibility results that suggest that such evaluations encounter serious difficulties. This is related to the well known problem of performing international comparisons of standard of living across countries with different consumption goods. We show how possibility results can be retrieved with restrictions on the domain of preferences, on the application of the independence axiom, or on the set of allocations to be ranked. Such restrictions appear more plausible when the objects of evaluation are allocations of composite commodities, characteristics, or human functionings rather than ordinary commodities.","['Fleurbaey, Marc', 'Tadenuma, Koichi']","['Consumer Economics: Theory', 'Social Choice; Clubs; Committees; Associations']","['D11', 'D71']",Do Irrelevant Commodities Matter?,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"This paper analyzes equilibrium and welfare for a tractable class of economies (games) that have externalities, strategic complementarity or substitutability, and heterogeneous information.","['Angeletos, George-Marios', 'Pavan, Alessandro']","['Allocative Efficiency; Cost-Benefit Analysis', 'Externalities', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D61', 'D62', 'D82', 'D83']",Efficient Use of Information and Social Value of Information,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"We present sufficient conditions for monotone matching in environments where utility is not fully transferable between partners. These conditions involve not only complementarity in types of the total payoff to a match, as in the transferable utility case, but also monotonicity in type of the degree of transferability between partners. We apply our conditions to study some models of risk sharing and incentive problems, deriving new results for predicted matching patterns in those contexts.","['Newman, Andrew F.', 'Legros, Patrick']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']","Beauty Is a Beast, Frog Is a Prince: Assortative Matching with Nontransferabilities",0,0,0,0,0,2007,07,01
75,4,2007-07-01,"In this paper, we generalize the notion of Pareto efficiency to make it applicable to environments with endogenous populations. Two efficiency concepts are proposed: P-efficiency and A-efficiency. The two concepts differ in how they treat potential agents that are not born. We show that these concepts are closely related to the notion of Pareto efficiency when fertility is exogenous. We prove a version of the first welfare theorem for Barro-Becker type fertility choice models and discuss how this result can be generalized. Finally, we study examples of equilibrium settings in which fertility decisions are not efficient, and we classify them into settings where inefficiencies arise inside the family and settings where they arise across families.","['Golosov, Mikhail', 'Jones, Larry E.', 'Tertilt, Michele']","['Allocative Efficiency; Cost-Benefit Analysis', 'Demographic Trends, Macroeconomic Effects, and Forecasts', 'Fertility; Family Planning; Child Care; Children; Youth']","['D61', 'J11', 'J13']",Efficiency with Endogenous Population Growth,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"Many tests of asset-pricing models address only the pricing predictions, but these pricing predictions rest on portfolio choice predictions that seem obviously wrong. This paper suggests a new approach to asset pricing and portfolio choices based on unobserved heterogeneity. This approach yields the standard pricing conclusions of classical models but is consistent with very different portfolio choices. Novel econometric tests link the price and portfolio predictions and take into account the general equilibrium effects of sample-size bias. This paper works through the approach in detail for the case of the classical capital asset pricing model (CAPM), producing a model called CAPM + epsilon. When these econometric tests are applied to data generated by large-scale laboratory asset markets that reveal both prices and portfolio choices, CAPM + epsilon is not rejected.","['Plott, Charles', 'Zame, William R.', 'Bossaerts, Peter']","['Model Construction and Estimation', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', 'G11', nan]","Prices and Portfolio Choices in Financial Markets: Theory, Econometrics, Experiments",0,0,0,0,0,2007,07,01
75,4,2007-07-01,"In this paper I demonstrate how one can generalize finitely many examples to statements about (infinite) classes of economic models. If there exist upper bounds on the number of connected components of one-dimensional linear subsets of the set of parameters for which a conjecture is true, one can conclude that it is correct for all parameter values in the class considered, except for a small residual set, once one has verified the conjecture for a predetermined finite set of points. I show how to apply this insight to computational experiments and spell out assumptions on the economic fundamentals that ensure that the necessary bounds on the number of connected components exist. I argue that these methods can be fruitfully utilized in applied general equilibrium analysis. I provide general assumptions on preferences and production sets that ensure that economic conjectures define sets with a bounded number of connected components. Using the theoretical results, I give an example of how one can explore qualitative and quantitative implications of general equilibrium models using computational experiments. Finally, I show how random algorithms can be used for generalizing examples in high-dimensional problems.","['Kubler, Felix']","['Computational Techniques; Simulation Modeling', 'General Equilibrium and Disequilibrium: General']","['C63', 'D50']",Approximate Generalizations and Computational Experiments,0,0,0,0,0,2007,07,01
75,4,2007-07-01,"We report recent advances concerning the package allocation problem, in which traders seek to buy or sell combinations of goods.","['Milgrom, Paul']",['Auctions'],['D44'],Package Auctions and Exchanges,0,0,1,0,0,2007,07,01
75,3,2007-05-01,"We analyze a cheap talk game, a la Crawford and Sobel, in a multidimensional state and policy space. A feature of the multidimensional state space is that communication on one dimension often reveals information on others. We show how this feature imposes bounds on communication.","['Levy, Gilat', 'Razin, Ronny']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D82', 'D83']",On the Limits of Communication in Multidimensional Cheap Talk: A Comment,0,0,0,0,0,2007,05,01
75,3,2007-05-01,"When two parties have different prior beliefs about some future event, they can realize gains through speculative trade. Can these gains be realized when the parties' prior beliefs are not common knowledge? We examine a simple example in which two parties having heterogeneous prior beliefs, independently drawn from some distribution, bet on what future action one of them will choose. We define a notion of ""constrained interim-efficient"" best and ask whether they can be implemented in Bayesian equilibrium by some mechanism. Our main result establishes that as the costs of unilaterally manipulating the bet's outcome become more symmetric across states, implementation becomes easier. In particular, when these costs are equal in both states, implementation is possible for any distribution.","['Spiegler, Ran', 'Eliaz, Kfir']","['Asymmetric and Private Information; Mechanism Design', 'Expectations; Speculations']","['D82', 'D84']",A Mechanism-Design Approach to Speculative Trade,0,0,0,0,0,2007,05,01
75,3,2007-05-01,"As the exchange rate, foreign demand, and production costs evolve, domestic producers are continually faced with two choices: whether to be an exporter and, if so, how much to export. We develop a dynamic structural model of export supply that characterizes these two decisions. The model embodies plant-level heterogeneity in export profits, uncertainty about the determinants of future profits, and market entry costs for new exporters. Using a Bayesian Monte Carlo Markov chain estimator, we fit this model to plant-level panel data on three Colombian manufacturing industries. We obtain profit function and sunk entry cost coefficients, and use them to simulate export responses to shifts in the exchange-rate process and several types of export subsidies. In each case, the aggregate export response depends on entry costs, expectations about the exchange rate process, prior exporting experience, and producer heterogeneity. Export revenue subsidies are far more effective at stimulating exports than policies that subsidize entry costs.","['Roberts, Mark J.', 'Tybout, James R.', 'Das, Sanghamitra']","['Empirical Studies of Trade', 'Multinational Firms; International Business', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'International Linkages to Development; Role of International Organizations']","['F14', 'F23', 'L11', 'O19']","Market Entry Costs, Producer Heterogeneity, and Export Dynamics",1,0,0,0,0,2007,05,01
75,3,2007-05-01,"We propose a simple method to help researchers develop quantitative models of economic fluctuations. The method rests on the insight that many models are equivalent to a prototype growth model with time-varying wedges that resemble productivity, labor and investment taxes, and government consumption. Wedges that correspond to these variables--efficiency, labor, investment, and government consumption wedges--are measured and then fed back into the model so as to assess the fraction of various fluctuations they account for. Applying this method to U.S. data for the Great Depression and the 1982 recession reveals that the efficiency and labor wedges together account for essentially all of the fluctuations; the investment wedge plays a decidedly tertiary role, and the government consumption wedge plays none. Analyses of the entire postwar period and alternative model specifications support these results. Models with frictions manifested primarily as investment wedges are thus not promising for the study of U.S. business cycles.","['Chari, V. V.', 'Kehoe, Patrick J.', 'McGrattan, Ellen R.']","['Business Fluctuations; Cycles', 'One, Two, and Multisector Growth Models', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['E32', 'O41', 'O47']",Business Cycle Accounting,0,0,0,0,0,2007,05,01
75,3,2007-05-01,"In this paper, we consider the nonparametric identification and estimation of the average effect of a dummy endogenous regressor in models where the regressors are weakly but not additively separable from the error term. The model is not required to be strictly increasing in the error term, and the class of models considered includes limited dependent variable models such as discrete choice models. Conditions are established conditions under which it is possible to identify the average effect of the dummy endogenous regressor in a weakly separable model without relying on parametric functional form or distributional assumptions and without the use of large support conditions.","['Yildiz, Nese', 'Vytlacil, Edward']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C24', 'C30']",Dummy Endogenous Variables in Weakly Separable Models,0,0,0,0,0,2007,05,01
75,3,2007-05-01,"Global games of regime change--coordination games of incomplete information in which a status quo is abandoned once a sufficiently large fraction of agents attack it--have been used to study crises phenomena such as currency attacks, bank runs, debt crises, and political change. We extend the static benchmark examined in the literature by allowing agents to take actions in many periods and to learn about the underlying fundamentals over time. We first provide a simple recursive algorithm for the characterization of monotone equilibria. We then show how the interaction of the knowledge that the regime survived past attacks with the arrival of information over time, or with changes in fundamentals, leads to interesting equilibrium properties. First, multiplicity may obtain under the same conditions on exogenous information that guarantee uniqueness in the static benchmark. Second, fundamentals may predict the eventual fate of the regime but not the timing or the number of attacks. Finally, equilibrium dynamics can alternate between phases of tranquility--where no attack is possible--and phases of distress--where a large attack can occur--even without changes in fundamentals.","['Angeletos, George-Marios', 'Hellwig, Christian', 'Pavan, Alessandro']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']","Dynamic Global Games of Regime Change: Learning, Multiplicity, and the Timing of Attacks",0,0,0,0,0,2007,05,01
75,3,2007-05-01,"Consider a two-person intertemporal bargaining problem in which players choose actions and offers each period, and collect payoffs (as a function of that period's actions) while bargaining proceeds. This can alternatively be viewed as an infinitely repeated game wherein players can offer one another enforceable contracts that govern play for the rest of the game. Theory is silent with regard to how the surplus is likely to be split, because a folk theorem applies. Perturbing such a game with a rich set of behavioral types for each player yields a specific asymptotic prediction for how the surplus will be divided, as the perturbation probabilities approach zero. Behavioral types may follow nonstationary strategies and respond to the opponent's play. In equilibrium, rational players initially choose a behavioral type to imitate and a war of attrition ensues. How much should a player try to get and how should she behave while waiting for the resolution of bargaining? In both respects she should build her strategy around the advice given by the ""Nash bargaining with threats"" (NBWT) theory developed for two-stage games. In any perfect Bayesian equilibrium, she can guarantee herself virtually her NBWT payoff by imitating a behavioral type with the following simple strategy: in every period, ask for (and accept nothing less than) that player's NBWT share and, while waiting for the other side to concede, take the action Nash recommends as a threat in his two-stage game. The results suggest that there are forces at work in some dynamic games that favor certain payoffs over all others. This is in stark contrast to the classic folk theorems, to the further folk theorems established for repeated games with two-sided reputational perturbations, and to the permissive results obtained in the literature on bargaining with payoffs as you go.","['Pearce, David', 'Abreu, Dilip']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'C78', 'D82']","Bargaining, Reputation, and Equilibrium Selection in Repeated Games with Contracts",0,0,0,0,0,2007,05,01
75,3,2007-05-01,"This paper applies some general concepts in decision theory to a simple instrumental variables model. There are two endogenous variables linked by a single structural equation; k of the exogenous variables are excluded from this structural equation and provide the instrumental variables (IV). The reduced-form distribution of the endogenous variables conditional on the exogenous variables corresponds to independent draws from a bivariate normal distribution with linear regression functions and a known covariance matrix. A canonical form of the model has parameter vector (rho, phi, omega), where phi is the parameter of interest and is normalized to be a point on the unit circle. The reduced-form coefficients on the instrumental variables are split into a scalar parameter rho and a parameter vector omega, which is normalized to be a point on the (k - 1)-dimensional unit sphere; rho measures the strength of the association between the endogenous variables and the instrumental variables, and omega is a measure of direction. A prior distribution is introduced for the IV model. The parameters phi, rho, and omega are treated as independent random variables. The distribution for phi is uniform on the unit circle; the distribution for omega is uniform on the unit sphere with dimension k - 1. These choices arise from the solution of a minimax problem. The prior for rho is left general. It turns out that given any positive value for rho, the Bayes estimator of phi does not depend on rho; it equals the maximum-likelihood estimator. This Bayes estimator has constant risk; because it minimizes average risk with respect to a proper prior, it is minimax. The same general concepts are applied to obtain confidence intervals. The prior distribution is used in two ways. The first way is to integrate out the nuisance parameter omega in the IV model. This gives an integrated likelihood function with two scalar parameters, phi and rho. Inverting a likelihood ratio test, based on the integrated likelihood function, provides a confidence interval for phi. This lacks finite sample optimality, but invariance arguments show that the risk function depends only on rho and not on phi or omega. The second approach to confidence sets aims for finite sample optimality by setting up a loss function that trades off coverage against the length of the interval. The automatic uniform priors are used for phi and omega, but a prior is also needed for the scalar rho, and no guidance is offered on this choice. The Bayes rule is a highest posterior density set. Invariance arguments show that the risk function depends only on rho and not on phi or omega. The optimality result combines average risk and maximum risk. The confidence set minimizes the average--with respect to the prior distribution for rho--of the maximum risk, where the maximization is with respect to phi and omega.","['Chamberlain, Gary']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Decision Theory Applied to an Instrumental Variables Model,0,0,0,0,0,2007,05,01
75,2,2007-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"Dekel, Lipman and Rustichini (2001) (henceforth DLR) axiomatically characterized three representations of preferences that allow for a desire for flexibility and/or commitment. In one of these representations (ordinal expected utility), the independence axiom is stated in a weaker form than is necessary to obtain the representation; in another (additive expected utility), the continuity axiom is too weak. In this erratum we provide examples showing that the axioms used by DLR are not sufficient, and provide stronger versions of these axioms that, together with the other axioms used by DLR, are necessary and sufficient for these two representations.","['Sarver, Todd', 'Lipman, Barton L.', 'Rustichini, Aldo', 'Dekel, Eddie']",['Consumer Economics: Theory'],['D11'],Representing Preferences with a Unique Subjective State Space: A Corrigendum,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"In this article we introduce efficient Wald tests for testing the null hypothesis of the unit root against the alternative of the fractional unit root. In a local alternative framework, the proposed tests are locally asymptotically equivalent to the optimal Robinson Lagrange multiplier tests. Our results contrast with the tests for fractional unit roots, introduced by Dolado, Gonzalo, and Mayoral, which are inefficient. In the presence of short range serial correlation, we propose a simple and efficient two-step test that avoids the estimation of a nonlinear regression model. In addition, the first-order asymptotic properties of the proposed tests are not affected by the preestimation of short or long memory parameters.","['Lobato, Ignacio N.', 'Velasco, Carlos']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Efficient Wald Tests for Fractional Unit Roots,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"We provide a nonparametric characterization of a general collective model for household consumption, which includes externalities and public consumption. Next, we establish testable necessary and sufficient conditions for data consistency with collective rationality that only include observed price and quantity information. These conditions have a similar structure as the generalized axiom of revealed preference for the unitary model, which is convenient from a testing point of view. In addition, we derive the minimum number of goods and observations that enable the rejection of collectively rational household behavior.","['Vermeulen, Frederic', 'De Rock, Bram', 'Cherchye, Laurens']","['Model Construction and Estimation', 'Consumer Economics: Theory', 'Household Production and Intrahousehold Allocation']","['C51', 'D11', 'D13']",The Collective Model of Household Consumption: A Nonparametric Characterization,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"This paper considers identification and estimation of the effect of a mismeasured binary regressor in a nonparametric or semiparametric regression, or the conditional average effect of a binary treatment or policy on some outcome where treatment may be misclassified. Failure to account for misclassification is shown to result in attenuation bias in the estimated treatment effect. An identifying assumption that overcomes this bias is the existence of an instrument for the binary regressor that is conditionally independent of the treatment effect. A discrete instrument suffices for nonparametric identification.","['Lewbel, Arthur']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C21', 'C31']",Estimation of Average Treatment Effects with Misclassification,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"An extension to Ellsberg's experiment demonstrates that attitudes to ambiguity and compound objective lotteries are tightly associated. The sample is decomposed into three main groups: subjective expected utility subjects, who reduce compound objective lotteries and are ambiguity neutral, and two groups that exhibit different forms of association between preferences over compound lotteries and ambiguity, corresponding to alternative theoretical models that account for ambiguity averse or seeking behavior.","['Halevy, Yoram']","['Design of Experiments: Laboratory, Individual', 'Criteria for Decision-Making under Risk and Uncertainty']","['C91', 'D81']",Ellsberg Revisited: An Experimental Study,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"This paper considers issues related to estimation, inference, and computation with multiple structural changes that occur at unknown dates in a system of equations. Changes can occur in the regression coefficients and/or the covariance matrix of the errors. We also allow arbitrary restrictions on these parameters, which permits the analysis of partial structural change models, common breaks that occur in all equations, breaks that occur in a subset of equations, and so forth. The method of estimation is quasi-maximum likelihood based on Normal errors. The limiting distributions are obtained under more general assumptions than previous studies. For testing, we propose likelihood ratio type statistics to test the null hypothesis of no structural change and to select the number of changes. Structural change tests with restrictions on the parameters can be constructed to achieve higher power when prior information is present. For computation, an algorithm for an efficient procedure is proposed to construct the estimates and test statistics. We also introduce a novel locally ordered breaks model, which allows the breaks in different equations to be related yet not occurring at the same dates.","['Qu, Zhongjun', 'Perron, Pierre']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Estimating and Testing Structural Changes in Multivariate Regressions,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"Does individual behavior in a laboratory setting provide a reliable indicator of behavior in a naturally occurring setting? We consider this general methodological question in the context of eliciting risk attitudes. The controls that are typically employed in laboratory settings, such as the use of abstract lotteries, could lead subjects to employ behavioral rules that differ from the ones they employ in the field. Because it is field behavior that we are interested in understanding, those controls might be a confound in themselves if they result in differences in behavior. We find that the use of artificial monetary prizes provides a reliable measure of risk attitudes when the natural counterpart outcome has minimal uncertainty, but that it can provide an unreliable measure when the natural counterpart outcome has background risk. Behavior tended to be moderately risk averse when artificial monetary prizes were used or when there was minimal uncertainty in the natural nonmonetary outcome, but subjects drawn from the same population were much more risk averse when their attitudes were elicited using the natural nonmonetary outcome that had some background risk. These results are consistent with conventional expected utility theory for the effects of background risk on attitudes to risk.","['List, John A.', 'Towe, Charles', 'Harrison, Glenn W.']","['Design of Experiments: Laboratory, Individual', 'Field Experiments', 'Criteria for Decision-Making under Risk and Uncertainty']","['C91', 'C93', 'D81']",Naturally Occurring Preferences and Exogenous Laboratory Experiments: A Case Study of Risk Aversion,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"This paper develops and applies some new results in the theory of monotone comparative statics. Let f be a real-valued function defined on R[superscript l] and consider the problem of maximizing f(x) when x is constrained to lie in some subset C of R[superscript l]. We develop a natural way to order the constraint sets C and find the corresponding restrictions on the objective function f that guarantee that optimal solutions increase with the constraint set. We apply our techniques to problems in consumer, producer, and portfolio theory. We also use them to generalize Rybcsynski's theorem and the LeChatelier principle.","['Quah, John K.-H.']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'Consumer Economics: Theory', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Portfolio Choice; Investment Decisions']","['C61', 'D11', 'D24', 'G11']",The Comparative Statics of Constrained Optimization Problems,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"Rationalizability is a central solution concept of game theory. Economic models often have many rationalizable outcomes, motivating economists to use refinements of rationalizability, including equilibrium refinements. In this paper we try to achieve a general understanding of when this multiplicity occurs and how one should deal with it. Assuming that the set of possible payoff functions and belief structures is sufficiently rich, we establish a revealing structure of the correspondence of beliefs to sets of rationalizable outcomes. We show that, for any rationalizable action a of any type, we can perturb the beliefs of the type in such a way that a is uniquely rationalizable for the new type. This unique outcome will be robust to further small changes. When multiplicity occurs, then we are in a ""knife-edge"" case, where the unique rationalizable outcome changes, sandwiched between open sets of types where each of the rationalizable actions is uniquely rationalizable. As an immediate application of this result, we characterize, for any refinement of rationalizability, the predictions that are robust to small misspecifications of interim beliefs. These are only those predictions that are true for all rationalizable strategies, that is, the predictions that could have been made without the refinement.","['Weinstein, Jonathan', 'Yildiz, Muhamet']",['Noncooperative Games'],['C72'],A Structure Theorem for Rationalizability with Application to Robust Predictions of Refinements,0,0,0,0,0,2007,03,01
75,2,2007-03-01,"This paper examines changes in the distribution of wages using bounds to allow for the impact of nonrandom selection into work. We show that worst case bounds can be informative. However, because employment rates in the United Kingdom are often low, they are not informative about changes in educational or gender wage differentials. Thus we explore ways to tighten these bounds using restrictions motivated from economic theory. With these assumptions, we find convincing evidence of an increase in inequality within education groups, changes in educational differentials, and increases in the relative wages of women.","['Gosling, Amanda', 'Blundell, Richard', 'Meghir, Costas', 'Ichimura, Hidehiko']","['Economics of Gender; Non-labor Discrimination', 'Wage Level and Structure; Wage Differentials']","['J16', 'J31']",Changes in the Distribution of Male and Female Wages Accounting for Employment Composition Using Bounds,0,0,0,0,0,2007,03,01
75,1,2007-01-01,ECONLIT None Found,"['Samuelson, Larry', 'Dekel, Eddie', 'Meghir, Costas', 'Levine, David', 'Newey, Whitney']",[nan],[nan],REPORT OF THE EDITORS OF ECONOMETRICA.,0,0,0,0,0,2007,01,01
75,1,2007-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],REPORT OF THE TREASURER.,0,0,0,0,0,2007,01,01
75,1,2007-01-01,ECONLIT None Found,"['Repullo, Rafael']",[nan],[nan],REPORT OF THE SECRETARY.,0,0,0,0,0,2007,01,01
75,1,2007-01-01,ECONLIT None Found,"['Aliprantis, Charalambos D.', 'Camera, Gabriele', 'Puzzello, Daniela']",['Money and Interest Rates: General'],['E40'],Contagion Equilibria in a Monetary Model,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"This paper develops estimators for quantile treatment effects under the identifying restriction that selection to treatment is based on observable characteristics. Identification is achieved without requiring computation of the conditional quantiles of the potential outcomes. Instead, the identification results for the marginal quantiles lead to an estimation procedure for the quantile treatment effect parameters that has two steps: nonparametric estimation of the propensity score and computation of the difference between the solutions of two separate minimization problems. Root-N consistency, asymptotic normality, and achievement of the semiparametric efficiency bound are shown for that estimator. A consistent estimation procedure for the variance is also presented. Finally, the method developed here is applied to evaluation of a job training program and to a Monte Carlo exercise. Results from the empirical application indicate that the method works relatively well even for a data set with limited overlap between treated and controls in the support of covariates. The Monte Carlo study shows that, for a relatively small sample size, the method produces estimates with good precision and low bias, especially for middle quantiles.","['Firpo, Sergio']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['C21', 'C31']",Efficient Semiparametric Estimation of Quantile Treatment Effects,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"Consider a Bayesian collective decision problem in which the preferences of agents are private information. We provide a general demonstration that the utility costs associated with incentive constraints become negligible when the decision problem is linked with a large number of independent copies of itself. This is established by defining a mechanism in which agents must budget their representations of preferences so that the frequency of preferences across problems mirrors the underlying distribution of preferences, and then arguing that agents' incentives are to satisfy their budget by being as truthful as possible. We also show that all equilibria of the linking mechanisms converge to the target utility levels. The mechanisms do not require transferable utility or interpersonal comparisons of utility, and are immune to manipulations by coalitions.","['Jackson, Matthew O.', 'Sonnenschein, Hugo F.']","['Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D71', 'D82']",Overcoming Incentive Constraints by Linking Decisions,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"This paper establishes that instruments enable the identification of nonparametric regression models in the presence of measurement error by providing a closed form solution for the regression function in terms of Fourier transforms of conditional expectations of observable variables. For parametrically specified regression functions, we propose a root n consistent and asymptotically normal estimator that takes the familiar form of a generalized method of moments estimator with a plugged-in nonparametric kernel density estimate. Both the identification and the estimation methodologies rely on Fourier analysis and on the theory of generalized functions. The finite-sample properties of the estimator are investigated through Monte Carlo simulations.","['Schennach, Susanne M.']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Instrumental Variable Estimation of Nonlinear Errors-in-Variables Models,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"Consider a decentralized, dynamic market with an infinite horizon and participation costs in which both buyers and sellers have private information concerning their values for the indivisible traded good. Time is discrete, each period has length d, and, each unit of time, continuums of new buyers and sellers consider entry. Traders whose expected utility is negative choose not to enter. Within a period each buyer is matched anonymously with a seller and each seller is matched with zero, one, or more buyers. Every seller runs a first price auction with a reservation price and, if trade occurs, both the seller and the winning buyer exit the market with their realized utility. Traders who fail to trade continue in the market to be rematched. We characterize the steady-state equilibria that are perfect Bayesian. We show that, as d converges to zero, equilibrium prices at which trades occur converge to the Walrasian price and the realized allocations converge to the competitive allocation. We also show the existence of equilibria for d sufficiently small, provided the discount rate is small relative to the participation costs.","['Shneyerov, Artyom', 'Satterthwaite, Mark']","['Bargaining Theory; Matching Theory', 'Exchange and Production Economies']","['C78', 'D51']","Dynamic Matching, Two-Sided Incomplete Information, and Participation Costs: Existence and Convergence to Perfect Competition",0,0,0,0,0,2007,01,01
75,1,2007-01-01,"We show experimentally that fairness concerns may have a decisive impact on the actual and optimal choice of contracts in a moral hazard context. Bonus contracts that offer a voluntary and unenforceable bonus for satisfactory performance provide powerful incentives and are superior to explicit incentive contracts when there are some fair-minded players, but trust contracts that pay a generous wage up front are less efficient than incentive contracts. The principals understand this and predominantly choose the bonus contracts. These results are consistent with recently developed theories of fairness, which offer important new insights into the interaction of contract choices, fairness, and incentives.","['Klein, Alexander', 'Schmidt, Klaus M.', 'Fehr, Ernst']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory', 'Labor Contracts']","['D63', 'D82', 'D86', 'J41']",Fairness and Contract Design,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"Families, primarily female-headed minority households with children, living in high-poverty public housing projects in five U.S. cities were offered housing vouchers by lottery in the Moving to Opportunity program. Four to seven years after random assignment, families offered vouchers lived in safer neighborhoods that had lower poverty rates than those of the control group not offered vouchers. We find no significant overall effects of this intervention on adult economic self-sufficiency or physical health. Mental health benefits of the voucher offers for adults and for female youth were substantial. Beneficial effects for female youth on education, risky behavior, and physical health were offset by adverse effects for male youth. For outcomes that exhibit significant treatment effects, we find, using variation in treatment intensity across voucher types and cities, that the relationship between neighborhood poverty rate and outcomes is approximately linear.","['Katz, Lawrence F.', 'Liebman, Jeffrey B.', 'Kling, Jeffrey R.']","['Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Housing Demand', 'Production Analysis and Firm Location: Government Policy']","['I38', 'J15', 'R21', 'R38']",Experimental Analysis of Neighborhood Effects,0,0,0,0,0,2007,01,01
75,1,2007-01-01,"This paper develops a theoretical framework for studying contract and enforcement in settings with nondurable trading opportunities and complete but unverifiable information. The framework explicitly accounts for the parties' individual trade actions. The sets of implementable state-contingent payoffs, under various assumptions about renegotiation opportunities, are characterized and compared. The results indicate the benefit of modeling trade actions as individual, rather than as public, and they highlight the usefulness of a structured game-theoretic framework for applied research.","['Watson, Joel']",['Economics of Contract: Theory'],['D86'],"Contract, Mechanism Design, and Technological Detail",0,0,0,0,0,2007,01,01
75,1,2007-01-01,"This paper studies the estimation of dynamic discrete games of incomplete information. Two main econometric issues appear in the estimation of these models: the indeterminacy problem associated with the existence of multiple equilibria and the computational burden in the solution of the game. We propose a class of pseudo maximum likelihood (PML) estimators that deals with these problems, and we study the asymptotic and finite sample properties of several estimators in this class. We first focus on two-step PML estimators, which, although they are attractive for their computational simplicity, have some important limitations: they are seriously biased in small samples; they require consistent nonparametric estimators of players' choice probabilities in the first step, which are not always available; and they are asymptotically inefficient. Second, we show that a recursive extension of the two-step PML, which we call nested pseudo likelihood (NPL), addresses those drawbacks at a relatively small additional computational cost. The NPL estimator is particularly useful in applications where consistent nonparametric estimates of choice probabilities either are not available or are very imprecise, e.g., models with permanent unobserved heterogeneity. Finally, we illustrate these methods in Monte Carlo experiments and in an empirical application to a model of firm entry and exit in oligopoly markets using Chilean data from several retail industries.","['Aguirregabiria, Victor', 'Mira, Pedro']","['Model Construction and Estimation', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C51', 'C73', 'D43']",Sequential Estimation of Dynamic Discrete Games,0,0,1,0,0,2007,01,01
81,2,2013-03-01,ECONLIT None Found,"['Massari, Filippo']","['Exchange and Production Economies', 'Incomplete Markets', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations']","['D51', 'D52', 'D83', 'D84']","If You're So Smart, Why Aren't You Rich? Belief Selection in Complete and Incomplete Markets: Comment",0,0,0,0,0,2013,03,01
81,1,2013-01-01,ECONLIT None Found,"['MAILATH, GEORGE J.', 'MATZKIN, ROSA L.']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE EDITORS OF THE MONOGRAPH SERIES.,0,0,0,0,0,2013,01,01
74,6,2006-11-01,"A convex, compact, and possibly discontinuous better reply secure game has a Nash equilibrium. We introduce a very weak notion of continuity that can be used to establish that a game is better reply secure and we show that this notion of continuity is satisfied by a large class of games.","['Bagh, Adib', 'Jofre, Alejandro']",['Noncooperative Games'],['C72'],Reciprocal Upper Semicontinuity and Better Reply Secure Games: A Comment,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"In this paper a bootstrap algorithm for a reduced rank vector autoregressive model with a restricted linear trend and independent, identically distributed errors is analyzed. For testing the cointegration rank, the asymptotic distribution under the hypothesis is the same as for the usual likelihood ratio test, so that the bootstrap is consistent. It is furthermore shown that a bootstrap procedure for determining the rank is asymptotically consistent in the sense that the probability of choosing the rank smaller than the true one converges to zero.","['Swensen, Anders Rygh']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Bootstrap Algorithms for Testing and Determining the Cointegration Rank in VAR Models,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"In 1971, President Nixon declared war on cancer. Thirty years later, many declared this war a failure: the age-adjusted mortality rate from cancer in 2000 was essentially the same as in the early 1970s. Meanwhile the age-adjusted mortality rate from cardiovascular disease fell dramatically. Since the causes that underlie cancer and cardiovascular disease are likely dependent, the decline in mortality rates from cardiovascular disease may partially explain the lack of progress in cancer mortality. Because competing risks models (used to model mortality from multiple causes) are fundamentally unidentified, it is difficult to estimate cancer trends. We derive bounds for aspects of the underlying distributions without assuming that the underlying risks are independent. We then estimate changes in cancer and cardiovascular mortality since 1970. The bounds for the change in duration until death for either cause are fairly tight and suggest much larger improvements in cancer than previously estimated.","['Honore, Bo E.', 'Lleras-Muney, Adriana']","['Health Behavior', 'Health: Government Policy; Regulation; Public Health']","['I12', 'I18']",Bounds in Competing Risks Models and the War on Cancer,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"Temporary price reductions (sales) are common for many goods and naturally result in large increases in the quantity sold. Demand estimation based on temporary price reductions may mismeasure the long-run responsiveness to prices. In this paper we quantify the extent of the problem and assess its economic implications. We structurally estimate a dynamic model of consumer choice using two years of scanner data on the purchasing behavior of a panel of households. The results suggest that static demand estimates, which neglect dynamics, (i) overestimate own-price elasticities by 30 percent, (ii) underestimate cross-price elasticities by up to a factor of 5, and (iii) overestimate the substitution to the no-purchase or outside option by over 200 percent. This suggests that policy analysis based on static elasticity estimates will underestimate price-cost margins and underpredict the effects of mergers.","['Nevo, Aviv', 'Hendel, Igal']","['Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis', 'Advertising']","['D11', 'D12', 'M37']",Measuring the Implications of Sales and Consumer Inventory Behavior,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"We study a repeated game with asymmetric information about a dynamic state of nature. In the course of the game, the better-informed player can communicate some or all of his information to the other. Our model covers costly and/or bounded communication. We characterize the set of equilibrium payoffs and contrast these with the communication equilibrium payoffs, which by definition entail no communication costs.","['Gossner, Olivier', 'Neyman, Abraham', 'Hernandez, Penelope']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'D82']",Optimal Use of Communication Resources,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"We examine experimentally the impact of communication on trust and cooperation. Our design admits observation of promises, lies, and beliefs. The evidence is consistent with people striving to live up to others' expectations so as to avoid guilt, as can be modeled using psychological game theory. When players exhibit such guilt aversion, communication may influence motivation and behavior by influencing beliefs about beliefs. Promises may enhance trustworthy behavior, which is what we observe. We argue that guilt aversion may be relevant for understanding strategic interaction in a variety of settings, and that it may shed light on the role of language, discussions, agreements, and social norms in these contexts.","['Dufwenberg, Martin', 'Charness, Gary']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D83', 'Z13']",Promises and Partnership,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"We propose a framework for out-of-sample predictive ability testing and forecast selection designed for use in the realistic situation in which the forecasting model is possibly misspecified, due to unmodeled dynamics, unmodeled heterogeneity, incorrect functional form, or any combination of these. Relative to the existing literature (Diebold and Mariano (1995) and West (1996)), we introduce two main innovations: (i) we derive our tests in an environment where the finite sample properties of the estimators on which the forecasts may depend are preserved asymptotically. (ii) We accommodate conditional evaluation objectives (can we predict which forecast will be more accurate at a future date?), which nest unconditional objectives (which forecast was more accurate on average?), that have been the sole focus of previous literature. As a result of (i), our tests have several advantages: they capture the effect of estimation uncertainty on relative forecast performance, they can handle forecasts based on both nested and nonnested models, they allow the forecasts to be produced by general estimation methods, and they are easy to compute. Although both unconditional and conditional approaches are informative, conditioning can help fine-tune the forecast selection to current economic conditions. To this end, we propose a two-step decision rule that uses current information to select the best forecast for the future date of interest. We illustrate the usefulness of our approach by comparing forecasts from leading parameter-reduction methods for macroeconomic forecasting using a large number of predictors.","['Giacomini, Raffaella', 'White, Halbert']","['Forecasting Models; Simulation Methods', 'General Aggregative Models: Forecasting and Simulation: Models and Applications']","['C53', 'E17']",Tests of Conditional Predictive Ability,0,0,0,0,0,2006,11,01
74,6,2006-11-01,"We prove the folk theorem for discounted repeated games under private, almost-perfect monitoring. Our result covers all finite, n-player games that satisfy the usual full-dimensionality condition. Mixed strategies are allowed in determining the individually rational payoffs. We assume no cheap-talk communication between players and no public randomization device.","['Olszewski, Wojciech', 'Horner, Johannes']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],The Folk Theorem for Games with Private Almost-Perfect Monitoring,0,0,0,0,0,2006,11,01
74,6,2006-11-01,ECONLIT None Found,"['Maccheroni, Fabio', 'Rustichini, Aldo', 'Marinacci, Massimo']","['Microeconomic Behavior: Underlying Principles', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D01', 'D81', 'D83']","Ambiguity Aversion, Robustness, and the Variational Representation of Preferences",0,0,0,0,0,2006,11,01
74,5,2006-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"This note revisits the identification theorems of Brown (1983) and Roehrig (1988). We describe an error in the proofs of the main identification theorems in these papers, and provide an important counterexample to the theorems on the identification of the reduced form. Specifically, the reduced form of a nonseparable simultaneous equations model is not identified even under the assumptions of these papers. We provide conditions under which the reduced form is identified and is recoverable using the distribution of the endogenous variables conditional on the exogenous variables. However, these conditions place substantial limitations on the structural model. We conclude the note with a conjecture that it may be possible to use classical exclusion restrictions to recover some of the key implications of the theorems in more general settings.","['Berry, Steven', 'Benkard, C. Lanier']","['Econometric and Statistical Methods and Methodology: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C10', 'C30']",On the Nonparametric Identification of Nonlinear Simultaneous Equations Models: Comment on Brown (1983) and Roehrig (1988),0,0,0,0,0,2006,09,01
74,5,2006-09-01,"The ethic of priority is a compromise between the extremely compensatory ethic of outcome equality and the needs-blind ethic of resource equality. We propose an axiom of priority and characterize resource-allocation rules that are impartial, prioritarian, and solidaristic. They comprise a class of rules that equalize across individuals some index of outcome and resources. Consequently, we provide an ethical rationalization for the many applications in which such indices have been used (e.g., the human development index, the index of primary goods, etc.).","['Roemer, John E.', 'Moreno-Ternero, Juan D.']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],"Impartiality, Priority, and Solidarity in the Theory of Justice",0,0,0,0,0,2006,09,01
74,5,2006-09-01,"Finite population noncooperative games with linear-quadratic utilities, where each player decides how much action she exerts, can be interpreted as a network game with local payoff complementarities, together with a globally uniform payoff substitutability component and an own-concavity effect. For these games, the Nash equilibrium action of each player is proportional to her Bonacich centrality in the network of local complementarities, thus establishing a bridge with the sociology literature on social networks. This Bonacich-Nash linkage implies that aggregate equilibrium increases with network size and density. We then analyze a policy that consists of targeting the key player, that is, the player who, once removed, leads to the optimal change in aggregate activity. We provide a geometric characterization of the key player identified with an intercentrality measure, which takes into account both a player's centrality and her contribution to the centrality of the others.","['Calvo-Armengol, Antoni', 'Ballester, Coralio', 'Zenou, Yves']",['Network Formation and Analysis: Theory'],['D85'],Who's Who in Networks: Wanted: The Key Player,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"This paper examines an exchange economy with heterogeneous indivisible objects that can be substitutable or complementary. We show that a competitive equilibrium exists in such economies, provided that all the objects can be partitioned into two groups, and from the viewpoint of each agent, objects in the same group are substitutes and objects across the two groups are complements. This condition generalizes the well-known Kelso-Crawford gross substitutes condition and is called gross substitutes and complements. We also provide practical and typical examples from which substitutes and complements are both jointly observed.","['Sun, Ning', 'Yang, Zaifu']",['Exchange and Production Economies'],['D51'],Equilibria and Indivisibilities: Gross Substitutes and Complements,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"Recent discoveries in behavioral economics have led scholars to question the underpinnings of neoclassical economics. We use insights gained from one of the most influential lines of behavioral research--gift exchange--in an attempt to maximize worker effort in two quite distinct tasks: data entry for a university library and door-to-door fundraising for a research center. In support of the received literature, our field evidence suggests that worker effort in the first few hours on the job is considerably higher in the ""gift"" treatment than in the ""nongift"" treatment. After the initial few hours, however, no difference in outcomes is observed, and overall the gift treatment yielded inferior aggregate outcomes for the employer: with the same budget we would have logged more data for our library and raised more money for our research center by using the market-clearing wage rather than by trying to induce greater effort with a gift of higher wages.","['List, John A.', 'Gneezy, Uri']",['Altruism; Philanthropy; Intergenerational Transfers'],['D64'],Putting Behavioral Economics to Work: Testing for Gift Exchange in Labor Markets Using Field Experiments,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"A seller and a buyer bargain over the terms of trade for an object. The seller receives a perfect signal that determines the value of the object to both players, whereas the buyer remains uninformed. We analyze the infinite-horizon bargaining game in which the buyer makes all the offers. When the static incentive constraints permit first-best efficiency, then under some regularity conditions the outcome of the sequential bargaining game becomes arbitrarily efficient as bargaining frictions vanish. When the static incentive constraints preclude first-best efficiency, the limiting bargaining outcome is not second-best efficient and may even perform worse than the outcome from the one-period bargaining game. With frequent buyer offers, the outcome is then characterized by recurring bursts of high probability of agreement, followed by long periods of delay in which the probability of agreement is negligible.","['Liang, Meng-Yu', 'Deneckere, Raymond']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining with Interdependent Values,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"We introduce and solve a new class of ""downward-recursive"" static portfolio choice problems. An individual simultaneously chooses among ranked stochastic options, and each choice is costly. In the motivational application, just one may be exercised from those that succeed. This often emerges in practice, such as when a student applies to many colleges or when a firm simultaneously tries several technologies. We show that such portfolio choice problems quite generally entail maximizing a submodular function of finite sets--which is NP-hard in general. Still, we show that a greedy algorithm finds the optimal set, finding first the best singleton, then the best single addition to it, and so on. We show that the optimal choices are ""less aggressive"" than the sequentially optimal ones, but ""more aggressive"" than the best singletons. Also, the optimal set in general contains gaps. We provide some comparative statics results on the chosen set.","['Smith, Lones', 'Chade, Hector']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Portfolio Choice; Investment Decisions']","['D83', 'G11']",Simultaneous Search,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"Comparisons of learning models in repeated games have been a central preoccupation of experimental and behavioral economics over the last decade. Much of this work begins with pooled estimation of the model(s) under scrutiny. I show that in the presence of parameter heterogeneity, pooled estimation can produce a severe bias that tends to unduly favor reinforcement learning relative to belief learning. This occurs when comparisons are based on goodness of fit and when comparisons are based on the relative importance of the two kinds of learning in hybrid structural models. Even misspecified random parameter estimators can greatly reduce the bias relative to pooled estimation.","['Wilcox, Nathaniel T.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Theories of Learning in Games and Heterogeneity Bias,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"A step toward a strategic foundation for rational expectations equilibrium is taken by considering a double auction with n buyers and m sellers with interdependent values and affiliated private information. If there are sufficiently many buyers and sellers, and their bids are restricted to a sufficiently fine discrete set of prices, then, generically, there is an equilibrium in nondecreasing bidding functions that is arbitrarily close to the unique fully revealing rational expectations equilibrium of the limit market with unrestricted bids and a continuum of agents. In particular, the large double-auction equilibrium is almost efficient and almost fully aggregates the agents' information.","['Reny, Philip J.', 'Perry, Motty']","['Auctions', 'Expectations; Speculations', 'General Aggregative Models: Neoclassical']","['D44', 'D84', 'E13']",Toward a Strategic Foundation for Rational Expectations Equilibrium,0,0,1,0,0,2006,09,01
74,5,2006-09-01,"School choice has become an increasingly prominent strategy for enhancing academic achievement. To evaluate the impact on participants, we exploit randomized lotteries that determine high school admission in the Chicago Public Schools. Compared to those students who lose lotteries, students who win attend high schools that are better in a number of dimensions, including peer achievement and attainment levels. Nonetheless, we find little evidence that winning a lottery provides any systematic benefit across a wide variety of traditional academic measures. Lottery winners do, however, experience improvements on a subset of nontraditional outcome measures, such as self-reported disciplinary incidents and arrest rates.","['Jacob, Brian A.', 'Cullen, Julie Berry', 'Levitt, Steven']",['Analysis of Education'],['I21'],The Effect of School Choice on Participants: Evidence from Randomized Lotteries,0,0,0,0,0,2006,09,01
74,5,2006-09-01,"We examine legislative policy making in institutions with two empirically relevant features: agenda setting occurs in real time and the default policy evolves. We demonstrate that these institutions select Condorcet winners when they exist, provided a sufficient number of individuals have opportunities to make proposals. In policy spaces with either pork barrel or pure redistributional politics (where a Condorcet winner does not exist), the last proposer is effectively a dictator or near-dictator under relatively weak conditions.","['Rayo, Luis', 'Bernheim, B. Douglas', 'Rangel, Antonio']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']",['D72'],The Power of the Last Word in Legislative Policy Making,0,0,0,0,0,2006,09,01
74,4,2006-07-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2006,07,01
74,4,2006-07-01,"We consider the situation when there is a large number of series, N, each with T observations, and each series has some predictive ability for some variable of interest. A methodology of growing interest is first to estimate common factors from the panel of data by the method of principal components and then to augment an otherwise standard regression with the estimated factors. In this paper, we show that the least squares estimates obtained from these factor-augmented regressions are square-root-of-T consistent and asymptotically normal if square-root-of-T/N -> 0. The conditional mean predicted by the estimated factors is min [square-root-of-T, square-root-of-N] consistent and asymptotically normal. Except when T/N goes to zero, inference should take into account the effect of ""estimated regressors"" on the estimated conditional mean. We present analytical formulas for prediction intervals that are valid regardless of the magnitude of N/T and that can also be used when the factors are nonstationary.","['Bai, Jushan', 'Ng, Serena']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Forecasting Models; Simulation Methods']","['C22', 'C23', 'C53']",Confidence Intervals for Diffusion Index Forecasts and Inference for Factor-Augmented Regressions,0,0,0,0,0,2006,07,01
74,4,2006-07-01,"We characterize dominant-strategy incentive compatibility with multidimensional types. A deterministic social choice function is dominant-strategy incentive compatible if and only if it is weakly monotone (W-Mon). The W-Mon requirement is the following: If changing one agent's type (while keeping the types of other agents fixed) changes the outcome under the social choice function, then the resulting difference in utilities of the new and original outcomes evaluated at the new type of this agent must be no less than this difference in utilities evaluated at the original type of this agent.","['Sen, Arunava', 'Lavi, Ron', 'Chatterji, Shurojit', 'Bikhchandani, Sushil', ""Mu'alem, Ahuva"", 'Nisan, Noam']","['Auctions', 'Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D71', 'D82']",Weak Monotonicity Characterizes Deterministic Dominant-Strategy Implementation,0,0,1,0,0,2006,07,01
74,4,2006-07-01,"A contract with multiple agents may be susceptible to collusion. We show that agents' collusion imposes no cost in a large class of circumstances with risk neutral agents, including both uncorrelated and correlated types. In those circumstances, any payoff the principal can attain in the absence of collusion, including the second-best level, can be attained in the presence of collusion in a way robust to many aspects of collusion behavior. The collusion-proof implementation generalizes to a setting in which only a subset of agents may collude, provided that noncollusive agents' incentives can be protected via an ex post incentive compatible and ex post individually rational mechanism. Our collusion-proof implementation also sheds light on the extent to which hierarchical delegation of contracts can optimally respond to collusion.","['Kim, Jinwoo', 'Che, Yeon-Koo']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Robustly Collusion-Proof Implementation,0,0,0,0,0,2006,07,01
74,4,2006-07-01,"Building upon a continuous-time model of search with Nash bargaining in a stationary environment, we analyze the effect of changes in minimum wages on labor market outcomes and welfare.","['Flinn, Christopher J.']","['Wage Level and Structure; Wage Differentials', 'Wages, Compensation, and Labor Costs: Public Policy', 'Labor Contracts']","['J31', 'J38', 'J41']","Minimum Wage Effects on Labor Market Outcomes under Search, Matching, and Endogenous Contact Rates",0,0,0,0,0,2006,07,01
74,4,2006-07-01,"This paper presents a new approach to estimation and inference in panel data models with a general multifactor error structure. The unobserved factors and the individual-specific errors are allowed to follow arbitrary stationary processes, and the number of unobserved factors need not be estimated. The basic idea is to filter the individual-specific regressors by means of cross-section averages such that asymptotically as the cross-section dimension (N) tends to infinity, the differential effects of unobserved common factors are eliminated. The estimation procedure has the advantage that it can be computed by least squares applied to auxiliary regressions where the observed regressors are augmented with cross-sectional averages of the dependent variable and the individual-specific regressors. A number of estimators (referred to as common correlated effects (CCE) estimators) are proposed and their asymptotic distributions are derived. The small sample properties of mean group and pooled CCE estimators are investigated by Monte Carlo experiments, showing that the CCE estimators have satisfactory small sample properties even under a substantial degree of heterogeneity and dynamics, and for relatively small values of N and T.","['Pesaran, M. Hashem']",['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models'],['C33'],Estimation and Inference in Large Heterogeneous Panels with a Multifactor Error Structure,0,0,0,0,0,2006,07,01
74,4,2006-07-01,"This paper provides an analysis of the asymptotic properties of Pareto optimal consumption allocations in a stochastic general equilibrium model with heterogeneous consumers. In particular, we investigate the market selection hypothesis that markets favor traders with more accurate beliefs. We show that in any Pareto-optimal allocation whether each consumer vanishes or survives is determined entirely by discount factors and beliefs. Whereas equilibrium allocations in economies with complete markets are Pareto optimal, our results characterize the limit behavior of these economies. We show that, all else equal, the market selects for consumers who use Bayesian learning with the truth in the support of their prior and selects among Bayesians according to the size of their parameter space. Finally, we show that in economies with incomplete markets, these conclusions may not hold. With incomplete markets, payoff functions can matter for long-run survival, and the market selection hypothesis fails.","['Easley, David', 'Blume, Lawrence']","['Exchange and Production Economies', 'Incomplete Markets', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations']","['D51', 'D52', 'D83', 'D84']","If You're So Smart, Why Aren't You Rich? Belief Selection in Complete and Incomplete Markets",0,0,0,0,0,2006,07,01
74,4,2006-07-01,"We present an equilibrium model of the market for higher education. Our model simultaneously predicts student selection into institutions of higher education, financial aid, educational expenditures, and educational outcomes. We show that the model gives rise to a strict hierarchy of colleges that differ by the educational quality provided to the students. We also develop a new estimation procedure that exploits the observed variation in prices within colleges. Identification is based on variation in endowments and technology. It does not rely on observed variation in potentially endogenous characteristics of colleges such as peer quality measures and expenditures. We estimate the structural parameters using data collected by the National Center for Education Statistics and aggregate data from Peterson's and the National Science Foundation.","['Epple, Dennis', 'Sieg, Holger', 'Romano, Richard']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Education and Research Institutions: General', 'Higher Education; Research Institutions']","['D43', 'I20', 'I23']","Admission, Tuition, and Financial Aid Policies in the Market for Higher Education",0,0,1,0,0,2006,07,01
74,4,2006-07-01,What on earth are economic theorists like me trying to accomplish? This paper discusses four dilemmas encountered by an economic theorist: the dilemma of absurd conclusions: should we abandon a model if it produces absurd conclusions or should we regard a model as a very limited set of assumptions that will inevitably fail in some contexts? The dilemma of responding to evidence: should our models be judged according to experimental results? The dilemma of modelless regularities: should models provide the hypothesis for testing or are they simply exercises in logic that have no use in identifying regularities? The dilemma of relevance: do we have the right to offer advice or to make statements that are intended to influence the real world?,"['Rubinstein, Ariel']","['Role of Economics; Role of Economists; Market for Economists', 'Microeconomics: General']","['A11', 'D00']",Dilemmas of an Economic Theorist,0,0,0,0,0,2006,07,01
74,3,2006-05-01,ECONLIT None Found,[nan],[nan],[nan],2005 ELECTION OF FELLOWS TO THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2006,05,01
74,3,2006-05-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"In this paper, we introduce a kernel-based estimation principle for nonparametric models named local partitioned regression (LPR). This principle is a nonparametric generalization of the familiar partition regression in linear models. It has several key advantages: First, it generates estimators for a very large class of semi- and nonparametric models. A number of examples that are particularly relevant for economic applications will be discussed in this paper. This class contains the additive, partially linear, and varying coefficient models as well as several other models that have not been discussed in the literature. Second, LPR-based estimators achieve optimality criteria: They have optimal speed of convergence and are oracle-efficient. Moreover, they are simple in structure, widely applicable, and computationally inexpensive. A Monte Carlo simulation highlights these advantages.","['Christopeit, Norbert', 'Hoderlein, Stefan G. N.']",['Semiparametric and Nonparametric Methods: General'],['C14'],Local Partitioned Regression,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"Building on the Ramsey-de Finetti idea of event exchangeability, we derive a characterization of probabilistic sophistication without requiring any of the various versions of monotonicity, continuity, or comparative likelihood assumptions imposed by Savage (1954), Machina and Schmeidler (1992), and Grant (1995). Our characterization identifies a unique and finitely-additive subjective probability measure over an algebra of events.","['Sagi, Jacob S.', 'Hong, Chew Soo']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Event Exchangeability: Probabilistic Sophistication without Continuity or Monotonicity,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"This paper considers tests of the parameter on an endogenous variable in an instrumental variables regression model. The focus is on determining tests that have some optimal power properties. We start by considering a model with normally distributed errors and known error covariance matrix. We consider tests that are similar and satisfy a natural rotational invariance condition. We determine a two-sided power envelope for invariant similar tests. This allows us to assess and compare the power properties of tests such as the conditional likelihood ratio (CLR), the Lagrange multiplier, and the Anderson-Rubin tests. We find that the CLR test is quite close to being uniformly most powerful invariant among a class of two-sided tests. The finite-sample results of the paper are extended to the case of unknown error covariance matrix and possibly nonnormal errors via weak instrument asymptotics. Strong instrument asymptotic results also are provided because we seek tests that perform well under both weak and strong instruments.","['Troger, Thomas', 'Garratt, Rod']",['Auctions'],['D44'],Speculation in Standard Auctions with Resale,0,0,1,0,0,2006,05,01
74,3,2006-05-01,"This paper considers tests of the parameter on an endogenous variable in an instrumental variables regression model. The focus is on determining tests that have some optimal power properties. We start by considering a model with normally distributed errors and known error covariance matrix. We consider tests that are similar and satisfy a natural rotational invariance condition. We determine a two-sided power envelope for invariant similar tests. This allows us to assess and compare the power properties of tests such as the conditional likelihood ratio (CLR), the Lagrange multiplier, and the Anderson-Rubin tests. We find that the CLR test is quite close to being uniformly most powerful invariant among a class of two-sided tests. The finite-sample results of the paper are extended to the case of unknown error covariance matrix and possibly nonnormal errors via weak instrument asymptotics. Strong instrument asymptotic results also are provided because we seek tests that perform well under both weak and strong instruments.","['Stock, James H.', 'Moreira, Marcelo J.', 'Andrews, Donald W. K.']",['Hypothesis Testing: General'],['C12'],Optimal Two-Sided Invariant Similar Tests for Instrumental Variables Regression,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"This paper considers the problem of conducting inference on the regression coefficient in a bivariate regression model with a highly persistent regressor. Gaussian asymptotic power envelopes are obtained for a class of testing procedures that satisfy a conditionality restriction. In addition, the paper proposes testing procedures that attain these power envelopes whether or not the innovations of the regression model are normally distributed.","['Moreira, Marcelo J.', 'Jansson, Michael']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Optimal Inference in Regression Models with Nearly Integrated Regressors,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"In this paper, I analyze a decentralized search and matching economy with transferable utility composed of heterogeneous agents.","['Atakan, Alp E.']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Assortative Matching with Explicit Search Costs,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"This paper studies the problem of identification and estimation in nonparametric regression models with a misclassified binary regressor where the measurement error may be correlated with the regressors. We show that the regression function is nonparametrically identified in the presence of an additional random variable that is correlated with the unobserved true underlying variable but unrelated to the measurement error. Identification for semiparametric and parametric regression functions follows straightforwardly from the basic identification result. We propose a kernel estimator based on the identification strategy, derive its large sample properties, and discuss alternative estimation procedures. We also propose a test for misclassification in the model based on an exclusion restriction that is straightforward to implement.","['Mahajan, Aprajit']",['Semiparametric and Nonparametric Methods: General'],['C14'],Identification and Estimation of Regression Models with Misclassification,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"Identification of dynamic nonlinear panel data models is an important and delicate problem in econometrics. In this paper we provide insights that shed light on the identification of parameters of some commonly used models. Using these insights, we are able to show through simple calculations that point identification often fails in these models. On the other hand, these calculations also suggest that the model restricts the parameter to lie in a region that is very small in many cases, and the failure of point identification may, therefore, be of little practical importance in those cases. Although the emphasis is on identification, our techniques are constructive in that they can easily form the basis for consistent estimates of the identified sets.","['Tamer, Elie', 'Honore, By Bo E.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",Bounds on Parameters in Panel Dynamic Discrete Choice Models,0,0,0,0,0,2006,05,01
74,3,2006-05-01,"The sensitivity of Bayesian implementation to agents' beliefs about others suggests the use of more robust notions of implementation such as ex post implementation, which requires that each agent's strategy be optimal for every possible realization of the types of other agents. We show that the only deterministic social choice functions that are ex post implementable in generic mechanism design frameworks with multidimensional signals, interdependent valuations, and transferable utilities are constant functions. In other words, deterministic ex post implementation requires that the same alternative must be chosen irrespective of agents' signals. The proof shows that ex post implementability of a nontrivial deterministic social choice function implies that certain rates of information substitution coincide for all agents. This condition amounts to a system of differential equations that are not satisfied by generic valuation functions.","['Meyer-ter-Vehn, Moritz', 'Zame, William R.', 'Moldovanu, Benny', 'Jehiel, Philippe']","['Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D71', 'D82']",The Limits of ex post Implementation,0,0,0,0,0,2006,05,01
74,2,2006-03-01,"A key argument in Caplin and Leahy (1997) states that the correlation between monetary shocks and output is falling in the variance of the money supply. We demonstrate that this conclusion depends on solving for the correlation in the nonstationary state of the model. In the stationary state, that correlation is initially rising.","['Damjanovic, Vladislav', 'Nolan, Charles']","['Price Level; Inflation; Deflation', 'Business Fluctuations; Cycles']","['E31', 'E32']",Aggregation and Optimization with State-Dependent Pricing: A Comment,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"Quantile regression (QR) fits a linear model for conditional quantiles just as ordinary least squares (OLS) fits a linear model for conditional means. An attractive feature of OLS is that it gives the minimum mean-squared error linear approximation to the conditional expectation function even when the linear model is misspecified. Empirical research using quantile regression with discrete covariates suggests that QR may have a similar property, but the exact nature of the linear approximation has remained elusive. In this paper, we show that QR minimizes a weighted mean-squared error loss function for specification error. The weighting function is an average density of the dependent variable near the true conditional quantile. The weighted least squares interpretation of QR is used to derive an omitted variables bias formula and a partial quantile regression concept, similar to the relationship between partial regression and OLS. We also present asymptotic theory for the QR process under misspecification of the conditional quantile function. The approximation properties of QR are illustrated using wage data from the U.S. census. These results point to major changes in inequality from 1990 to 2000.","['Chernozhukov, Victor', 'Angrist, Joshua', 'Fernandez-Val, Ivan']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Wage Level and Structure; Wage Differentials']","['C21', 'J31']","Quantile Regression under Misspecification, with an Application to the U.S. Wage Structure",0,0,0,0,0,2006,03,01
74,2,2006-03-01,"This paper is concerned with inference about a function g that is identified by a conditional moment restriction involving instrumental variables. The paper presents a test of the hypothesis that g belongs to a finite-dimensional parametric family against a nonparametric alternative. The test does not require nonparametric estimation of g and is not subject to the ill-posed inverse problem of nonparametric instrumental variables estimation. Under mild conditions, the test is consistent against any alternative model. In large samples, its power is arbitrarily close to 1 uniformly over a class of alternatives whose distance from the null hypothesis is O (n[superscript -1/2]), where n is the sample size. In Monte Carlo simulations, the finite-sample power of the new test exceeds that of existing tests.","['Horowitz, Joel L.']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Testing a Parametric Model against a Nonparametric Alternative with Identification through Instrumental Variables,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"Most theoretical or applied research on repeated games with imperfect monitoring has focused on public strategies: strategies that depend solely on the history of publicly observable signals. This paper sheds light on the role of private strategies: strategies that depend not only on public signals, but also on players' own actions in the past. Our main finding is that players can sometimes make better use of information by using private strategies and that efficiency in repeated games can be improved. Our equilibrium private strategy for repeated prisoners' dilemma games consists of two states and has the property that each player's optimal strategy is independent of the other player's state.","['Kandori, Michihiro', 'Obara, Ichiro']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Efficiency in Repeated Games Revisited: The Role of Private Strategies,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"This paper develops a generalization of the widely used difference-in-differences method for evaluating the effects of policy changes. We propose a model that allows the control and treatment groups to have different average benefits from the treatment. The assumptions of the proposed model are invariant to the scaling of the outcome. We provide conditions under which the model is nonparametrically identified and propose an estimator that can be applied using either repeated cross section or panel data. Our approach provides an estimate of the entire counterfactual distribution of outcomes that would have been experienced by the treatment group in the absence of the treatment and likewise for the untreated group in the presence of the treatment. Thus, it enables the evaluation of policy interventions according to criteria such as a mean-variance trade-off. We also propose methods for inference, showing that our estimator for the average treatment effect is root-N consistent and asymptotically normal. We consider extensions to allow for covariates, discrete dependent variables, and multiple groups and time periods.","['Athey, Susan', 'Imbens, Guido W.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C21', 'C23']",Identification and Inference in Nonlinear Difference-in-Differences Models,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"The Lemke-Howson algorithm is the classical method for finding one Nash equilibrium of a bimatrix game. This paper presents a class of square bimatrix games for which this algorithm takes, even in the best case, an exponential number of steps in the dimension d of the game. Using polytope theory, the games are constructed using pairs of dual cyclic polytopes with 2d suitably labeled facets in d-space. The construction is extended to nonsquare games where, in addition to exponentially long Lemke-Howson computations, finding an equilibrium by support enumeration takes on average exponential time.","['von Stengel, Bernhard', 'Savani, Rahul']","['Computational Techniques; Simulation Modeling', 'Noncooperative Games']","['C63', 'C72']",Hard-to-Solve Bimatrix Games,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"We study the optimal trade-off between commitment and flexibility in a consumption-savings model. Individuals expect to receive relevant information regarding tastes and thus they value the flexibility provided by larger choice sets. On the other hand, they also expect to suffer from temptation, with or without self-control, and thus they value the commitment afforded by smaller choice sets. The optimal commitment problem we study is to find the best subset of the individual's budget set. This problem leads to a principal-agent formulation. We find that imposing a minimum level of savings is always a feature of the solution. Necessary and sufficient conditions are derived for minimum-savings policies to completely characterize the solution. We also discuss other applications, such as the design of fiscal constitutions, the problem faced by a paternalist, and externalities.","['Angeletos, George-Marios', 'Werning, Ivan', 'Amador, Manuel']","['Asymmetric and Private Information; Mechanism Design', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D82', 'D15']",Commitment vs. Flexibility,0,0,0,0,0,2006,03,01
74,2,2006-03-01,"Most applications of Nash bargaining over wages ignore between-employer competition for labor services and attribute all of the workers' rent to their bargaining power. In this paper, we write and estimate an equilibrium model with strategic wage bargaining and on-the-job search and use it to take another look at the determinants of wages in France. There are three essential determinants of wages in our model: productivity, competition between employers resulting from on-the-job search, and the workers' bargaining power. We find that between-firm competition matters a lot in the determination of wages, because it is quantitatively more important than wage bargaining a la Nash in raising wages above the workers' ""reservation wages,"" defined as out-of-work income. In particular, we detect no significant bargaining power for intermediate- and low-skilled workers, and a modestly positive bargaining power for high-skilled workers.","['Postel-Vinay, Fabien', 'Cahuc, Pierre', 'Robin, Jean-Marc']","['Wage Level and Structure; Wage Differentials', 'Labor Contracts']","['J31', 'J41']",Wage Bargaining with On-the-Job Search: Theory and Evidence,0,0,0,0,0,2006,03,01
74,1,2006-01-01,ECONLIT None Found,[nan],[nan],[nan],2006 NORTH AMERICAN WINTER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2006,01,01
74,1,2006-01-01,ECONLIT None Found,"['Dekel, Eddie', 'Postlewaite, Andrew', 'Meghir, Costas', 'Levine, David', 'Newey, Whitney']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Editors 2004-2005,0,0,0,0,0,2006,01,01
74,1,2006-01-01,ECONLIT None Found,"['Gordon, Robert J.']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Treasurer,0,0,0,0,0,2006,01,01
74,1,2006-01-01,ECONLIT None Found,"['Gordon, Robert J.', 'Gordon, Julie P.']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: Report of the Secretary,0,0,0,0,0,2006,01,01
74,1,2006-01-01,ECONLIT None Found,"['Kollmann, Robert']","['Open Economy Macroeconomics', 'Portfolio Choice; Investment Decisions', 'International Financial Markets']","['F41', 'G11', 'G15']",A Dynamic Equilibrium Model of International Portfolio Holdings: Comment,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"Matching estimators for average treatment effects are widely used in evaluation research despite the fact that their large sample properties have not been established in many cases. The absence of formal results in this area may be partly due to the fact that standard asymptotic expansions do not apply to matching estimators with a fixed number of matches because such estimators are highly nonsmooth functionals of the data. In this article we develop new methods for analyzing the large sample properties of matching estimators and establish a number of new results. We focus on matching with replacement with a fixed number of matches. First, we show that matching estimators are not N[superscript 1/2]-consistent in general and describe conditions under which matching estimators do attain N[superscript 1/2]-consistency. Second, we show that even in settings where matching estimators are N[superscript 1/2]-consistent, simple matching estimators with a fixed number of matches do not attain the semiparametric efficiency bound. Third, we provide a consistent estimator for the large sample variance that does not require consistent nonparametric estimation of unknown functions. Software for implementing these methods is available in Matlab, Stata, and R.","['Abadie, Alberto', 'Imbens, Guido W.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Large Sample Properties of Matching Estimators for Average Treatment Effects,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"A number of studies, most notably Cremer and McLean (1985, 1988), have shown that in generic type spaces that admit a common prior and are of a fixed finite size, an uninformed seller can design mechanisms that extract all the surplus from privately informed bidders. We show that this result hinges on the nonconvexity of such a family of priors. When the ambient family of priors is convex, generic priors do not allow for full surplus extraction provided that for at least one prior in this family, players' beliefs about other players' types do not pin down the players' own preferences. In particular, full surplus extraction is generically impossible in finite type spaces with a common prior. Similarly, generic priors on the universal type space do not allow for full surplus extraction.","['Neeman, Zvika', 'Heifetz, Aviad']",['Asymmetric and Private Information; Mechanism Design'],['D82'],On the Generic (Im)possibility of Full Surplus Extraction in Mechanism Design,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"This paper demonstrates how time consistency of the Ramsey policy--the optimal fiscal and monetary policy under commitment--can be achieved. Each government should leave its successor with a unique maturity structure for nominal and indexed debt, such that the marginal benefit of a surprise inflation exactly balances the marginal cost. Unlike in earlier papers on the topic, the result holds for quite general Ramsey policies, including time-varying polices with positive inflation and positive nominal interest rates. We compare our results with those in Persson, Persson, and Svensson (1987), Calvo and Obstfeld (1990), and Alvarez, Kehoe, and Neumeyer (2004).","['Svensson, Lars E. O.', 'Persson, Mats', 'Persson, Torsten']","['Monetary Policy', 'Policy Objectives; Policy Designs and Consistency; Policy Coordination', 'Fiscal Policy']","['E52', 'E61', 'E62']",Time Consistency of Fiscal and Monetary Policy: A Solution,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"This paper provides a first order asymptotic theory for generalized method of moments (GMM) estimators when the number of moment conditions is allowed to increase with the sample size and the moment conditions may be weak. Examples in which these asymptotics are relevant include instrumental variable (IV) estimation with many (possibly weak or uninformed) instruments and some panel data models that cover moderate time spans and have correspondingly large numbers of instruments. Under certain regularity conditions, the GMM estimators are shown to converge in probability but not necessarily to the true parameter, and conditions for consistent GMM estimation are given. A general framework for the GMM limit distribution theory is developed based on epiconvergence methods. Some illustrations are provided, including consistent GMM estimation of a panel model with time varying individual effects, consistent limited information maximum likelihood estimation as a continuously updated GMM estimator, and consistent IV structural estimation using large numbers of weak or irrelevant instruments. Some simulations are reported.","['Han, Chirok', 'Phillips, Peter C. B.']","['Estimation: General', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C13', 'C23']",GMM with Many Moment Conditions,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"We develop and analyze a model of random choice and random expected utility. A decision problem is a finite set of lotteries that describe the feasible choices. A random choice rule associates with each decision problem a probability measure over choices. A random utility function is a probability measure over von Neumann-Morgenstern utility functions. We show that a random choice rule maximizes some random utility function if and only if it is mixture continuous, monotone (the probability that a lottery is chosen does not increase when other lotteries are added to the decision problem), extreme (lotteries that are not extreme points of the decision problem are chosen with probability 0), and linear (satisfies the independence axiom).","['Pesendorfer, Wolfgang', 'Gul, Faruk']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",Random Expected Utility,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"This paper studies the econometrics of computed dynamic models. Since these models generally lack a closed-form solution, their policy functions are approximated by numerical methods. Hence, the researcher can only evaluate an approximated likelihood associated with the approximated policy function rather than the exact likelihood implied by the exact policy function. What are the consequences for inference of the use of approximated likelihoods? First, we find conditions under which, as the approximated policy function converges to the exact policy, the approximated likelihood also converges to the exact likelihood. Second, we show that second order approximation errors in the policy function, which almost always are ignored by researchers, have first order effects on the likelihood function. Third, we discuss convergence of Bayesian and classical estimates. Finally, we propose to use a likelihood ratio test as a diagnostic device for problems derived from the use of approximated likelihoods.","['Fernandez-Villaverde, Jesus', 'Santos, Manuel S.', 'Rubio-Ramirez, Juan F.']",['Model Construction and Estimation'],['C51'],Convergence Properties of the Likelihood of Computed Dynamic Models,0,0,0,0,0,2006,01,01
74,1,2006-01-01,"We consider large double auctions with private values. Values need be neither symmetric nor independent. Multiple units may be owned or desired. Participation may be stochastic. We introduce a very mild notion of ""a little independence."" We prove that all nontrivial equilibria of auctions that satisfy this notion are asymptotically efficient. For any alpha > 0, inefficiency disappears at rate 1/n[superscript 2 - alpha].","['Swinkels, Jeroen M.', 'Cripps, Martin W.']",['Auctions'],['D44'],Efficiency of Large Double Auctions,0,0,1,0,0,2006,01,01
74,1,2006-01-01,"One of the most striking changes in the U.S. economy over the past 50 years has been the growth in the service sector. Between 1950 and 2000, service-sector employment grew from 57 to 75 percent of total employment. However, over this time, the real hourly wage in the service sector grew only slightly faster than in the goods sector. In this paper, we assess whether or not the essential constancy of the relative wage implies that individuals face small costs of switching sectors, and we quantify the relative importance of labor supply and demand factors in the growth of the service sector. We specify and estimate a two-sector labor market equilibrium model that allows us to address these empirical issues in a unified framework. Our estimates imply that there are large mobility costs: output in both sectors would have been double their current levels if these mobility costs had been zero. In addition, we find that demand-side factors, that is, technological change and movements in product and capital prices, were responsible for the growth of the service sector.","['Wolpin, Kenneth I.', 'Lee, Donghoon']","['Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Job, Occupational, and Intergenerational Mobility; Promotion', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Industry Studies: Services: General']","['E24', 'J31', 'J62', 'L16', 'L80']",Intersectoral Labor Mobility and the Growth of the Service Sector,1,0,0,0,0,2006,01,01
80,5,2012-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 80 Iss. 5.,0,0,0,0,0,2012,09,01
80,4,2012-07-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 80 Iss. 4.,0,0,0,0,0,2012,07,01
80,3,2012-05-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 80 Iss. 3.,0,0,0,0,0,2012,05,01
80,3,2012-05-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2012,05,01
85,2,2017-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 2.,0,0,0,0,0,2017,03,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 85 Iss. 1.,0,0,0,0,0,2017,01,01
86,5,2018-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,09,01
86,5,2018-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 86 Iss. 5.,0,0,0,0,0,2018,09,01
86,5,2018-09-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 86 Iss. 5.,0,0,0,0,0,2018,09,01
71,5,2003-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"We provide easy to verify sufficient conditions for the consistency and asymptotic normality of a class of semiparametric optimization estimators where the criterion function does not obey standard smoothness conditions and simultaneously depends on some nonparametric estimators that can themselves depend on the parameters to be estimated. Our results extend existing theories such as those of Pakes and Pollard (1989), Andrews (1994a), and Newey (1994). We also show that bootstrap provides asymptotically correct confidence regions for the finite dimensional parameters. We apply our results to two examples: a ""hit rate"" and a partially linear median regression with some endogenous regressors.","['Linton, Oliver', 'Chen, Xiaohong', 'Van Keilegom, Ingrid']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Estimation of Semiparametric Models When the Criterion Function Is Not Smooth,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"This paper presents new identification conditions for the mixed proportional hazard model. In particular, the baseline hazard is assumed to be bounded away from 0 and infinity near t = 0. These conditions ensure that the information matrix is nonsingular. The paper also presents an estimator for the mixed proportional hazard model that converges at rate N[superscript -1/2].","['Woutersen, Tiemen M.', 'Ridder, Geert']","['Duration Analysis; Optimal Timing Strategies', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C41', 'C21']",The Singularity of the Information Matrix of the Mixed Proportional Hazard Model,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"In econometrics there are many occasions where knowledge of the structural relationship among dependent variables is required to answer questions of interest. This paper gives identification and estimation results for nonparametric conditional moment restrictions. We characterize identification of structural functions as completeness of certain conditional distributions, and give sufficient identification conditions for exponential families and discrete variables. We also give a consistent, nonparametric estimator of the structural function. The estimator is nonparametric two-stage least squares based on series approximation, which overcomes an ill-posed inverse problem by placing bounds on integrals of higher-order derivatives.","['Powell, James L.', 'Newey, Whitney K.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Single Equation Models; Single Variables: General']","['C30', 'C20']",Instrumental Variable Estimation of Nonparametric Models,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"It has been known that, in aggregating infinite utility streams, there does not exist any social welfare function, which satisfies the axioms of Pareto, intergenerational equity, and continuity. We show that the impossibility result persists even without imposing the continuity axiom, and in frameworks allowing for more general domains of utilities than those used in the existing literature.","['Basu, Kaushik', 'Mitra, Tapan']",['Social Choice; Clubs; Committees; Associations'],['D71'],Aggregating Infinite Utility Streams with Intergenerational Equity: The Impossibility of Being Paretian,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"We study the problem of the existence and uniqueness of solutions to the Bellman equation in the presence of unbounded returns. We introduce a new approach based both on consideration of a metric on the space of all continuous functions over the state space, and on the application of some metric fixed point theorems. With appropriate conditions we prove uniqueness of solutions with respect to the whole space of continuous functions. Furthermore, the paper provides new sufficient conditions for the existence of solutions that can be applied to fairly general models. It is also proven that the fixed point coincides with the value function and that it can be approached by successive iterations of the Bellman operator.","['Rincon-Zapatero, Juan Pablo', 'Rodriguez-Palmero, Carlos']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],Existence and Uniqueness of Solutions to the Bellman Equation in the Unbounded Case,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"This paper analyzes the specification and identification of causal multivariate duration models. We focus on the case in which one duration concerns the point in time a treatment is initiated and we are interested in the effect of this treatment on some outcome duration. We define ""no anticipation of treatment"" and relate it to a common assumption in biostatistics. We show that (i) no anticipation and (ii) randomized treatment assignment can be imposed without restricting the observational data. We impose (i) but not (ii) and prove identification of models that impose some structure. We allow for dependent unobserved heterogeneity and we do not exploit exclusion restrictions on covariates. We provide results for both single-spell and multiple-spell data. The timing of events conveys useful information on the treatment effect.","['van den Berg, Gerard J.', 'Abbring, Jaap H.']",['Duration Analysis; Optimal Timing Strategies'],['C41'],The Nonparametric Identification of Treatment Effects in Duration Models,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"This paper proposes an estimation method for a repeated auction game under the presence of capacity constraints. The estimation strategy is computationally simple as it does not require solving for the equilibrium of the game. It uses a two stage approach. In the first stage the distribution of bids conditional on state variables is estimated using data on bids, bidder characteristics, and contract characteristics. In the second stage, an expression of the expected sum of future profits based on the distribution of bids is obtained, and costs are inferred based on the first order condition of optimal bids. We apply the estimation method to repeated highway construction procurement auctions in the state of California between May 1996 and May 1999. In this market, previously won uncompleted contracts reduce the probability of winning further contracts. We quantify the effect of intertemporal constraints on bidders' costs and on bids. Due to the intertemporal effect and also to bidder asymmetry, the auction can be inefficient. Based on the estimates of costs, we quantify efficiency losses.","['Pesendorfer, Martin', 'Jofre-Bonet, Mireia']","['Model Construction and Estimation', 'Auctions']","['C51', 'D44']",Estimation of a Dynamic Auction Game,0,0,1,0,0,2003,09,01
71,5,2003-09-01,"Weak nonparametric restrictions are developed, sufficient to identify the values of derivatives of structural functions in which latent random variables are nonseparable. These derivatives can exhibit stochastic variation. In a microeconometric context this allows the impact of a policy intervention, as measured by the value of a structural derivative, to vary across people who are identical as measured by covariates. When the restrictions are satisfied quantiles of the distribution of a policy impact across people can be identified. The identification restrictions are local in the sense that they are specific to the values of the covariates and the specific quantiles of latent variables at which identification is sought. The conditions do not include the commonly required independence of latent variables and covariates. They include local versions of the classical rank and order conditions and local quantile insensitivity conditions. Values of structural derivatives are identified by functionals of quantile regression functions and can be estimated using the same functionals applied to estimated quantile regression functions.","['Chesher, Andrew']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Identification in Nonseparable Models,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"In this study we consider a labor market matching model where firms post wage-tenure contracts and workers, both employed and unemployed, search for new job opportunities. Given workers are risk averse, we establish there is a unique equilibrium in the environment considered. Although firms in the market make different offers in equilibrium, all post a wage-tenure contract that implies a worker's wage increases smoothly with tenure at the firm. As firms make different offers, there is job turnover, as employed workers move jobs as the opportunity arises. This implies the increase in a worker's wage can be due to job-to-job movements as well as wage-tenure effects. Further, there is a nondegenerate equilibrium distribution of initial wage offers that is differentiable on its support except for a mass point at the lowest initial wage. We also show that relevant characteristics of the equilibrium can be written as explicit functions of preferences and the other market parameters.","['Burdett, Ken', 'Coles, Melvyn']","['Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J31', 'J41', 'J64']",Equilibrium Wage-Tenure Contracts,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"We present estimators for nonparametric functions that are nonadditive in unobservable random terms. The distributions of the unobservable random terms are assumed to be unknown. We show that when a nonadditive, nonparametric function is strictly monotone in an unobservable random term, and it satisfies some other properties that may be implied by economic theory, such as homogeneity of degree one or separability, the function and the distribution of the unobservable random term are identified. We also present convenient normalizations, to use when the properties of the function, other than strict monotonicity in the unobservable random term, are unknown. The estimators for the nonparametric function and for the distribution of the unobservable random term are shown to be consistent and asymptotically normal. We extend the results to functions that depend on a multivariate random term. The results of a limited simulation study are presented.","['Matzkin, Rosa L.']","['Single Equation Models; Single Variables: General', 'Estimation: General']","['C20', 'C13']",Nonparametric Estimation of Nonadditive Random Functions,0,0,0,0,0,2003,09,01
71,5,2003-09-01,"In certain auction, search, and related models, the boundary of the support of the observed data depends on some of the parameters of interest. For such nonregular models, standard asymptotic distribution theory does not apply. Previous work has focused on characterizing the nonstandard limiting distributions of particular estimators in these models. In contrast, we study the problem of constructing efficient point estimators. We show that the maximum likelihood estimator is generally inefficient, but that the Bayes estimator is efficient according to the local asymptotic minmax criterion for conventional loss functions. We provide intuition for this result using Le Cam's limits of experiments framework.","['Porter, Jack R.', 'Hirano, Keisuke']","['Estimation: General', 'Single Equation Models; Single Variables: General']","['C13', 'C20']",Asymptotic Efficiency in Parametric Structural Models with Parameter-Dependent Support,0,0,0,0,0,2003,09,01
71,4,2003-07-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"We consider the problem of constructing a portfolio of finitely many assets whose returns are described by a discrete joint distribution. We propose mean-risk models that are solvable by linear programming and generate portfolios whose returns are nondominated in the sense of second-order stochastic dominance. Next, we develop a specialized parametric method for recovering the entire mean-risk efficient frontiers of these models and we illustrate its operation on a large data set involving thousands of assets and realizations.","['Ruszczynski, Andrzej', 'Vanderbei, Robert J.']",['Portfolio Choice; Investment Decisions'],['G11'],Frontiers of Stochastically Nondominated Portfolios,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"The paper analyzes the impact of the initial condition on the problem of testing for unit roots. To this end, we derive a family of optimal tests that maximize a weighted average power criterion with respect to the initial condition. We then investigate the relationship of this optimal family to popular tests. We find that many unit root tests are closely related to specific members of the optimal family, but the corresponding members employ very different weightings for the initial condition. The popular Dickey-Fuller tests, for instance, put a large weight on extreme deviations of the initial observation from the deterministic component, whereas other popular tests put more weight on moderate deviations. Since the power of unit root tests varies dramatically with the initial condition, this paper explains the results of comparative power studies of unit root tests. The results allow a much deeper understanding of the merits of particular tests in specific circumstances, and a guide to choosing which statistics to use in practice.","['Elliott, Graham', 'Muller, Ulrich K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Tests for Unit Roots and the Initial Condition,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"I characterize the implications of the common prior assumption for finite orders of beliefs about beliefs at a state and show that in finite models, the only such implications are those stemming from the weaker assumption of a common support. More precisely, given any finite N and any finite partitions model where priors have the same support, there is another finite partitions model with common priors that has the same nth order beliefs and knowledge for all n <= N.","['Lipman, Barton L.']","['Game Theory and Bargaining Theory: General', 'Information, Knowledge, and Uncertainty: General']","['C70', 'D80']",Finite Order Implications of Common Priors,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"We present a general method for computing the set of supergame equilibria in infinitely repeated games with perfect monitoring and public randomization. We present a three-stage algorithm that constructs a convex set containing the set of equilibrium values, constructs another convex set contained in the set of equilibrium values, and produces strategies that support them. We explore the properties of this algorithm by applying it to familiar games.","['Conklin, James', 'Yeltekin, Sevin', 'Judd, Kenneth L.']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Computing Supergame Equilibria,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"This paper develops new econometric methods to infer hospital quality in a model with discrete dependent variables and nonrandom selection. Mortality rates in patient discharge records are widely used to infer hospital quality. However, hospital admission is not random and some hospitals may attract patients with greater unobserved severity of illness than others. In this situation the assumption of random admission leads to spurious inference about hospital quality. This study controls for hospital selection using a model in which distance between the patient's residence and alternative hospitals are key exogenous variables. Bayesian inference in this model is feasible using a Markov chain Monte Carlo posterior simulator, and attaches posterior probabilities to quality comparisons between individual hospitals and groups of hospitals. The study uses data on 74,848 Medicare patients admitted to 114 hospitals in Los Angeles County from 1989 through 1992 with a diagnosis of pneumonia. It finds the smallest and largest hospitals to be of the highest quality. There is strong evidence of dependence between the unobserved severity of illness and the assignment of patients to hospitals, whereby patients with a high unobserved severity of illness are disproportionately admitted to high quality hospitals. Consequently a conventional probit model leads to inferences about quality that are markedly different from those in this study's selection model.","['Gowrisankaran, Gautam', 'Town, Robert J.', 'Geweke, John']","['Analysis of Health Care Markets', 'Health Behavior']","['I11', 'I12']",Bayesian Inference for Hospital Quality in a Selection Model,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"An isotone pure strategy equilibrium exists in any game of incomplete information in which each player's action set is a finite sublattice of multidimensional Euclidean space, types are multidimensional and atomless, and each player's interim expected payoff function satisfies two ""nonprimitive conditions"" whenever others adopt isotone pure strategies: (i) single-crossing in own action and type and (ii) quasi-supermodularity in own action. Conditions (i), (ii) are satisfied in supermodular and log-supermodular games given affiliated types, and in games with independent types in which each player's ex post payoff satisfies supermodularity in own action and nondecreasing differences in own action and type. This result is applied to provide the first proof of pure strategy equilibrium existence in the uniform price auction when bidders have multi-unit demand, nonprivate values, and independent types.","['McAdams, David']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Auctions']","['C72', 'D83', 'D44']",Isotone Equilibrium in Games of Incomplete Information,0,0,1,0,0,2003,07,01
71,4,2003-07-01,"We are interested in estimating the average effect of a binary treatment on a scalar outcome. If assignment to the treatment is exogenous or unconfounded, that is, independent of the potential outcomes given covariates, biases associated with simple treatment-control average comparisons can be removed by adjusting for differences in the covariates. Rosenbaum and Rubin (1983) show that adjusting solely for differences between treated and control units in the propensity score removes all biases associated with differences in covariates. Although adjusting for differences in the propensity score removes all the bias, this can come at the expense of efficiency, as shown by Hahn (1998), Heckman, Ichimura, and Todd (1998), and Robins, Mark, and Newey (1992). We show that weighting by the inverse of a nonparametric estimate of the propensity score, rather than the true propensity score, leads to an efficient estimate of the average treatment effect. We provide intuition for this result by showing that this estimator can be interpreted as an empirical likelihood estimator that efficiently incorporates the information about the propensity score.","['Ridder, Geert', 'Hirano, Keisuke', 'Imbens, Guido W.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Semiparametric and Nonparametric Methods: General']","['C21', 'C14']",Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"In this paper we derive the asymptotic properties of within groups (WG), GMM, and LIML estimators for an autoregressive model with random effects when both T and N tend to infinity. GMM and LIML are consistent and asymptotically equivalent to the WG estimator. When T/N [right arrow] 0 the fixed T results for GMM and LIML remain valid, but WG, although consistent, has an asymptotic bias in its asymptotic distribution. When T/N tends to a positive constant, the WG, GMM, and LIML estimators exhibit negative asymptotic biases of order 1/T, 1/N, and 1/(2N - T), respectively. In addition, the crude GMM estimator that neglects the autocorrelation in first differenced errors is inconsistent as T/N [right arrow] c > 0, despite being consistent for fixed T. Finally, we discuss the properties of a random effects pseudo MLE with unrestricted initial conditions when both T and N tend to infinity.","['Alvarez, Javier', 'Arellano, Manuel']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C23', 'C22']",The Time Series and Cross-Section Asymptotics of Dynamic Panel Data Estimators,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"In this paper we focus on strategic voting behavior when both an election and a signaling motivation affect voters' behavior. We analyze a model of elections with two candidates competing on a one-dimensional policy space. Voters are privately and imperfectly informed about a common shock affecting the electorate's preferences. Candidates are assumed to choose policy in response to information gleaned from election results and according to exogenous factors that may lead to polarization in candidates' policy choices. We analyze a subset of symmetric equilibria in which strategies are symmetric to candidates' names and private signals (CSS equilibria). We show that signaling and election motivations pull voters to vote in different directions. We provide conditions that show the relation between the amount of information aggregated in the election and the motivation that influences voting behavior the most. Finally, we show that when candidates are responsive and polarized, all CSS equilibria are inefficient in the limit.","['Razin, Ronny']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']",['D72'],Signaling and Election Motivations in a Voting Model with Common Values and Responsive Candidates,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"The block bootstrap is the best known bootstrap method for time-series data when the analyst does not have a parametric model that reduces the data generation process to simple random sampling. However, the errors made by the block bootstrap converge to zero only slightly faster than those made by first-order asymptotic approximations. This paper describes a bootstrap procedure for data that are generated by a Markov process or a process that can be approximated by a Markov process with sufficient accuracy. The procedure is based on estimating the Markov transition density nonparametrically. Bootstrap samples are obtained by sampling the process implied by the estimated transition density. Conditions are given under which the errors made by the Markov bootstrap converge to zero more rapidly than those made by the block bootstrap.","['Horowitz, Joel L.']","['Statistical Simulation Methods: General', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Hypothesis Testing: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C15', 'C32', 'C12', 'C22']",Bootstrap Methods for Markov Processes,0,0,0,0,0,2003,07,01
71,4,2003-07-01,"This paper develops a general method for constructing exactly similar tests based on the conditional distribution of nonpivotal statistics in a simultaneous equations model with normal errors and known reduced-form covariance matrix. These tests are shown to be similar under weak-instrument asymptotics when the reduced-form covariance matrix is estimated and the errors are non-normal. The conditional test based on the likelihood ratio statistic is particularly simple and has good power properties. Like the score test, it is optimal under the usual local-to-null asymptotics, but it has better power when identification is weak.","['Moreira, Marcelo J.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],A Conditional Likelihood Ratio Test for Structural Models,0,0,0,0,0,2003,07,01
71,4,2003-07-01,We introduce a game of complete information with multiple principals and multiple common agents. Each agent makes a decision that can affect the payoffs of all principals. Each principal offers monetary transfers to each agent conditional on the action taken by the agent. We characterize pure-strategy equilibria and we provide conditions--in terms of game balancedness--for the existence of an equilibrium with an efficient outcome. Games played through agents display a type of strategic inefficiency that is absent when either there is a unique principal or there is a unique agent.,"['Rustichini, Aldo', 'Prat, Andrea']","['Asymmetric and Private Information; Mechanism Design', 'Game Theory and Bargaining Theory: General']","['D82', 'C70']",Games Played through Agents,0,0,0,0,0,2003,07,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],REPORT OF THE PRESIDENT.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"A popular way to account for unobserved heterogeneity is to assume that the data are drawn from a finite mixture distribution. A barrier to using finite mixture models is that parameters that could previously be estimated in stages must now be estimated jointly: using mixture distributions destroys any additive separability of the log-likelihood function. We show, however, that an extension of the EM algorithm reintroduces additive separability, thus allowing one to estimate parameters sequentially during each maximization step. In establishing this result, we develop a broad class of estimators for mixture models. Returning to the likelihood problem, we show that, relative to full information maximum likelihood, our sequential estimator can generate large computational savings with little loss of efficiency.","['Arcidiacono, Peter', 'Jones, John Bailey']","['Estimation: General', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C13', 'C25']","Finite Mixture Distributions, Sequential Likelihood and the EM Algorithm",0,0,0,0,0,2003,05,01
71,3,2003-05-01,"This paper analyzes the linear regression model y = x beta + epsilon with a conditional median assumption med (epsilon|z) = 0, where z is a vector of exogenous instrument random variables. We study inference on the parameter beta when y is censored and x is endogenous.","['Hong, Han', 'Tamer, Elie']",['Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models'],['C24'],Inference in Censored Models with Endogenous Regressors,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"This paper provides deterministic approximation results for stochastic processes that arise when finite populations recurrently play finite games. The processes are Markov chains, and the approximation is defined in continuous time as a system of ordinary differential equations of the type studied in evolutionary game theory. We establish precise connections between the long-run behavior of the discrete stochastic process, for large populations, and its deterministic flow approximation. In particular, we provide probabilistic bounds on exit times from and visitation rates to neighborhoods of attractors to the deterministic flow. We sharpen these results in the special case of ergodic processes.","['Benaim, Michel', 'Weibull, Jorgen W.']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Deterministic Approximation of Stochastic Evolution in Games,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"Many refinements of Nash equilibrium yield solution correspondences that do not have closed graph in the space of payoffs or information. This has significance for implementation theory, especially under complete information. If a planner is concerned that all equilibria of his mechanism yield a desired outcome, and entertains the possibility that players may have even the slightest uncertainty about payoffs, then the planner should insist on a solution concept with closed graph.","['Ely, Jeffrey C.', 'Chung, Kim-Sau']","['Asymmetric and Private Information; Mechanism Design', 'Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'C72', 'D83']",Implementation with Near-Complete Information,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"A nonparametric, residual-based block bootstrap procedure is proposed in the context of testing for integrated (unit root) time series. The resampling procedure is based on weak assumptions on the dependence structure of the stationary process driving the random walk and successfully generates unit root integrated pseudo-series retaining the important characteristics of the data. It is more general than previous bootstrap approaches to the unit root problem in that it allows for a very wide class of weakly dependent processes and it is not based on any parametric assumption on the process generating the data. As a consequence the procedure can accurately capture the distribution of many unit root test statistics proposed in the literature. Large sample theory is developed and the asymptotic validity of the block bootstrap-based unit root testing is shown via a bootstrap functional limit theorem. Applications to some particular test statistics of the unit root hypothesis, i.e., least squares and Dickey-Fuller type statistics are given. The power properties of our procedure are investigated and compared to those of alternative bootstrap approaches to carry out the unit root test. Some simulations examine the finite sample performance of our procedure.","['Politis, Dimitris N.', 'Paparoditis, Efstathios']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Residual-Based Block Bootstrap for Unit Root Testing,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"In sequential bargaining models without outside options, each player's bargaining power is ultimately determined by which player will make an offer and when. This paper analyzes a sequential bargaining model in which players may hold different beliefs about which player will make an offer and when. Excessive optimism about making offers in the future can cause delays in agreement. The main result states that, despite this, if players will remain sufficiently optimistic for a sufficiently long future, then in equilibrium they will agree immediately. This result is also extended to other canonical models of optimism.","['Yildiz, Muhamet']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining without a Common Prior--An Immediate Agreement Theorem,0,0,0,0,0,2003,05,01
71,3,2003-05-01,"The paper studies bilateral contracting between one principal and N agents when each agent's utility depends on the principal's unobservable contracts with other agents. We show that allowing deviations to menu contracts from which the principal chooses bounds equilibrium outcomes in a wide class of bilateral contracting games without imposing ad hoc restrictions on the agents' beliefs. This bound yields, for example, competitive convergence as N approaches infinity in environments in which an appropriately-defined notion of competitive equilibrium exists. We also examine the additional restrictions arising in two common bilateral contracting games: the ""offer game"" in which the principal makes simultaneous offers to the agents, and the ""bidding game"" in which the agents make simultaneous offers to the principal.","['Segal, Ilya', 'Whinston, Michael D.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Asymmetric and Private Information; Mechanism Design', 'Externalities', 'Transactional Relationships; Contracts and Reputation; Networks']","['D43', 'D82', 'D62', 'L14']",Robust Predictions for Bilateral Contracting with Externalities,1,0,1,0,0,2003,05,01
71,3,2003-05-01,"We develop a model of monetary exchange where, as in the random matching literature, agents trade bilaterally and not through centralized markets. Rather than assuming they match exogenously and at random, however, we determine who meets whom as part of the equilibrium. We show how to formalize this process of directed matching in dynamic models with double coincidence problems, and present several examples and applications that illustrate how the approach can be used in monetary theory. Some of our results are similar to those in the random matching literature; others differ significantly.","['Wright, Randall', 'Corbae, Dean', 'Temzelides, Ted']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Money and Interest Rates: General', 'Bargaining Theory; Matching Theory']","['D83', 'E40', 'C78']",Directed Matching and Monetary Exchange,0,0,0,0,0,2003,05,01
71,2,2003-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2003,03,01
71,2,2003-03-01,ECONLIT None Found,"['Quah, John K.-H.']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",The Law of Demand and Risk Aversion,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"We propose a bias-reduced log-periodogram regression estimator, d-hat[subscript r], of the long-memory parameter, d, that eliminates the first- and higher-order biases of the Geweke and Porter-Hudak (1983) (GPH) estimator. The bias-reduced estimator is the same as the GPH estimator except that one includes frequencies to the power 2k for k = 1, . . . ,r, for some positive integer r, as additional regressors hi the pseudo-regression model that yields the GPH estimator. We determine the asymptotic bias, variance, and mean-squared error (MSE) of d-hat[subscript r], determine the asymptotic MSE optimal number of frequencies to include in the regression, and establish the asymptotic normality of d-hat[subscript r]. These results show that the bias of d[subscript r goes to zero at a faster rate than that of the GPH estimator, but that its variance only is increased by a multiplicative constant.","['Guggenberger, Patrik', 'Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],A Bias-Reduced Log-Periodogram Regression Estimator for the Long-Memory Parameter,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"Empirically achievable limits for time series modeling and forecasting are given a quantitative characterization using bounds that delimit the proximity of empirical measures to the true measure (DGP). For practical purposes, the proximity bound has the asymptotic form (K/2)log n, where K is a new dimensionality factor that depends on the nature of the data as well as the number of parameters. The bound applies even in situations where the models may be incorrectly specified. A major implication is that time trends are more costly than stochastic trends, which are more costly than stationary regressors in achieving proximity to the DGP. Thus, in a quantifiable manner, the DGP is more elusive when there is nonstationarity in the data. The implications for prediction are explored and a second proximity theorem is given which provides a similar bound measuring how close feasible predictors can come to the optimal predictor.","['Phillips, Peter C. B.', 'Ploberger, Werner']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Forecasting Models; Simulation Methods', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C32', 'C53', 'C22']",Empirical Limits for Time Series Econometric Models,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"We provide a framework for integration of high-frequency intraday data into the measurement, modeling, and forecasting of daily and lower frequency return volatilities and return distributions. Building on the theory of continuous-time arbitrage-free price processes and the theory of quadratic variation, we develop formal links between realized volatility and the conditional covariance matrix. Next, using continuously recorded observations for the Deutschemark/Dollar and Yen/Dollar spot exchange rates, we find that forecasts from a simple long-memory Gaussian vector autoregression for the logarithmic daily realized volatilities perform admirably. Moreover, the vector autoregressive volatility forecast, coupled with a parametric lognormal-normal mixture distribution produces well-calibrated density forecasts of future returns, and correspondingly accurate quantile predictions. Our results hold promise for practical modeling and forecasting of the large covariance matrices relevant in asset pricing, asset allocation and financial risk management applications.","['Andersen, Torben G.']","['Forecasting Models; Simulation Methods', 'International Financial Markets', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C53', 'G15', nan]",Modeling and Forecasting Realized Volatility,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"Is the stock market boom a result of the baby boom? This paper develops an overlapping generations model in which a baby boom is modeled as a high realization of a random birth rate, and the price of capital is determined endogenously by a convex cost of adjustment. A baby boom increases national saving and investment and thus causes an increase in the price of capital. The price of capital is mean-reverting so the initial increase in the price of capital is followed by a decrease. Social Security can potentially affect national saving and investment, though in the long run, it does not affect the price of capital.","['Abel, Andrew B.']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Social Security and Public Pensions', 'Macroeconomics: Consumption; Saving; Wealth', 'Investment; Capital; Intangible Capital; Capacity']","[nan, 'H55', 'E21', 'E22']",The Effects of a Baby Boom on Stock Prices and Capital Accumulation in the Presence of Social Security,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"High-frequency financial data are not only discretely sampled in time but the time separating successive observations is often random. We analyze the consequences of this dual feature of the data when estimating a continuous-time model. In particular, we measure the additional effects of the randomness of the sampling intervals over and beyond those due to the discreteness of the data. We also examine the effect of simply ignoring the sampling randomness. We find that in many situations the randomness of the sampling has a larger impact than the discreteness of the data.","['Mykland, Per A.', 'Ait-Sahalia, Yacine']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', nan]",The Effects of Random and Discrete Sampling When Estimating Continuous-Time Diffusions,0,0,0,0,0,2003,03,01
71,2,2003-03-01,"I consider transactions involving asymmetric prisoners' dilemmas between pairs of players randomly selected from two large populations. Games are played repeatedly, but information about cheating is not adequate to sustain cooperation, and there is no official legal system of contract enforcement. I examine how profit-maximizing private intermediation can supply the information and enforcement. I obtain conditions under which private governance can improve upon no governance, and examine why it fails to achieve social optimality.","['Dixit, Avinash']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design', 'Firm Behavior: Theory', 'Law and Economics: General', 'Transactional Relationships; Contracts and Reputation; Networks']","['C73', 'D82', 'D21', 'K00', 'L14']",On Modes of Economic Governance,1,1,0,0,0,2003,03,01
71,1,2003-01-01,ECONLIT None Found,"['Gordon, Robert J.']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS.,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Gordon, Julie P.']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS.,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Hamermesh, Daniel S.', 'Schmidt, Peter']",['Sociology of Economics'],['A14'],The Determinants of Econometric Society Fellows Elections,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Sharma, Tridib']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Optimal Contracts When Enforcement Is a Decision Variable: A Comment,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Doornik, Jurgen A.', 'Rothenberg, Thomas J.', 'Nielsen, Bent']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],The Influence of VAR Dimensions on Estimator Biases: Comment,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Smith, Anthony A., Jr.', 'Krusell, Per']",['Intertemporal Household Choice; Life Cycle Models and Saving'],['D15'],Consumption-Savings Decisions with Quasi-geometric Discounting,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Elbers, Chris', 'Lanjouw, Peter', 'Lanjouw, Jean O.']","['Measurement and Analysis of Poverty', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Personal Income, Wealth, and Their Distributions']","['I32', 'O15', 'D31']",Micro-level Estimation of Poverty and Inequality,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Kandori, Michihiro']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']","Randomization, Communication, and Efficiency in Repeated Games with Imperfect Public Monitoring",0,0,0,0,0,2003,01,01
71,1,2003-01-01,The paper proposes a new and normative approach for adjusting households' incomes in order to account for the heterogeneity of needs across income recipients when measuring inequality and welfare. We derive the implications for the structure of the adjustment method of two conditions concerned with the way the ranking of situations is modified by a change in the reference household type and by more equally distributed living standards across households. Our results suggest that concern for greater equality in living standards conflicts with the basic welfarist principle of symmetrical treatment of individuals that is at the core of the standard equivalence scale approach.,"['Ebert, Udo', 'Moyes, Patrick']","['Consumer Economics: Theory', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D11', 'D63']",Equivalence Scales Reconsidered,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"ARCH and GARCH models directly address the dependency of conditional second moments, and have proved particularly valuable in modelling processes where a relatively large degree of fluctuation is present. These include financial time series, which can be particularly heavy tailed. However, little is known about properties of ARCH or GARCH models in the heavy-tailed setting, and no methods are available for approximating the distributions of parameter estimators there. In this paper we show that, for heavy-tailed errors, the asymptotic distributions of quasi-maximum likelihood parameter estimators in ARCH and GARCH models are nonnormal, and are particularly difficult to estimate directly using standard parametric methods. Standard bootstrap methods also fail to produce consistent estimators. To overcome these problems we develop percentile-t, subsample bootstrap approximations to estimator distributions. Studentizing is employed to approximate scale, and the subsample bootstrap is used to estimate shape. The good performance of this approach is demonstrated both theoretically and numerically.","['Yao, Qiwei', 'Hall, Peter']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Inference in ARCH and GARCH Models with Heavy-Tailed Errors,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"We propose a functional estimation procedure for homogeneous stochastic differential equations based on a discrete sample of observations and with minimal requirements on the data generating process. We show how to identify the drift and diffusion function in situations where one or the other function is considered a nuisance parameter. The asymptotic behavior of the estimators is examined as the observation frequency increases and as the time span lengthens. We prove almost sure consistency and weak convergence to mixtures of normal laws, where the mixing variates depend on the chronological local time of the underlying diffusion process, that is the random time spent by the process in the vicinity of a generic spatial point. The estimation method and asymptotic results apply to both stationary and nonstationary recurrent processes.","['Bandi, Federico M.', 'Phillips, Peter C. B.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Fully Nonparametric Estimation of Scalar Diffusion Models,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"This paper applies revealed preference theory to the nonparametric statistical analysis of consumer demand. Knowledge of expansion paths is shown to improve the power of nonparametric tests of revealed preference. The tightest bounds on indifference surfaces and welfare measures are derived using an algorithm for which revealed preference conditions are shown to guarantee convergence. Nonparametric Engel curves are used to estimate expansion paths and provide a stochastic structure within which to examine the consistency of household level data and revealed preference theory. An application is made to a long time series of repeated cross-sections from the Family Expenditure Survey for Britain. The consistency of these data with revealed preference theory is examined. For periods of consistency with revealed preference, tight bounds are placed on true cost of living indices.","['Browning, Martin', 'Crawford, Ian A.', 'Blundell, Richard W.']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis']","['C51', 'D12']",Nonparametric Engel Curves and Revealed Preference,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"We present a model in which an asset bubble can persist despite the presence of rational arbitrageurs. The resilience of the bubble stems from the inability of arbitrageurs to temporarily coordinate their selling strategies. This synchronization problem together with the individual incentive to time the market results in the persistence of bubbles over a substantial period. Since the derived trading equilibrium is unique, our model rationalizes the existence of bubbles in a strong sense. The model also provides a natural setting in which news events, by enabling synchronization, can have a disproportionate impact relative to their intrinsic informational content.","['Brunnermeier, Markus K.', 'Abreu, Dilip']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', nan]",Bubbles and Crashes,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"This paper develops an inferential theory for factor models of large dimensions. The principal components estimator is considered because it is easy to compute and is asymptotically equivalent to the maximum likelihood estimator (if normality is assumed). We derive the rate of convergence and the limiting distributions of the estimated factors, factor loadings, and common components. The theory is developed within the framework of large cross sections (N) and a large time dimension (T), to which classical factor analysis does not apply. We show that the estimated common components are asymptotically normal with a convergence rate equal to the minimum of the square roots of N and T. The estimated factors and their loadings are generally normal, although not always so. The convergence rate of the estimated factors and factor loadings can be faster than that of the estimated common components. These results are obtained under general conditions that allow for correlations and heteroskedasticities in both dimensions. Stronger results are obtained when the idiosyncratic errors are serially uncorrelated and homoskedastic. A necessary and sufficient condition for consistency is derived for large N but fixed T.","['Bai, Jushan']",['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models'],['C33'],Inferential Theory for Factor Models of Large Dimensions,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"Public information in financial markets often arrives through the disclosures of interested parties who have a material interest in the reactions of the market to the new information. When the strategic interaction between the sender and the receiver is formalized as a disclosure game with verifiable reports, equilibrium prices can be given a simple characterization in terms of the concatenation of binomial pricing trees. There are a number of empirical implications. The theory predicts that the return variance following a poor disclosed outcome is higher than it would have been if the disclosed outcome were good. Also, when investors are risk averse, this leads to negative serial correlation of asset returns. Other points of contact with the empirical literature are discussed.","['Shin, Hyun Song']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Accounting', 'Criteria for Decision-Making under Risk and Uncertainty']","[nan, 'M41', 'D81']",Disclosures and Asset Returns,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"Methods are proposed for testing stochastic dominance of any pre-specified order, with primary interest in the distributions of income. We consider consistent tests, that are similar to Kolmogorov-Smirnov tests, of the complete set of restrictions that relate to the various forms of stochastic dominance. For such tests, in the case of tests for stochastic dominance beyond first order, we propose and justify a variety of approaches to inference based on simulation and the bootstrap. We compare these approaches to one another and to alternative approaches based on multiple comparisons in the context of a Monte Carlo experiment and an empirical example.","['Donald, Stephen G.', 'Barrett, Garry F.']","['Hypothesis Testing: General', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['C12', 'D63']",Consistent Tests for Stochastic Dominance,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"In this paper we estimate a bargaining model of government formation in parliamentary democracies. We use the estimated structural model to conduct constitutional experiments aimed at evaluating the impact of institutional features of the political environment on the duration of the government formation process, the type of coalitions that form, and their relative stability.","['Eraslan, Hulya', 'Merlo, Antonio', 'Diermeier, Daniel']","['Bargaining Theory; Matching Theory', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Structure, Scope, and Performance of Government']","['C78', 'D72', 'H11']",A Structural Model of Government Formation,0,0,0,0,0,2003,01,01
71,1,2003-01-01,"A predictor is asked to rank eventualities according to their plausibility, based on past cases. We assume that she can form a ranking given any memory that consists of finitely many past cases. Mild consistency requirements on these rankings imply that they have a numerical representation via a matrix assigning numbers to eventuality-case pairs, as follows. Given a memory, each eventuality is ranked according to the sum of the numbers in its row, over cases in memory. The number attached to an eventuality-case pair can be interpreted as the degree of support that the past case lends to the plausibility of the eventuality. Special instances of this result may be viewed as axiomatizing kernel methods for estimation of densities and for classification problems. Interpreting the same result for rankings of theories or hypotheses, rather than of specific eventualities, it is shown that one may ascribe to the predictor subjective conditional probabilities of cases given theories, such that her rankings of theories agree with rankings by the likelihood functions.","['Gilboa, Itzhak', 'Schmeidler, David']","['Econometric and Statistical Methods and Methodology: General', 'Criteria for Decision-Making under Risk and Uncertainty']","['C10', 'D81']",Inductive Inference: An Axiomatic Approach,0,0,0,0,0,2003,01,01
84,5,2016-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 84 Iss. 5.,0,0,0,0,0,2016,09,01
84,4,2016-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 84 Iss. 4.,0,0,0,0,0,2016,07,01
70,6,2002-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2002,11,01
70,6,2002-11-01,ECONLIT None Found,"['Hu, Luojia']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Estimation of a Censored Dynamic Panel Data Model,0,0,0,0,0,2002,11,01
70,6,2002-11-01,ECONLIT None Found,"['Ergin, Haluk I.']",['Allocative Efficiency; Cost-Benefit Analysis'],['D61'],Efficient Resource Allocation on the Basis of Priorities,0,0,0,0,0,2002,11,01
70,6,2002-11-01,ECONLIT None Found,"['Rubinstein, Ariel', 'Kalai, Gil', 'Spiegler, Ran']",['Microeconomics: General'],['D00'],Rationalizing Choice Functions by Multiple Rationales,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"Choice models with nonlinear budget sets provide a precise way of accounting for the nonlinear tax structures present in many applications. In this paper we propose a nonparametric approach to estimation of these models. The basic idea is to think of the choice, in our case hours of labor supply, as being a function of the entire budget set. Then we can do nonparametric regression where the variable in the regression is the budget set. We reduce the dimensionality of this problem by exploiting structure implied by utility maximization with piecewise linear convex budget sets. This structure leads to estimators where the number of segments can differ across observations and does not affect accuracy. We give consistency and asymptotic normality results for these estimators. The usefulness of the estimator is demonstrated in an empirical example, where we find it has a large impact on estimated effects of the Swedish tax reform.","['Blomquist, Soren', 'Newey, Whitney']","['Model Construction and Estimation', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Time Allocation and Labor Supply']","['C51', 'H31', 'J22']",Nonparametric Estimation with Nonlinear Budget Sets,0,0,0,0,0,2002,11,01
70,6,2002-11-01,We examine a general equilibrium model with asymmetrically informed agents. The presence of asymmetric information generally presents a conflict between incentive compatibility and Pareto efficiency. We present a notion of informational size and show that the conflict between incentive compatibility and efficiency can be made arbitrarily small if agents are of sufficiently small informational size.,"['McLean, Richard', 'Postlewaite, Andrew']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",Informational Size and Incentive Compatibility,0,0,0,0,0,2002,11,01
70,6,2002-11-01,ECONLIT None Found,"['Dahl, Gordon B.']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Geographic Labor Mobility; Immigrant Workers', 'Analysis of Education']","['J24', 'J61', 'I21']",Mobility and the Return to Education: Testing a Roy Model with Multiple Markets,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"An unresolved problem in Bayesian decision theory is how to value and price information. This paper resolves both problems assuming inexpensive information. Building on Large Deviation Theory, we produce a generically complete asymptotic order on samples of i.i.d. signals in finite-state, finite-action models. Computing the marginal value of an additional signal, we find it is eventually exponentially falling in quantity, and higher for lower quality signals. We provide a precise formula for the information demand, valid at low prices: asymptotically a constant times the log price, and falling in the signal quality for a given price.","['Smith, Lones', 'Moscarini, Giuseppe']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],The Law of Large Demand for Information,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"We construct and estimate an equilibrium search model with on-the-job-search. Firms make take-it-or-leave-it wage offers to workers conditional on their characteristics and they can respond to the outside job offers received by their employees. Unobserved worker productive heterogeneity is introduced in the form of cross-worker differences in a ""competence"" parameter. On the other side of the market, firms also are heterogeneous with respect to their marginal productivity of labor. The model delivers a theory of steady-state wage dispersion driven by heterogenous worker abilities and firm productivities, as well as by matching frictions. The structural model is estimated using matched employer and employee French panel data. The exogenous distributions of worker and firm heterogeneity components are nonparametrically estimated. We use this structural estimation to provide a decomposition of cross-employee wage variance. We find that the share of the cross-sectional wage variance that is explained by person effects varies across skill groups. Specifically, this share lies close to 40% for high-skilled white collars, and quickly decreases to 0% as the observed skill level decreases. The contribution of market imperfections to wage dispersion is typically around 50%.","['Postel-Vinay, Fabien', 'Robin, Jean-Marc']","['Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J31', 'J41', 'J64']",Equilibrium Wage Dispersion with Worker and Employer Heterogeneity,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"We establish global convergence results for stochastic fictitious play for four classes of games: games with an interior ESS, zero sum games, potential games, and supermodular games. We do so by appealing to techniques from stochastic approximation theory, which relate the limit behavior of a stochastic process to the limit behavior of a differential equation defined by the expected motion of the process. The key result in our analysis of supermodular games is that the relevant differential equation defines a strongly monotone dynamical system. Our analyses of the other cases combine Lyapunov function arguments with a discrete choice theory result: that the choice probabilities generated by any additive random utility model can be derived from a deterministic model based on payoff perturbations that depend nonlinearly on the vector of choice probabilities.","['Sandholm, William H.', 'Hofbauer, Josef']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],On the Global Convergence of Stochastic Fictitious Play,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"This paper studies the relation between discrete-time and continuous-time principal-agent models. We derive the continuous-time model as a limit of discrete-time models with ever shorter periods and show that optimal incentive schemes in the discrete-time models approximate the optimal incentive scheme in the continuous model, which is linear in accounts. Under the additional assumption that the principal observes only cumulative total profits at the end and the agent can destroy profits unnoticed, an incentive scheme that is linear in total profits is shown to be approximately optimal in the discrete-time model when the length of the period is small.","['Hellwig, Martin F.', 'Schmidt, Klaus M.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Discrete-Time Approximations of the Holmstrom-Milgrom Brownian-Motion Model of Intertemporal Incentive Provision,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"This paper investigates the design of seller-optimal auctions when winning bidders can attempt to resell the good. In that case, the optimal allocation characterized by Myerson (1981) cannot be achieved without resale. I find a sufficient and necessary condition for sincere bidding given the possibility of resale. In two-bidder cases, I prove that the Myerson allocation can be achieved under standard conditions supplemented with two assumptions. With three or more bidders, achieving the Myerson allocation is more difficult. I prove that it can be implemented in special cases. In those cases, the Myerson allocation is generated through a sequence of resale auctions, each optimally chosen by a reseller.","['Zheng, Charles Zhoucheng']",['Auctions'],['D44'],Optimal Auction with Resale,0,0,1,0,0,2002,11,01
70,6,2002-11-01,"The goal of this paper is to probe the validity of the fiscal theory of the price level by modelling explicitly the market structure in which households and the government make their decisions. I describe the economy as a game, and I am thus able to state precisely the consequences of actions that are out of the equilibrium path. I show that there exist government strategies that lead to a version of the fiscal theory, in which the price level is determined by fiscal variables alone. These strategies are however more complex than the simple budgetary rules usually associated with the fiscal theory, and the government budget constraint cannot be merely viewed as an equilibrium condition.","['Bassetto, Marco']","['Price Level; Inflation; Deflation', 'Fiscal Policy']","['E31', 'E62']",A Game-Theoretic View of the Fiscal Theory of the Price Level,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"Reinforcement learning and stochastic fictitious play are apparent rivals as models of human learning. They embody quite different assumptions about the processing of information and optimization. This paper compares their properties and finds that they are far more similar than were thought. In particular, the expected motion of stochastic fictitious play and reinforcement learning with experimentation can both be written as a perturbed form of the evolutionary replicator dynamics. Therefore they will in many cases have the same asymptotic behavior. In particular, local stability of mixed equilibria under stochastic fictitious play implies local stability under perturbed reinforcement learning. The main identifiable difference between the two models is speed: stochastic fictitious play gives rise to faster learning.","['Hopkins, Ed']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['D83', 'C73']",Two Competing Models of How People Learn in Games,0,0,0,0,0,2002,11,01
70,6,2002-11-01,"This paper presents new identification results for models of first-price, second-price, ascending (English), and descending (Dutch) auctions. We consider a general specification of the latent demand and information structure, nesting both private values and common values models, and allowing correlated types as well as ex ante asymmetry. We address identification of a series of nested models and derive testable restrictions enabling discrimination between models on the basis of observed data. The simplest model--symmetric independent private values--is nonparametrically identified even if only the transaction price from each auction is observed. For richer models, identification and testable restrictions may be obtained when additional information of one or more of the following types is available: (i) the identity of the winning bidder or other bidders; (ii) one or more bids in addition to the transaction price; (iii) exogenous variation in the number of bidders; (iv) bidder-specific covariates. While many private values (PV) models are nonparametrically identified and testable with commonly available data, identification of common values (CV) models requires stringent assumptions. Nonetheless, the PV model can be tested against the CV alternative, even when neither model is identified.","['Haile, Philip A.', 'Athey, Susan']",['Auctions'],['D44'],Identification of Standard Auction Models,0,0,1,0,0,2002,11,01
70,5,2002-09-01,ECONLIT None Found,"['Belzil, Christian', 'Hansen, Jorgen']","['Analysis of Education', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['I21', 'J24']",Unobserved Ability and the Return to Schooling,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['Nachbar, John H.']",['Exchange and Production Economies'],['D51'],General Equilibrium Comparative Statics,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['Honore, Bo E.', 'Lewbel, Arthur']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",Semiparametric Binary Choice Panel Data Models without Strictly Exogeneous Regressors,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['Wegkamp, Marten H.', 'Brown, Donald J.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Weighted Minimum Mean-Square Distance from Independence Estimation,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['McAfee, R. Preston']","['Bargaining Theory; Matching Theory', 'Rationing; Licensing', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D45', 'D82']",Coarse Matching,0,0,1,0,0,2002,09,01
70,5,2002-09-01,"Iterated elimination of strictly dominated strategies is an order dependent procedure. It can also generate spurious Nash equilibria, fail to converge in countable steps, or converge to empty strategy sets. If best replies are well-defined, then spurious Nash equilibria cannot appear; if strategy spaces are compact and payoff functions are uppersemicontinuous in own strategies, then order does not matter; if strategy sets are compact and payoff functions are continuous in all strategies, then a unique and nonempty maximal reduction exists. These positive results extend neither to the better-reply secure games for which Reny has established the existence of a Nash equilibrium, nor to games in which (under iterated eliminations) any dominated strategy has an undominated dominator.","['Stegeman, Mark', 'Dufwenberg, Martin']","['Noncooperative Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C72', 'D43']",Existence and Uniqueness of Maximal Reductions under Iterated Strict Dominance,0,0,1,0,0,2002,09,01
70,5,2002-09-01,"This paper presents a new test for fractionally integrated (FI) processes. In particular, we propose a testing procedure in the time domain that extends the well-known Dickey-Fuller approach, originally designed for the I(1) versus I(0) case, to the more general setup of FI(d[subscript 0]) versus FI(d[subscript 1]), with d[subscript 1] < d[subscript 0]. When d[subscript 0] = 1, the proposed test statistics are based on the OLS estimator, or its t-ratio, of the coefficient on Delta[superscript d[subscript 1]]y[subscript t-1] in a regression of Delta y[subscript t] on Delta[superscript d[subscript 1]]y[subscript t-1] and, possibly, some lags of Delta y[subscript t]. When d[subscript 1] is not taken to be known a priori, a pre-estimation of d[subscript 1 is needed to implement the test. We show that the choice of any T[superscript 1/2]-consistent estimator of d[subscript 1] is an element of [0 ,1) suffices to make the test feasible, while achieving asymptotic normality. Monte-Carlo simulations support the analytical results derived in the paper and show that proposed tests fare very well, both in terms of power and size, when compared with others available in the literature. The paper ends with two empirical applications.","['Mayoral, Laura', 'Gonzalo, Jesus', 'Dolado, Juan J.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],A Fractional Dickey-Fuller Test for Unit Roots,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"With the cointegration formulation of economic long-run relations the test for cointegrating rank has become a useful econometric tool. The limit distribution of the test is often a poor approximation to the finite sample distribution and it is therefore relevant to derive an approximation to the expectation of the likelihood ratio test for cointegration in the vector autoregressive model in order to improve the finite sample properties. The correction factor depends on moments of functions of the random walk, which are tabulated by simulation, and functions of the parameters, which are estimated. From this approximation we propose a correction factor with the purpose of improving the small sample performance of the test. The correction is found explicitly in a number of simple models and its usefulness is illustrated by some simulation experiments.","['Johansen, Soren']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],A Small Sample Correction for the Test of Cointegrating Rank in the Vector Autoregressive Model,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"The main contribution of this paper is the development and application of cryptographic techniques to the design of strategic communication mechanisms. One of the main assumptions in cryptography is the limitation of the computational power available to agents. We introduce the concept of limited computational complexity, and by borrowing results from cryptography, we construct a communication protocol to establish that every correlated equilibrium of a two-person game with rational payoffs can be achieved by means of computationally restricted unmediated communication. This result provides an example in game theory where limitations of computational abilities of players are helpful in solving implementation problems. More specifically, it is possible to construct mechanisms with the property that profitable deviations are too complicated to compute.","['Vila, Jose E.', 'Urbano, Amparo']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D83']",Computational Complexity and Communication: Coordination in Two-Player Games,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"In a differential information economy with quasi-linear utilities, monetary transfers facilitate the fulfillment of incentive compatibility constraints: the associated ex ante core is generically nonempty. However, we exhibit a well-behaved exchange economy in which this core is empty, even if goods are allocated through random mechanisms.","['Mertens, Jean-Francois', 'Forges, Francoise', 'Vohra, Rajiv']","['Allocative Efficiency; Cost-Benefit Analysis', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D61', 'D82', 'D83']",The Ex Ante Incentive Compatible Core in the Absence of Wealth Effects,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"Strategic behavior in a finite market can cause inefficiency in the allocation, and market mechanisms differ in how successfully they limit this inefficiency. A method for ranking algorithms in computer science is adapted here to rank market mechanisms according to how quickly inefficiency diminishes as the size of the market increases. It is shown that trade at a single market-clearing price in the k-double auction is worst-case asymptotic optimal among all plausible mechanisms: evaluating mechanisms in their least favorable trading environments for each possible size of the market, the k-double auction is shown to force the worst-case inefficiency to zero at the fastest possible rate.","['Satterthwaite, Mark A.', 'Williams, Steven R.']","['Market Structure, Pricing, and Design: General', 'Allocative Efficiency; Cost-Benefit Analysis']","['D40', 'D61']",The Optimality of a Simple Market Mechanism,0,0,1,0,0,2002,09,01
70,5,2002-09-01,"This paper argues that incompleteness of intertemporal financial markets has little effect (on welfare, prices, or consumption) in an economy with a single consumption good, provided that traders are long-lived and patient, a riskless bond is traded, shocks are transitory, and there is no aggregate risk. In an economy with aggregate risk, a similar conclusion holds, provided traders share the same CRRA utility function and the right assets are traded. Examples demonstrate that these conclusions need not hold if the wrong assets are traded or if the economy has multiple consumption goods.","['Zame, William R.', 'Levine, David K.']","['Incomplete Markets', 'Financial Markets and the Macroeconomy', 'Criteria for Decision-Making under Risk and Uncertainty', 'Macroeconomics: Consumption; Saving; Wealth']","['D52', 'E44', 'D81', 'E21']",Does Market Incompleteness Matter?,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"We propose a novel statistic for conducting joint tests on all the structural parameters in instrumental variables regression. The statistic is straightforward to compute and equals a quadratic form of the score of the concentrated log-likelihood. It therefore attains its minimal value equal to zero at the maximum likelihood estimator. The statistic has a x[superscript 2] limiting distribution with a degrees of freedom parameter equal to the number of structural parameters. The limiting distribution does not depend on nuisance parameters. The statistic overcomes the deficiencies of the Anderson-Rubin statistic, whose limiting distribution has a degrees of freedom parameter equal to the number of instruments, and the likelihood based, Wald, likelihood ratio, and Lagrange multiplier statistics, whose limiting distributions depend on nuisance parameters. Size and power comparisons reveal that the statistic is a (asymptotic) size-corrected likelihood ratio statistic. We apply the statistic to the Angrist-Krueger (1991) data and find similar results as in Staiger and Stock (1997).","['Kleibergen, Frank']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Single Equation Models; Single Variables: General']","['C30', 'C20']",Pivotal Statistics for Testing Structural Parameters in Instrumental Variables Regression,0,0,0,0,0,2002,09,01
70,5,2002-09-01,"We develop a Ricardian trade model that incorporates realistic geographic features into general equilibrium. It delivers simple structural equations for bilateral trade with parameters relating to absolute advantage, to comparative advantage (promoting trade), and to geographic barriers (resisting it). We estimate the parameters with data on bilateral trade in manufactures, prices, and geography from 19 OECD countries in 1990. We use the model to explore various issues such as the gains from trade, the role of trade in spreading the benefits of new technology, and the effects of tariff reduction.","['Eaton, Jonathan', 'Kortum, Samuel']","['Neoclassical Models of Trade', 'Empirical Studies of Trade', 'Size and Spatial Distributions of Regional Economic Activity']","['F11', 'F14', 'R12']","Technology, Geography, and Trade",0,0,0,0,0,2002,09,01
70,5,2002-09-01,"This paper offers a new approach to the study of economic problems usually modeled as games of incomplete information with discontinuous payoffs. Typically, the discontinuities arise from indeterminacies (ties) in the underlying problem. The point of view taken here is that the tie-breaking rules that resolve these indeterminacies should be viewed as part of the solution rather than part of the description of the model. A solution is therefore a tie-breaking rule together with strategies satisfying the usual best-response criterion. When information is incomplete, solutions need not exist; that is, there may be no tie-breaking rule that is compatible with the existence of strategy profiles satisfying the usual best-response criteria. It is shown that the introduction of incentive compatible communication (cheap talk) restores existence.","['Jackson, Matthew O.']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Noncooperative Games']","['D44', 'D83', 'C72']",Communication and Equilibrium in Discontinuous Games of Incomplete Information,0,0,1,0,0,2002,09,01
70,4,2002-07-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,"['Chen, Songnian']",['Single Equation Models; Single Variables: General'],['C20'],Rank Estimation of Transformation Models,0,0,0,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,"['Kremer, Ilan']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",Information Aggregation in Common Value Auctions,0,0,1,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,"['Martimort, David', 'Stole, Lars']",['Asymmetric and Private Information; Mechanism Design'],['D82'],The Revelation and Delegation Principles in Common Agency Games,0,0,0,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,"['Kuersteiner, Guido', 'Hahn, Jinyong']",['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models'],['C33'],Asymptotically Unbiased Inference for a Dynamic Panel Model with Fixed Effects When Both n and T Are Large,0,0,0,0,0,2002,07,01
70,4,2002-07-01,ECONLIT None Found,"['Araujo, Aloisio', 'Torres-Martinez, Juan Pablo', 'Pascoa, Mario Rui']",['Incomplete Markets'],['D52'],Collateral Avoids Ponzi Schemes in Incomplete Markets,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"Tests based on the quantile regression process can be formulated like the classical Kolmogorov-Smirnov and Cramer-von Mises tests of goodness-of-fit employing the theory of Bessel processes as in Kiefer (1959). However, it is frequently desirable to formulate hypotheses involving unknown nuisance parameters, thereby jeopardizing the distribution free character of these tests. We characterize this situation as ""the Durbin problem"" since it was posed in Durbin (1973), for parametric empirical processes. In this paper we consider an approach to the Durbin problem involving a martingale transformation of the parametric empirical process suggested by Khmaladze (1981) and show that it can be adapted to a wide variety of inference problems involving the quantile regression process. In particular, we suggest new tests of the location shift and location-scale shift models that underlie much of classical econometric inference. The methods are illustrated with a reanalysis of data on unemployment durations from the Pennsylvania Reemployment Bonus Experiments. The Pennsylvania experiments, conducted in 1988-89, were designed to test the efficacy of cash bonuses paid for early reemployment in shortening the duration of insured unemployment spells.","['Koenker, Roger', 'Xiao, Zhijie']",['Single Equation Models; Single Variables: General'],['C20'],Inference on the Quantile Regression Process,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"We show that it is possible to adapt to nonparametric disturbance autocorrelation in time series regression in the presence of long memory in both regressors and disturbances by using a smoothed nonparametric spectrum estimate in frequency-domain generalized least squares. When the collective memory in regressors and disturbances is sufficiently strong, ordinary least squares is not only asymptotically inefficient but asymptotically non-normal and has a slow rate of convergence, whereas generalized least squares is asymptotically normal and Gauss-Markov efficient with standard convergence rate. Despite the anomalous behavior of nonparametric spectrum estimates near a spectral pole, we are able to justify a standard construction of frequency-domain generalized least squares, earlier considered in case of short memory disturbances. A small Monte Carlo study of finite sample performance is included.","['Hidalgo, Javier', 'Robinson, Peter M.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Adapting to Unknown Disturbance Autocorrelation in Regression with Long Memory,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"This paper proposes a new nested algorithm (NPL) for the estimation of a class of discrete Markov decision models and studies its statistical and computational properties. Our method is based on a representation of the solution of the dynamic programming problem in the space of conditional choice probabilities. When the NPL algorithm is initialized with consistent nonparametric estimates of conditional choice probabilities, successive iterations return a sequence of estimators of the structural parameters which we call K-stage policy iteration estimators. We show that the sequence includes as extreme cases a Hotz-Miller estimator (for K = 1) and Rust's nested fixed point estimator (in the limit when K approaches infinity). Furthermore, the asymptotic distribution of all the estimators in the sequence is the same and equal to that of the maximum likelihood estimator. We illustrate the performance of our method with several examples based on Rust's bus replacement model. Monte Carlo experiments reveal a trade-off between finite sample precision and computational cost in the sequence of policy iteration estimators.","['Aguirregabiria, Victor', 'Mira, Pedro']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],Swapping the Nested Fixed Point Algorithm: A Class of Estimators for Discrete Markov Decision Models,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"The presence of obstinate types in bargaining has been shown to alter dramatically the bargaining equilibrium strategies and outcomes. This paper shows that outside options may cancel out the effect of obstinacy in bargaining. When parties have access to stationary outside options, we show that when opting out is preferable to accepting the inflexible demand of the other party, there is a unique Perfect Bayesian Equilibrium in which each party reveals himself as rational as soon as possible. A similar conclusion holds when outside options may only be available at a later date or when only one party has access to an outside option.","['Compte, Olivier', 'Jehiel, Philippe']",['Bargaining Theory; Matching Theory'],['C78'],On the Role of Outside Options in Bargaining with Obstinate Parties,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"We prove the existence of a symmetric equilibrium in a circular city in which businesses and housing can both be located anywhere in the city. In this equilibrium, firms balance the external benefits from locating near other producers against the costs of longer commutes for workers. An equilibrium city need not take the form of a central business district surrounded by a residential area. We propose a general algorithm for constructing equilibria, and use it to study the way land use is affected by changes in the model's underlying parameters.","['Rossi-Hansberg, Esteban', 'Lucas, Robert E., Jr.']","['Regional Economic Activity: Growth, Development, Environmental Issues, and Changes', 'Land Use Patterns']","['R11', 'R14']",On the Internal Structure of Cities,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"Models of utility in stochastic continuous-time settings typically assume that beliefs are represented by a probability measure, hence ruling out a priori any concern with ambiguity. This paper formulates a continuous-time intertemporal version of multiple-priors utility, where aversion to ambiguity is admissible. In a representative agent asset market setting, the model delivers restrictions on excess returns that admit interpretations reflecting a premium for risk and a separate premium for ambiguity.","['Chen, Zengjing', 'Epstein, Larry']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D81', nan]","Ambiguity, Risk, and Asset Returns in Continuous Time",0,0,0,0,0,2002,07,01
70,4,2002-07-01,"In previous work on cheap talk, uncertainty has almost always been modeled using a single-dimensional state variable. In this paper we prove that the dimensionality of the uncertain variable has an important qualitative impact on results and yields interesting insights into the ""mechanics"" of information transmission. Contrary to the unidimensional case, if there is more than one sender, full revelation of information in all states of nature is generically possible, even when the conflict of interest is arbitrarily large. What really matters in transmission of information is the local behavior of senders' indifference curves at the ideal point of the receiver, not the proximity of players' ideal point.","['Battaglini, Marco']","['Asymmetric and Private Information; Mechanism Design', 'Criteria for Decision-Making under Risk and Uncertainty']","['D82', 'D81']",Multiple Referrals and Multidimensional Cheap Talk,0,0,0,0,0,2002,07,01
70,4,2002-07-01,"Economists have lately been called upon not only to analyze markets, but to design them. Market design involves a responsibility for detail, a need to deal with all of a market's complications, not just its principle features. Designers therefore cannot work only with the simple conceptual models used for theoretical insights into the general working of markets. Instead, market design calls for an engineering approach. Drawing primarily on the design of the entry level labor market for American doctors (the National Resident Matching Program), and of the auctions of radio spectrum conducted by the Federal Communications Commission, this paper makes the case that experimental and computational economics are natural complements to game theory in the work of design. The paper also argues that some of the challenges facing both markets involve dealing with related kinds of complementarities, and that this suggests an agenda for future theoretical research.","['Roth, Alvin E.']","['Asymmetric and Private Information; Mechanism Design', 'Bargaining Theory; Matching Theory', 'Auctions', 'Professional Labor Markets; Occupational Licensing']","['D82', 'C78', 'D44', 'J44']","The Economist as Engineer: Game Theory, Experimentation, and Computation as Tools for Design Economics",0,0,1,0,0,2002,07,01
70,4,2002-07-01,Liberalization of infrastructure industries presents classic economic issues about how organization and procedure affect market performance. These issues are examined in wholesale power markets. The perspective from game theory complements standard economic theory to examine effects on efficiency and incentives.,"['Wilson, Robert']","['Energy: Demand and Supply; Prices', 'Electric Utilities', 'Industry Studies: Utilities and Transportation: Government Policy', 'Comparison of Public and Private Enterprises and Nonprofit Institutions; Privatization; Contracting Out', 'Industry Studies: Transportation and Utilities: General']","['Q41', 'L94', 'L98', 'L33', 'L90']",Architecture of Power Markets,1,0,0,0,0,2002,07,01
70,3,2002-05-01,ECONLIT None Found,[nan],[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2001.",0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Grodal, Birgit', 'Dierker, Egbert', 'Dierker, Hildegard']","['Incomplete Markets', 'Allocative Efficiency; Cost-Benefit Analysis']","['D52', 'D61']",Nonexistence of Constrained Efficient Equilibria When Markets Are Incomplete,0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Zheng, Buhong']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Personal Income, Wealth, and Their Distributions']","['D63', 'D31']",Testing Lorenz Curves with Non-simple Random Samples,0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Victoria-Feser, Maria-Pia', 'Cowell, Frank A.']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],Welfare Rankings in the Presence of Contaminated Data,0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Bobenrieth H., Eugenio S. A.', 'Bobenrieth H., Juan R. A.', 'Wright, Brian D.']","['Agriculture: Aggregate Supply and Demand Analysis; Prices', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['Q11', 'L11']",A Commodity Price Process with a Unique Continuous Invariant Distribution Having Infinite Mean,1,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Reny, Philip J.', 'Perry, Motty']",['Auctions'],['D44'],An Efficient Auction,0,0,1,0,0,2002,05,01
70,3,2002-05-01,"How can diversity be measured? What does it mean to value biodiversity? Can we assist Noah in constructing his preferences? To address these questions, we propose a multi-attribute approach under which the diversity of a set of species is the sum of the values of all attributes possessed by some species in the set. We develop the basic intuitions and requirements for a theory of diversity and show that the multi-attribute approach satisfies them in a flexible yet tractable manner. A natural starting point is to think of the diversity of a set as an aggregate of the pairwise dissimilarities between its elements. The multi-attribute framework allows one to make this program formally precise. It is shown that the program can be realized if and only if the family of relevant attributes is well-ordered (""acyclic""). Moreover, there is a unique functional form aggregating dissimilarity into diversity, the length of a minimum spanning tree. Examples are taxonomic hierarchies and lines representing uni-dimensional qualities. In multi-dimensional settings, pairwise dissimilarity information among elements is insufficient to determine their diversity. By consequence, the qualitative and quantitative behavior of diversity differs fundamentally.","['Puppe, Clemens', 'Nehring, Klaus']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Renewable Resources and Conservation: General']","['D63', 'Q20']",A Theory of Diversity,0,0,0,0,0,2002,05,01
70,3,2002-05-01,"We investigate the nature of price competition among firms that produce differentiated products and compete in markets that are limited in extent. We propose an instrumental variables series estimator for the matrix of cross price response coefficients, demonstrate that our estimator is consistent, and derive its asymptotic distribution. Our semiparametric approach allows us to discriminate among models of global competition, in which all products compete with all others, and local competition, in which products compete only with their neighbors.","['Brett, Craig', 'Slade, Margaret E.', 'Pinkse, Joris']","['Model Construction and Estimation', 'Other Spatial Production and Pricing Analysis', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['C51', 'R32', 'L11']",Spatial Price Competition: A Semiparametric Approach,1,0,0,0,0,2002,05,01
70,3,2002-05-01,"Band spectral regression with both deterministic and stochastic trends is considered. It is shown that trend removal by regression in the time domain prior to band spectral regression can lead to biased and inconsistent estimates in models with frequency dependent coefficients. Both semiparametric and nonparametric regression formulations are considered, the latter including general systems of two-sided distributed lags such as those arising in lead and lag regressions. The bias problem arises through omitted variables and is avoided by careful specification of the regression equation. Trend removal in the frequency domain is shown to be a convenient option in practice. An asymptotic theory is developed and the two cases of stationary data and cointegrated nonstationary data are compared. In the latter case, a levels and differences regression formulation is shown to be useful in estimating the frequency response function at nonzero as well as zero frequencies.","['Phillips, Peter C. B.', 'Corbae, Dean', 'Ouliaris, Sam']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Band Spectral Regression with Trending Data,0,0,0,0,0,2002,05,01
70,3,2002-05-01,"Important estimation problems in econometrics like estimating the value of a spectral density at frequency zero, which appears in the econometrics literature in the guises of heteroskedasticity and autocorrelation consistent variance estimation and long run variance estimation, are shown to be ""ill-posed"" estimation problems. A prototypical result obtained in the paper is that the minimax risk for estimating the value of the spectral density at frequency zero is infinite regardless of sample size, and that confidence sets are close to being uninformative. In this result the maximum risk is over commonly used specifications for the set of feasible data generating processes. The consequences for inference on unit roots and cointegration are discussed. Similar results for persistence estimation and estimation of the long memory parameter are given. All these results are obtained as special cases of a more general theory developed for abstract estimation problems, which readily also allows for the treatment of other ill-posed estimation problems such as, e.g., nonparametric regression or density estimation.","['Potscher, Benedikt M.']","['Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C13', 'C22']","Lower Risk Bounds and Properties of Confidence Sets for Ill-Posed Estimation Problems with Applications to Special Density and Persistence Estimation, Unit Roots, and Estimation of Long Memory Parameters",0,0,0,0,0,2002,05,01
70,3,2002-05-01,"We consider a general mechanism design setting where each agent can acquire (covert) information before participating in the mechanism. The central question is whether a mechanism exists that provides the efficient incentives for information acquisition ex-ante and implements the efficient allocation conditional on the private information ex-post, It is shown that in every private value environment the Vickrey-Clark-Groves mechanism guarantees both ex-ante as well as ex-post efficiency. In contrast, with common values, ex-ante and ex-post efficiency cannot be reconciled in general. Sufficient conditions in terms of sub- and supermodularity are provided when (all) ex-post efficient mechanisms lead to private under- or over-acquisition of information.","['Bergemann, Dirk', 'Valimaki, Juuso']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Information Acquisition and Efficient Mechanism Design,0,0,0,0,0,2002,05,01
70,3,2002-05-01,ECONLIT None Found,"['Nyarko, Yaw', 'Schotter, Andrew']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['D83', 'C73']",An Experimental Study of Belief Learning Using Elicited Beliefs,0,0,0,0,0,2002,05,01
70,3,2002-05-01,"This article concerns an infinite horizon economy where trade must occur pairwise, using a double auction mechanism, and where fiat money overcomes lack of double coincidence of wants. Traders are anonymous and lack market power. Goods are divisible and perishable, and are consumed at every date. Preferences are defined by utility-stream overtaking. Money is divisible and not subject to inventory constraints. The evolution of individual and economywide money holdings distributions is characterized. There is a welfare-ordered continuum of single price equilibria, reflecting indeterminacy of the price level rather than of relative prices.","['Zhou, Ruilin', 'Green, Edward J.']","['Market Structure, Pricing, and Design: General', 'Bargaining Theory; Matching Theory']","['D40', 'C78']",Dynamic Monetary Equilibrium in a Random Matching Economy,0,0,1,0,0,2002,05,01
70,3,2002-05-01,"Backus, Kehoe, and Kydland (1992), Baxter and Crucini (1995), and Stockman and Tesar (1995) find two major discrepancies between standard international business cycle models with complete markets and the data: In the models, cross-country correlations are much higher for consumption than for output, while in the data the opposite is true; and cross-country correlations of employment and investment are negative, while in the data they are positive. This paper introduces a friction into a standard model that helps resolve these anomalies. The friction is that international loans are imperfectly enforceable; any country can renege on its debts and suffer the consequences for future borrowing. To solve for equilibrium in this economy with endogenous incomplete markets, the methods of Marcet and Marimon (1999) are extended. Incorporating the friction helps resolve the anomalies more than does exogenously restricting the assets that can be traded.","['Perri, Fabrizio', 'Kehoe, Patrick J.']","['Business Fluctuations; Cycles', 'Open Economy Macroeconomics']","['E32', 'F41']",International Business Cycles with Endogenous Incomplete Markets,0,0,0,0,0,2002,05,01
70,3,2002-05-01,"Do political institutions shape economic policy? I argue that this question should naturally appeal to economists. Moreover, the answer is in the affirmative, both in theory and in practice. In particular, recent theoretical work predicts systematic effects of electoral rules and political regimes on the size and composition of government spending. Results from ongoing empirical work indicate that such effects are indeed present in the data. Some empirical results are consistent with theoretical predictions: presidential regimes have smaller governments and countries with majoritarian elections have smaller welfare-state programs and less corruption. Other results present puzzles for future research: the adjustment to economic events appears highly institution-dependent, as does the timing and nature of the electoral cycle.","['Persson, Torsten']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Fiscal Policy', 'Structure, Scope, and Performance of Government']","['D72', 'E62', 'H11']",Do Political Institutions Shape Economic Policy?,0,0,0,0,0,2002,05,01
70,3,2002-05-01,"In this lecture, it is argued that Schumpeterian Growth Theory, in which growth is driven by a sequence of quality-improving innovations, can shed light on two important puzzles raised by the recent evolution of wage inequality in developed economies. The first puzzle concerns wage inequality between educational groups, which has substantially risen in the US and the UK during the past two decades following a sharp increase in the supply of educated labor. The second puzzle concerns wage inequality within educational groups, which accounts for a large fraction of the observed increase in wage inequality, although in contrast to between-group wage inequality it has mainly affected the temporary component of income.","['Aghion, Philippe']","['One, Two, and Multisector Growth Models', 'Wage Level and Structure; Wage Differentials', 'Innovation and Invention: Processes and Incentives', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['O41', 'J31', 'O31', 'J24']",Schumpeterian Growth Theory and the Dynamics of Income Inequality,0,0,0,1,0,2002,05,01
70,2,2002-03-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Echenique, Federico']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],Comparative Statics by Adaptive Dynamics and the Correspondence Principle,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Dagsvik, John K.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C25', 'C35', 'C22', 'C32']",Discrete Choice in Continuous Time: Implications of an Intertemporal Version of the IIA Property,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Thesmar, David', 'Magnac, Thierry']","['Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C35', 'C25', 'C32', 'C22']",Identifying Dynamic Discrete Decision Processes,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Hirano, Keisuke']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Wage Level and Structure; Wage Differentials']","['C32', 'C33', 'J31']",Semiparametric Bayesian Inference in Autoregressive Panel Data Models,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Linton, Oliver', 'Lewbel, Arthur']",['Single Equation Models; Single Variables: General'],['C20'],Nonparametric Censored and Truncated Regression,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Marinacci, Massimo']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Probabilistic Sophistication and Multiple Priors,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Andreoni, James', 'Miller, John']",['Altruism; Philanthropy; Intergenerational Transfers'],['D64'],Giving According to GARP: An Experimental Test of the Consistency of Preferences for Altruism,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"This paper uses ""revealed probability trade-offs"" to provide a natural foundation for probability weighting in the famous von Neumann and Morgenstern axiomatic set-up for expected utility. In particular, it shows that a rank-dependent preference functional is obtained in this set-up when the independence axiom is weakened to stochastic dominance and a probability trade-off consistency condition. In contrast with the existing axiomatizations of rank-dependent utility, the resulting axioms allow for complete flexibility regarding the outcome space. Consequently, a parameter-free test/elicitation of rank-dependent utility becomes possible. The probability-oriented approach of this paper also provides theoretical foundations for probabilistic attitudes towards risk. It is shown that the preference conditions that characterize the shape of the probability weighting function can be derived from simple probability trade-off conditions.","['Abdellaoui, Mohammed']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Genuine Rank-Dependent Generalization of the von Neumann-Morgenstern Expected Utility Theorem,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"This paper presents an algorithm for computing an equilibrium of an extensive two-person game with perfect recall. The method is computationally efficient by virtue of using the sequence form, whose size is proportional to the size of the game tree. The equilibrium is traced on a piecewise linear path in the sequence form strategy space from an arbitrary starting vector. If the starting vector represents a pair of completely mixed strategies, then the equilibrium is normal form perfect. Computational experiments compare the sequence form and the reduced normal form, and show that only the sequence form is tractable for larger games.","['von Stengel, Bernhard', 'van den Elzen, Antoon', 'Talman, Dolf']","['Noncooperative Games', 'Computational Techniques; Simulation Modeling']","['C72', 'C63']",Computing Normal Form Perfect Equilibria for Extensive Two-Person Games,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"We develop a square-root-of-n-consistent and asymptotically normal estimator of the parameters (regression coefficients and threshold points) of a semiparametric ordered response model under the assumption of independence of errors and regressors. The independence assumption implies shift restrictions allowing identification of threshold points up to location and scale. The estimator is useful in various applications, particularly in new product demand forecasting from survey data subject to systematic misreporting. We apply the estimator to assess exaggeration bias in survey data on demand for a new telecommunications service.","['Sherman, Robert P.', 'Klein, Roger W.']",['Single Equation Models; Single Variables: General'],['C20'],Shift Restrictions and Semiparametric Estimation in Ordered Response Models,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"One of the central features of classical models of competitive markets is the generic determinacy of competitive equilibria. For smooth economies with a finite number of commodities and a finite number of consumers, almost all initial endowments admit only a finite number of competitive equilibria, and these equilibria vary (locally) smoothly with endowments; thus equilibrium comparative statics are locally determinate. This paper establishes parallel results for economies with finitely many consumers and infinitely many commodities. The most important new condition we introduce, quadratic concavity, rules out preferences in which goods are perfect substitutes globally, locally, or asymptotically. Our framework is sufficiently general to encompass many of the models that have proved important in the study of continuous-time trading in financial markets, trading over an infinite time horizon, and trading of finely differentiated commodities.","['Zame, William R.', 'Shannon, Chris']","['Exchange and Production Economies', 'Existence and Stability Conditions of Equilibrium']","['D51', 'C62']",Quadratic Concavity and Determinacy of Equilibrium,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"Evidence suggests that municipal water utility administrators in the western US price water significantly below its marginal cost and, in so doing, inefficiently exploit aquifer stocks and induce social surplus losses. This paper empirically identifies the objective function of those managers, measures the deadweight losses resulting from their price-discounting decisions, and recovers the efficient water pricing policy function from counterfactual experiments. In doing so, the estimation uses a ""continuous-but-constrained-control"" version of a nested fixed-point algorithm in order to measure the important intertemporal consequences of groundwater pricing decisions.","['Timmins, Christopher']","['Gas Utilities; Pipelines; Water Utilities', 'Renewable Resources and Conservation: Water', 'Economics of Regulation']","['L95', 'Q25', 'L51']",Measuring the Dynamic Efficiency Costs of Regulators' Preferences: Municipal Water Utilities in the Arid West,1,0,0,0,0,2002,03,01
70,2,2002-03-01,"The standard envelope theorems apply to choice sets with convex and topological structure, providing sufficient conditions for the value function to be differentiable in a parameter and characterizing its derivative. This paper studies optimization with arbitrary choice sets and shows that the traditional envelope formula holds at any differentiability point of the value function. We also provide conditions for the value function to be, variously, absolutely continuous, left- and right-differentiable, or fully differentiable. These results are applied to mechanism design, convex programming, continuous optimization problems, saddle-point problems, problems with parameterized constraints, and optimal stopping problems.","['Segal, Ilya', 'Milgrom, Paul']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'Household Behavior: General', 'Production and Organizations: General']","['C61', 'D10', 'D20']",Envelope Theorems for Arbitrary Choice Sets,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"A principal and an agent enter into a sequence of agreements. The principal faces an interim participation constraint at each date, but can commit to the current agreement; in contrast, the agent has the opportunity to renege on the current agreement. We study the time structure of agreement sequences that satisfy participation and no-deviation constraints and are (constrained) efficient. We show that every such sequence must, after a finite number of dates, exhibit a continuation that maximizes the agent's payoff over all such efficient, self-enforcing sequences. Additional results are provided for situations with transferable payoffs.","['Ray, Debraj']",['Asymmetric and Private Information; Mechanism Design'],['D82'],The Time Structure of Self-Enforcing Agreements,0,0,0,0,0,2002,03,01
70,2,2002-03-01,ECONLIT None Found,"['Tamer, Elie', 'Manski, Charles F.']",['Single Equation Models; Single Variables: General'],['C20'],Inference on Regressions with Interval Data on a Regressor or Outcome,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"This paper studies the effects of progressive income taxes and education finance in a dynamic heterogeneous-agent economy. Such redistributive policies entail distortions to labor supply and savings, but also serve as partial substitutes for missing credit and insurance markets. The resulting tradeoffs for growth and efficiency are explored, both theoretically and quantitatively, in a model that yields complete analytical solutions. Progressive education finance always leads to higher income growth than taxes and transfers, but at the cost of lower insurance. Overall efficiency is assessed using a new measure that properly reflects aggregate resources and idiosyncratic risks but, unlike a standard social welfare function, does not reward equality per se. Simulations using empirical parameter estimates show that the efficiency costs and benefits of redistribution are generally of the same order of magnitude, resulting in plausible values for the optimal rates. Aggregate income and aggregate welfare provide only crude lower and upper bounds around the true efficiency tradeoff.","['Benabou, Roland']","['Educational Finance; Financial Aid', 'Fiscal Policy', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'One, Two, and Multisector Growth Models']","['I22', 'E62', 'H23', 'H24', 'O41']",Tax and Education Policy in a Heterogeneous-Agent Economy: What Levels of Redistribution Maximize Growth and Efficiency?,0,0,0,0,0,2002,03,01
70,2,2002-03-01,"The paper examines within a unified methodology expectational coordination in a series of economic models. The methodology views the predictions associated with the Rational Expectations Hypothesis as reasonable whenever they can be derived from the more basic Common Knowledge Hypothesis. The paper successively considers a simple non-noisy N-dimensional model, standard models with ""intrinsic"" uncertainty, and reference intertemporal models with infinite horizon. It reviews existing results and suggests new ones. It translates the formal results into looser but economically intuitive statements, whose robustness, in the present state of knowledge, is tentatively ascertained.","['Guesnerie, R.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations', 'Forecasting Models; Simulation Methods']","['D83', 'D84', 'C53']",Anchoring Economic Predictions in Common Knowledge,0,0,0,0,0,2002,03,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Econometrica Referees 2000–2001.,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Treasurer.,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Secretary.,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Barnett, Richard C.', ""Fisher, Eric O'N.""]",['Exchange and Production Economies'],['D51'],Do Sunspots Matter When Spot Market Equilibria Are Unique?: Comment,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Inoue, Atsushi', 'Kilian, Lutz']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Bootstrapping Autoregressive Processes with Possible Unit Roots,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['van Veelen, Matthijs']",['Index Numbers and Aggregation; Leading indicators'],['C43'],An Impossibility Theorem Concerning Multilateral International Comparison of Volumes,0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Manski, Charles F.', 'Cross, Philip J.']",['Single Equation Models; Single Variables: General'],['C20'],"Regressions, Short and Long",0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Compte, Olivier', 'Jehiel, Philippe']",['Auctions'],['D44'],On the Value of Competition in Procurement Auctions,0,0,1,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Vytlacil, Edward']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],"Independence, Monotonicity, and Latent Index Models: An Equivalence Result",0,0,0,0,0,2002,01,01
70,1,2002-01-01,ECONLIT None Found,"['Wozniakowski, H.', 'Traub, J. F.', 'Rust, J.']",['Computational Techniques; Simulation Modeling'],['C63'],Is There a Curse of Dimensionality for Contraction Fixed Points in the Worst Case?,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"We present an axiomatic model depicting the choice behavior of a self-interest seeking moral individual over random allocation procedures. Individual preferences are decomposed into a self-interest component and a component representing the individual's moral value judgment. Each component has a distinct utility representation, and the preference relation depicting the choice behavior is representable by a real-valued function defined on the components utilities. The utility representing the self-interest component is linear and the utility representing the individual's moral value judgment is quasi-concave.","['Safra, Zvi', 'Karni, Edi']","['Consumer Economics: Theory', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D11', 'D63']",Individual Sense of Justice: A Utility Representation,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"When a continuous-time diffusion is observed only at discrete dates, in most cases the transition distribution and hence the likelihood function of the observations is not explicitly computable. Using Hermite polynomials, I construct an explicit sequence of closed-form functions and show that it converges to the true (but unknown) likelihood function. I document that the approximation is very accurate and prove that maximizing the sequence results in an estimator that converges to the true maximum likelihood estimator and shares its asymptotic properties. Monte Carlo evidence reveals that this method outperforms other approximation schemes in situations relevant for financial models.","['Ait-Sahalia, Yacine']",['Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions'],['C35'],Maximum Likelihood Estimation of Discretely Sampled Diffusions: A Closed-Form Approximation Approach,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"In this paper we develop some econometric theory for factor models of large dimensions. The focus is the determination of the number of factors (r), which is an unresolved issue in the rapidly growing literature on multifactor models. We first establish the convergence rate for the factor estimates that will allow for consistent estimation of r. We then propose some panel criteria and show that the number of factors can be consistently estimated using the criteria. The theory is developed under the framework of large cross-sections (N) and large time dimensions (T). No restriction is imposed on the relation between N and T. Simulations show that the proposed criteria have good finite sample properties in many configurations of the panel data encountered in practice.","['Bai, Jushan', 'Ng, Serena']","['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C33', nan]",Determining the Number of Factors in Approximate Factor Models,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"We develop a new specification test for IV estimators adopting a particular second order approximation of Bekker. The new specification test compares the difference of the forward (conventional) 2SLS estimator of the coefficient of the right-hand side endogenous variable with the reverse 2SLS estimator of the same unknown parameter when the normalization is changed. Under the null hypothesis that conventional first order asymptotics provide a reliable guide to inference, the two estimates should be very similar. Our test sees whether the resulting difference in the two estimates satisfies the results of second order asymptotic theory. Essentially the same idea is applied to develop another new specification test using second-order unbiased estimators of the type first proposed by Nagar. If the forward and reverse Nagar-type estimators are not significantly different we recommend estimation by LIML, which we demonstrate is the optimal linear combination of the Nagar-type estimators (to second order). We also demonstrate the high degree of similarity for k-class estimators between the approach of Bekker and the Edgeworth expansion approach of Rothenberg. An empirical example and Monte Carlo evidence demonstrate the operation of the new specification test.","['Hausman, Jerry', 'Hahn, Jinyong']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],A New Specification Test for the Validity of Instrumental Variables,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"This paper establishes the higher-order equivalence of the k-step bootstrap, introduced recently by Davidson and MacKinnon (1999), and the standard bootstrap. The k-step bootstrap is a very attractive alternative computationally to the standard bootstrap for statistics based on nonlinear extremum estimators, such as generalized method of moment and maximum likelihood estimators. The paper also extends results of Hall and Horowitz (1996) to provide new results regarding the higher-order improvements of the standard bootstrap and the k-step bootstrap for extremum estimators (compared to procedures based on first-order asymptotics). The results of the paper apply to Newton-Raphson (NR), default NR, line-search NR, and Gauss-Newton k-step bootstrap procedures. The results apply to the nonparametric iid bootstrap and nonoverlapping and overlapping block bootstraps. The results cover symmetric and equal-tailed two-sided t tests and confidence intervals, one-sided t tests and confidence intervals, Wald tests and confidence regions, and J tests of over-identifying restrictions.","['Andrews, Donald W. K.']",['Estimation: General'],['C13'],Higher-Order Improvements of a Computationally Attractive k-Step Bootstrap for Extremum Estimators,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"This paper reports estimates of the effects of JTPA training programs on the distribution of earnings. The estimation uses a new instrumental variable (IV) method that measures program impacts on quantiles. The quantile treatment effects (QTE) estimator reduces to quantile regression when selection for treatment is exogenously determined. QTE can be computed as the solution to a convex linear programming problem, although this requires first-step estimation of a nuisance function. We develop distribution theory for the case where the first step is estimated nonparametrically. For women, the empirical results show that the JTPA program had the largest proportional impact at low quantiles. Perhaps surprisingly, however, JTPA training raised the quantiles of earnings for men only in the upper half of the trainee earnings distribution.","['Angrist, Joshua D.', 'Abadie, Alberto', 'Imbens, Guido']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Model Construction and Estimation', 'Wage Level and Structure; Wage Differentials', 'Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models']","['J24', 'C51', 'J31', 'C31']",Instrumental Variables Estimates of the Effect of Subsidized Training on the Quantiles of Trainee Earnings,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"This paper estimates a structural model of optimal life-cycle consumption expenditures in the presence of realistic labor income uncertainty. We employ synthetic cohort techniques and Consumer Expenditure Survey data to construct average age-profiles of consumption and income over the working lives of typical households across different education and occupation groups. The model fits the profiles quite well. In addition to providing reasonable estimates of the discount rate and risk aversion, we find that consumer behavior changes strikingly over the life cycle. Young consumers behave as buffer-stock agents. Around age 40, the typical household starts accumulating liquid assets for retirement and its behavior mimics more closely that of a certainty equivalent consumer. Our methodology provides a natural decomposition of saving and wealth into its precautionary and life-cycle components.","['Parker, Jonathan A.', 'Gourinchas, Pierre-Oliver']","['Consumer Economics: Empirical Analysis', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D12', 'D15']",Consumption over the Life Cycle,0,0,0,0,0,2002,01,01
70,1,2002-01-01,"The paper studies the implementation problem, first analyzed by Maskin and Moore (1999), in which two agents observe an unverifiable state of nature and may renegotiate inefficient outcomes following play of the mechanism. We develop a first-order approach to characterizing the set of implementable utility mappings in this problem, paralleling Mirrlees's (1971) first-order analysis of standard mechanism design problems. We use this characterization to study optimal contracting in hold-up and risk-sharing models. In particular, we examine when the contracting parties can optimally restrict attention to simple contracts, such as noncontingent contracts and option contracts (where only one agent sends a message).","['Segal, Ilya', 'Whinston, Michael D.']","['Asymmetric and Private Information; Mechanism Design', 'Transactional Relationships; Contracts and Reputation; Networks', 'Criteria for Decision-Making under Risk and Uncertainty']","['D82', 'L14', 'D81']",The Mirrlees Approach to Mechanism Design with Renegotiation (With Applications to Hold-Up and Risk Sharing),1,0,0,0,0,2002,01,01
69,6,2001-11-01,ECONLIT None Found,[nan],[nan],[nan],"Nomination of Fellows, 2002.",0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Yatchew, Adonis', 'No, Joungyeo Angela']","['Consumer Economics: Empirical Analysis', 'Mining, Extraction, and Refining: Hydrocarbon Fuels']","['D12', 'L71']",Household Gasoline Demand in Canada,1,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Volij, Oscar', 'Vohra, Rajiv', 'Serrano, Roberto']","['Asymmetric and Private Information; Mechanism Design', 'Exchange and Production Economies']","['D82', 'D51']",On the Failure of Core Convergence in Economics with Asymmetric Information,0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Ottaviani, Marco', 'Prat, Andrea']","['Market Structure, Pricing, and Design: Monopoly', 'Monopoly; Monopolization Strategies', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D42', 'L12', 'D83']",The Value of Public Information in Monopoly,1,0,1,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Kitamura, Yuichi']",['Hypothesis Testing: General'],['C12'],Asymptotic Optimality of Empirical Likelihood for Testing Moment Restrictions,0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Hirano, Keisuke']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Methodology for Collecting, Estimating, and Organizing Microeconomic Data; Data Access']","['C23', 'C81']",Combining Panel Data Sets with Attrition and Refreshment Samples,0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Smith, Lones', 'Moscarini, Giuseppe']","['Criteria for Decision-Making under Risk and Uncertainty', 'Asymmetric and Private Information; Mechanism Design']","['D81', 'D82']",The Optimal Level of Experimentation,0,0,0,0,0,2001,11,01
69,6,2001-11-01,This paper evaluates the effectiveness of four econometric approaches intended to identify the learning rules being used by subjects in experiments with normal form games. This is done by simulating experimental data and then estimating the econometric models on the simulated data to determine if they can correctly identify the rule that was used to generate the data. The results show that all of the models examined possess difficulties in accurately distinguishing between the data generating processes.,"['Salmon, Timothy C.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Model Evaluation, Validation, and Selection']","['D83', 'C52']",An Evaluation of Econometric Models of Adaptive Learning,0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,"['Hansen, Bruce E.', 'Caner, Mehmet']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Threshold Autoregression with a Unit Root,0,0,0,0,0,2001,11,01
69,6,2001-11-01,"It is widely known that when there are errors with a moving-average root close to -1, a high order augmented autoregression is necessary for unit root tests to have good size, but that information criteria such as the AIC and the BIC tend to select a truncation lag (k) that is very small. We consider a class of Modified Information Criteria (MIC) with a penalty factor that is sample dependent. It takes into account the fact that the bias in the sum of the autoregressive coefficients is highly dependent on k and adapts to the type of deterministic components present. We use a local asymptotic framework in which the moving-average root is local to -1 to document how the MIC performs better in selecting appropriate values of k. In Monte-Carlo experiments, the MIC is found to yield huge size improvements to the DF[superscript GLS] and the feasible point optimal P[subscript T] test developed in Elliott, Rothenberg, and Stock (1996). We also extend the M tests developed in Perron and Ng (1996) to allow for GLS detrending of the data. The MIC along with GLS detrended data yield a set of tests with desirable size and power properties.","['Perron, Pierre', 'Ng, Serena']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Lag Length Selection and the Construction of Unit Root Tests with Good Size and Power,0,0,0,0,0,2001,11,01
69,6,2001-11-01,"This paper presents a full characterization of the equilibrium value set of a Ramsey tax model. More generally, it develops a dynamic programming method for a class of policy games between the government and a continuum of households. By selectively incorporating Euler conditions into a strategic dynamic programming framework, we wed two technologies that are usually considered competing alternatives, resulting in a substantial simplification of the problem.","['Stacchetti, Ennio', 'Phelan, Christopher']","['Taxation and Subsidies: Efficiency; Optimal Taxation', 'Fiscal Policy', 'Fiscal Policies and Behavior of Economic Agents: Household']","['H21', 'E62', 'H31']",Sequential Equilibria in a Ramsey Tax Model,0,0,0,0,0,2001,11,01
69,6,2001-11-01,"This paper develops a continuous-time equilibrium model of a two-country exchange economy with heterogeneous agents and nontraded goods. Nontraded goods play the role of state variables that shift the marginal utility of traded goods. This affects prices and generates dynamic hedging demands that explain the well documented home bias puzzle in international equity portfolios. When calibrated to both consumption and production data, the model is able to generate significative home bias in equity portfolios. A new methodology, based on Malliavin calculus, is presented to solve for the portfolio policies along the equilibrium path. This methodology allows one to reduce the determination of equilibrium portfolio holdings to the solution of a linear algebraic system, rather than a partial differential equation.","['Serrat, Angel']","['International Financial Markets', 'Portfolio Choice; Investment Decisions', 'Open Economy Macroeconomics']","['G15', 'G11', 'F41']",A Dynamic Equilibrium Model of International Portfolio Holdings,0,0,0,0,0,2001,11,01
69,6,2001-11-01,"The goal of this paper is to provide a comprehensive empirical analysis of majority rule and Tiebout sorting within a system of local jurisdictions. The idea behind the estimation procedure is to investigate whether observed levels of public expenditures satisfy necessary conditions implied by majority rule in a general equilibrium model of residential choice. The estimator controls for observed and unobserved heterogeneity among households, observed and unobserved characteristics of communities, and the potential endogeneity of prices and expenditures, as well as the self-selection of households into communities of their choice. We estimate the structural parameters of the model using data from the Boston Metropolitan Area. The empirical findings reject myopic voting models. More sophisticated voting models based on utility-taking provide a potential explanation of the main empirical regularities.","['Epple, Dennis', 'Sieg, Holger', 'Romer, Thomas']","['State and Local Government; Intergovernmental Relations: Interjurisdictional Differentials and Their Effects', 'Urban, Rural, Regional, Real Estate, and Transportation Economics: Housing Demand', 'Public Goods', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['H73', 'R21', 'H41', 'D72', 'H24']",Interjurisdictional Sorting and Majority Rule: An Empirical Analysis,0,0,0,0,0,2001,11,01
69,6,2001-11-01,"We study a two-period model where ex ante inferior choice may tempt the decision-maker in the second period. Individuals have preferences over sets of alternatives that represent second period choices. Our axioms yield a representation that identifies the individual's commitment ranking, temptation ranking, and cost of self-control. An agent has a preference for commitment if she strictly prefers a subset of alternatives to the set itself. An agent has self-control if she resists temptation and chooses an option with higher ex ante utility.","['Pesendorfer, Wolfgang', 'Gul, Faruk']",['Microeconomics: General'],['D00'],Temptation and Self-Control,0,0,0,0,0,2001,11,01
69,5,2001-09-01,ECONLIT None Found,"['Edlin, Aaron S.', 'Hermalin, Benjamin E.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Implementing the First Best in an Agency Relationship with Renegotiation: A Corrigendum,0,0,0,0,0,2001,09,01
69,5,2001-09-01,ECONLIT None Found,"['Woglom, Geoffrey']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],More Results on the Exact Small Sample Properties of the Instrumental Variable Estimator,0,0,0,0,0,2001,09,01
69,5,2001-09-01,ECONLIT None Found,"['Ui, Takashi']",['Noncooperative Games'],['C72'],Robust Equilibria of Potential Games,0,0,0,0,0,2001,09,01
69,5,2001-09-01,ECONLIT None Found,"['Peters, Michael']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Common Agency and the Revelation Principle,0,0,0,0,0,2001,09,01
69,5,2001-09-01,ECONLIT None Found,"['Lehrer, Ehud']",['Forecasting Models; Simulation Methods'],['C53'],Any Inspection Is Manipulable,0,0,0,0,0,2001,09,01
69,5,2001-09-01,"When individual statistics are aggregated through a strictly monotone function to an aggregate statistic, common knowledge of the value of the aggregate statistic does not imply, in general, that the individual statistics are either equal or constant. This paper discusses circumstances where constancy and equality both hold. The first case arises when partitions are independently drawn, and each individual's information is determined by their own partition and some public signal. In this case common knowledge of the value of the aggregator function implies (with probability one) that the individual statistics are constant, so that in the case where the individual statistics have the same expected value, they must all be equal. The second circumstance is where private statistics are related: affiliation of individual statistics and a lattice condition imply that the individual statistics are equal when the value of the aggregate statistic is common knowledge.","['Bergin, James']","['Game Theory and Bargaining Theory: General', 'Information, Knowledge, and Uncertainty: General']","['C70', 'D80']",Common Knowledge with Monotone Statistics,0,0,0,0,0,2001,09,01
69,5,2001-09-01,"A new method is proposed for constructing confidence intervals in autoregressive models with linear time trend. Interest focuses on the sum of the autoregressive coefficients because this parameter provides a useful scalar measure of the long-run persistence properties of an economic time series. Since the type of the limiting distribution of the corresponding OLS estimator, as well as the rate of its convergence, depend in a discontinuous fashion upon whether the true parameter is less than one or equal to one (that is, trend-stationary case or unit root case), the construction of confidence intervals is notoriously difficult. The crux of our method is to recompute the OLS estimator on smaller blocks of the observed data, according to the general subsampling idea of Politis and Romano (1994), although some extensions of the standard theory are needed. The method is more general than previous approaches in that it works for arbitrary parameter values, but also because it allows the innovations to be a martingale difference sequence rather than i.i.d. Some simulation studies examine the finite sample performance.","['Romano, Joseph P.', 'Wolf, Michael']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Subsampling Intervals in Autoregressive Models with Linear Time Trend,0,0,0,0,0,2001,09,01
69,5,2001-09-01,"This paper introduces a stochastic algorithm for computing symmetric Markov perfect equilibria. The algorithm computes equilibrium policy and value functions, and generates a transition kernel for the (stochastic) evolution of the state of the system. It has two features that together imply that it need not be subject to the curse of dimensionality. First, the integral that determines continuation values is never calculated; rather it is approximated by a simple average of returns from past outcomes of the algorithm, an approximation whose computational burden is not tied to the dimension of the state space. Second, iterations of the algorithm update value and policy functions at a single (rather than at all possible) points in the state space. Random draws from a distribution set by the updated policies determine the location of the next iteration's updates. This selection only repeatedly hits the recurrent class of points, a subset whose cardinality is not directly tied to that of the state space. Numerical results for industrial organization problems show that our algorithm can increase speed and decrease memory requirements by several orders of magnitude.","['McGuire, Paul', 'Pakes, Ariel']","['Computational Techniques; Simulation Modeling', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C63', 'C73']","Stochastic Algorithms, Symmetric Markov Perfect Equilibrium, and the 'Curse' of Dimensionality",0,0,0,0,0,2001,09,01
69,5,2001-09-01,"We study efficient, Bayes--Nash incentive compatible mechanisms in a social choice setting that allows for informational and allocative externalities. We show that such mechanisms exist only if a congruence condition relating private and social rates of information substitution is satisfied. If signals are multi-dimensional, the congruence condition is determined by an integrability constraint, and it can hold only in nongeneric cases where values are private or a certain symmetry assumption holds. If signals are one-dimensional, the congruence condition reduces to a monotonicity constraint and it can be generically satisfied. We apply the results to the study of multi-object auctions, and we discuss why such auctions cannot be reduced to one-dimensional models without loss of generality.","['Moldovanu, Benny', 'Jehiel, Philippe']","['Auctions', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D82', 'D83']",Efficient Design with Interdependent Valuations,0,0,1,0,0,2001,09,01
69,5,2001-09-01,"This paper reports experiments designed to study strategic sophistication, the extent to which behavior in games reflects attempts to predict others' decisions, taking their incentives into account. We study subjects' initial responses to normal-form games with various patterns of iterated dominance and unique pure-strategy equilibria without dominance, using a computer interface that allowed them to search for hidden payoff information, while recording their searches. Monitoring subjects' information searches along with their decisions allows us to better understand how their decisions are determined, and subjects' deviations from the search patterns suggested by equilibrium analysis help to predict their deviations from equilibrium decisions.","['Broseta, Bruno', 'Costa-Gomes, Miguel', 'Crawford, Vincent P.']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Noncooperative Games']","['D83', 'C72']",Cognition and Behavior in Normal-Form Games: An Experimental Study,0,0,0,0,0,2001,09,01
69,5,2001-09-01,"Properties of instrumental variable estimators are sensitive to the choice of valid instruments, even in large cross-section applications. In this paper we address this problem by deriving simple mean-square error criteria that can be minimized to choose the instrument set. We develop these criteria for two-stage least squares (2SLS), limited information maximum likelihood (LIML), and a bias adjusted version of 2SLS (B2SLS). We give a theoretical derivation of the mean-square error and show optimality. In Monte Carlo experiments we find that the instrument choice generally yields an improvement in performance. Also, in the Angrist and Krueger (1991) returns to education application, when the instrument set is chosen in the way we consider, it turns out that both 2SLS and LIML give similar (large) returns to education.","['Donald, Stephen G.', 'Newey, Whitney K.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Choosing the Number of Instruments,0,0,0,0,0,2001,09,01
69,5,2001-09-01,"This paper reviews a set of recent studies that have attempted to measure the causal effect of education on labor market earnings by using institutional features of the supply side of the education system as exogenous determinants of schooling outcomes. A simple theoretical model that highlights the role of comparative advantage in the optimal schooling decision is presented and used to motivate an extended discussion of econometric issues, including the properties of ordinary least squares and instrumental variables estimators. A review of studies that have used compulsory schooling laws, differences in the accessibility of schools, and similar features as instrumental variables for completed education, reveals that the resulting estimates of the return to schooling are typically as big or bigger than the corresponding ordinary least squares estimates. One interpretation of this finding is that marginal returns to education among the low-education subgroups typically affected by supply-side innovations tend to be relatively high, reflecting their high marginal costs of schooling, rather than low ability that limits their return to education.","['Card, David']","['Model Construction and Estimation', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Analysis of Education']","['C51', 'J24', 'J31', 'I21']",Estimating the Return to Schooling: Progress on Some Persistent Econometric Problems,0,0,0,0,0,2001,09,01
69,4,2001-07-01,ECONLIT None Found,[nan],[nan],[nan],Announcements: 2001 Australasian Meeting of the Econometric Society Announcement and Call for Papers.,0,0,0,0,0,2001,07,01
69,4,2001-07-01,ECONLIT None Found,"['Krishna, Vijay', 'Maenner, Eliot']","['Asymmetric and Private Information; Mechanism Design', 'Optimization Techniques; Programming Models; Dynamic Analysis', 'Criteria for Decision-Making under Risk and Uncertainty']","['D82', 'C61', 'D81']",Convex Potentials with an Application to Mechanism Design,0,0,0,0,0,2001,07,01
69,4,2001-07-01,ECONLIT None Found,"['Philipson, Tomas']","['Survey Methods; Sampling Methods', 'Analysis of Health Care Markets']","['C83', 'I11']","Data Markets, Missing Data, and Incentive Pay",0,0,0,0,0,2001,07,01
69,4,2001-07-01,"This paper extends the revelation principle to environments in which the mechanism designer cannot fully commit to the outcome induced by the mechanism. We show that he may optimally use a direct mechanism under which truthful revelation is an optimal strategy for the agent. In contrast with the conventional revelation principle, however, the agent may not use this strategy with probability one. Our results apply to contracting problems between a principal and a single agent. By reducing such problems to well-defined programming problems they provide a basic tool for studying imperfect commitment.","['Bester, Helmut', 'Strausz, Roland']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Contracting with Imperfect Commitment and the Revelation Principle: The Single Agent Case,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"We show that, in repeated common interest games without discounting, strong ""perturbation implies efficiency"" results require that the perturbations must include strategies that are ""draconian"" in the sense that they are prepared to punish to the maximum extent possible. Moreover, there is a draconian strategy whose presence in the perturbations guarantees that any equilibrium is efficient. We also argue that the results of Anderlini and Sabourian (1995) using perturbation strategies that are cooperative (and hence nondraconian) are not due to computability per se but to the further restrictions they impose on allowable beliefs.","['Thomas, Jonathan P.', 'Evans, Robert']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Cooperation and Punishment,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"In expected utility theory, risk attitudes are modeled entirely in terms of utility. In the rank-dependent theories, a new dimension is added: chance attitude, modeled in terms of nonadditive measures or nonlinear probability transformations that are independent of utility. Most empirical studies of chance attitude assume probabilities given and adopt parametric fitting for estimating the probability transformation. Only a few qualitative conditions have been proposed or tested as yet, usually quasi-concavity or quasi-convexity in the case of given probabilities. This paper presents a general method of studying qualitative properties of chance attitude such as optimism, pessimism, and the ""inverse-S shape"" pattern, both for risk and for uncertainty. These qualitative properties can be characterized by permitting appropriate, relatively simple, violations of the sure-thing principle. In particular, this paper solves a hitherto open problem: the preference axiomatization of convex (""pessimistic"" or ""uncertainty averse"") nonadditive measures under uncertainty. The axioms of this paper preserve the central feature of rank-dependent theories, i.e. the separation of chance attitude and utility.","['Wakker, Peter P.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Testing and Characterizing Properties of Nonadditive Measures through Violations of the Sure-Thing Principle,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"We study the incentives of candidates to strategically affect the outcome of a voting procedure. We show that the outcomes of every nondictatorial voting procedure that satisfies unanimity will be affected by the incentives of noncontending candidates (i.e., who cannot win the election) to influence the outcome by entering or exiting the election.","['Jackson, Matthew O.', 'Dutta, Bhaskar', 'Le Breton, Michel']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']",['D72'],Strategic Candidacy and Voting Procedures,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"This paper studies necessity of transversality conditions for the continuous time, reduced form model. By generalizing Benveniste and Scheinkman's (1982) ""envelope"" condition and Michel's (1990) version of the squeezing argument, we show a generalization of Michel's (1990, Theorem 1) necessity result that does not assume concavity. The generalization enables us to generalize Ekeland and Scheinkman's (1986) result as well as to establish a new result that does not require the objective functional to be finite. The new result implies that homogeneity of the return function alone is sufficient for the necessity of the most standard transversality condition. Our results are also applied to a nonstationary version of the one-sector growth model. It is shown that bubbles never arise in an equilibrium asset pricing model with a nonlinear constraint.","['Kamihigashi, Takashi']","['Optimization Techniques; Programming Models; Dynamic Analysis', 'One, Two, and Multisector Growth Models', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C61', 'O41', nan]",Necessity of Transversality Conditions for Infinite Horizon Problems,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"This paper is concerned with the Bayesian estimation of nonlinear stochastic differential equations when observations are discretely sampled. The estimation framework relies on the introduction of latent auxiliary data to complete the missing diffusion between each pair of measurements. Tuned Markov chain Monte Carlo (MCMC) methods based on the Metropolis-Hastings algorithm, in conjunction with the Euler-Maruyama discretization scheme, are used to sample the posterior distribution of the latent data and the model parameters. Techniques for computing the likelihood function, the marginal likelihood, and diagnostic measures (all based on the MCMC output) are developed. Examples using simulated and real data are presented and discussed in detail.","['Shephard, Neil', 'Chib, Siddhartha', 'Elerain, Ola']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Likelihood Inference for Discretely Observed Nonlinear Diffusions,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"Laboratory and field studies of time preference find that discount rates are much greater in the short-run than in the long-run. Hyperbolic discount functions capture this property. This paper solves the decision problem of a hyperbolic consumer who faces stochastic income and a borrowing constraint. The paper uses the bounded variation calculus to derive the Hyperbolic Euler Relation, a natural generalization of the standard Exponential Euler Relation. The Hyperbolic Euler Relation implies that consumers act as if they have endogenous rates of time preference that rise and fall with the future marginal propensity to consume (e.g., discount rates that endogenously range from 5% to 41% for the example discussed in the paper).","['Harris, Christopher', 'Laibson, David']",['Intertemporal Household Choice; Life Cycle Models and Saving'],['D15'],Dynamic Choices of Hyperbolic Consumers,0,0,0,0,0,2001,07,01
69,4,2001-07-01,ECONLIT None Found,"['Lipman, Barton L.', 'Rustichini, Aldo', 'Dekel, Eddie']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Representing Preferences with a Unique Subjective State Space,0,0,0,0,0,2001,07,01
69,4,2001-07-01,"This paper analyzes a class of games of incomplete information where each agent has private information about her own type, and the types are drawn from an atomless joint probability distribution. The main result establishes existence of pure strategy Nash equilibria (PSNE) under a condition we call the single crossing condition (SCC), roughly described as follows: whenever each opponent uses a nondecreasing strategy (in the sense that higher types choose higher actions), a player's best response strategy is also nondecreasing. When the SCC holds, a PSNE exists in every finite-action game. Further, for games with continuous payoffs and a continuum of actions, there exists a sequence of PSNE to finite-action games that converges to a PSNE of the continuum-action game. These convergence and existence results also extend to some classes of games with discontinuous payoffs, such as first-price auctions, where bidders may be heterogeneous and reserve prices are permitted. Finally, the paper characterizes the SCC based on properties of utility functions and probability distributions over types. Applications include first-price, multi-unit, and all-pay auctions; pricing games with incomplete information about costs; and noisy signaling games.","['Athey, Susan']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design', 'Auctions']","['C72', 'D82', 'D44']",Single Crossing Properties and the Existence of Pure Strategy Equilibria in Games of Incomplete Information,0,0,1,0,0,2001,07,01
69,4,2001-07-01,"We report the results of an experiment designed to study the role of speculation in the formation of bubbles and crashes in laboratory asset markets. In a setting in which speculation is not possible, bubbles and crashes are observed. The results suggest that the departures from fundamental values are not caused by the lack of common knowledge of rationality leading to speculation, but rather by behavior that itself exhibits elements of irrationality. Much of the trading activity that accompanies bubble formation, in markets where speculation is possible, is due to the fact that there is no other activity available for participants in the experiment.","['Plott, Charles R.', 'Lei, Vivian', 'Noussair, Charles N.']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Expectations; Speculations']","[nan, 'D84']",Nonspeculative Bubbles in Experimental Asset Markets: Lack of Common Knowledge of Rationality vs. Actual Irrationality,0,0,0,0,0,2001,07,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],2001 North American Summer Meeting of the Econometric Society: Announcement and Call for Papers.,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],Fellows of the Econometric Society January 2001.,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],2000 Election of Fellows to the Econometric Society.,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Vohra, Rajiv', 'Serrano, Roberto']","['Asymmetric and Private Information; Mechanism Design', 'Social Choice; Clubs; Committees; Associations']","['D82', 'D71']",Some Limitations of Virtual Bayesian Implementation,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Page, Frank H., Jr.', 'Berliant, Marcus']","['Public Goods', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Taxation and Subsidies: Efficiency; Optimal Taxation']","['H41', 'H24', 'H21']",Income Taxes and the Provision of Public Goods: Existence of an Optimum,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Wilson, Robert', 'Govindan, Srihari']",['Noncooperative Games'],['C72'],Direct Proofs of Generic Finiteness of Nash Equilibrium Outcomes,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Van Huyck, John', 'Battalio, Raymond', 'Samuelson, Larry']",['Noncooperative Games'],['C72'],Optimization Incentives and Coordination Failure in Laboratory Stag Hunt Games,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Juang, Wei-Torng']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Learning from Popularity,0,0,0,0,0,2001,05,01
69,3,2001-05-01,"This paper considers testing problems where several of the standard regularity conditions fail to hold. We consider the case where (i) parameter vectors in the null hypothesis may lie on the boundary of the maintained hypothesis and (ii) there may be a nuisance parameter that appears under the alternative hypothesis, but not under the null. The paper establishes the asymptotic null and local alternative distributions of quasi-likelihood ratio, rescaled quasilikelihood ratio, Wald, and score tests in this case. The results apply to tests based on a wide variety of extremum estimators and apply to a wide variety of models. Examples treated in the paper are: (i) tests of the null hypothesis of no conditional heteroskedasticity in a GARCH(1,-1) regression model and (ii) tests of the null hypothesis that some random coefficients have variances equal to zero in a random coefficients regression model with (possibly) correlated random coefficients.","['Andrews, Donald W. K.']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C12', 'C20', 'C22']",Testing When a Parameter Is on the Boundary of the Maintained Hypothesis,0,0,0,0,0,2001,05,01
69,3,2001-05-01,"Regulation requiring insiders to publicly disclose their stock trades after the fact complicates the trading decisions of informed, rent-seeking insiders. Given this requirement, we present an insider's equilibrium trading strategy in a multiperiod rational expectations framework. Relative to Kyle (1985), price discovery is accelerated and insider profits are lower. The strategy balances immediate profits from informed trades against the reduction in future profits following trade disclosure and, hence, revelation of some of the insider's information. Our results offer a novel rationale for contrarian trading: dissimulation, a phenomenon distinct from manipulation, may underlie insiders' trading decisions.","['Levine, Carolyn B.', 'Hughes, John S.', 'Huddart, Steven']","['Information and Market Efficiency; Event Studies; Insider Trading', 'General Financial Markets: Government Policy and Regulation', 'Business and Securities Law']","['G14', 'G18', 'K22']",Public Disclosure and Dissimulation of Insider Trades,0,1,0,0,0,2001,05,01
69,3,2001-05-01,"We study the implications of imperfect information for term structures of credit spreads on corporate bonds. We suppose that bond investors cannot observe the issuer's assets directly, and receive instead only periodic and imperfect accounting reports. For a setting in which the assets of the firm are a geometric Brownian motion until informed equityholders optimally liquidate, we derive the conditional distribution of the assets, given accounting data and survivorship. Contrary to the perfect-information case, there exists a default-arrival intensity process. That intensity is calculated in terms of the conditional distribution of assets. Credit yield spreads are characterized in terms of accounting information. Generalizations are provided.","['Duffie, Darrell', 'Lando, David']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill', 'Interest Rates: Determination, Term Structure, and Effects']","[nan, 'G32', 'E43']",Term Structures of Credit Spreads with Incomplete Accounting Information,0,0,0,0,0,2001,05,01
69,3,2001-05-01,"We develop a new test of a parametric model of a conditional mean function against a nonparametric alternative. The test adapts to the unknown smoothness of the alternative model and is uniformly consistent against alternatives whose distance from the parametric model converges to zero at the fastest possible rate. This rate is slower than n[superscript -1/2]. Some existing tests have nontrivial power against restricted classes of alternatives whose distance from the parametric model decreases at the rate n[superscript -1/2]. There are, however, sequences of alternatives against which these tests are inconsistent and ours is consistent. As a consequence, there are alternative models for which the finite-sample power of our test greatly exceeds that of existing tests. This conclusion is illustrated by the results of some Monte Carlo experiments.","['Spokoiny, Vladimir G.', 'Horowitz, Joel L.']",['Single Equation Models; Single Variables: General'],['C20'],"An Adaptive, Rate-Optimal Test of a Parametric Mean-Regression Model against a Nonparametric Alternative",0,0,0,0,0,2001,05,01
69,3,2001-05-01,"This paper compares two different models in a common environment. The first model has liquidity constraints in that consumers save a single asset that they cannot sell short. The second model has debt constraints in that consumers cannot borrow so much that they would want to default, but is otherwise a standard complete markets model. Both models share the features that individuals are unable to completely insure against idiosyncratic shocks and that interest rates are lower than subjective discount rates. In a stochastic environment, the two models have quite different dynamic properties, with the debt constrained model exhibiting simple stochastic steady states, while the liquidity constrained model has greater persistence of shocks.","['Kehoe, Timothy J.', 'Levine, David K.']",['Incomplete Markets'],['D52'],Liquidity Constrained Markets versus Debt Constrained Markets,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,"['Hamilton, James D.']","['Single Equation Models; Single Variables: General', 'Price Level; Inflation; Deflation', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity']","['C20', 'E31', 'E24']",A Parametric Approach to Flexible Nonlinear Inference,0,0,0,0,0,2001,05,01
69,2,2001-03-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2001,03,01
69,2,2001-03-01,ECONLIT None Found,"['Zhang, Qiang', 'Ogaki, Masao']","['Criteria for Decision-Making under Risk and Uncertainty', 'Consumer Economics: Empirical Analysis', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Household Production and Intrahousehold Allocation']","['D81', 'D12', 'O15', 'D13']",Decreasing Relative Risk Aversion and Tests of Risk Sharing,0,0,0,0,0,2001,03,01
69,2,2001-03-01,ECONLIT None Found,"['Horowitz, Joel L.']",['Single Equation Models; Single Variables: General'],['C20'],Nonparametric Estimation of a Generalized Additive Model with an Unknown Link Function,0,0,0,0,0,2001,03,01
69,2,2001-03-01,ECONLIT None Found,"['Taylor, Alan M.']","['Production, Pricing, and Market Structure; Size Distribution of Firms', 'Foreign Exchange', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['L11', 'F31', 'D43']",Potential Pitfalls for the Purchasing-Power-Parity Puzzle? Sampling and Specification Biases in Mean-Reversion Tests of the Law of One Price,1,0,1,0,0,2001,03,01
69,2,2001-03-01,"Consider nonempty finite pure strategy sets S[subscript 1], . . . , S[subscript n], let S = S[subscript 1] times . . . times S[subscript n], let Omega be a finite space of ""outcomes,"" let Delta(Omega) be the set of probability distributions on Omega, and let theta: S approaches Delta(Omega) be a function. We study the conjecture that for any utility in a generic set of n-tuples of utilities on Omega there are finitely many distributions on Omega induced by the Nash equilibria of the game given by the induced utilities on S. We give a counterexample refuting the conjecture for n >= 3. Several special cases of the conjecture follow from well-known theorems, and we provide some generalizations of these results.","['McLennan, Andrew', 'Govindan, Srihari']",['Noncooperative Games'],['C72'],On the Generic Finiteness of Equilibrium Outcome Distributions in Game Forms,0,0,0,0,0,2001,03,01
69,2,2001-03-01,"We experimentally investigate the sensitivity of bidders demanding multiple units of a homogeneous commodity to the demand reduction incentives inherent in uniform price auctions. There is substantial demand reduction in both sealed bid and ascending price clock auctions with feedback regarding rivals' drop-out prices. Although both auctions have the same normal form representation, bidding is much closer to equilibrium in the ascending price auctions. We explore the behavioral process underlying these differences along with dynamic Vickrey auctions designed to eliminate the inefficiencies resulting from demand reduction in the uniform price auctions.","['Kagel, John H.', 'Levin, Dan']",['Auctions'],['D44'],Behavior in Multi-unit Demand Auctions: Experiments with Uniform Price and Dynamic Vickrey Auctions,0,0,1,0,0,2001,03,01
69,2,2001-03-01,"We identify the inefficiencies that arise when negotiation between two parties takes place in the presence of transaction costs. First, for some values of these costs it is efficient to reach an agreement but the unique equilibrium outcome is one in which agreement is never reached. Secondly, even when there are equilibria in which an agreement is reached, we find that the model always has an equilibrium in which agreement is never reached, as well as equilibria in which agreement is delayed for an arbitrary length of time. Finally, the only way in which the parties can reach an agreement in equilibrium is by using inefficient punishments for (some of) the opponent's deviations. We argue that this implies that, when the parties are given the opportunity to renegotiate out of these inefficiencies, the only equilibrium outcome that survives is the one in which agreement is never reached, regardless of the value of the transaction costs.","['Felli, Leonardo', 'Anderlini, Luca']","['Bargaining Theory; Matching Theory', 'Organizational Behavior; Transaction Costs; Property Rights']","['C78', 'D23']",Costly Bargaining and Renegotiation,0,0,0,0,0,2001,03,01
69,2,2001-03-01,"We study a two-person bargaining problem in which the buyer may invest and increase his valuation of the object before bargaining. We show that if all offers are made by the seller and the time between offers is small, then the buyer invests efficiently and the seller extracts all of the surplus. Hence, bargaining with frequently repeated offers remedies the hold-up problem even when the agent who makes the relation-specific investment has no bargaining power and contracting is not possible. We consider alternative formulations with uncertain gains from trade or two-sided investment.","['Gul, Faruk']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",Unobservable Investment and the Hold-Up Problem,0,0,0,0,0,2001,03,01
69,2,2001-03-01,"The ready-to-eat cereal industry is characterized by high concentration, high price-cost margins, large advertising-to-sales ratios, and numerous introductions of new products. Previous researchers have concluded that the ready-to-eat cereal industry is a classic example of an industry with nearly collusive pricing behavior and intense nonprice competition. This paper empirically examines this conclusion. In particular, I estimate price-cost margins, but more importantly I am able empirically to separate these margins into three sources: (i) that which is due to product differentiation; (ii) that which is due to multi-product firm pricing; and (iii) that due to potential price collusion. The results suggest that given the demand for different brands of cereal, the first two effects explain most of the observed price-cost margins. I conclude that prices in the industry are consistent with noncollusive pricing behavior, despite the high price-cost margins. Leading firms are able to maintain a portfolio of differentiated products and influence the perceived product quality. It is these two factors that lead to high price-cost margins.","['Nevo, Aviv']","['Oligopoly and Other Imperfect Markets', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Food; Beverages; Cosmetics; Tobacco; Wine and Spirits']","['L13', 'L11', 'L66']",Measuring Market Power in the Ready-to-Eat Cereal Industry,1,0,0,0,0,2001,03,01
69,2,2001-03-01,"This paper suggests a behavioral definition of (subjective) ambiguity in an abstract setting where objects of choice are Savage-style acts. Then axioms are described that deliver probabilistic sophistication of preference on the set of unambiguous acts. In particular, both the domain and the values of the decision-maker's probability measure are derived from preference. It is argued that the noted result also provides a decision-theoretic foundation for the Knightian distinction between risk and ambiguity.","['Epstein, Larry G.', 'Zhang, Jiankang']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Subjective Probabilities on Subjectively Unambiguous Events,0,0,0,0,0,2001,03,01
69,1,2001-01-01,ECONLIT None Found,"['Gordon, Robert J.']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2000 REPORT OF THE TREASURER.",0,0,0,0,0,2001,01,01
69,1,2001-01-01,ECONLIT None Found,"['Gordon, Julie P.']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2000.",0,0,0,0,0,2001,01,01
69,1,2001-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2001,01,01
69,1,2001-01-01,ECONLIT None Found,"['Nielsen, Bent']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],The Asymptotic Distribution of Unit Root Tests of Unstable Autoregressive Processes,0,0,0,0,0,2001,01,01
69,1,2001-01-01,ECONLIT None Found,"['Todd, Petra', 'Van der Klaauw, Wilbert', 'Hahn, Jinyong']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Model Construction and Estimation']","['C21', 'C51']",Identification and Estimation of Treatment Effects with a Regression-Discontinuity Design,0,0,0,0,0,2001,01,01
69,1,2001-01-01,"We prove a Folk Theorem for asynchronously repeated games in which the set of players who may not be able to change their actions simultaneously. We impose a condition, the finite periods of inaction (FPI) condition, which requires that the number of periods in which every player has at least one opportunity to move is bounded. Given the FPI condition together with the standard nonequivalent utilities (NEU) condition, we show that every feasible and strictly individually rational payoff vector can be supported as a subgame perfect equilibrium outcome of an asynchronously repeated game.","['Yoon, Kiho']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],A Folk Theorem for Asynchronously Repeated Games,0,0,0,0,0,2001,01,01
69,1,2001-01-01,"We study a coordination game with randomly changing payoffs and small frictions in changing actions. Using only backwards induction, we find that players must coordinate on the risk-dominant equilibrium. More precisely, a continuum of fully rational players are randomly matched to play a symmetric 2 x 2 game. The payoff matrix changes according to a random walk. Players observe these payoffs and the population distribution of actions as they evolve. The game has frictions: opportunities to change strategies arrive from independent random processes, so that the players are locked into their actions for some time. As the frictions disappear, each player ignores what the others are doing and switches at her first opportunity to the risk-dominant action. History dependence emerges in some cases when frictions remain positive.","['Burdzy, Krzysztof', 'Pauzner, Ady', 'Frankel, David M.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games']","['C73', 'C72']",Fast Equilibrium Selection by Rational Players Living in a Changing World,0,0,0,0,0,2001,01,01
69,1,2001-01-01,"An asymptotic theory is developed for nonlinear regression with integrated processes. The models allow for nonlinear effects from unit root time series and therefore deal with the case of parametric nonlinear cointegration. The theory covers integrable and asymptotically homogeneous functions. Sufficient conditions for weak consistency are given and a limit distribution theory is provided. The rates of convergence depend on the properties of the nonlinear regression function, and are shown to be as slow as n[superscript 1/4] for integrable functions, and to be generally polynomial in n[superscript 1/2] for homogeneous functions. For regressions with integrable functions, the limiting distribution theory is mixed normal with mixing variates that depend on the sojourn time of the limiting Brownian motion of the integrated process.","['Phillips, Peter C. B.', 'Park, Joon Y.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Nonlinear Regressions with Integrated Time Series,0,0,0,0,0,2001,01,01
69,1,2001-01-01,"The fiscal theory says that the price level is determined by the ratio of nominal debt to the present value of real primary surpluses. The maturity structure of the debt matters in this theory. For example, it determines whether news of future deficits implies current inflation or future inflation, and the long-term debt allows the government to offset surplus shocks by ex-post devaluation. In the optimal policy, the government uses fiscal operations to smooth cyclical fiscal shocks. Since policy movements react to events rather than cause them, the optimal policy produces time series that are similar to U.S. time series.","['Cochrane, John H.']","['Price Level; Inflation; Deflation', 'Fiscal Policy']","['E31', 'E62']",Long-Term Debt and Optimal Policy in the Fiscal Theory of the Price Level,0,0,0,0,0,2001,01,01
69,1,2001-01-01,"We consider discriminatory and uniform price auctions for multiple identical units of a good. Players have private values, possibly asymmetrically distributed and for multiple units. Our setting allows for aggregate uncertainty about demand and supply. In this setting, equilibria generally will be inefficient. Despite this, we show that such auctions become arbitrarily close to efficient if they are ""large,"" and use this to derive an asymptotic characterization of revenue and bidding behavior.","['Swinkels, Jeroen M.']",['Auctions'],['D44'],Efficiency of Large Private Value Auctions,0,0,1,0,0,2001,01,01
69,1,2001-01-01,"The paper first develops an economic analysis of the concept of shareholder value, describes its approach, and discusses some open questions. It emphasizes the relationship between pledgeable income, monitoring, and control rights using a unifying and simple framework. The paper then provides a first and preliminary analysis of the concept of the stakeholder society. It investigates whether the managerial incentives and the control structure described in the first part can be modified so as to promote the stakeholder society. It shows that the implementation of the stakeholder society strikes three rocks: dearth of pledgeable income, deadlocks in decision-making, and lack of clear mission for management. While it fares better than the stakeholder society on those three grounds, shareholder value generates biased decision-making; the paper analyzes the costs and benefits of various methods of protecting noncontrolling stakeholders: covenants, exit options, flat claims, enlarged fiduciary duty.","['Tirole, Jean']","['Mergers; Acquisitions; Restructuring; Voting; Proxy Contests; Corporate Governance', 'Capitalist Systems: Political Economy', 'Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill']","['G34', 'P16', 'G32']",Corporate Governance,0,0,0,0,1,2001,01,01
86,4,2018-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2018,07,01
86,4,2018-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,07,01
86,3,2018-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,05,01
68,6,2000-11-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2000,11,01
68,6,2000-11-01,ECONLIT None Found,"['Benhabib, Jess', 'Nishimura, Kazuo', 'Meng, Qinglai']","['One, Two, and Multisector Growth Models']",['O41'],Indeterminacy under Constant Returns to Scale in Multisector Economies,0,0,0,0,0,2000,11,01
68,6,2000-11-01,ECONLIT None Found,"['Shannon, Chris', 'Brown, Donald J.']",['Exchange and Production Economies'],['D51'],"Uniqueness, Stability, and Comparative Statics in Rationalizable Walrasian Markets",0,0,0,0,0,2000,11,01
68,6,2000-11-01,ECONLIT None Found,"['Hall, Alastair R.']",['Estimation: General'],['C13'],Covariance Matrix Estimation and the Power of the Overidentifying Restrictions Test,0,0,0,0,0,2000,11,01
68,6,2000-11-01,ECONLIT None Found,"['Lai, Tze Leung', 'Brezzi, Monica']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Notes and Comments: Incomplete Learning from Endogenous Data in Dynamic Allocation,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"We investigate the effect of introducing costs of complexity in the n-person unanimity game. Without complexity costs, every individually rational outcome is sustainable as a subgame perfect equilibrium for n > 2 and for sufficiently patient players. We study a notion of complexity involving length of memory and modify the Nash equilibrium concept to include complexity costs lexicographically after the standard payoffs. We find there must be, in equilibrium, no agreement or agreement on any non-wasteful, feasible division by period n. This helps us establish that equilibrium strategies must be stationary, and the subgame perfect allocation unique.","['Sabourian, Hamid', 'Chatterjee, Kalyan']",['Bargaining Theory; Matching Theory'],['C78'],Multiperson Bargaining and Strategic Complexity,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"We introduce a consistent nonparametric Granger-causality test for covariance stationary processes under, possibly, the presence of long-range dependence which has power against alternatives converging at the rate T[superscript -1/2]. Since the test is based on estimates of the parameters of the representation of a VAR model as a two sided infinite distributed lag model, we first show that a modification of Hannan's (1967) estimator is root-T consistent and asymptotically normal for the coefficients of the representation. Under long-range dependence this estimator becomes more attractive than Least Squares since the latter may not share the aforementioned two properties.","['Hidalgo, Javier']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Nonparametric Test for Causality with Long-Range Dependence,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"We derive the asymptotic sampling distribution of various estimators of indices of poverty, welfare, and inequality, and of the curves used to infer stochastic dominance of any order. We also derives the sampling distribution of the maximal poverty lines up to which poverty is greater in one distribution than in another, as also of convenient dual estimators for the measurement of poverty. The statistical results are established for deterministic or stochastic poverty lines, as well as for paired or independent samples of incomes. Our results are illustrated using data from the Luxemburg Income Study.","['Davidson, Russell', 'Duclos, Jean-Yves']","['Measurement and Analysis of Poverty', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['I32', 'D63']",Statistical Inference for Stochastic Dominance and for the Measurement of Poverty and Inequality,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"We give a characterization of the set of group-strategyproof, Pareto-optimal, and reallocation-proof allocation rules for the assignment problem, where individuals are assigned at most one indivisible object, without any medium of exchange. Although there are no property rights in the model, the rules satisfying the above criteria imitate a trading procedure with individual endowments, in which individuals exchange objects from their hierarchically determined endowment sets in an iterative manner. In particular, these assignment rules generalize Gale's top trading cycle procedure, the classical rule for the model in which each individual owns an indivisible good.","['Papai, Szilvia']",['Bargaining Theory; Matching Theory'],['C78'],Strategyproof Assignment by Hierarchical Exchange,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"This paper is concerned with asymptotic properties on the accuracy of numerical solutions. It is shown that the approximation error of the policy function is of the same order of magnitude as the size of the Euler equation residuals. Moreover, for bounding this approximation error the most relevant parameters are the discount factor and the curvature of the return function. These findings provide theoretical foundations for the construction of tests to assess the performance of alternative computational methods.","['Santos, Manuel S.']",['Computational Techniques; Simulation Modeling'],['C63'],Accuracy of Numerical Solutions Using the Euler Equation Residuals,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"In the setting of ""affine"" jump-diffusion state processes, this paper provides an analytical treatment of a class of transforms, including various Laplace and Fourier transforms, that allow an analytical treatment of a range of valuation and econometric problems. Example applications include fixed-income pricing models, with a role for intensity-based models of default, and a wide range of option-pricing applications. An illustrative example examines the implications of stochastic volatility and jumps for option valuation. This example highlights the impact on option ""smirks"" of the joint distribution of jumps in volatility and jumps in the underlying asset price, through both jump amplitude and jump timing.","['Duffie, Darrell', 'Singleton, Kenneth', 'Pan, Jun']","['Contingent Pricing; Futures Pricing; option pricing', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['G13', nan]",Transform Analysis and Asset Pricing for Affine Jump-Diffusions,0,0,0,0,0,2000,11,01
68,6,2000-11-01,"Blume and Easley (1992) show that if agents' have the same savings rule, those who maximize the expected logarithm of next period's outcomes will eventually hold all wealth (i.e. are ""most prosperous""). However, if no agent adopts this rule then the most prosperous are not necessarily those who make the most accurate predictions. Thus, agents who make inaccurate predictions need not be driven out of the market. In this paper, it is shown that, among agents who have the same intertemporal discount factor (and who choose savings endogenously), the most prosperous are those who make accurate predictions. Hence, convergence to rational expectations obtains because agents who make inaccurate predictions are driven out of the market.","['Sandroni, Alvaro']",['Expectations; Speculations'],['D84'],Do Markets Favor Agents Able to Make Accurate Predictions?,0,0,0,0,0,2000,11,01
68,5,2000-09-01,ECONLIT None Found,"['Rabin, Matthew']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Risk Aversion and Expected-Utility Theory: A Calibration Theorem,0,0,0,0,0,2000,09,01
68,5,2000-09-01,ECONLIT None Found,"['Phillips, C. B.', 'Park, Joon Y.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C25', 'C22']",Nonstationary Binary Choice,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"This paper examines Markov perfect equilibria of general, finite state stochastic games. Our main result is that the number of such equilibria is finite for a set of stochastic game payoffs with full Lebesgue measure. We further discuss extensions to lower dimensional stochastic games like the alternating move game.","['Lagunoff, Roger', 'Haller, Hans']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Genericity and Markovian Behavior in Stochastic Games,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"We present an approach to network formation based on the notion that social networks are formed by individual decisions that trade off the costs of forming and maintaining links against the potential rewards from doing so. We suppose that a link with another agent allows access, in part and in due course, to the benefits available to the latter via his own links. Thus individual links generate externalities whose value depends on the level of decay/delay associated with indirect links. A distinctive aspect of our approach is that the costs of link formation are incurred only by the person who initiates the link. This allows us to formulate the network formation process as a noncooperative game. We first provide a characterization of the architecture of equilibrium networks. We then study the dynamics of network formation. We find that individual efforts to access benefits offered by others lead, rapidly, to the emergence of an equilibrium social network, under a variety of circumstances. The limiting networks have simple architectures, e.g., the wheel, the star, or generalizations of these networks. In many cases, such networks are also socially efficient.","['Goyal, Sanjeev', 'Bala, Venkatesh']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Noncooperative Games']","['D83', 'C72']",A Noncooperative Model of Network Formation,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"We construct a quantitative equilibrium model with firms setting prices in a staggered fashion and use it to ask whether monetary shocks can generate business cycle fluctuations. These fluctuations include persistent movements in output along with the other defining features of business cycles, like volatile investment and smooth consumption. We assume that prices are exogenously sticky for a short time. Persistent output fluctuations require endogenous price stickiness in the sense that firms choose not to change prices much when they can do so. We find that for a wide range of parameter values, the amount of endogenous stickiness is small. Thus, we find that in a standard quantitative model, staggered price-setting, alone, does not generate business cycle fluctuations.","['Chari, V. V.', 'Kehoe, Patrick J.', 'McGrattan, Ellen R.']","['Business Fluctuations; Cycles', 'Price Level; Inflation; Deflation', 'Money Supply; Credit; Money Multipliers']","['E32', 'E31', 'E51']",Sticky Price Models of the Business Cycle: Can the Contract Multiplier Solve the Persistence Problem?,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"We propose a new and simple adaptive procedure for playing a game: ""regret-matching."" In this procedure, players may depart from their current play with probabilities that are proportional to measures of regret for not having used other strategies in the past. It is shown that our adaptive procedure guarantees that, with probability one, the empirical distributions of play converge to the set of correlated equilibria of the game.","['Hart, Sergiu', 'Mas-Colell, Andreu']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'C72', 'D83']",A Simple Adaptive Procedure Leading to Correlated Equilibrium,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"Data snooping occurs when a given set of data is used more than once for purposes of inference or model selection. When such data reuse occurs, there is always the possibility that any satisfactory results obtained may simply be due to chance rather than to any merit inherent in the method yielding the results. This problem is practically unavoidable in the analysis of time-series data, as typically only a single history measuring a given phenomenon of interest is available for analysis. It is widely acknowledged by empirical researchers that data snooping is a dangerous practice to be avoided, but in fact it is endemic. The main problem has been a lack of sufficiently simple practical methods capable of assessing the potential dangers of data snooping in a given situation. Our purpose here is to provide such methods by specifying a straightforward procedure for testing the null hypothesis that the best model encountered in a specification search has no predictive superiority over a given benchmark model. This permits data snooping to be undertaken with some degree of confidence that one will not mistake results that could have been generated by chance for genuinely good results.","['White, Halbert']","['Forecasting Models; Simulation Methods', 'Econometric and Statistical Methods and Methodology: General', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C53', 'C10', nan]",A Reality Check for Data Snooping,0,0,0,0,0,2000,09,01
68,5,2000-09-01,This paper develops asymptotic distribution theory for GMM estimators and test statistics when some or all of the parameters are weakly identified. General results are obtained and are specialized to two important cases: linear instrumental variables regression and Euler equations estimation of the CCAPM. Numerical results for the CCAPM demonstrate that weak-identification asymptotics explains the breakdown of conventional GMM procedures documented in previous Monte Carlo studies. Confidence sets immune to weak identification are proposed. We use these results to inform an empirical investigation of various CCAPM specifications; the substantive conclusions reached differ from those obtained using conventional methods.,"['Wright, Jonathan H.', 'Stock, James H.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C30', nan]",GMM with Weak Identification,0,0,0,0,0,2000,09,01
68,5,2000-09-01,"The supply and price of skilled labor relative to unskilled labor have changed dramatically over the postwar period. The relative quantity of skilled labor has increased substantially, and the skill premium, which is the wage of skilled labor relative to that of unskilled labor, has grown significantly since 1980. Many studies have found that accounting for the increase in the skill premium on the basis of observable variables is difficult and have concluded implicitly that latent skill-biased technological change must be the main factor responsible. This paper examines that view systematically. We develop a framework that provides a simple, explicit economic mechanism for understanding skill-biased technological change in terms of observable variables, and we use the framework to evaluate the fraction of variation in the skill premium that can be accounted for by changes in observed factor quantities. We find that with capital-skill complementarity, changes in observed inputs alone can account for most of the variations in the skill premium over the last 30 years.","['Krusell, Per']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Employment; Unemployment; Wages; Intergenerational Income Distribution; Aggregate Human Capital; Aggregate Labor Productivity', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Aggregate Factor Income Distribution']","['J24', 'E24', 'O33', 'E25']",Capital-Skill Complementarity and Inequality: A Macroeconomic Analysis,0,0,0,1,0,2000,09,01
68,4,2000-07-01,ECONLIT None Found,[nan],[nan],[nan],Announcements: The 2000 Frisch Medal Award.,0,0,0,0,0,2000,07,01
68,4,2000-07-01,ECONLIT None Found,"['Vogelsang, Timothy J.', 'Zambrano, Eduardo']","['Macroeconomics: Consumption; Saving; Wealth', 'Consumer Economics: Theory']","['E21', 'D11']",A Simple Test of the Law of Demand for the United States,0,0,0,0,0,2000,07,01
68,4,2000-07-01,ECONLIT None Found,"['Pepper, John V.', 'Manski, Charles F.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Construction and Estimation', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['C30', 'C51', 'J24']",Monotone Instrumental Variables: With an Application to the Returns to Schooling,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"This paper introduces a new notion of consistency for social choice functions, called self-selectivity, which requires that a social choice function employed by a society to make a choice from a given alternative set should choose itself from among other rival such functions when it is employed by the society to make this latter choice as well. A unanimous and neutral social choice function turns out to be universally self-selective if and only if it is dictatorial. Moreover, universal self-selectivity for such functions is equivalent to the conjunction of strategy-proofness and independence of irrelevant alternatives.","['Koray, Semih']",['Social Choice; Clubs; Committees; Associations'],['D71'],Self-Selective Social Choice Functions Verify Arrow and Gibbard-Satterthwaite Theorems,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"A valid Edgeworth expansion is established for the limit distribution of density-weighted semiparametric averaged derivative estimates of single index models. The leading term that corrects the normal limit varies in magnitude, depending on the choice of bandwidth and kernel order. A valid empirical Edgeworth expansion is also established. We also provide theoretical and empirical Edgeworth expansions for a studentized statistic, where the correction terms are different from those for the unstudentized case. Optimal bandwidth choices which minimize the normal approximation error are derived based on these expansions. We report a Monte Carlo study of finite sample performance.","['Nishiyama, Y.', 'Robinson, P. M.']",['Single Equation Models; Single Variables: General'],['C20'],Edgeworth Expansions for Semiparametric Averaged Derivatives,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"This paper studies the monotonicity of demand using the indirect utility function. It identifies sufficient and necessary conditions on an agent's indirect utility function which guarantee that he has a monotonic demand. These conditions point to a natural way of extending Hildenbrand's result, which says that market demand is monotonic if the income distribution has a downward sloping density function (even though agents' demand may individually violate monotonicity). Using the indirect utility function, a measure of violations of individual monotonicity is introduced, conditional upon which a larger class of density functions generating a monotonic market demand is identified.","['Quah, John K.-H.']",['Consumer Economics: Theory'],['D11'],The Monotonicity of Individual and Market Demand,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"This paper analyzes a dynamic model of an employment relation in which individual workers enjoy some bargaining power. The main elements are that the employment contracts are non-binding and that the firm has opportunities to replace workers. Equilibrium analysis yields the following results. The unique stationary equilibrium exhibits inefficient over-employment and the steady state wages coincide with the workers' reservation wage. It confirms earlier results derived by Stole and Zwiebel (1996) in the context of a static model. In contrast, the profit maximizing equilibrium outcome is nearly efficient and the wage exhibits a mark-up over the reservation wage.","['Wolinsky, Asher']","['Labor Contracts', 'Firm Behavior: Theory']","['J41', 'D21']",A Theory of the Firm with Non-binding Employment Contracts,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"We consider identification and estimation in panel data discrete choice models when the explanatory variable set includes strictly exogenous variables, lags of the endogenous dependent variable as well as unobservable individual-specific effects. For the logit specification we propose an estimator that is consistent and asymptotically normal, although its rate of convergence is slower than the inverse of the square root of the sample size. In the semiparametric case the proposed estimator is shown to be consistent.","['Honore, Bo E.', 'Kyriazidou, Ekaterini']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C23', 'C25']",Panel Data Discrete Choice Models with Lagged Dependent Variables,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"Consider strategic risk-neutral traders competing in schedules to supply liquidity to a risk-averse agent who is privately informed about the value of the asset and his hedging needs. Imperfect competition in this common value environment is analyzed as a multi-principal game in which liquidity suppliers offer trading mechanisms in a decentralized way. There exists a unique equilibrium in convex schedules. Liquidity suppliers charge positive mark-ups and make positive expected profits when their number goes to infinity, ask (resp. bid) prices converge towards the upper (resp. lower) tail expectations obtained in Glosten (1994) and expected profits are zero.","['Martimort, David', 'Biais, Bruno', 'Rochet, Jean-Charles']","['General Financial Markets: General (includes Measurement and Data)', 'Asymmetric and Private Information; Mechanism Design']","[nan, 'D82']",Competing Mechanisms in a Common Value Environment,0,0,0,0,0,2000,07,01
68,4,2000-07-01,"We study an equilibrium concept for the environment in Kehoe and Levine (1993) and Kocherlakota (1996) that has complete sequential markets and endogenous solvency constraints, which prevent default at the cost of reducing risk sharing. We show the welfare theorems; characterize the preferences and endowments that lead to equilibria with incomplete risk sharing; compare the pricing kernel with the one for economies without participation constraints: interest rates are lower and risk premia depend on the covariance of the idiosyncratic and aggregate shocks; and show that asset prices depend only on the valuation of agents with substantial idiosyncratic risk.","['Alvarez, Fernando', 'Jermann, Urban J.']","['General Equilibrium and Disequilibrium: General', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Financial Markets and the Macroeconomy']","['D50', nan, 'E44']","Efficiency, Equilibrium, and Asset Pricing with Risk of Default",0,0,0,0,0,2000,07,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 2000 North American Winter Meeting of the Econometric Society.,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],Fellows of the Econometric Society.,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],1999 Election of Fellows to the Econometric Society.,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,"['Ravikumar, B.', 'Savin, N. Eugene', 'Ray, Surajit']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Robust Wald Tests in SUR Systems with Adding-Up Restrictions,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,"['Vogelsang, Timothy J.', 'Bunzel, Helle', 'Kiefer, Nicholas M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C22', 'C21']",Simple Robust Testing of Regression Hypotheses,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,"['Billot, Antoine']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Sharing Beliefs: Between Agreeing and Disagreeing,0,0,0,0,0,2000,05,01
68,3,2000-05-01,"In a rationing problem, agents demand a quantity of a single commodity and the available resources fall short of total demand. We impose four axioms: Consistency--with respect to variations of the set of agents, Upper and Lower Composition--with respect to variations of the available resources, and Scale Invariance. Only three symmetric methods meet all four axioms: proportional, uniform gains and uniform losses. The asymmetric methods partition the agents into priority classes; within each class, they use either the proportional method or a weighted version of the uniform gains or uniform losses methods.","['Moulin, Herve']","['Rationing; Licensing', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D45', 'D63']",Priority Rules and Other Asymmetric Rationing Methods,0,0,1,0,0,2000,05,01
68,3,2000-05-01,"This paper examines the abilities of learning models to describe subject behavior in a new experiment and in earlier experiments by other researchers. Experimental data are compared with the predictions of Nash equilibrium, a reinforcement-based model, and a class of belief-based models. We examine several criteria for quantitatively comparing the models. According to almost all of these criteria, both types of learning model outperform equilibrium. According to some criteria, the reinforcement-based model outperforms the belief-based model; according to others, the belief-based model performs better.","['Feltovich, Nick']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Asymmetric and Private Information; Mechanism Design', 'Noncooperative Games']","['D83', 'D82', 'C72']",Reinforcement-Based vs. Belief-Based Learning Models in Experimental Asymmetric-Information Games,0,0,0,0,0,2000,05,01
68,3,2000-05-01,This paper develops a statistical theory for threshold estimation in the regression context. We allow for either cross-section or time series observations. Least squares estimation of the regression parameters is considered. An asymptotic distribution theory for the regression estimates (the threshold and the regression slopes) is developed. It is found that the distribution of the threshold estimate is non-standard. A method to construct asymptotic confidence intervals is developed by inverting the likelihood ratio statistic. It is shown that this yields asymptotically conservative confidence regions.,"['Hansen, Bruce E.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Empirical Studies of Economic Growth; Aggregate Productivity; Cross-Country Output Convergence']","['C21', 'O47']",Sample Splitting and Threshold Estimation,0,0,0,0,0,2000,05,01
68,3,2000-05-01,"This paper proposes a general and computationally convenient estimation procedure for the structural analysis of auction data. Considering first-price sealed-bid auction models within the independent private value paradigm, we show that the underlying distribution of bidders' private values is identified from observed bids and the number of actual bidders without parametric assumptions. Using minimax theory, we establish the best rate of uniform convergence at which the density of private values can be estimated nonparametrically from available data. We then propose a two-step kernel-based estimator that converges at the optimal rate.","['Vuong, Quang', 'Guerre, Emmanuel', 'Perrigne, Isabelle']","['Auctions', 'Model Construction and Estimation']","['D44', 'C51']",Optimal Nonparametric Estimation of First-Price Auctions,0,0,1,0,0,2000,05,01
68,2,2000-03-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 54th European Meeting of the Econometric Society.,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,[nan],[nan],[nan],Program of the XVII Latin American Meeting of the Econometric Society.,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,[nan],[nan],[nan],Announcements: Nomination of Fellows.,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,"['Hens, Thorsten']",['Exchange and Production Economies'],['D51'],Do Sunspots Matter When Spot Market Equilibria Are Unique?,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,"['Kajii, Atsushi', 'Polak, Ben', 'Grant, Simon']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Criteria for Decision-Making under Risk and Uncertainty']","['D15', 'D81']",Temporal Resolution of Uncertainty and Recursive Non-expected Utility Models,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,"['Davidson, James', 'de Jong, Robert M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C22', 'C14', 'C21']",Consistency of Kernel Estimators of Heteroscedastic and Autocorrelated Covariance Matrices,0,0,0,0,0,2000,03,01
68,2,2000-03-01,ECONLIT None Found,"['Andrews, Donald W. K.']","['Estimation: General', 'Semiparametric and Nonparametric Methods: General']","['C13', 'C14']",Inconsistency of the Bootstrap When a Parameter Is on the Boundary of the Parameter Space,0,0,0,0,0,2000,03,01
68,2,2000-03-01,"This paper explores how Bayes-rational individuals learn sequentially from the discrete actions of others. Unlike earlier informational herding papers, we admit heterogeneous preferences. Not only may type-specific ""herds"" eventually arise, but a new robust possibility emerges: ""confounded learning"". Beliefs may converge to a limit point where history offers no decisive lessons for anyone, and each type's actions forever nontrivially split between two actions. To verify that our identified limit outcomes do arise, we exploit the Markov-martingale character of beliefs. Learning dynamics are stochastically stable near a fixed point in many Bayesian learning models like this one.","['Smith, Lones', 'Sorensen, Peter']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Pathological Outcomes of Observational Learning,0,0,0,0,0,2000,03,01
68,2,2000-03-01,"In Becker's (1973) neoclassical marriage market model, matching is positively assortative if types are complements: i.e. match output is supermodular. We reprise this famous result assuming time-intensive partner search and transferable output. We prove existence of a search equilibrium with a continuum of types, and then characterize matching.","['Smith, Lones', 'Shimer, Robert']",['Bargaining Theory; Matching Theory'],['C78'],Assortative Matching and Search,0,0,0,0,0,2000,03,01
68,2,2000-03-01,"In a public good environment with positively correlated types, we characterize optimal mechanisms when agents have private information and can enter collusive agreements. First, we prove a weak-collusion-proof principle according to which there is no restriction for the principal in offering weak-collusion-proof mechanisms. Second, with this principle, we characterize the set of allocations that satisfy individual and coalitional incentive constraints. The optimal weakly collusion-proof mechanism calls for distortions away from first-best efficiency obtained without collusion. Allowing collusion restores continuity between the correlated and the uncorrelated environments. When the correlation becomes almost perfect, first-best efficiency is approached. Finally, the optimal collusion-proof mechanism is strongly ratifiable.","['Martimort, David', 'Laffont, Jean-Jacques']","['Public Goods', 'Asymmetric and Private Information; Mechanism Design', 'Cooperative Games']","['H41', 'D82', 'C71']",Mechanism Design with Collusion and Correlation,0,0,0,0,0,2000,03,01
68,2,2000-03-01,"Option theory predicts that mortgage prepayment or default will be exercised by homeowners if the call or put option is sufficiently ""in the money."" This analysis: tests the extent to which the option approach explains default and prepayment behavior; evaluates the importance of modeling both options simultaneously; and models the unobserved heterogeneity of mortgage holders. The paper presents a unified model of the competing risks of mortgage termination, considering the hazards as dependent competing risks, estimated jointly. It also accounts for the unobserved heterogeneity among borrowers, and estimates the unobserved heterogeneity simultaneously with the prepayment and default functions.","['Quigley, John M.', 'Van Order, Robert', 'Deng, Yongheng']","['Banks; Depository Institutions; Micro Finance Institutions; Mortgages', 'Contingent Pricing; Futures Pricing; option pricing']","['G21', 'G13']","Mortgage Terminations, Heterogeneity and the Exercise of Mortgage Options",0,0,0,0,0,2000,03,01
68,2,2000-03-01,"This paper reviews research on the welfare cost of inflation. New estimates are provided, based on U.S. time series for 1900-94, interpreted in a variety of ways. It is estimated that the gain from reducing the annual inflation rate from 10 percent to zero is equivalent to an increase in real income of slightly less than one percent. Using aggregate evidence only, it may not be possible to estimate reliably the gains from reducing inflation to a rate consistent with zero nominal interest.","['Lucas, Robert E., Jr.']","['Price Level; Inflation; Deflation', 'Demand for Money', 'Monetary Policy']","['E31', 'E41', 'E52']",Inflation and Welfare,0,0,0,0,0,2000,03,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1999 Australasian Meeting of the Econometric Society.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1999 Far Eastern Meeting of the Econometric Society.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1999 North American Summer Meeting of the Econometric Society.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Treasurer.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Secretary.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Announcement: Nomination of Fellows.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Econometrica Referees.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,"['Rauch, Bernhard']","['Monetary Systems; Standards; Regimes; Government and the Monetary System; Payment Systems', 'Monetary Policy']","['E42', 'E52']",A Divisible Search Model of Fiat Money: A Comment,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,"['Persico, Nicola']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",Information Acquisition in Auctions,0,0,1,0,0,2000,01,01
68,1,2000-01-01,"The paper analyzes choice-theoretic costly enforcement in an intertemporal contracting model with a differentially informed investor and entrepreneur. An intertemporal contract is modeled as a mechanism with limited commitment to payment and enforcement decisions. The paper shows that simple debt is the optimal contract when commitment is limited and costly enforcement is a decision variable. In contrast, stochastic contracts are optimal when agents can commit to the ex-ante optimal decisions. The paper also shows that the Costly State Verification model can be viewed as a reduced form of an enforcement model.","['Krasa, Stefan', 'Villamil, Anne P.']",['Transactional Relationships; Contracts and Reputation; Networks'],['L14'],Optimal Contracts When Enforcement Is a Decision Variable,1,0,0,0,0,2000,01,01
68,1,2000-01-01,"A complete information bargaining model is amended to accommodate ""irrational types"" who are inflexible in their offers and demands. An ""independence of procedures"" result is derived: the bargaining outcome is independent of the details of the bargaining protocol if players can make offers frequently. In the limiting continuous-time game, equilibrium is unique, and entails delay, consequently inefficiency. As the probability of irrationality goes to zero, delay and inefficiency disappear; furthermore, if there are a rich set of types for both agents, their limit equilibrium payoffs are inversely proportional to their rates of time preference.","['Gul, Faruk', 'Abreu, Dilip']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining and Reputation,0,0,0,0,0,2000,01,01
68,1,2000-01-01,"This paper develops a new concept of separability with overlapping groups. This is shown to provide a useful empirical and theoretical framework for investigating the grouping of goods and prices. It is a generalisation of weak separability in which goods are allowed to enter more than one group and where the composition of groups is identified by the choice of group specific exclusive goods. For the Almost Ideal and Translog demand models and their generalisations, we provide a method for choosing the number of separable groups. A detailed method for exploring the composition of the separable groups is also presented.","['Blundell, Richard', 'Robin, Jean-Marc']","['Model Construction and Estimation', 'Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis']","['C51', 'D11', 'D12']",Latent Separability: Grouping Goods without Weak Separability,0,0,0,0,0,2000,01,01
68,1,2000-01-01,"This paper considers the problem of choosing the number of bootstrap repetitions B for bootstrap standard errors, confidence intervals, confidence regions, hypothesis tests, p-values, and bias correction. For each of these problems, the paper provides a three-step method for choosing B to achieve a desired level of accuracy. Accuracy is measured by the percentage deviation of the bootstrap standard error estimate, confidence interval length, test's critical value, test's p-value, or bias-corrected estimate based on B bootstrap simulations from the corresponding ideal bootstrap quantities for which B = infinity. The results apply to parametric, semiparametric, and nonparametric models with independent or dependent data.","['Buchinsky, Moshe', 'Andrews, Donald W. K.']",['Semiparametric and Nonparametric Methods: General'],['C14'],A Three-Step Method for Choosing the Number of Bootstrap Repetitions,0,0,0,0,0,2000,01,01
68,1,2000-01-01,A complete transactions record is defined to be ultra-high frequency data. The transaction arrival times and associated characteristics can be analyzed by marked point processes. The ACD model developed by Engle and Russell (1998) is then applied to IBM transactions data to develop semi-parametric hazard estimates and measures of conditional variances. Both returns and variances are negatively influenced by surprisingly long durations as suggested by asymmetric information models of market micro-structure.,"['Engle, Robert F.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', 'C51', nan]",The Econometrics of Ultra-High-Frequency Data,0,0,0,0,0,2000,01,01
80,2,2012-03-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2012,03,01
80,2,2012-03-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 80 Iss. 2.,0,0,0,0,0,2012,03,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 80 Iss. 1.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors of the Monograph Series.,0,0,0,0,0,2012,01,01
67,6,1999-11-01,ECONLIT None Found,[nan],[nan],[nan],"Announcements: Nomination of Fellows, 2000.",0,0,0,0,0,1999,11,01
67,6,1999-11-01,ECONLIT None Found,"['Armstrong, Mark', 'Hillier, Grant']",['Semiparametric and Nonparametric Methods: General'],['C14'],The Density of the Maximum Likelihood Estimator: Notes and Comments,0,0,0,0,0,1999,11,01
67,6,1999-11-01,"We analyze under which conditions a given vector field can be disaggregated as a linear combination of gradients. This problem is typical of aggregation theory, as illustrated by the literature on the characterization of aggregate market demand and excess demand. We argue that exterior differential calculus provides very useful tools to address these problems. In particular, we show, using these techniques, that any analytic mapping in [open letter R][superscript n] satisfying Walras Law can be locally decomposed as the sum of n individual, utility-maximizing market demand functions. In addition, we show that the result holds for arbitrary (price-dependent) income distributions, and that the decomposition can be chosen such that it varies continuously with the mapping. Finally, when income distribution can be freely chosen, then decomposition requires only n/2 agents.","['Chiappori, P. A.', 'Ekeland, I.']","['Consumer Economics: Theory', 'Index Numbers and Aggregation; Leading indicators', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['D11', 'C43', 'L11']",Aggregation and Market Demand: An Exterior Differential Calculus Viewpoint,1,0,0,0,0,1999,11,01
67,6,1999-11-01,"We study a model in which two carriers choose networks to connect cities and compete for customers. We show that if carriers compete aggressively (e.g., Bertrand-like behavior), one carrier operating a single hub-spoke network is an equilibrium outcome. Competing hub-spoke networks are not an equilibrium outcome, although duopoly equilibria in non-hub networks can exist. If carriers do not compete aggressively, a duopoly equilibrium in hubs always exists if the number of cities is not small. We provide conditions under which all equilibria consist of hub-spoke networks.","['Hendricks, Ken', 'Piccione, Michele', 'Tan, Guofu']","['Air Transportation', 'Oligopoly and Other Imperfect Markets', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['L93', 'L13', 'L11', 'D43']",Equilibria in Networks,1,0,1,0,0,1999,11,01
67,6,1999-11-01,"I provide a systematic treatment of the asymptotic properties of weighted M-estimators under variable probability stratified sampling. The characterization of the sampling scheme and representation of the objective function allow for a straightforward analysis. Simple, consistent asymptotic variance matrix estimators are proposed. When stratification is based on exogenous variables, I show that the unweighted M-estimator is more efficient than the weighted estimator under a generalized conditional information matrix equality. When population frequencies are known, a more efficient weighting is possible. I also show how the results carry over to multinomial sampling.","['Wooldridge, Jeffrey M.']","['Estimation: General', 'Single Equation Models; Single Variables: General']","['C13', 'C20']",Asymptotic Properties of Weighted M-Estimators for Variable Probability Samples,0,0,0,0,0,1999,11,01
67,6,1999-11-01,"This paper establishes the asymptotic distribution of extremum estimators when the true parameter lies on the boundary of the parameter space. The boundary may be linear, curved, and/or kinked. Typically the asymptotic distribution is a function of a multivariate normal distribution in models without stochastic trends and a function of a multivariate Brownian motion in models with stochastic trends. The results apply to a wide variety of estimators and models. Examples treated in the paper are: (1) quasi-ML estimation of a random coefficients regression model with some coefficient variances equal to zero and (2) LS estimation of an augmented Dickey-Fuller regression with unit root and time trend parameters on the boundary of the parameter space.","['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Estimation When a Parameter Is on a Boundary,0,0,0,0,0,1999,11,01
67,6,1999-11-01,"In this paper, we structurally estimate a sequential model of high school attendance and work decisions. The estimates imply that youths who drop out of high school have different traits than those who graduate, e.g., they have lower school ability and/or motivation, lower expectations about the rewards from graduation, and a comparative advantage at jobs that are done by non-graduates. We also found that working while in school reduces school performance. However, policy experiments indicate that even a complete prohibition on working would have a limited impact on the high school graduation rates of white males.","['Wolpin, Kenneth I.', 'Eckstein, Zvi']","['Fertility; Family Planning; Child Care; Children; Youth', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Education and Research Institutions: General']","['J13', 'J24', 'I20']",Why Youths Drop out of High School:,0,0,0,0,0,1999,11,01
67,6,1999-11-01,"The intertemporal labor force participation of married women is analyzed using a dynamic search framework. Maximum simulated likelihood (MSL) estimation is used to estimate dynamic Probit models, and the sensitivity to alternative assumptions examined using Linear Probability models. Participation decisions are characterized by significant positive state dependence, unobserved heterogeneity, and negatively correlated errors. The hypothesis that women's participation is exogenous to their fertility decisions is rejected when dynamics are ignored, but there is no evidence against this hypothesis in dynamic specifications. Women's participation response is stronger to permanent than current non-labor income, reflecting unobserved taste factors.","['Hyslop, Dean R.']","['Time Allocation and Labor Supply', 'Economics of Gender; Non-labor Discrimination', 'Model Construction and Estimation', 'Fertility; Family Planning; Child Care; Children; Youth']","['J22', 'J16', 'C51', 'J13']","State Dependence, Serial Correlation and Heterogeneity in Intertemporal Labor Force Participation of Married Women",0,0,0,0,0,1999,11,01
67,5,1999-09-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"Bidding is studied in first-price common value auctions where an insider is better informed than other bidders (outsiders). As in symmetric information structure (SIS) auctions, inexperienced outsiders suffer from a strong winner's curse. Super-experienced bidders, who have largely overcome the winner's curse, satisfy the comparative static predictions of the theory (i) An insider increases average seller's revenue compared to SIS auctions, (ii) insiders make substantially greater profits than outsiders, and (iii) more rivals cause insiders to bid higher. Changes in insiders' bids are consistent with directional learning theory (Selten and Buchta, 1994).","['Kagel, John H.', 'Levin, Dan']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",Common Value Auctions with Insider Information,0,0,1,0,0,1999,09,01
67,5,1999-09-01,"This paper defines a general equilibrium model with exchange and club formation. Agents trade multiple private goods widely in the market, can belong to several clubs, and care about the characteristics of the other members of their clubs. The space of agents is a continuum, but clubs are finite. It is shown that (i) competitive equilibria exist, and (ii) the core coincides with the set of equilibrium states. The central subtlety is in modeling club memberships and expressing the notion that membership choices are consistent across the population.","['Ellickson, Bryan']","['Social Choice; Clubs; Committees; Associations', 'Exchange and Production Economies', 'Public Goods']","['D71', 'D51', 'H41']",Clubs and the Market,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"This paper provides an axiomatic foundation for decision making in complex settings in which the decision maker does not have complete structural knowledge of the environment. The agent knows the set of actions he can take, he formulates preferences directly on the actions, and chooses according to these preferences. On the basis of experience he modifies these preferences according to a systematic procedure. A group of natural structural restrictions and a group of independence axioms are imposed on this procedure. The main result is an axiomatic foundation for a set of simple adaptive learning procedures which include the replicator dynamic.","['Easley, David', 'Rustichini, Aldo']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D81', 'D83']",Choice without Beliefs,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"We show how to correctly extend known methods for generating error bands in reduced form VAR's to overidentified models. We argue that the conventional pointwise bands common in the literature should be supplemented with measures of shape uncertainty, and we show how to generate such measures. We focus on bands that characterize the shape of the likelihood. Such bands are not classical confidence regions. We explain that classical confidence regions mix information about parameter location with information about model fit, and hence can be misleading as summaries of the implications of the data for the location of parameters.","['Sims, Christopher A.', 'Zha, Tao']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Error Bands for Impulse Responses,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"This paper develops a regression limit theory for nonstationary panel data with large numbers of cross section and time series observations. The limit theory allows for both sequential limits and joins limits, and the relationship between these multidimensional limits is explored. The panel structures considered allow for no time series cointegration, heterogeneous cointegration, homogeneous cointegration, and near-homogeneous cointegration. The paper explores the existence of long-run average relations between integrated panel vectors. In the case of homogeneous and near homogeneous cointegrating panels, a panel fully modified regression estimator is developed and studied.","['Phillips, Peter C. B.', 'Moon, Hyungsik R.']","['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C33', 'C23']",Linear Regression Limit Theory for Nonstationary Panel Data,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"A game is better-reply secure if for every non equilibrium strategy x* and every payoff vector limit u* resulting from strategies approaching x*, some player i has a strategy yielding a payoff strictly above u[subscript i superscript *] even if the others deviate slightly from x*. If strategy spaces are compact and convex, payoffs are quasiconcave in the owner's strategy, and the game is better-reply secure, then a pure strategy Nash equilibrium exists. Better-reply security holds in many economic games. It also permits new results on the existence of symmetric and mixed strategy equilibria.","['Reny, Philip J.']","['Noncooperative Games', 'Existence and Stability Conditions of Equilibrium']","['C72', 'C62']",On the Existence of Pure and Mixed Strategy Nash Equilibria in Discontinuous Games,0,0,0,0,0,1999,09,01
67,5,1999-09-01,"The proportional hazard model with unobserved heterogeneity gives the hazard function of a random variable conditional on covariates and a second random variable representing unobserved heterogeneity. This paper shows how to estimate the baseline hazard function and the distribution of the unobserved heterogeneity nonparametrically. The baseline hazard function and heterogeneity distribution are assumed to satisfy smoothness conditions but are not assumed to belong to known, finite-dimensional, parametric families. Existing estimators assume that the baseline hazard function or heterogeneity distribution belongs to a known parametric family. Thus, the estimators presented in this paper are more general than existing ones.","['Horowitz, Joel L.']",['Duration Analysis; Optimal Timing Strategies'],['C41'],Semiparametric Estimation of a Proportional Hazard Model with Unobserved Heterogeneity,0,0,0,0,0,1999,09,01
67,4,1999-07-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1999 North American Winter Meeting of the Econometric Society.,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1998 European Meeting of the Econometric Society.,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,"['Gul, Faruk']",['Noncooperative Games'],['C72'],Efficiency and Immediate Agreement: A Reply to Hart and Levy,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,"['Hart, Sergiu', 'Levy, Zohar']",['Noncooperative Games'],['C72'],Efficiency Does Not Imply Immediate Agreement,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,"['Ok, Efe A.', 'Foster, James E.']","['Personal Income, Wealth, and Their Distributions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Model Construction and Estimation']","['D31', 'D63', 'C51']",Lorenz Dominance and the Variance of Logarithms,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,"['Reny, Philip J.', 'Perry, Motty']",['Auctions'],['D44'],On the Failure of the Linkage Principle in Multi-unit Auctions,0,0,1,0,0,1999,07,01
67,4,1999-07-01,"A probability distribution governing the evolution of a stochastic process has infinitely many Bayesian representations of the form mu = integral operator [subscript theta] mu[subscript theta] delta lambda (theta). Among these, a natural representation is one whose components (mu[subscript theta]'s) are 'learnable' (one can approximate mu[subscript theta] by conditioning mu on observation of the process) and 'sufficient for prediction' (mu[subscript theta]'s predictions are not aided by conditioning on observation of the process). The authors show the existence and uniqueness of such a representation under a suitable asymptotic mixing condition on the process. This representation can be obtained by conditioning on the tail-field of the process, and any learnable representation that is sufficient for prediction is asymptotically like the tail-field representation. This result is related to the celebrated de Finetti theorem, but with exchangeability weakened to an asymptotic mixing condition, and with his conclusion of a decomposition into i.i.d. component distributions weakened to components that are learnable and sufficient for prediction.","['Jackson, Matthew O.', 'Smorodinsky, Rann', 'Kalai, Ehud']","['Bayesian Analysis: General', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C11', 'C73', 'D83']",Bayesian Representation of Stochastic Processes under Learning: De Finetti Revisited,0,0,0,0,0,1999,07,01
67,4,1999-07-01,"In 'experience-weighted attraction' (EWA) learning, strategies have attractions which reflect initial predispositions, are updated based on payoff experience, and determine choice probabilities according to some rule (e.g., logit). EWA includes reinforcement learning and weighted fictitious play (belief learning) as special cases, and hybridizes their key elements. Using three sets of experimental data, the authors show that reinforcement and belief learning are generally rejected in favor of EWA. EWA is able to combine the best features of these approaches, allowing attractions to begin and grow flexibly as choice reinforcement does but reinforcing unchosen strategies substantially as belief-based models implicitly do.","['Camerer, Colin', 'Ho, Teck-Hua']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']",Experience-Weighted Attraction Learning in Normal Form Games,0,0,0,0,0,1999,07,01
67,4,1999-07-01,"In this paper, the authors derive a model of aggregate investment that builds from the lumpy microeconomic behavior of firms facing stochastic fixed adjustment costs. Instead of the standard sharp (S, s) bands, firms' adjustment policies take the form of a probability of adjustment (adjustment hazard) that responds smoothly to changes in firms' capacity gap. The model has appealing aggregation properties, and yields nonlinear aggregate time series processes. The passivity of normal times is, occasionally, more than offset by the brisk response to large accumulated shocks. Using within and out-of-sample criteria, the authors find that the model performs substantially better than the standard linear models of investment for postwar sectoral U.S. manufacturing equipment and structures investment data.","['Caballero, Ricardo J.', 'Engel, Eduardo M. R. A.']","['Investment; Capital; Intangible Capital; Capacity', 'Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Industry Studies: Manufacturing: General']","['E22', 'D25', 'L60']","Explaining Investment Dynamics in U.S. Manufacturing: A Generalized (S, s) Approach",1,0,0,0,0,1999,07,01
67,4,1999-07-01,"This paper takes stock of the advances and directions for research on the incomplete contracting front. It first illustrates some of the main ideas of the incomplete contract literature through an example. It then offers methodological insights on the standard approach to modeling incomplete contracts; in particular it discusses a tension between two assumptions made in the literature, namely rationality and the existence of transaction costs. Last, it argues that, contrary to what is commonly argued, the complete contract methodology need not be unable to account for standard institutions such as authority and ownership; and it concludes with a discussion of the research agenda.","['Tirole, Jean']","['Asymmetric and Private Information; Mechanism Design', 'Organizational Behavior; Transaction Costs; Property Rights', 'Transactional Relationships; Contracts and Reputation; Networks']","['D82', 'D23', 'L14']",Incomplete Contracts: Where Do We Stand?,1,0,0,0,0,1999,07,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1998 India and South East Asia Meeting of the Econometric Society.,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],"Fellows of the Econometric Society as of January, 1999.",0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],1998 Election of Fellows to the Econometric Society.,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],Report of the President.,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Sonmez, Tayfun']","['Allocative Efficiency; Cost-Benefit Analysis', 'Bargaining Theory; Matching Theory', 'Cooperative Games']","['D61', 'C78', 'C71']",Strategy-Proofness and Essentially Single-Valued Cores,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Polak, Ben']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Noncooperative Games']","['D83', 'C72']","Epistemic Conditions for Nash Equilibrium, and Common Knowledge of Rationality",0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Araujo, Aloisio', 'Sandroni, Alvaro']","['Expectations; Speculations', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D84', 'D83']",On the Convergence to Homogeneous Expectations When Markets Are Complete,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Stoker, Thomas M.', 'Schmalensee, Richard']",['Consumer Economics: Empirical Analysis'],['D12'],Household Gasoline Demand in the United States,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Magnus, Jan R.', 'Durbin, J.']",['Single Equation Models; Single Variables: General'],['C20'],Estimation of Regression Coefficients of Interest When Other Regression Coefficients Are of No Interest,0,0,0,0,0,1999,05,01
67,3,1999-05-01,ECONLIT None Found,"['Faust, Jon']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Conventional Confidence Intervals for Points on Spectrum Have Confidence Level Zero,0,0,0,0,0,1999,05,01
67,3,1999-05-01,"The authors consider strategyproof social choice functions defined over product domains. If preferences are strict orderings and separable, then strategyproof social choice functions must be decomposable provided that the domain of preferences is rich. The authors provide several applications of this result, including a characterization of the libertarian social choice function.","['Sen, Arunava', 'Le Breton, Michel']",['Social Choice; Clubs; Committees; Associations'],['D71'],"Separable Preferences, Strategyproofness, and Decomposability",0,0,0,0,0,1999,05,01
67,3,1999-05-01,"This paper presents a simple two-step nonparametric estimator for a triangular simultaneous equation model. The authors use series approximations that exploit the additive structure of the model. The first step comprises the nonparametric estimation of the reduced form and the corresponding residuals. The second step is the estimation of the primary equation via nonparametric regression with the reduced form residuals included as a regressor. The authors derive consistency and asymptotic normality results for their estimator, including optimal convergence rates. An empirical example, on the relationship between the hourly wage rate and hours worked, illustrates the utility of the authors' approach.","['Vella, Francis', 'Powell, James L.', 'Newey, Whitney K.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Nonparametric Estimation of Triangular Simultaneous Equations Models,0,0,0,0,0,1999,05,01
67,3,1999-05-01,"This paper considers a generalized method of moments (GMM) estimation problem in which one has a vector of moment conditions, some of which are correct and some incorrect. The paper introduces several procedures for consistently selecting the correct moment conditions. Application of the results of the paper to instrumental variables estimation problems yields consistent procedures for selecting instrumental variables. The paper specifies moment selection criteria that are GMM analogues of the widely used BIC and AIC model selection criteria. (The latter is not consistent.) The paper also considers downward and upward testing procedures.","['Andrews, Donald W. K.']",['Estimation: General'],['C13'],Consistent Moment Selection Procedures for Generalized Method of Moments Estimation,0,0,0,0,0,1999,05,01
67,3,1999-05-01,"An overlapping generations model of social security with productivity and demographic shocks is studied. The authors focus attention on stationary long-run allocations. An allocation is interim optimal if there does not exist another feasible allocation that improves the expected welfare of all generations, computed conditionally on the state of the world when they are born. The authors characterize the set of interim optimal allocations and study the equilibria associated with various institutional forms of social security from the point of view of this optimality criterion. They obtain the analogs of the two traditional welfare theorems of microeconomic theory.","['Demange, Gabrielle', 'Laroque, Guy']","['Social Security and Public Pensions', 'Intertemporal Household Choice; Life Cycle Models and Saving', 'National Budget; Budget Systems']","['H55', 'D15', 'H61']",Social Security and Demographic Shocks,0,0,0,0,0,1999,05,01
67,3,1999-05-01,"When do dynamic nonconvexities at the disaggregate level translate into dynamic nonconvexities at the aggregate level? The authors address this question in a framework where the production of differentiated intermediate inputs is subject to dynamic nonconvexities and show that the answer depends on the degree of Hicks-Allen complementarity between differentiated inputs. In the simplest case, there are dynamic nonconvexities at the aggregate level if and only if differentiated inputs are Hicks-Allen complements. The authors also compare dynamic equilibrium and optimal allocations in the presence of aggregate dynamic nonconvexities due to Hicks-Allen complementarities between differentiated inputs.","['Matsuyama, Kiminori', 'Ciccone, Antonio']","['One, Two, and Multisector Growth Models', 'General Aggregative Models: Keynes; Keynesian; Post-Keynesian', 'Macroeconomics: Production']","['O41', nan, 'E23']",Efficiency and Equilibrium with Dynamic Increasing Aggregate Returns Due to Demand Complementarities,0,0,0,0,0,1999,05,01
67,3,1999-05-01,"In a framework of preferences over lotteries, the authors show that an axiom system consisting of weakened versions of Arrow's axioms has a unique solution, 'relative utilitarianism.' This consists of first normalizing individual von Neumann-Morgenstern utilities between zero and one and then summing them. The weakening consists chiefly in removing from IIA the requirement that social preferences be insensitive to variations in the intensity of preferences. The authors also show the resulting axiom system to be in a strong sense independent.","['Dhillon, Amrita', 'Mertens, Jean-Francois']",['Social Choice; Clubs; Committees; Associations'],['D71'],Relative Utilitarianism,0,0,0,0,0,1999,05,01
67,2,1999-03-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1998 Australasian Meeting of the Econometric Society.,0,0,0,0,0,1999,03,01
67,2,1999-03-01,ECONLIT None Found,[nan],[nan],[nan],Announcements: Nomination of Fellows.,0,0,0,0,0,1999,03,01
67,2,1999-03-01,ECONLIT None Found,"['Palfrey, Thomas R.', 'Ledyard, John O.']",['Public Goods'],['H41'],A Characterization of Interim Efficiency with Public Goods,0,0,0,0,0,1999,03,01
67,2,1999-03-01,ECONLIT None Found,"['Lee, Myoung-jae']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C25', 'C23']",A Root-N Consistent Semiparametric Estimator for Related-Effect Binary Response Panel Data,0,0,0,0,0,1999,03,01
67,2,1999-03-01,ECONLIT None Found,"['Savin, N. E.', 'Wurtz, A. H.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Model Evaluation, Validation, and Selection']","['C25', 'C52']",Power of Tests in Binary Response Models,0,0,0,0,0,1999,03,01
67,2,1999-03-01,"This paper provides a folk theorem for two-player repeated games in which players have different discount factors. In such games, players can mutually benefit from trading payoffs across time. Hence, the set of feasible repeated game payoffs is typically larger than the convex hull of the underlying stage-game payoffs. However, many trade plans that guarantee individually rational payoffs are not sustainable by an equilibrium, no matter how patient the players are. Therefore, the set of equilibrium payoffs might not approach the set of all feasible and individually rational repeated game payoffs.","['Pauzner, Ady', 'Lehrer, Ehud']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Repeated Games with Differential Time Preferences,0,0,0,0,0,1999,03,01
67,2,1999-03-01,"The authors derive necessary and sufficient conditions for a pair of functions to be the optimal policy function and the optimal value function of a dynamic maximization problem with convex constraints and concave objective functional. It is shown that every Lipschitz continuous function can be the solution of such a problem. If the maintained assumptions include free disposal and monotonicity, then the authors obtain a complete characterization of all optimal policy and optimal value functions. This is the case, e.g., in the standard aggregative optimal growth model.","['Mitra, Tapan', 'Sorger, Gerhard']","['One, Two, and Multisector Growth Models', 'Optimization Techniques; Programming Models; Dynamic Analysis', 'Policy Objectives; Policy Designs and Consistency; Policy Coordination']","['O41', 'C61', 'E61']",Rationalizing Policy Functions by Dynamic Optimization,0,0,0,0,0,1999,03,01
67,2,1999-03-01,"This paper extends the classic two-armed bandit problem to a many-agent setting in which N players each face the same experimentation problem. The main change from the single-agent problem is that an agent can now learn from the current experimentation of other agents. Information is therefore a public good, and a free-rider problem in experimentation naturally arises. More interestingly, the prospect of future experimentation by others encourages agents to increase current experimentation, in order to bring forward the time at which the extra information generated by such experimentation becomes available. The paper provides an analysis of the set of stationary Markov equilibria in terms of the free-rider effect and the encouragement effect.","['Harris, Christopher', 'Bolton, Patrick']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Strategic Experimentation,0,0,0,0,0,1999,03,01
67,2,1999-03-01,"An endogenous growth model is developed, where the balanced growth path is unstable and the economy achieves sustainable growth through cycles, perpetually moving back and forth between two phases. One phase is characterized by higher investment, no innovation, and a competitive market structure, as in the neoclassical model. The other phase is characterized by lower investment, high innovation, and a more monopolistic market structure, as in the neo-Schumpeterian model. Both investment and innovation are essential in sustaining growth indefinitely and yet only one of them appears to play a dominant role in each phase.","['Matsuyama, Kiminori']","['One, Two, and Multisector Growth Models', 'Business Fluctuations; Cycles']","['O41', 'E32']",Growing through Cycles,0,0,0,0,0,1999,03,01
67,2,1999-03-01,"Using a longitudinal sample of one million French workers and 500,000 employing firms, the authors decompose real total annual compensation per worker into components: observable employee characteristics, personal heterogeneity, firm heterogeneity, and residual. Unobserved personal heterogeneity is a very important source of wage variation. Unobserved firm heterogeneity, while important, is not as important as person effects. Enterprises that hire high-wage workers are more productive but not more profitable. Enterprises that pay higher wages, controlling for person effects, are more productive and more profitable. Person effects explain about 90 percent of interindustry and firm-size wage differences while firm effects explain substantially less.","['Abowd, John M.', 'Kramarz, Francis', 'Margolis, David N.']",['Wage Level and Structure; Wage Differentials'],['J31'],High Wage Workers and High Wage Firms,0,0,0,0,0,1999,03,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Program of the Sixteenth Latin American Meeting of the Econometric Society.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Report on the Far Eastern Activities of the Econometric Society.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Econemetrica Referees 1997–1998.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Treasurer.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Secretary.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Announcements: Nomination of Fellows.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,"['Tzavalis, Elias', 'Hadri, Kaddour', 'Abadir, Karim M.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],The Influence of VAR Dimensions on Estimator Biases,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,"['Riddell, W. Craig', 'Jones, Stephen R. G.']","['Mobility, Unemployment, Vacancies, and Immigrant Workers: General', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J60', 'J64']",The Measurement of Unemployment: An Empirical Approach,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"For economies with one private good and one public good, the author discusses social choice functions satisfying the following requirements: strategy-proofness--representing true preferences is a dominant strategy; symmetry--two agents having the same preference pay equal cost shares--anonymity--when agents' preferences are switched, so are their consumption bundles; and individual rationality--allocations making agents worse off than their initial situations are never obtained. Theorem 1 characterizes strategy-proof, budget-balancing, and symmetric social choice functions under convex public good technology. Theorems 2 and 3 characterize such functions without the convexity assumption, but employ anonymity and individual rationality requirements respectively.","['Serizawa, Shigehiro']","['Social Choice; Clubs; Committees; Associations', 'Public Goods']","['D71', 'H41']",Strategy-Proof and Symmetric Social Choice Functions for Public Good Economies,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"The authors study preferences over Savage acts that map states to opportunity sets and satisfy the Savage axioms. Preferences over opportunity sets may exhibit a preference for flexibility due to an implicit uncertainty about future preferences reflecting anticipated unforeseen contingencies. The main result of the paper characterizes maximization of the expected indirect utility in terms of an 'indirect stochastic dominance' axiom that expresses a preference for 'more opportunities in expectation.' The key technical tool of the paper, conjugate Mobius inversion, allows an alternative representation using Choquet integration and yields a simple proof of D. Kreps's (1979) classic result.","['Nehring, Klaus']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Preference for Flexibility in a Savage Framework,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"The authors consider the problem of design and sale of a security backed by specified assets. Given access to higher-return investments, the issuer has an incentive to raise capital by securitizing part of these assets. At the time the security is issued, the issuer's or underwriter's private information regarding the payoff of the security may cause illiquidity in the form of a downward-sloping demand curve for the security. The authors characterize the optimal security design in several cases. They also demonstrate circumstances under which standard debt is optimal and show that the riskiness of the debt is increasing in the issuer's retention costs for assets.","['Duffie, Darrell', 'DeMarzo, Peter']",['Financing Policy; Financial Risk and Risk Management; Capital and Ownership Structure; Value of Firms; Goodwill'],['G32'],A Liquidity-Based Model of Security Design,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"An exponentially small departure from the common knowledge assumption on the number T of repetitions of the prisoners' dilemma already enables cooperation. More generally, with such a departure, any feasible individually rational outcome of any one-shot game can be approximated by an equilibrium of a finitely repeated version of that game. The departure from common knowledge is small in the following sense: (1) the players know T with precision +/-K; (2) with probability 1 - epsilon, the players know T precisely; moreover, this knowledge is mutual of order epsilon T; and (3) the deviation of T from its finite expectation is exponentially small.","['Neyman, Abraham']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games']","['C73', 'C72']",Cooperation in Repeated Games When the Number of Stages Is Not Commonly Known,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"The authors consider the strategic options facing workers in labor markets with centralized market clearing mechanisms, such as those in the entry-level labor markets of a number of professions. If workers do not have detailed information about the preferences of other workers and firms, the scope of potentially profitable strategic behavior is considerably reduced, although not entirely eliminated. Specifically, the authors demonstrate that stating preferences that reverse the true preference order of two acceptable firms is not beneficial in a low information environment, but submitting a truncation of the true preferences may be. This gives some insight into the successful operation of these market mechanisms.","['Rothblum, Uriel G.', 'Roth, Alvin E.']","['Bargaining Theory; Matching Theory', 'Professional Labor Markets; Occupational Licensing', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'J44', 'D83']",Truncation Strategies in Matching Markets--In Search of Advice for Participants,0,0,0,0,0,1999,01,01
67,1,1999-01-01,"Why do both left and right political parties typically propose progressive income taxation schemes in political competition? Analysis of this problem has been hindered by the two-dimensionality space of admissible tax policies: Nash equilibria in pure strategies of the usual political game generically fail to exist. A new equilibrium concept, based on the fact of factional conflict within parties, is introduced. Each party has incomplete preference orders on the strategy space, formed as the intersection of the complete preference orders of its factions. Nash equilibria of the two-party game, so construed, do exist and, in such equilibria, both parties propose progressive income taxation.","['Roemer, John E.']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Taxation and Subsidies: Incidence', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Capitalist Systems: Political Economy']","['D72', 'H22', 'H24', 'P16']",The Democratic Political Economy of Progressive Income Taxation,0,0,0,0,0,1999,01,01
79,6,2011-11-01,ECONLIT None Found,[nan],[nan],[nan],Backmatter of Econometrica Vol. 79 Iss. 6.,0,0,0,0,0,2011,11,01
79,4,2011-07-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUCEMENTS.,0,0,0,0,0,2011,07,01
86,2,2018-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,03,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2018,01,01
86,1,2018-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2018,01,01
85,6,2017-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,11,01
85,5,2017-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,09,01
85,4,2017-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,07,01
85,4,2017-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2017,07,01
85,3,2017-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,05,01
79,2,2011-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2011,03,01
79,1,2011-01-01,ECONLIT None Found,"['MAI LATH, GEORGE J.', 'MATZKIN, ROSA L.']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS.,0,0,0,0,0,2011,01,01
84,2,2016-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 84 Iss. 2.,0,0,0,0,0,2016,03,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 84 Iss. 1.,0,0,0,0,0,2016,01,01
83,5,2015-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 5.,0,0,0,0,0,2015,09,01
83,4,2015-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 4.,0,0,0,0,0,2015,07,01
83,3,2015-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 3.,0,0,0,0,0,2015,05,01
78,1,2010-01-01,ECONLIT None Found,"['Chesher, Andrew', 'Mailath, George']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE EDITORS OF THE MONOGRAPH SERIES.,0,0,0,0,0,2010,01,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],PROGRAM OF THE 1992 AUSTRALASIAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,11,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],PROGRAM OF THE 1992 NORTH AMERICAN SUMMER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,11,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,1992,11,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],INDEX.,0,0,0,0,0,1992,11,01
60,6,1992-11-01,ECONLIT None Found,"['Matsushima, Hitoshi', 'Abreu, Dilip']",['Social Choice; Clubs; Committees; Associations'],['D71'],A Response [Virtual Implementation in Iteratively Undominated Strategies I: Complete Information].,0,0,0,0,0,1992,11,01
60,6,1992-11-01,ECONLIT None Found,"['Rosenthal, Robert W.', 'Glazer, Jacob']",['Social Choice; Clubs; Committees; Associations'],['D71'],A Note on Abreu-Matsushima Mechanisms,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"This paper reports the results of a systematic experimental comparison of the effect of alternative arbitration systems on dispute rates. The three main findings indicate that (1) dispute rates are inversely related to the monetary costs of disputes; (2) the dispute rate in a final-offer arbitration system is at least as high as the dispute rate in a comparable conventional arbitration system; and (3) dispute rates are inversely related to the uncertainty costs of disputes, indicating that some bargainers behave as if they were risk averse. Coauthors are Janet Currie, Henry S. Farber, and Matthew Spiegel.","['Ashenfelter, Orley']","['Bargaining Theory; Matching Theory', 'Dispute Resolution: Strikes, Arbitration, and Mediation; Collective Bargaining']","['C78', 'J52']",An Experimental Comparison of Dispute Rates in Alternative Arbitration Systems,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"The existence and stability of invariant distributions for stochastically monotone processes is studied. The Knaster-Tarski fixed point theorem is applied to establish existence of fixed points of mappings on compact sets of measures that are increasing with respect to a stochastic ordering. Global convergence of a monotone Markov process to its unique invariant distribution is established under an easily verified assumption. Topkis's theory of supermodular functions is applied to stochastic dynamic optimization, providing conditions under which optimal stationary decisions are monotone functions of the state and induce a monotone Markov process. Applications of these results to investment theory, stochastic growth and industry equilibrium dynamics are given.","['Prescott, Edward C.', 'Hopenhayn, Hugo A.']","['Existence and Stability Conditions of Equilibrium', 'Economic Growth and Aggregate Productivity: General']","['C62', 'O40']",Stochastic Monotonicity and Stationary Distributions for Dynamic Economies,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"This paper develops a two-sector overlapping-generations model. It characterizes the dynamical system globally and establishes sufficient conditions for the existence of a globally unique perfect-foresight equilibrium. It provides, therefore, a useful framework for global dynamic analysis of phenomena whose modeling requires a multidimensional commodity space. The analysis demonstrates that gross substitutability in consumption is not sufficient for the determinacy of equilibrium in this production economy. However, if in addition the investment good is capital intensive and second period consumption of two-period-lived individuals is a normal good, then the perfect-foresight equilibrium is globally unique.","['Galor, Oded']","['One, Two, and Multisector Growth Models']",['O41'],A Two-Sector Overlapping-Generations Model: A Global Characterization of the Dynamical System,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"The author considers fair division when monetary compensations are feasible and utilities are quasi-linear. Four axioms are discussed: individual rationality, resource monotonicity, population solidarity, and the stand alone test. The latter views the utility from consuming all the goods as an upper bound on every coalition's actual (joint) utility. Under efficiency, the four axioms show little compatibility. However, when the goods have enough substitutability in everyone's preferences, the Shapley value of the surplus sharing game satisfies all four axioms. An example is the optimal assignment of indivisible goods when every agent consumes only one good.","['Moulin, Herve']","['Allocative Efficiency; Cost-Benefit Analysis', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D61', 'D63']",An Application of the Shapley Value to Fair Division with Money,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"The authors provide conditions on an exchange economy with asymmetric information that guarantee that when the economy is replicated sufficiently often, there will be an allocation that is incentive compatible, individually rational, and nearly efficient. The main theorem covers both the case in which aggregate uncertainty remains when the economy is replicated and the case in which replication eliminates aggregate uncertainty. In addition, the authors demonstrate how their theorem does or does not apply to standard asymmetric information problems such as the buyer's bid double auction problem, Akerlof's lemons problem, and insurance with asymmetric information.","['Postlewaite, Andrew', 'Gul, Faruk']","['Exchange and Production Economies', 'Asymmetric and Private Information; Mechanism Design']","['D51', 'D82']",Asymptotic Efficiency in Large Exchange Economies with Asymmetric Information,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"This paper provides an extension of L. J. Savage's subjective expected utility theory for decisions under uncertainty. It includes in the set of events both unambiguous events for which probabilities are additive and ambiguous events for which probabilities are permitted to be nonadditive. The main axiom is cumulative dominance, which adapts stochastic dominance to decision-making under uncertainty. The authors derive a Choquet expected utility representation and show that a modification of cumulative dominance leads to the classical expected utility representation. The relationship of their approach with that of D. Schmeidler, who uses a two-stage formulation to derive Choquet expected utility, is also explored.","['Sarin, Rakesh K.', 'Wakker, Peter']","['Criteria for Decision-Making under Risk and Uncertainty', 'Consumer Economics: Theory']","['D81', 'D11']",A Simple Axiomatization of Nonadditive Expected Utility,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"This paper presents a new approach to organizing universal health insurance. First, the government divides the entire population into many large groups. Then, the government creates a federal health insurance system (HealthFed), modeled on the Federal Reserve System, to fill the role now played by the benefits office of a large firm. The HealthFed would create a short menu of alternatives, solicit bids for insuring the entire group, and price alternatives. There would be redistribution between groups and pricing of alternatives to reflect optimal social insurance principles. There would be no connection between health insurance and employment.","['Diamond, Peter']",['Health: Government Policy; Regulation; Public Health'],['I18'],Organizing the Health Insurance Market,0,0,0,0,0,1992,11,01
60,5,1992-09-01,This paper considers a class of statistics that can be written as the ratio of the sample variance of a filtered time series to the sample variance of the original series. Any such statistic is shown to be optimal under normality for testing a null of white noise against some class of serially dependent alternatives. A simple characterization of the alternative class is provided. The results are used to show that a variance ratio test for mean reversion is an optimal test and to illustrate the forms of mean reversion it is best at detecting.,"['Faust, Jon']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],When Are Variance Ratio Tests for Serial Dependence Optimal?,0,0,0,0,0,1992,09,01
60,5,1992-09-01,"In this paper, a new estimator is proposed for discrete choice models with choice-based sampling. The estimator is efficient and can incorporate information on the marginal choice probabilities in a straightforward manner and for that case leads to a procedure that is computationally and intuitively more appealing than the estimators that have been proposed before. The idea is to start with a flexible parametrization of the distribution of the explanatory variables and then rewrite the estimator to remove dependence on these parametric assumptions.","['Imbens, Guido W.']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],An Efficient Method of Moments Estimator for Discrete Choice Models with Choice-Based Sampling,0,0,0,0,0,1992,09,01
60,5,1992-09-01,This paper questions the interpretation of the Nash bargaining solution. A new definition is suggested. Revisions of Nash axioms characterize the solution. The definition makes possible its extension to non-expected-utility preferences. It also reveals the logic behind the comparative statics of risk aversion and the connection between the Nash bargaining solution and strategic models.,"['Safra, Zvi', 'Rubinstein, Ariel', 'Thomson, William']",['Bargaining Theory; Matching Theory'],['C78'],On the Interpretation of the Nash Bargaining Solution and Its Extension to Non-expected Utility Preferences,0,0,0,0,0,1992,09,01
60,5,1992-09-01,"An experimental test of some qualitative predictions of the Kreps-Wilson (1982) model of reputation building is conducted in a version of a borrower-lender game first used experimentally by Colin Camerer and Keith Weigelt (1988). A systematic response to changes in the payoff function of borrowers is observed. However, the response is opposite to the direction predicted by the theory. Furthermore, the observed behavior cannot be reconciled with the theory by an appeal to ""homemade"" priors of the type specified by Camerer and Weigelt.","['Neral, John', 'Ochs, Jack']","['Noncooperative Games', 'Transactional Relationships; Contracts and Reputation; Networks']","['C72', 'L14']",The Sequential Equilibrium Theory of Reputation Building: A Further Test,1,0,0,0,0,1992,09,01
60,5,1992-09-01,"A dynamic stochastic model for a competitive industry is developed in which entry, exit, and the growth of firms' output and employment is determined. The paper extends long-run industry equilibrium theory to account for entry, exit, and heterogeneity in the size and growth rate of firms. Conditions under which there is entry and exit in the long run are developed. Cross sectional implications and distributions of profits and value of firms are derived. Comparative statics on the equilibrium size distribution and turnover rates are analyzed.","['Hopenhayn, Hugo A.']","['Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Market Structure, Pricing, and Design: Perfect Competition']","['D25', 'D41']","Entry, Exit, and Firm Dynamics in Long Run Equilibrium",0,0,1,0,0,1992,09,01
60,5,1992-09-01,"The paper investigates the existence of stationary sunspot equilibria (SSE) in the vicinity of a steady state in a general, one-step forward looking economic model of dimension n. It is shown that, whenever the steady state is indeterminate, for the associated deterministic dynamics--i.e., there exists a continuum of perfect foresight paths converging to the steady state--then there exists a continuum of SSE of finite order in any neighborhood of the steady state. The proof relies upon bifurcation theory; it provides a characterization of the random processes for which SSE may appear and a description of the location of the support of the SSE close to the bifurcation. The results apply in particular to linear models.","['Geoffard, Pierre-Yves', 'Guesnerie, Roger', 'Chiappori, Pierre-Andre']",['Business Fluctuations; Cycles'],['E32'],"Sunspot Fluctuations around a Steady State: The Case of Multidimensional, One-Step Forward Looking Economic Models",0,0,0,0,0,1992,09,01
60,5,1992-09-01,"This paper studies the class of denumerable-armed (i.e., finite- or countably infinite-armed) Bandit problems with independent arms and geometric discounting over an infinite horizon in which each arm generates rewards according to one of a finite number of distributions. The authors derive certain continuity and curvature properties of the Gittins Index, and provide necessary and sufficient conditions under which this index characterizes the optimal strategies. They then show that at each point in time the arm selected by an optimal strategy will, with positive probability, remain an optimal selection forever.","['Sundaram, Rangarajan K.', 'Banks, Jeffrey S.']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Denumerable-Armed Bandits,0,0,0,0,0,1992,09,01
60,5,1992-09-01,"For each two-player game, a linear-programming algorithm finds a component of the Nash equilibria and a subset of its perfect equilibria that are simply stable in the sense that there are nearby equilibria for each nearby game that perturbs one strategy's probability or payoff more than others.","['Wilson, Robert']",['Noncooperative Games'],['C72'],Computing Simply Stable Equilibria,0,0,0,0,0,1992,09,01
60,5,1992-09-01,"The authors consider the problem of cost sharing in the case of a fixed group of agents sharing a one input, one output technology with decreasing returns. They introduce and analyze the serial cost sharing method. Among agents endowed with convex and monotonic preferences, serial cost sharing is dominance solvable and its unique Nash equilibrium is also robust to coalitional deviations. The authors show that no other smooth cost sharing mechanism yields a unique Nash equilibrium at all preference profiles.","['Shenker, Scott', 'Moulin, Herve']","['Noncooperative Games', 'Social Choice; Clubs; Committees; Associations']","['C72', 'D71']",Serial Cost Sharing,0,0,0,0,0,1992,09,01
60,5,1992-09-01,"The authors investigate the implementation of social choice functions that map to lotteries over alternatives. They require virtual implementation in iteratively undominated strategies. Under very weak domain restrictions, they show that if there are three or more players, any social choice function may be so implemented. The literature on implementation in Nash equilibrium and its refinements is compromised by its reliance on game forms with unnatural features (for example, ""integer games"") or ""modulo"" constructions with mixed strategies arbitrarily excluded. In contrast, the authors' results employ finite (consequently ""well-behaved"") mechanisms and allow for mixed strategies.","['Matsushima, Hitoshi', 'Abreu, Dilip']","['Social Choice; Clubs; Committees; Associations', 'Noncooperative Games', 'Positive Analysis of Policy Formulation and Implementation']","['D71', 'C72', 'D78']",Virtual Implementation in Iteratively Undominated Strategies: Complete Information,0,0,0,0,0,1992,09,01
60,4,1992-07-01,ECONLIT None Found,"['Smith, Richard J.']","['Single Equation Models; Single Variables: General', 'Hypothesis Testing: General']","['C20', 'C12']",Non-nested Tests for Competing Models Estimated by Generalized Method of Moments,0,0,0,0,0,1992,07,01
60,4,1992-07-01,ECONLIT None Found,"['Hansen, Bruce E.']",['Single Equation Models; Single Variables: General'],['C20'],Consistent Covariance Matrix Estimation for Dependent Heterogeneous Processes,0,0,0,0,0,1992,07,01
60,4,1992-07-01,ECONLIT None Found,"['Monahan, J. Christopher', 'Andrews, Donald W. K.']",['Single Equation Models; Single Variables: General'],['C20'],An Improved Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimator,0,0,0,0,0,1992,07,01
60,4,1992-07-01,ECONLIT None Found,"['Stern, Steven']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],A Method for Smoothing Simulated Moments of Discrete Probabilities in Multinomial Probit Models,0,0,0,0,0,1992,07,01
60,4,1992-07-01,"One elicitation diagnostic identifies a family of prior distributions that are so diffuse that they are practically equivalent to the ""completely"" diffuse prior. Another elicitation diagnostic identifies a family of prior distributions that concentrate enough mass in the neighborhood of zero that they are practically equivalent to the dogmatic prior that sets a parameter exactly equal to zero. If either question thus posed can be answered in the affirmative then there is no need to go to the expense of a more accurate elicitation of the prior distribution.","['Leamer, Edward E.']",['Bayesian Analysis: General'],['C11'],Bayesian Elicitation Diagnostics,0,0,0,0,0,1992,07,01
60,4,1992-07-01,This paper considers the effect of an airline's scale of operation at an airport on the profitability of routes flown out of that airport. The empirical methodology uses the entry decisions of airlines as indicators of underlying profitability; the results extend the empirical literature on airport presence by providing a new set of estimates of the determinants of city-pair profitability. These estimates imply that city-pair profits increase in airport presence and decrease rapidly in the number of entering firms. The literature on empirical models of oligopoly entry is also extended via a focus on the role of differences between firms.,"['Berry, Steven T.']","['Air Transportation', 'Oligopoly and Other Imperfect Markets']","['L93', 'L13']",Estimation of a Model of Entry in the Airline Industry,1,0,0,0,0,1992,07,01
60,4,1992-07-01,"Suppose two agents play a game, each using a computable algorithm to decide what to do, these algorithms being common knowledge. The author shows that it is possible to act rationally provided he limits his attention to a natural subset of solvable games and to opponents who use rational algorithms; the outcome is a Nash equilibrium. Going further, the author shows that rationality is possible on many domains of games and opposing algorithms but each domain requires a particular solution algorithm; no one algorithm is rational on all possible domains.","['Canning, David']",['Noncooperative Games'],['C72'],"Rationality, Computability, and Nash Equilibrium",0,0,0,0,0,1992,07,01
60,4,1992-07-01,Most of the available results on the existence of marginal cost pricing equilibrium are unsatisfactory in that they make a survival assumption that is stated as a condition on the production equilibria of the economy. The primary objective of this paper is to provide a relatively elementary existence result that replaces such an assumption with one on the primitive data of the economy. The author's main assumption is that no firm faces unbounded increasing returns in the sense that if it uses some input then the rate at which this input can be substituted into an output is finite.,"['Vohra, Rajiv']","['Exchange and Production Economies', 'Allocative Efficiency; Cost-Benefit Analysis']","['D51', 'D61']",Marginal Cost Pricing under Bounded Marginal Returns,0,0,0,0,0,1992,07,01
60,4,1992-07-01,"This paper supposes an individual cares about his/her own wealth not only directly but also via the relative standing that this wealth induces. The implications for risk-taking are investigated in particular. Such a model provides a natural explanation of the ""concave-convex-concave"" utility described by M. Friedman and L. Savage (1948). However, there are a number of key differences between the present model and any model based on own wealth alone. For example, an equilibrium wealth distribution here may have a middle class. Further, the status interaction involves an externality and an equilibrium wealth distribution may be Pareto inefficient.","['Robson, Arthur J.']","['Personal Income, Wealth, and Their Distributions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D31', 'D81']","Status, the Distribution of Wealth, Private and Social Attitudes to Risk",0,0,0,0,0,1992,07,01
60,4,1992-07-01,ECONLIT None Found,"['Palfrey, Thomas R.', 'McKelvey, Richard D.']","['Noncooperative Games', 'Design of Experiments: Laboratory, Individual']","['C72', 'C91']",An Experimental Study of the Centipede Game,0,0,0,0,0,1992,07,01
60,4,1992-07-01,ECONLIT None Found,"['Hindy, Ayman', 'Huang, Chi-fu']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Criteria for Decision-Making under Risk and Uncertainty']","['D15', 'D81']",Intertemporal Preferences for Uncertain Consumption: A Continuous Time Approach,0,0,0,0,0,1992,07,01
60,4,1992-07-01,"The goal of choice-theoretic derivations of subjective probability is to separate a decisionmaker's underlying beliefs (subjective probabilities of events) from their preferences (attitudes toward risk). Classical derivations have all relied upon some form of the Marschak-Samuelson ""Independence Axiom"" or the Savage ""Sure-Thing Principle,"" which imply that preferences over lotteries conform to the expected utility hypothesis. This paper presents a choice-theoretic derivation of subjective probability in a Savage-type setting of purely subjective uncertainty, which neither assumes nor implies that the decisionmaker's preferences over lotteries necessarily conform to the expected utility hypothesis.","['Machina, Mark J.', 'Schmeidler, David']","['Information, Knowledge, and Uncertainty: General', 'Econometric and Statistical Methods and Methodology: General']","['D80', 'C10']",A More Robust Definition of Subjective Probability,0,0,0,0,0,1992,07,01
60,3,1992-05-01,ECONLIT None Found,[nan],[nan],[nan],PROGRAM OF THE 1991 WINTER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,05,01
60,3,1992-05-01,"Equilibrium predictions of the noisy rational expectations model are relatively accurate for laboratory asset and information markets. When information about an asset's uncertain dividend is sold to a fixed number of highest bidders, prices, allocations, efficiency, and a distribution of profit predictions of the full revelation rational expectations model in the asset market dominate the predictions of the Walrasian model; demand for information shifts leftward and its price approaches zero. When the price of information is fixed, the number of informed agents and the informativeness of the asset market adjusts to permit the information buyers to recover their investment in information.","['Sunder, Shyam']","['Information and Market Efficiency; Event Studies; Insider Trading', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['G14', 'D83']",Market for Information: Experimental Evidence,0,0,0,0,0,1992,05,01
60,3,1992-05-01,"The authors analyze the evolution of duopolists' prices and market shares in an infinite-period market with consumer switching costs in which in every period new consumers arrive and a fraction of old consumers leaves. They show prices (and profits) are higher than without switching costs and that this result does not depend importantly on their specific assumptions. The authors show switching costs make the market more attractive to a new entrant, even though an entrant must overcome the disadvantage that a large fraction of the market is already committed to the incumbent's product. They also examine the effects of market growth.","['Beggs, Alan W.', 'Klemperer, Paul']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D43', 'L13']",Multi-period Competition with Switching Costs,1,0,1,0,0,1992,05,01
60,3,1992-05-01,"A weakening of D. Kreps and R. Wilson's (1982) notion of sequential rationality is presented. The motivation stems from the difficulty in justifying sequentially rational behavior in subgames reachable only through a violation of sequential rationality. Although the present notion of weak sequential rationality is based upon extensive form considerations, it bears a close relation to R. Selten's (1975) normal form perfect equilibria. Backward induction outcomes can be achieved in generic games of perfect information with additional restrictions on beliefs. An example with imperfect information shows that sequential rationality is not the consequence of equilibrium play and the absence of incredible threats.","['Reny, Philip J.']",['Noncooperative Games'],['C72'],"Backward Induction, Normal Form Perfection and Explicable Equilibria",0,0,0,0,0,1992,05,01
60,3,1992-05-01,"This paper analyzes a class of alternating-offer bargaining games with one-sided incomplete information for the case of ""no gap."" If sequential equilibria are required to satisfy the additional restrictions of stationarity, monotonicity, pure strategies, and no free screening, the authors establish the silence theorem: when the time interval between successive periods is made sufficiently short, the informed party never makes any serious offers in the play of alternating-offer bargaining games. A class of parametric examples suggests that the time interval required to assure silence is not especially brief.","['Ausubel, Lawrence M.', 'Deneckere, Raymond J.']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining and the Right to Remain Silent,0,0,0,0,0,1992,05,01
60,3,1992-05-01,"Efficiency bounds for conditional moment restrictions with a nonparametric component are derived. There is a given function of the data (a random sample from a distribution F) and a parameter. The restriction is that a conditional expectation of this function is zero at some point in the parameter space. The parameter has two parts: a finite-dimensional component and a general function evaluated at a subset of the conditioning variables. An example is a regression function that is additive in parametric and nonparametric component, as arises in sample selection models.","['Chamberlain, Gary']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: General']","['C14', 'C20']",Efficiency Bounds for Semiparametric Regression,0,0,0,0,0,1992,05,01
60,3,1992-05-01,"This paper considers estimation of truncated and censored regression models with fixed effects. Up until now, no estimator has been shown to be consistent as the cross-section dimension increases with the time dimension fixed. Trimmed least absolute deviations and trimmed least squares estimators are proposed for the case where the panel is of length two, and it is proven that they are consistent and asymptotically normal. It is not necessary to maintain parametric assumptions on the error terms to obtain this result. A small scale Monte Carlo study demonstrates that these estimators can perform well in small samples.","['Honore, Bo E.']","['Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C24', 'C23']",Trimmed LAD and Least Squares Estimation of Truncated and Censored Regression Models with Fixed Effects,0,0,0,0,0,1992,05,01
60,3,1992-05-01,"This paper describes a semiparametric estimator for binary response models in which there may be arbitrary heteroskedasticity of unknown form. The estimator is obtained by maximizing a smoothed version of the objective function of C. Manski's maximum score estimator. The smoothing procedure is similar to that used in kernel nonparametric density estimation. The resulting estimator's rate of convergence in probability is the fastest possible under the assumptions that are made. The centered, normalized estimator is asymptotically normally distributed. Methods are given for consistently estimating the parameters of the limiting distribution and for selecting the bandwidth required by the smoothing procedure.","['Horowitz, Joel L.']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],A Smoothed Maximum Score Estimator for the Binary Response Model,0,0,0,0,0,1992,05,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],PROGRAM OF THE 1991 EUROPEAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],PROGRAM OF THE TENTH LATIN AMERICAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],"ELEVENTH LATIN AMERICAN MEETING OF THE ECONOMETRIC SOCIETY--1992 MEXICO CITY, MEXICO.",0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,"['Huo, Teh-Ming']","['Money and Interest Rates: General', 'General Aggregative Models: Neoclassical']","['E40', 'E13']",Money and Interest in a Cash-in-Advance Economy: A Corrigendum,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,"['DeJong, David N.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Integration versus Trend Stationarity in Time Series,0,0,0,0,0,1992,03,01
60,2,1992-03-01,"In models of asymmetric information, possession of private information leads to rents for the possessors. This induces mechanism designers to distort away from efficiency. The authors show that this is an artifact of the presumption that information is independently distributed. Rent extraction in a large class of mechanism design games is analyzed, and a necessary and sufficient condition for arbitrarily small rents to private information is provided. Additionally, the two-person bargaining game is shown to have an efficient solution under first-order stochastic dominance and a hazard rate condition. Similar conditions allow full rent extraction in Milgrom-Weber auctions.","['McAfee, R. Preston', 'Reny, Philip J.']","['Asymmetric and Private Information; Mechanism Design', 'Auctions']","['D82', 'D44']",Correlated Information and Mechanism Design,0,0,1,0,0,1992,03,01
60,2,1992-03-01,"A stochastic differential formulation of recursive utility is given sufficient conditions for existence, uniqueness, time consistency, monotonicity, continuity, risk aversion, concavity, and other properties. In the setting of Brownian information, recursive and intertemporal expected utility functions are observationally distinguishable. However, one cannot distinguish between a number of non-expected-utility theories of one-shot choice under uncertainty after they are suitably integrated into an intertemporal framework. In a ""smooth"" Markov setting, the stochastic differential utility model produces a generalization of the Hamilton-Bellman-Jacobi characterization of optimality. A companion paper explores the implications for asset prices.","['Duffie, Darrell', 'Epstein, Larry G.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Consumer Economics: Theory']","['D81', 'D11']",Stochastic Differential Utility,0,0,0,0,0,1992,03,01
60,2,1992-03-01,"A model of endogenous growth is developed in which growth is driven by vertical innovations that involve creative destruction. Equilibrium is determined by a forward-looking difference equation, according to which the amount of research in any period depends negatively upon the amount expected next period. The paper analyzes positive and normative properties of stationary equilibria, and shows conditions for the existence of cyclical equilibria and no-growth traps. The growth rate may be more or less than optimal because a business-stealing effect counteracts the usual spillover and appropriability effects. In addition, innovations tend to be too small.","['Aghion, Philippe', 'Howitt, Peter']","['One, Two, and Multisector Growth Models', 'Innovation and Invention: Processes and Incentives']","['O41', 'O31']",A Model of Growth through Creative Destruction,0,0,0,1,0,1992,03,01
60,2,1992-03-01,"This paper tests the separation of farm labor supply and labor demand decisions, using the observation that household composition is an important determinant of farm labor use with nonseparation. After assessing the conditions under which the test has power against several alternatives, an empirical model is developed to test the proposition that farm employment is independent of family composition. The model is estimated on a data set from rural Java. The null hypothesis that farm labor allocation decisions are independent of household structure is not rejected. The results are robust to different specifications of the labor demand function.","['Benjamin, Dwayne']","['Micro Analysis of Farm Firms, Farm Households, and Farm Input Markets']",['Q12'],"Household Composition, Labor Markets, and Labor Demand: Testing for Separation in Agricultural Household Models",0,0,0,0,0,1992,03,01
60,2,1992-03-01,"The authors show that the CUSUM test of the stability over time of the coefficients of a linear regression model, which is usually based on recursive residuals, can also be applied to ordinary least squares residuals. The authors derive the limiting null distribution of the resulting test and compare its local power to that of the standard procedure. It turns out that neither version is uniformly superior to the other.","['Kramer, Walter', 'Ploberger, Werner']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],The CUSUM Test with OLS Residuals,0,0,0,0,0,1992,03,01
60,2,1992-03-01,The author shows that it is possible to identify binary threshold crossing models and binary choice models without imposing any parametric structure either on the systematic function of observable exogenous variables or on the distribution of the random term. This identification result is employed to develop a fully nonparametric maximum likelihood estimator for both the function of observable exogenous variables and the distribution of the random term. The estimator is shown to be strongly consistent and a two step procedure for its calculation is developed. The paper also includes examples of economic models that satisfy the conditions necessary to apply the results.,"['Matzkin, Rosa L.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Semiparametric and Nonparametric Methods: General']","['C25', 'C14']",Nonparametric and Distribution-Free Estimation of the Binary Threshold Crossing and the Binary Choice Models,0,0,0,0,0,1992,03,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 1991 REPORT OF THE TREASURER.",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 1991 REPORT OF THE SECRETARY.",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"ELEVENTH LATIN AMERICAN MEETING OF THE ECONOMETRIC SOCIETY--1992 MEXICO CITY, MEXICO.",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,"['Dow, James', 'Werlang, Sergio Ribeiro da Costa']",['Portfolio Choice; Investment Decisions'],['G11'],"Uncertainty Aversion, Risk Aversion, and the Optimal Choice of Portfolio",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,"['Cumby, Robert E.', 'Huizinga, John']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Testing the Autocorrelation Structure of Disturbances in Ordinary Least Squares and Instrumental Variables Regressions,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,"['Buse, A.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],The Bias of Instrumental Variable Estimators,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"This paper proposes a new test statistic to deter the presence of heteroskedasticity. The proposed test does not require a parametric specification of the mean regression function in the first stage regression. The regression function is estimated nonparametrically by the kernel estimation method. The nonparametric residual is estimated and used as a proxy for the random disturbance term. This nonparametric residual is robust to regression function misspecification. Asymptotic normality is established using extensions of classical U-statistic theorems. The test statistic is computed using the nonparametric quantities, but the resulting inference has a standard chi-square distribution.","['Lee, Byung-Joo']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Semiparametric and Nonparametric Methods: General']","['C21', 'C14']",A Heteroskedasticity Test Robust to Conditional Mean Misspecification,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"A new form of the information matrix test is developed for a wide variety of statistical models. The test is constructed against an explicit alternative with random parameter variation. It is computed using a double-length artificial regression instead of the more conventional outer-product-of-the-gradient regression, which is known to have very poor finite-sample properties. In Monte Carlo experiments for the case of univariate linear regression models, the new form performs remarkably well. Some approximate finite-sample distributions are also calculated for this case and lend support to the use of the new form.","['Davidson, Russell', 'MacKinnon, James G.']",['Hypothesis Testing: General'],['C12'],A New Form of the Information Matrix Test,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"A new procedure for statistical inference in cointegrating regressions is developed. The author introduces canonical cointegrating regressions (regressions formulated with the transformed data). The required transformations involve simple adjustments of the integrated processes using stationary components in cointegrating models. Canonical cointegrating regressions, therefore, represent the same cointegrating relationships as the original models. They are, however, constructed in such a way that the usual least squares procedure yields asymptotically efficient estimators and chi-square tests. The methodology presented here is applicable to a very wide class of cointegrating models, including models with deterministic and singular, as well as stochastic and regular, cointegrations.","['Park, Joon Y.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Canonical Cointegrating Regressions,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"Much macroeconometric discussion has recently emphasized the economic significance of the size of the permanent component in GNP. Consequently, a large literature has developed that tries to estimate this magnitude--measured, essentially, as the spectral density of increments in GNP at frequency zero. This paper shows that, unless the permanent component is a random walk, this attention has been misplaced: in general, that quantity does not identify the magnitude of the permanent component. Further, by developing bounds on reasonable measures of this magnitude, this paper shows that a random walk specification is biased toward establishing the permanent component as important.","['Quah, Danny']","['Business Fluctuations; Cycles', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'General Aggregative Models: General']","['E32', 'C22', 'E10']",The Relative Importance of Permanent and Transitory Components: Identification and Some Theoretical Bounds,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"This paper presents a unifying theory for valuing contingent claims under a stochastic term structure of interest rates. The methodology, based on the equivalent martingale measure technique, takes as given an initial forward rate curve and a family of potential stochastic processes for its subsequent movements. A no-arbitrage condition restricts this family of processes, yielding valuation formula for interest rate sensitive contingent claims that do not explicitly depend on the market prices of risk. Examples are provided to illustrate the key results.","['Morton, Andrew', 'Jarrow, Robert', 'Heath, David']","['Contingent Pricing; Futures Pricing; option pricing', 'Interest Rates: Determination, Term Structure, and Effects']","['G13', 'E43']",Bond Pricing and the Term Structure of Interest Rates: A New Methodology for Contingent Claims Valuation,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"Quotas are the predominant means of protection in developed countries, with quota rents commonly shared between exporter and importer. This paper derives shadow prices appropriate to evaluating trade reform under these circumstances and provides a number of useful sufficient conditions for welfare-improving ""piecemeal"" reform. In doing so, the authors apply the distorted (quantity-constrained) expenditure function and use implicit separability to derive more powerful results than have previously been available.","['Neary, J. Peter', 'Anderson, James E.']",['Trade Policy; International Trade Organizations'],['F13'],"Trade Reform with Quotas, Partial Rent Retention, and Tariffs",0,0,0,0,0,1992,01,01
60,1,1992-01-01,"This paper is concerned with a problem of implementation of a given social choice correspondence. The authors introduces an essential monotonicity condition and show that any implementable social choice correspondence satisfies this condition. Conversely, in a case of three or more participants, any essentially monotone social choice correspondence is implementable. In a case of two participants, the essential monotonicity condition must be completed by a requirement that the social choice correspondence is close to an individually rational correspondence.","['Danilov, Vladimir']",['Social Choice; Clubs; Committees; Associations'],['D71'],Implementation via Nash Equilibria,0,0,0,0,0,1992,01,01
60,1,1992-01-01,"A principal has private information that directly affects her agent's payoff (i.e., ""common values"" obtains). The authors analyze their relationship as a three-stage game: (1) the principal proposes a contract; (2) the agent accepts or rejects; and (3) the contract is executed. They show that the equilibrium outcomes are the allocations that weakly Pareto dominate the allocation maximizing the payoff of each ""type"" of the principal within the class of incentive-compatible allocations ensuring the agent his reservation utility irrespective of his beliefs about the principal's type. The authors also characterize the equilibria that are immune to renegotiation.","['Tirole, Jean', 'Maskin, Eric']",['Asymmetric and Private Information; Mechanism Design'],['D82'],"The Principal-Agent Relationship with an Informed Principal, II: Common Values",0,0,0,0,0,1992,01,01
77,6,2009-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2009,11,01
77,1,2009-01-01,ECONLIT None Found,"['MAILATH, GEORGE', 'CHESHER, ANDREW']",[nan],[nan],REPORT OF THE EDITORS OF THE MONOGRAPH SERIES.,0,0,0,0,0,2009,01,01
77,1,2009-01-01,ECONLIT None Found,"['Sinclair-Desgagne, Bernard']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Ancillary Statistics in Principal-Agent Models,0,0,0,0,0,2009,01,01
76,6,2008-11-01,ECONLIT None Found,[nan],[nan],[nan],INDEX.,0,0,0,0,0,2008,11,01
76,1,2008-01-01,ECONLIT None Found,"['Jackson, Matthew O.', 'Chesher, Andrew']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS: REPORT OF THE EDITORS OF THE MONOGRAPH SERIES.,0,0,0,0,0,2008,01,01
75,4,2007-07-01,ECONLIT None Found,"['Blundell, Richard']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2006 REPORT OF THE PRESIDENT.",0,0,0,0,0,2007,07,01
75,3,2007-05-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2007,05,01
75,1,2007-01-01,ECONLIT None Found,"['Jackson, Matthew', 'Chesher, Andrew']",[nan],[nan],REPORT OF THE EDITORS OF THE MONOGRAPH SERIES.,0,0,0,0,0,2007,01,01
74,1,2006-01-01,ECONLIT None Found,"['Jackson, Matthew', 'Chesher, Andrew']",['Miscellaneous Categories: Other'],['Y90'],The Econometric Society Annual Reports: The Econometric Society Research Monograph Series Report of the Editors,0,0,0,0,0,2006,01,01
85,2,2017-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,03,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2017,01,01
85,1,2017-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2017,01,01
71,5,2003-09-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2003,09,01
71,1,2003-01-01,ECONLIT None Found,"['Ellison, Glenn', 'Dekel, Eddie', 'Postlewaite, Andrew', 'Horowitz, Jeol', 'Meghir, Costas']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS.,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Tests for Parameter Instability and Structural Change with Unknown Change Point: A Corrigendum,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Krasa, Stefan', 'Villamil, Anne P.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Optimal Contracts When Enforcement Is a Decision Variable: Reply,0,0,0,0,0,2003,01,01
83,2,2015-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 2.,0,0,0,0,0,2015,03,01
83,1,2015-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 83 Iss. 1.,0,0,0,0,0,2015,01,01
84,6,2016-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2016,11,01
84,5,2016-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2016,09,01
84,4,2016-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2016,07,01
84,4,2016-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2016,07,01
70,5,2002-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['Abadir, Karim M.', 'Paruolo, Paolo']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C22', 'C21']",Simple Robust Testing of Regression Hypotheses: A Comment,0,0,0,0,0,2002,09,01
70,5,2002-09-01,ECONLIT None Found,"['Vogelsang, Timothy J.', 'Kiefer, Nicholas M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C22', 'C21']",Heteroskedasticity-Autocorrelation Robust Standard Errors Using the Barlett Kernel without Truncation,0,0,0,0,0,2002,09,01
70,3,2002-05-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2002,05,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors 2000–2001.,0,0,0,0,0,2002,01,01
82,5,2014-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 5.,0,0,0,0,0,2014,09,01
82,4,2014-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 4.,0,0,0,0,0,2014,07,01
82,3,2014-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 3.,0,0,0,0,0,2014,05,01
69,6,2001-11-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2001,11,01
69,5,2001-09-01,ECONLIT None Found,[nan],[nan],[nan],2002 North American Summer Meeting of the Econometric Society: Announcement and Call for Papers.,0,0,0,0,0,2001,09,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],"The Econometric Society Annual Reports, 2000: Report of The President.",0,0,0,0,0,2001,05,01
69,1,2001-01-01,ECONLIT None Found,"['Fudenberg, Drew', 'Stokey, Nancy', 'Blundell, Richard', 'Monfort, Alain', 'Postlewaite, Andrew']",[nan],[nan],THE ECONOMETRIC SOCIETY ANNUAL REPORTS REPORT OF THE EDITORS 1999-2000.,0,0,0,0,0,2001,01,01
69,1,2001-01-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2001,01,01
68,5,2000-09-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2000,09,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors.,0,0,0,0,0,2000,01,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,01,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,05,01
67,2,1999-03-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,03,01
67,2,1999-03-01,ECONLIT None Found,"['Geweke, John']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Model Evaluation, Validation, and Selection']","['C25', 'C52']",Power of Tests in Binary Response Models: Comment,0,0,0,0,0,1999,03,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors.,0,0,0,0,0,1999,01,01
82,2,2014-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 2.,0,0,0,0,0,2014,03,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 82 Iss. 1.,0,0,0,0,0,2014,01,01
84,2,2016-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2016,03,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2016,01,01
84,1,2016-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2016,01,01
81,5,2013-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 81 Iss. 5.,0,0,0,0,0,2013,09,01
83,6,2015-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,11,01
83,5,2015-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,09,01
83,4,2015-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,07,01
83,4,2015-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2015,07,01
83,3,2015-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,05,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,1992,11,01
60,2,1992-03-01,ECONLIT None Found,"['Diamond, Peter']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 1991 REPORT OF THE PRESIDENT.",0,0,0,0,0,1992,03,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 1991 REPORT OF THE EDITORS.",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,"['Maddala, G. S.', 'Jeong, Jinook']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],On the Exact Small Sample Distribution of the Instrumental Variable Estimator,0,0,0,0,0,1992,01,01
78,4,2010-07-01,"We use a second-price common-value auction, called the maximal game, to experimentally study whether the winner's curse (WC) can be explained by models which retain best-response behavior but allow for inconsistent beliefs. We compare behavior in a regular version of the maximal game, where the WC can be explained by inconsistent beliefs, to behavior in versions where such explanations are less plausible. We find little evidence of differences in behavior. Overall, our study casts a serious doubt on theories that posit the WC is driven by beliefs.","['Levin, Dan', 'Niederle, Muriel', 'Ivanov, Asen']","['Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D44', 'D83']",Can Relaxation of Beliefs Rationalize the Winner's Curse? An Experimental Study,0,0,1,0,0,2010,07,01
78,4,2010-07-01,"The minimax argument represents game theory in its most elegant form: simple but with stark predictions. Although some of these predictions have been met with reasonable success in the field, experimental data have generally not provided results close to the theoretical predictions. In a striking study, Palacios-Huerta and Volij (2008) presented evidence that potentially resolves this puzzle: both amateur and professional soccer players play nearly exact minimax strategies in laboratory experiments. In this paper, we establish important bounds on these results by examining the behavior of four distinct subject pools: college students, bridge professionals, world-class poker players, who have vast experience with high-stakes randomization in card games, and American professional soccer players. In contrast to Palacios-Huerta and Volij's results, we find little evidence that real-world experience transfers to the lab in these games--indeed, similar to previous experimental results, all four subject pools provide choices that are generally not close to minimax predictions. We use two additional pieces of evidence to explore why professionals do not perform well in the lab: (i) complementary experimental treatments that pit professionals against preprogrammed computers and (ii) post-experiment questionnaires. The most likely explanation is that these professionals are unable to transfer their skills at randomization from the familiar context of the field to the unfamiliar context of the lab.","['Reiley, David H.', 'Levitt, Steven D.', 'List, John A.']","['Noncooperative Games', 'Design of Experiments: Laboratory, Individual']","['C72', 'C91']",What Happens in the Field Stays in the Field: Exploring Whether Professionals Play Minimax in Laboratory Experiments,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"It has long been recognized that there is considerable heterogeneity in individual risk taking behavior, but little is known about the distribution of risk taking types. We present a parsimonious characterization of risk taking behavior by estimating a finite mixture model for three different experimental data sets, two Swiss and one Chinese, over a large number of real gains and losses. We find two major types of individuals: In all three data sets, the choices of roughly 80% of the subjects exhibit significant deviations from linear probability weighting of varying strength, consistent with prospect theory. Twenty percent of the subjects weight probabilities near linearly and behave essentially as expected value maximizers. Moreover, individuals are cleanly assigned to one type with probabilities close to unity. The reliability and robustness of our classification suggest using a mix of preference theories in applied economic modeling.","['Fehr-Duda, Helga', 'Epper, Thomas', 'Bruhin, Adrian']","['Criteria for Decision-Making under Risk and Uncertainty', 'Socialist Institutions and Their Transitions: Consumer Economics; Health; Education and Training: Welfare, Income, Wealth, and Poverty']","['D81', 'P36']",Risk and Rationality: Uncovering Heterogeneity in Probability Distortion,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"We provide theoretical foundations for several common (nested) representations of intrinsic linear habit formation. Our axiomatization introduces an intertemporal theory of weaning a decision-maker from her habits using the device of compensation. We clarify differences across specifications of the model, provide measures of habit-forming tendencies, and suggest methods for axiomatizing time-nonseparable preferences.","['Rozen, Kareen']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D11', 'D83', 'D15']",Foundations of Intrinsic Habit Formation,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"We study preferences over menus which can be represented as if the individual is uncertain of her tastes, but is able to engage in costly contemplation before selecting an alternative from a menu. Since contemplation is costly, our key axiom, aversion to contingent planning, reflects the individual's preference to learn the menu from which she will be choosing prior to engaging in contemplation about her tastes for the alternatives. Our representation models contemplation strategies as subjective signals over a subjective state space. The subjectivity of the state space and the information structure in our representation makes it difficult to identify them from the preference. To overcome this issue, we show that each signal can be modeled in reduced form as a measure over ex post utility functions without reference to a state space. We show that in this reduced-form representation, the set of measures and their costs are uniquely identified. Finally, we provide a measure of comparative contemplation costs and characterize the special case of our representation where contemplation is costless.","['Ergin, Haluk', 'Sarver, Todd']","['Consumer Economics: Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D11', 'D83']",A Unique Costly Contemplation Representation,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"This paper develops a new framework for examining the determinants of wage distributions that emphasizes within-industry reallocation, labor market frictions, and differences in workforce composition across firms. More productive firms pay higher wages and exporting increases the wage paid by a firm with a given productivity. The opening of trade enhances wage inequality and can either raise or reduce unemployment. While wage inequality is higher in a trade equilibrium than in autarky, gradual trade liberalization first increases and later decreases inequality.","['Itskhoki, Oleg', 'Helpman, Elhanan', 'Redding, Stephen']","['Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity', 'Trade and Labor Market Interactions', 'Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['D24', 'F16', 'J24', 'J31', 'J41', 'J64']",Inequality and Unemployment in a Global Economy,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"This paper develops a technique for studying incentive problems with unidimensional hidden characteristics in a way that is independent of whether the type set is finite, the type distribution has a continuous density, or the type distribution has both mass points and an atomless part. By this technique, the proposition that optimal incentive schemes induce no distortion ""at the top"" and downward distortions ""below the top"" is extended to arbitrary type distributions. However, mass points in the interior of the type set require pooling with adjacent higher types and, unless there are other complications, a discontinuous jump in the transition from adjacent lower types.","['Hellwig, Martin F.']","['Asymmetric and Private Information; Mechanism Design', 'Economics of Contract: Theory']","['D82', 'D86']",Incentive Problems with Unidimensional Hidden Characteristics: A Unified Approach,0,0,0,0,0,2010,07,01
78,4,2010-07-01,"This paper provides a directed search model designed to explain the residual part of wage variation left over after the impact of education and other observable worker characteristics have been removed. Workers have private information about their characteristics at the time they apply for jobs. Firms value these characteristics differently and can observe them once workers apply. They hire the worker they most prefer. However, the characteristics are not contractible, so firms cannot condition their wages on them. This paper shows how to extend arguments from directed search to handle this, allowing for arbitrary distributions of worker and firm types. The model is used to provide a functional relationship that ties together the wage distribution and the wage-duration function. This relationship provides a testable implication of the model. This relationship suggests a common property of wage distributions that guarantees that workers who leave unemployment at the highest wages also have the shortest unemployment duration. This is in strict contrast to the usual (and somewhat implausible) directed search story in which high wages are always accompanied by higher probability of unemployment.","['Peters, Michael']","['Model Construction and Estimation', 'Wage Level and Structure; Wage Differentials', 'Unemployment: Models, Duration, Incidence, and Job Search']","['C51', 'J31', 'J64']",Noncontractible Heterogeneity in Directed Search,0,0,0,0,0,2010,07,01
81,1,2013-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2013,01,01
77,4,2009-07-01,"In Bayesian environments with private information, as described by the types of Harsanyi, how can types of agents be (statistically) disassociated from each other and how are such disassociations reflected in the agents' knowledge structure? Conditions studied are (i) subjective independence (the opponents' types are independent conditional on one's own) and (ii) type disassociation under common knowledge (the agents' types are independent, conditional on some common-knowledge variable). Subjective independence is motivated by its implications in Bayesian games and in studies of equilibrium concepts. We find that a variable that disassociates types is more informative than any common-knowledge variable. With three or more agents, conditions (i) and (ii) are equivalent. They also imply that any variable which is common knowledge to two agents is common knowledge to all, and imply the existence of a unique common-knowledge variable that disassociates types, which is the one defined by Aumann.","['Gossner, Olivier', 'Weber, Robert', 'Kalai, Ehud']","['Game Theory and Bargaining Theory: General', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C70', 'D82', 'D83']",Information Independence and Common Knowledge,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"This paper extends Imbens and Manski's (2004) analysis of confidence intervals for interval identified parameters. The extension is motivated by the discovery that for their final result, Imbens and Manski implicitly assumed locally superefficient estimation of a nuisance parameter. I reanalyze the problem both with assumptions that merely weaken this superefficiency condition and with assumptions that remove it altogether. Imbens and Manski's confidence region is valid under weaker assumptions than theirs, yet superefficiency is required. I also provide a confidence interval that is valid under superefficiency, but can be adapted to the general case. A methodological contribution is to observe that the difficulty of inference comes from a preestimation problem regarding a nuisance parameter, clarifying the connection to other work on partial identification.","['Stoye, Jorg']","['Hypothesis Testing: General', 'Estimation: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models']","['C12', 'C13', 'C24']",More on Confidence Intervals for Partially Identified Parameters,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"This paper proposes a method for testing complementarities between explanatory and dependent variables in a large class of economic models. The proposed test is based on the monotone comparative statics (MCS) property of equilibria. Our main result is that MCS produces testable implications on the (small and large) quantiles of the dependent variable, despite the presence of multiple equilibria. The key features of our approach are that (i) we work with a nonparametric structural model of a continuous dependent variable in which the unobservable is allowed to be correlated with the explanatory variable in a reasonably general way; (ii) we do not require the structural function to be known or estimable; and (iii) we remain fairly agnostic on how an equilibrium is selected. We illustrate the usefulness of our result for policy evaluation within Berry, Levinsohn, and Pakes's (1999) model.","['Echenique, Federico', 'Komunjer, Ivana']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: General', 'Firm Behavior: Theory', 'Trade Policy; International Trade Organizations', 'Multinational Firms; International Business', 'Automobiles; Other Transportation Equipment; Related Parts and Equipment']","['C12', 'C20', 'D21', 'F13', 'F23', 'L62']",Testing Models with Multiple Equilibria by Quantile Methods,1,0,0,0,0,2009,07,01
77,4,2009-07-01,"This paper considers large N and large T panel data models with unobservable multiple interactive effects, which are correlated with the regressors. In earnings studies, for example, workers' motivation, persistence, and diligence combined to influence the earnings in addition to the usual argument of innate ability. In macroeconomics, interactive effects represent unobservable common shocks and their heterogeneous impacts on cross sections. We consider identification, consistency, and the limiting distribution of the interactive-effects estimator. Under both large N and large T, the estimator is shown to be consistent, which is valid in the presence of correlations and heteroskedasticities of unknown form in both dimensions. We also derive the constrained estimator and its limiting distribution, imposing additivity coupled with interactive effects. The problem of testing additive versus interactive effects is also studied. In addition, we consider identification and estimation of models in the presence of a grand mean, time-invariant regressors, and common regressors. Given identification, the rate of convergence and limiting results continue to hold.","['Bai, Jushan']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Panel Data Models with Interactive Fixed Effects,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"This paper studies the nonparametric identification of the first-price auction model with risk averse bidders within the private value paradigm. First, we show that the benchmark model is nonindentified from observed bids. We also derive the restrictions imposed by the model on observables and show that these restrictions are weak. Second, we establish the nonparametric identification of the bidders' utility function under exclusion restrictions. Our primary exclusion restriction takes the form of an exogenous bidders' participation, leading to a latent distribution of private values that is independent of the number of bidders. The key idea is to exploit the property that the bid distribution varies with the number of bidders while the private value distribution does not. We then extend these results to endogenous bidders' participation when the exclusion restriction takes the form of instruments that do not affect the bidders' private value distribution. Though derived for a benchmark model, our results extend to more general cases such as a binding reserve price, affiliated private values, and asymmetric bidders. Last, possible estimation methods are proposed.","['Vuong, Quang', 'Guerre, Emmanuel', 'Perrigne, Isabelle']","['Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D44', 'D81']",Nonparametric Identification of Risk Aversion in First-Price Auctions under Exclusion Restrictions,0,0,1,0,0,2009,07,01
77,4,2009-07-01,"Comparative advantage, whether driven by technology or factor endowment, is at the core of neoclassical trade theory. Using tools from the mathematics of complementarity, this paper offers a simple yet unifying perspective on the fundamental forces that shape comparative advantage. The main results characterize sufficient conditions on factor productivity and factor supply to predict patterns of international specialization in a multifactor generalization of the Ricardian model which we refer to as an ""elementary neoclassical economy."" These conditions, which hold for an arbitrarily large number of countries, goods, and factors, generalize and extend many results from the previous trade literature. They also offer new insights about the joint effects of technology and factor endowments on international specialization.","['Costinot, Arnaud']",['Neoclassical Models of Trade'],['F11'],An Elementary Theory of Comparative Advantage,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"We characterize equilibria with endogenous debt constraints for a general equilibrium economy with limited commitment in which the only consequence of default is losing the ability to borrow in future periods. First, we show that equilibrium debt limits must satisfy a simple condition that allows agents to exactly roll over existing debt period by period. Second, we provide an equivalence result, whereby the resulting set of equilibrium allocations with self-enforcing private debt is equivalent to the allocations that are sustained with unbacked public debt or rational bubbles. In contrast to the classic result by Bulow and Rogoff (1989a), positive levels of debt are sustainable in our environment because the interest rate is sufficiently low to provide repayment incentives.","['Hellwig, Christian', 'Lorenzoni, Guido']","['General Aggregative Models: Neoclassical', 'Financial Markets and the Macroeconomy', 'International Lending and Debt Problems']","['E13', 'E44', 'F34']",Bubbles and Self-Enforcing Debt,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"The English auction is susceptible to tacit collusion when post-auction interbidder resale is allowed. We show this by constructing equilibria where, with positive probability, one bidder wins the auction without any competition and divides the spoils by optimally reselling the good to the other bidders. These equilibria interim Pareto-dominate (among bidders) the standard value-bidding equilibrium without requiring the bidders to make any commitment on bidding behavior or postbidding spoil division.","['Troger, Thomas', 'Zheng, Charles Z.', 'Garratt, Rodney J.']",['Auctions'],['D44'],Collusion via Resale,0,0,1,0,0,2009,07,01
77,4,2009-07-01,"We present evidence on the effect of social connections between workers and managers on productivity in the workplace. To evaluate whether the existence of social connections is beneficial to the firm's overall performance, we explore how the effects of social connections vary with the strength of managerial incentives and worker's ability. To do so, we combine panel data on individual worker's productivity from personnel records with a natural field experiment in which we engineered an exogenous change in managerial incentives, from fixed wages to bonuses based on the average productivity of the workers managed. We find that when managers are paid fixed wages, they favor workers to whom they are socially connected irrespective of the worker's ability, but when they are paid performance bonuses, they target their effort toward high ability workers irrespective of whether they are socially connected to them or not. Although social connections increase the performance of connected workers, we find that favoring connected workers is detrimental for the firm's overall performance.","['Bandiera, Oriana', 'Rasul, Imran', 'Barankay, Iwan']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Personnel Management; Executives; Executive Compensation', 'Personnel Economics: Compensation and Compensation Methods and Their Effects', 'Personnel Economics: Labor Management', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['J24', 'M12', 'M52', 'M54', 'Z13']",Social Connections and Incentives in the Workplace: Evidence from Personnel Data,0,0,0,0,0,2009,07,01
77,4,2009-07-01,"We develop a model of friendship formation that sheds light on segregation patterns observed in social and economic networks. Individuals have types and see type-dependent benefits from friendships. We examine the properties of a steady-state equilibrium of a matching process of friendship formation. We use the model to understand three empirical patterns of friendship formation: (i) larger groups tend to form more same-type ties and fewer other-type ties than small groups, (ii) larger groups form more ties per capita, and (iii) all groups are biased towards same-type relative to demographics, with the most extreme bias coming from middle-sized groups. We show how these empirical observations can be generated by biases in preferences and biases in meetings. We also illustrate some welfare implications of the model.","['Jackson, Matthew O.', 'Currarini, Sergio', 'Pin, Paolo']","['Network Formation and Analysis: Theory', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D85', 'J15', 'Z13']","An Economic Model of Friendship: Homophily, Minorities, and Segregation",0,0,0,0,0,2009,07,01
80,6,2012-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2012,11,01
80,5,2012-09-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2012,09,01
80,5,2012-09-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 80 Iss. 5.,0,0,0,0,0,2012,09,01
80,4,2012-07-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 80 Iss. 4.,0,0,0,0,0,2012,07,01
80,4,2012-07-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2012,07,01
80,3,2012-05-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 80 Iss. 3.,0,0,0,0,0,2012,05,01
83,2,2015-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,03,01
83,1,2015-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2015,01,01
83,1,2015-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2015,01,01
82,6,2014-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,11,01
82,5,2014-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,09,01
82,4,2014-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2014,07,01
82,4,2014-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,07,01
82,4,2014-07-01,ECONLIT None Found,"['Kain, John F.', 'Hanushek, Eric A.', 'Rivkin, Steven G.']",['Analysis of Education'],['I21'],"Teachers, Schools, and Academic Achievement: Corrigendum",0,0,0,0,0,2014,07,01
82,3,2014-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,05,01
73,6,2005-11-01,"This paper investigates the driving forces behind informal sanctions in cooperation games and the extent to which theories of fairness and reciprocity capture these forces. We find that cooperators' punishment is almost exclusively targeted toward the defectors, but the latter also impose a considerable amount of spiteful punishment on the cooperators. However, spiteful punishment vanishes if the punishers can no longer affect the payoff differences between themselves and the punished individual, whereas the cooperators even increase the resources devoted to punishment in this case. Our data also discriminate between different fairness principles. Fairness theories that are based on the assumption that players compare their own payoff to the group's average or the group's total payoff cannot explain the fact that cooperators target their punishment at the defectors. Fairness theories that assume that players aim to minimize payoff inequalities cannot explain the fact that cooperators punish defectors even if payoff inequalities cannot be reduced. Therefore, retaliation, i.e., the desire to harm those who committed unfair acts, seems to be the most important motive behind fairness-driven informal sanctions.","['Fischbacher, Urs', 'Fehr, Ernst', 'Falk, Armin']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Altruism; Philanthropy; Intergenerational Transfers', 'Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification']","['D63', 'D64', 'Z13']",Driving Forces behind Informal Sanctions,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"We derive a lower bound for the volatility of the permanent component of investors' marginal utility of wealth or, more generally, asset pricing kernels. The bound is based on return properties of long-term zero-coupon bonds, risk-free bonds, and other risky securities. We find the permanent component of the pricing kernel to be very volatile; its volatility is about at least as large as the volatility of the stochastic discount factor. A related measure for the transitory component suggest it to be considerably less important. We also show that, for many cases where the pricing kernel is a function of consumption, innovations to consumption need to have permanent effects.","['Alvarez, Fernando', 'Jermann, Urban J.']","['Consumer Economics: Empirical Analysis', 'Personal Income, Wealth, and Their Distributions', 'Portfolio Choice; Investment Decisions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D12', 'D31', 'G11', nan]",Using Asset Prices to Measure the Persistence of the Marginal Utility of Wealth,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"This paper is concerned with accuracy properties of simulations of approximate solutions for stochastic dynamic models. Our analysis rests upon a continuity property of invariant distributions and a generalized law of large numbers. We then show that the statistics generated by any sufficiently good numerical approximation are arbitrarily close to the set of expected values of the model's invariant distributions. Also, under a contractivity condition on the dynamics, we establish error bounds. These results are of further interest for the comparative study of stationary solutions and the estimation of structural dynamic models.","['Peralta-Alva, Adrian', 'Santos, Manuel S.']","['Statistical Simulation Methods: General', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C15', 'C32']",Accuracy of Simulations for Stochastic Dynamic Models,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"Alternating-offer and demand bargaining models of legislative bargaining make very different predictions in terms of both ex ante and ex post distribution of payoffs, as well as in the role of the order of play. The experiment shows that actual bargaining behavior is not as sensitive to the different bargaining rules as the theoretical point predictions, whereas the comparative statics are in line with both models. We compare our results to studies that attempt to distinguish between these two approaches using field data, finding strong similarities between the laboratory and field data regardless of the underlying bargaining process.","['Kagel, John H.', 'Morelli, Massimo', 'Frechette, Guillaume']","['Bargaining Theory; Matching Theory', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['C78', 'D72']",Behavioral Identification in Coalitional Bargaining: An Experimental Analysis of Demand Bargaining and Alternating Offers,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"We propose and characterize a model of preferences over acts such that the decision maker prefers act f to act g if and only if E[subscript mu] phi (E[subscript pi] u circle f) >= E[subscript mu] phi (E[subscript phi] u circle g), where E is the expectation operator, u is a von Neumann-Morgenstern utility function, phiis an increasing transformation, and mu is a subjective probability over the set Pi of probability measures pi that the decision maker thinks are relevant given his subjective information. A key feature of our model is that it achieves a separation between ambiguity, identified as a characteristic of the decision maker's subjective beliefs, and ambiguity attitude, a characteristic of the decision maker's tastes. We show that attitudes toward pure risk are characterized by the shape of u, as usual, while attitudes toward ambiguity are characterized by the shape of phi. Ambiguity itself is defined behaviorally and is shown to be characterized by properties of the subjective set of measures Pi. One advantage of this model is that the well-developed machinery for dealing with risk attitudes can be applied as well to ambiguity attitudes. The model is also distinct from many in the literature on ambiguity in that it allows smooth, rather than kinked, indifference curves. This leads to different behavior and improved tractability, while still sharing the main features (e.g., Ellsberg's paradox). The maxmin expected utility model (e.g., Gilboa and Schmeidler (1989)) with a given set of measures may be seen as a limiting case of our model with infinite ambiguity aversion. Two illustrative portfolio choice examples are offered.","['Klibanoff, Peter', 'Mukerji, Sujoy', 'Marinacci, Massimo']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Smooth Model of Decision Making under Ambiguity,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"We study how intermediation and asset prices in over-the-counter markets are affected by illiquidity associated with search and bargaining. We compute explicitly the prices at which investors trade with each other, as well as marketmakers' bid and ask prices, in a dynamic model with strategic agents. Bid-ask spreads are lower if investors can more easily find other investors or have easier access to multiple marketmakers. With a monopolistic marketmaker, bid-ask spreads are higher if investors have easier access to the marketmaker. We characterize endogenous search and welfare, and discuss empirical implications.","['Garleanu, Nicolae', 'Duffie, Darrell', 'Pedersen, Lasse Heje']","['Market Structure, Pricing, and Design: General', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D40', 'G14']",Over-the-Counter Markets,0,0,1,0,0,2005,11,01
73,6,2005-11-01,"The mechanism design literature assumes too much common knowledge of the environment among the players and planner. We relax this assumption by studying mechanism design on richer type spaces. We ask when ex post implementation is equivalent to interim (or Bayesian) implementation for all possible type spaces. The equivalence holds in the case of separable environments; examples of separable environments arise (1) when the planner is implementing a social choice function (not correspondence) and (2) in a quasilinear environment with no restrictions on transfers. The equivalence fails in general, including in some quasilinear environments with budget balance. In private value environments, ex post implementation is equivalent to dominant strategies implementation. The private value versions of our results offer new insights into the relationship between dominant strategy implementation and Bayesian implementation.","['Bergemann, Dirk', 'Morris, Stephen']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Robust Mechanism Design,0,0,0,0,0,2005,11,01
73,6,2005-11-01,"In the Self Sufficiency Project (SSP) welfare demonstration, members of a randomly assigned treatment group could receive a subsidy for full-time work. The subsidy was available for 3 years, but only to people who began working full time within 12 months of random assignment. A simple optimizing model suggests that the eligibility rules created an ""establishment"" incentive to find a job and leave welfare within a year of random assignment, and an ""entitlement"" incentive to choose work over welfare once eligibility was established. Building on this insight, we develop an econometric model of welfare participation that allows us to separate the two effects and estimate the impact of the earnings subsidy on welfare entry and exit rates among those who achieved eligibility. The combination of the two incentives explains the time profile of the experimental impacts, which peaked 15 months after random assignment and faded relatively quickly. Our findings suggest that about half of the peak impact of SSP was attributable to the establishment incentive. Despite the extra work effort generated by SSP, the program had no lasting impact on wages and little or no long-run effect on welfare participation.","['Hyslop, Dean R.', 'Card, David']","['Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Wages, Compensation, and Labor Costs: Public Policy']","['I38', 'J38']",Estimating the Effects of a Time-Limited Earnings Subsidy for Welfare-Leavers,0,0,0,0,0,2005,11,01
73,5,2005-09-01,"Each agent in a finite set requests an integer quantity of an idiosyncratic good; the resulting total cost must be shared among the participating agents. The Aumann-Shapley prices are given by the Shapley value of the game where each unit of each good is regarded as a distinct player. The Aumann-Shapley cost-sharing method charges to an agent the sum of the prices attached to the units she consumes. We show that this method is characterized by the two standard axioms of Additivity and Dummy, and the property of No Merging or Splitting: agents never find it profitable to split or to merge their consumptions. We offer a variant of this result using the No Reshuffling condition: the total cost share paid by a group of agents who consume perfectly substitutable goods depends only on their aggregate consumption. We extend this characterization to the case where agents are allowed to consume bundles of goods.","['Sprumont, Yves']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],On the Discrete Version of the Aumann-Shapley Cost-Sharing Method,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"This paper analyzes the conditions under which consistent estimation can be achieved in instrumental variables (IV) regression when the available instruments are weak and the number of instruments, K[subscript n], goes to infinity with the sample size. We show that consistent estimation depends importantly on the strength of the instruments as measured by r[subscript n], the rate of growth of the so-called concentration parameter, and also on K[subscript n]. In particular, when K[subscript n] approaches infinity, the concentration parameter can grow, even if each individual instrument is only weakly correlated with the endogenous explanatory variables, and consistency of certain estimators can be established under weaker conditions than have previously been assumed in the literature. Hence, the use of many weak instruments may actually improve the performance of certain point estimators. More specifically, we find that the limited information maximum likelihood (LIML) estimator and the bias-corrected two-stage least squares (B2SLS) estimator are consistent when sqare-root-of-K[subscript n]/r[subscript n] approaches 0, while the two-stage least squares (2SLS) estimator is consistent only if K[subscript n]/r[subscript n] approaches 0 as n approaches infinity. These consistency results suggest that LIML and B2SLS are more robust to instrument weakness than 2SLS.","['Swanson, Norman R.', 'Chao, John C.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Consistent Estimation with a Large Number of Weak Instruments,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"There is evidence that people do not fully take into account how other people's actions depend on these other people's information. This paper defines and applies a new equilibrium concept in games with private information, cursed equilibrium, which assumes that each player correctly predicts the distribution of other players' actions, but underestimates the degree to which these actions are correlated with other players' information. We apply the concept to common-values auctions, where cursed equilibrium captures the widely observed phenomenon of the winner's curse, and to bilateral trade, where cursedness predicts trade in adverse-selections settings for which conventional analysis predicts no trade. We also apply cursed equilibrium to voting and signalling models. We test a single-parameter variant of our model that embeds Bayesian Nash equilibrium as a special case and find that parameter values that correspond to cursedness fit a broad range of experimental datasets better than the parameter value that corresponds to Bayesian Nash equilibrium.","['Eyster, Erik', 'Rabin, Matthew']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Cursed Equilibrium,0,0,1,0,0,2005,09,01
73,5,2005-09-01,"In this paper, I consider a dynamic economy in which a government needs to finance a stochastic process of purchases. The agents in the economy are privately informed about their skills, which evolve stochastically over time; I impose no restriction on the stochastic evolution of skills. I construct a tax system that implements a symmetric constrained Pareto optimal allocation. The tax system is constrained to be linear in an agent's wealth, but can be arbitrarily nonlinear in his current and past labor incomes. I find that wealth taxes in a given period depend on the individual's labor income in that period and previous ones. However, in any period, the expectation of an agent's wealth tax rate in the following period is zero. As well, the government never collects any net revenue from wealth taxes.","['Kocherlakota, Narayana R.']","['Asymmetric and Private Information; Mechanism Design', 'Fiscal Policy', 'Taxation and Subsidies: Efficiency; Optimal Taxation', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['D82', 'E62', 'H21', 'H24']",Zero Expected Wealth Taxes: A Mirrlees Approach to Dynamic Optimal Taxation,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"This paper considers regression models for cross-section data that exhibit cross-section dependence due to common shocks, such as macroeconomic shocks. The paper analyzes the properties of least squares (LS) estimators in this context. The results of the paper allow for any form of cross-section dependence and heterogeneity across population units. The probability limits of the LS estimators are determined, and necessary and sufficient conditions are given for consistency. The asymptotic distributions of the estimators are found to be mixed normal after recentering and scaling. The t, Wald, and F statistics are found to have asymptotic standard normal, chi[superscript 2], and scaled chi[superscript 2] distributions, respectively, under the null hypothesis when the conditions required for consistency of the parameter under test hold. However, the absolute values of t, Wald, and F statistics are found to diverge to infinity under the null hypothesis when these conditions fail. Confidence intervals exhibit similarly dichotomous behavior. Hence, common shocks are found to be innocuous in some circumstances, but quite problematic in others. Models with factor structures for errors and regressors are considered. Using the general results, conditions are determined under which consistency of the LS estimators holds and fails in models with factor structures. The results are extended to cover heterogeneous and functional factor structures in which common factors have different impacts on different population units.","['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Cross-Section Regression with Common Shocks,0,0,0,0,0,2005,09,01
73,5,2005-09-01,This paper provides weak conditions under which there is nonparametric interval identification of local features of a structural function that depends on a discrete endogenous variable and is nonseparable in latent variates. The function delivers values of a discrete or continuous outcome and instruments may be discrete valued. Application of the analog principle leads to quantile regression based interval estimators of values and partial differences of structural functions. The results are used to investigate the nonparametric identifying power of the quarter-of-birth instruments used in Angrist and Krueger's 1991 study of the returns to schooling.,"['Chesher, Andrew']","['Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions', 'Analysis of Education']","['C35', 'I21']",Nonparametric Identification under Discrete Variation,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"This paper addresses how changing the admission and financial aid rules at colleges affects future earnings. I estimate a structural model of the following decisions by individuals: where to submit applications, which school to attend, and what field to study. The model also includes decisions by schools as to which students to accept and how much financial aid to offer. Simulating how black educational choices would change were they to face the white admission and aid rules shows that race-based advantages had little effect on earnings.","['Arcidiacono, Peter']","['Analysis of Education', 'Economics of Minorities, Races, Indigenous Peoples, and Immigrants; Non-labor Discrimination', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['I21', 'J15', 'J24']",Affirmative Action in Higher Education: How Do Admission and Financial Aid Rules Affect Future Earnings?,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"How much discretion should the monetary authority have in setting its policy? This question is analyzed in an economy with an agreed-upon social welfare function that depends on the economy's randomly fluctuating state. The monetary authority has private information about that state. Well designed rules trade off society's desire to give the monetary authority discretion to react to its private information against society's need to prevent that authority from giving in to the temptation to stimulate the economy with unexpected inflation, the time inconsistency problem. Although this dynamic mechanism design problem seems complex, its solution is simple: legislate an inflation cap. The optimal degree of monetary policy discretion turns out to shrink as the severity of the time inconsistency problem increases relative to the importance of private information. In an economy with a severe time inconsistency problem and unimportant private information, the optimal degree of discretion is none.","['Athey, Susan', 'Atkeson, Andrew', 'Kehoe, Patrick J.']",['Monetary Policy'],['E52'],The Optimal Degree of Discretion in Monetary Policy,0,0,0,0,0,2005,09,01
73,5,2005-09-01,"We exhibit a large class of simple rules of behavior, which we call adaptive heuristics, and show that they generate rational behavior in the long run. These adaptive heuristics are based on natural regret measures, and may be viewed as a bridge between rational and behavioral viewpoints. Taken together, the results presented here establish a solid connection between the dynamic approach of adaptive heuristics and the static approach of correlated equilibria.","['Hart, Sergiu']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Microeconomic Behavior: Underlying Principles']","['C73', 'D01']",Adaptive Heuristics,0,0,0,0,0,2005,09,01
73,4,2005-07-01,ECONLIT None Found,"['Noldeke, Georg', 'Samuelson, Larry']",['Consumer Economics: Theory'],['D11'],Information-Based Relative Consumption Effects: Correction,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"We apply recent econometric advances to study the distribution of commuters' preferences for speedy and reliable highway travel. Our analysis applies mixed logit to combined revealed and stated preference data on commuter choices of whether to pay a toll for congestion-free express travel. We find that motorists exhibit high values of travel time and reliability, and substantial heterogeneity in those values. We suggest that road pricing policies designed to cater to such varying preferences can improve efficiency and reduce the disparity of welfare impacts compared with recent pricing experiments.","['Yan, Jia', 'Winston, Clifford', 'Small, Kenneth A.']","['Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise']",['R41'],Uncovering the Distribution of Motorists' Preferences for Travel Time and Reliability,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"It is well known that standard asymptotic theory is not applicable or is very unreliable in models with identification problems or weak instruments. One possible way out consists of using a variant of the Anderson-Rubin ((1949), AR) procedure. The latter allows one to build exact tests and confidence sets only for the full vector of the coefficients of the endogenous explanatory variables in a structural equation, but not for individual coefficients. This problem may in principle be overcome by using projection methods (Dufour (1997), Dufour and Jasiak (2001)). At first sight, however, this technique requires the application of costly numerical algorithms. In this paper, we give a general necessary and sufficient condition that allows one to check whether an AR-type confidence set is bounded. Furthermore, we provide an analytic solution to the problem of building projection-based confidence sets from AR-type confidence sets. The latter involves the geometric properties of ""quadrics"" and can be viewed as an extension of usual confidence intervals and ellipsoids. Only least squares techniques are needed to build the confidence intervals.","['Taamouti, Mohamed', 'Dufour, Jean-Marie']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Projection-Based Statistical Inference in Linear Structural Models with Possibly Weak Instruments,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"This paper proposes a model for multilateral contracting, where contracts are written and renegotiated over time, and where contracts may impose externalities on other agents. Equilibria always exist and the equilibrium value function is linear and monotonically increasing on the contracts. If the grand coalition, or contracting among all agents, is inefficient, we show that bargaining delays arise in positive-externality games and equilibrium inefficiency may remain bounded away from zero even as bargaining frictions converge to zero. Otherwise, if the grand coalition is efficient, there are no bargaining delays, convergence to the grand coalition occurs in a finite number of contracting rounds, and the outcome becomes efficient as players become more patient.","['Gomes, Armando']","['Bargaining Theory; Matching Theory', 'Economics of Contract: Theory']","['C78', 'D86']",Multilateral Contracting with Externalities,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"We consider semiparametric estimation of the memory parameter in a model that includes as special cases both long-memory stochastic volatility and fractionally integrated exponential GARCH (FIEGARCH) models. Under our general model the logarithms of the squared returns can be decomposed into the sum of a long-memory signal and a white noise. We consider periodogram-based estimators using a local Whittle criterion function. We allow the optional inclusion of an additional term to account for possible correlation between the signal and noise processes, as would occur in the FIEGARCH model. We also allow for potential nonstationarity in volatility by allowing the signal process to have a memory parameter d* >= 1/2. We show that the local Whittle estimator is consistent for d* element of (0,1). We also show that the local Whittle estimator is asymptotically normal for d* element of (0,3/4) and essentially recovers the optimal semiparametric rate of convergence for this problem. In particular, if the spectral density of the short-memory component of the signal is sufficiently smooth, a convergence rate of n[superscript 2/5 - delta] for d* element of (0,3/4) can be attained, where n is the sample size and delta >0 is arbitrarily small. This represents a strong improvement over the performance of existing semiparametric estimators of persistence in volatility. We also prove that the standard Gaussian semiparametric estimator is asymptotically normal if d* = 0. This yields a test for long memory in volatility.","['Moulines, Eric', 'Hurvich, Clifford M.', 'Soulier, Philippe']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Estimating Long Memory in Volatility,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"In econometric applications, often several hypothesis tests are carried out at once. The problem then becomes how to decide which hypotheses to reject, accounting for the multitude of tests. This paper suggests a stepwise multiple testing procedure that asymptotically controls the familywise error rate. Compared to related single-step methods, the procedure is more powerful and often will reject more false hypotheses. In addition, we advocate the use of studentization when feasible. Unlike some stepwise methods, the method implicitly captures the joint dependence structure of the test statistics, which results in increased ability to detect false hypotheses. The methodology is presented in the context of comparing several strategies to a common benchmark. However, our ideas can easily be extended to other contexts where multiple tests occur. Some simulation studies show the improvements of our methods over previous proposals. We also provide an application to a set of real data.","['Romano, Joseph P.', 'Wolf, Michael']","['Hypothesis Testing: General', 'Statistical Simulation Methods: General']","['C12', 'C15']",Stepwise Multiple Testing as Formalized Data Snooping,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"This paper develops theoretical foundations for an error analysis of approximate equilibria in dynamic stochastic general equilibrium models with heterogeneous agents and incomplete financial markets. While there are several algorithms that compute prices and allocations for which agents' first-order conditions are approximately satisfied (""approximate equilibria""), there are few results on how to interpret the errors in these candidate solutions and how to relate the computed allocations and prices to exact equilibrium allocations and prices. We give a simple example to illustrate that approximate equilibria might be very far from exact equilibria. We then interpret approximate equilibria as equilibria for close-by economies; that is, for economies with close-by individual endowments and preferences. We present an error analysis for two models that are commonly used in applications, an overlapping generations (OLG) model with stochastic production and an asset pricing model with infinitely lived agents. We provide sufficient conditions that ensure that approximate equilibria are close to exact equilibria of close-by economies. Numerical examples illustrate the analysis.","['Schmedders, Karl', 'Kubler, Felix']","['Model Evaluation, Validation, and Selection', 'Existence and Stability Conditions of Equilibrium', 'Computational Techniques; Simulation Modeling', 'Incomplete Markets', 'General Aggregative Models: Neoclassical']","['C52', 'C62', 'C63', 'D52', 'E13']",Approximate versus Exact Equilibria in Dynamic Economies,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"This paper shows that the bootstrap does not consistently estimate the asymptotic distribution of the maximum score estimator. The theory developed also applies to other estimators within a cube-root convergence class. For some single-parameter estimators in this class, the results suggest a simple method for inference based upon the bootstrap.","['Abrevaya, Jason', 'Huang, Jian']","['Statistical Simulation Methods: General', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities']","['C15', 'C25']",On the Bootstrap of the Maximum Score Estimator,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"Exploiting a rich panel data set on anti-ulcer drug prescriptions, we measure the effects of uncertainty and learning in the demand for pharmaceutical drugs. We estimate a dynamic matching model of demand under uncertainty in which patients learn from prescription experience about the effectiveness of alternative drugs. Unlike previous models, we allow drugs to have distinct symptomatic and curative effects, and endogenize treatment length by allowing drug choices to affect patients' underlying probability of recovery. We find that drugs' rankings along these dimensions differ, with high symptomatic effects for drugs with the highest market shares and high curative effects for drugs with the greatest medical efficacy. Our results also indicate that while there is substantial heterogeneity in drug efficacy across patients, learning enables patients and their doctors to dramatically reduce the costs of uncertainty in pharmaceutical markets.","['Shum, Matthew', 'Crawford, Gregory S.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Chemicals; Rubber; Drugs; Biotechnology; Plastics']","['D81', 'D83', 'L65']",Uncertainty and Learning in Pharmaceutical Demand,1,0,0,0,0,2005,07,01
73,4,2005-07-01,"A decision maker is asked to express her beliefs by assigning probabilities to certain possible states. We focus on the relationship between her database and her beliefs. We show that if beliefs given a union of two databases are a convex combination of beliefs given each of the databases, the belief formation process follows a simple formula: beliefs are a similarity-weighted average of the beliefs induced by each past case.","['Gilboa, Itzhak', 'Schmeidler, David', 'Samet, Dov', 'Billot, Antoine']","['Information, Knowledge, and Uncertainty: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D80', 'D83']",Probabilities as Similarity-Weighted Frequencies,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"We propose a generalized method of moments (GMM) Lagrange multiplier statistic, i.e., the K statistic, that uses a Jacobian estimator based on the continuous updating estimator that is asymptotically uncorrelated with the sample average of the moments. Its asymptotic chi[superscript 2] distribution therefore holds under a wider set of circumstances, like weak instruments, than the standard full rank case for the expected Jacobian under which the asymptotic chi[superscript 2] distributions of the traditional statistics are valid. The behavior of the K statistic can be spurious around inflection points and maxima of the objective function. This inadequacy is overcome by combining the K statistic with a statistic that tests the validity of the moment equations and by an extension of Moreira's (2003) conditional likelihood ratio statistic toward GMM. We conduct a power comparison to test for the risk aversion parameter in a stochastic discount factor model and construct its confidence set for observed consumption growth and asset return series.","['Kleibergen, Frank']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Testing Parameters in GMM without Assuming That They Are Identified,0,0,0,0,0,2005,07,01
73,4,2005-07-01,"We propose two new methods for estimating models with nonseparable errors and endogenous regressors. The first method estimates a local average response. One estimates the response of the conditional mean of the dependent variable to a change in the explanatory variable while conditioning on an external variable and then undoes the conditioning. The second method estimates the nonseparable function and the joint distribution of the observable and unobservable explanatory variables. An external variable is used to impose an equality restriction, at two points of support, on the conditional distribution of the unobservable random term given the regressor and the external variable. Our methods apply to cross sections, but our lead examples involve panel data cases in which the choice of the external variable is guided by the assumption that the distribution of the unobservable variables is exchangeable in the values of the endogenous variable for members of a group.","['Matzkin, Rosa L.', 'Altonji, Joseph G.']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models']","['C23', 'C33']",Cross Section and Panel Data Estimators for Nonseparable Models with Endogenous Regressors,0,0,0,0,0,2005,07,01
73,3,2005-05-01,"For stationary time series models with serial correlation, we consider generalized method of moments (GMM) estimators that use heteroskedasticity and autocorrelation consistent (HAC) positive definite weight matrices and generalized empirical likelihood (GEL) estimators based on smoothed moment conditions. Following the analysis of Newey and Smith (2004) for independent observations, we derive second order asymptotic biases of these estimators. The inspection of bias expressions reveals that the use of smoothed GEL, in contrast to GMM, removes the bias component associated with the correlation between the moment function and its derivative, while the bias component associated with third moments depends on the employed kernel function. We also analyze the case of no serial correlation, and find that the seemingly unnecessary smoothing and HAC estimation can reduce the bias for some of the estimators.","['Anatolyev, Stanislav']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']","GMM, GEL, Serial Correlation, and Asymptotic Bias",0,0,0,0,0,2005,05,01
73,3,2005-05-01,"We present a new method for solving asset pricing models, which yields an analytic price-dividend function of one state variable. To illustrate our method we give a detailed analysis of Abel's asset pricing model. A function is analytic in an open interval if it can be represented as a convergent power series near every point of that interval. In addition to allowing us to solve for the exact equilibrium price-dividend function, the analyticity property also lets us assess the accuracy of any numerical solution procedure used in the asset pricing literature.","['Cosimano, Thomas F.', 'Chen, Yu', 'Himonas, Alex A.', 'Calin, Ovidiu L.']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Solving Asset Pricing Models When the Price-Dividend Function Is Analytic,0,0,0,0,0,2005,05,01
73,3,2005-05-01,"Previous work on the denomination structure of currency treats as exogenous the distribution of transactions and the denominations held by people. Here, by way of a matching model, both are endogenous. In the model, trades in pairwise meetings alternate in time with the opportunity to freely choose a portfolio of denominations and there is a trade-off between the benefits of small-denomination money for transacting and the costliness of carrying a large quantity of small-denomination money. For a given denomination structure, a monetary steady state is shown to exist. The model implies that too small denominations are abandoned.","['Wallace, Neil', 'Lee, Manjong', 'Zhu, Tao']",['Monetary Systems; Standards; Regimes; Government and the Monetary System; Payment Systems'],['E42'],Modeling Denomination Structures,0,0,0,0,0,2005,05,01
73,3,2005-05-01,"In a number of semiparametric models, smoothing seems necessary in order to obtain estimates of the parametric component which are asymptotically normal and converge at parametric rate. However, smoothing can inflate the error in the normal approximation, so that refined approximations are of interest, especially in sample sizes that are not enormous. We show that a bootstrap distribution achieves a valid Edgeworth correction in the case of density-weighted averaged derivative estimates of semiparametric index models. Approaches to bias reduction are discussed. We also develop a higher-order expansion to show that the bootstrap achieves a further reduction in size distortion in the case of two-sided testing. The finite-sample performance of the methods is investigated by means of Monte Carlo simulations from a Tobit model.","['Nishiyama, Yoshihiko', 'Robinson, Peter M.']","['Semiparametric and Nonparametric Methods: General', 'Statistical Simulation Methods: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C14', 'C15', 'C21']",The Bootstrap and the Edgeworth Correction for Semiparametric Averaged Derivatives,0,0,0,0,0,2005,05,01
73,3,2005-05-01,"Entropy is a classical statistical concept with appealing properties. Establishing asymptotic distribution theory for smoothed nonparametric entropy measures of dependence has so far proved challenging. In this paper, we develop an asymptotic theory for a class of kernel-based smoothed nonparametric entropy measures of serial dependence in a time-series context. We use this theory to derive the limiting distribution of Granger and Lin's (1994) normalized entropy measure of serial dependence, which was previously not available in the literature. We also apply our theory to construct a new entropy-based test for serial dependence, providing an alternative to Robinson's (1991) approach. To obtain accurate inferences, we propose and justify a consistent smoothed bootstrap procedure. The naive bootstrap is not consistent for our test. Our test is useful in, for example, testing the random walk hypothesis, evaluating density forecasts, and identifying important lags of a time series. It is asymptotically locally more powerful than Robinson's (1991) test, as is confirmed in our simulation. An application to the daily S&P 500 stock price index illustrates our approach.","['White, Halbert', 'Hong, Yongmiao']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Asymptotic Distribution Theory for Nonparametric Entropy Measures of Serial Dependence,0,0,0,0,0,2005,05,01
73,3,2005-05-01,"We investigate a class of semiparametric ARCH(8) models that includes as a special case the partially nonparametric (PNP) model introduced by Engle and Ng (1993) and which allows for both flexible dynamics and flexible function form with regard to the ""news impact"" function. We show that the functional part of the model satisfies a type II linear integral equation and give simple conditions under which there is a unique solution. We propose an estimation method that is based on kernel smoothing and profiled likelihood. We establish the distribution theory of the parametric components and the pointwise distribution of the nonparametric component of the model. We also discuss efficiency of both the parametric part and the nonparametric part. We investigate the performance of our procedures on simulated data and on a sample of S&P500 index returns. We find evidence of asymmetric news impact functions, consistent with the parametric analysis.","['Mammen, E.', 'Linton, O.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Estimating Semiparametric ARCH(Infinity) Models by Kernal Smoothing Methods,0,0,0,0,0,2005,05,01
73,3,2005-05-01,"Extensive-form market games typically have a large number of noncompetitive equilibria. In this paper, we argue that the complexity of noncompetitive behavior provides a justification for competitive equilibrium in the sense that if rational agents have an aversion to complexity (at the margin), then maximizing behavior will result in simple behavioral rules and hence in a competitive outcome. For this purpose, we use a class of extensive-form dynamic matching and bargaining games with a finite number of agents. In particular, we consider markets with heterogeneous buyers and sellers and deterministic, exogenous, sequential matching rules, although the results can be extended to other matching processes. If the complexity costs of implementing strategies enter players' preferences lexicographically with the standard payoff, then every equilibrium strategy profile induces a competitive outcome.","['Gale, Douglas', 'Sabourian, Hamid']","['Bargaining Theory; Matching Theory', 'Market Structure, Pricing, and Design: Perfect Competition', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C78', 'D41', 'D43']",Complexity and Competition,0,0,1,0,0,2005,05,01
73,3,2005-05-01,"This paper uses the marginal treatment effect (MTE) to unify the nonparametric literature on treatment effects with the econometric literature on structural estimation using a nonparametric analog of a policy invariant parameter; to generate a variety of treatment effects from a common semiparametric functional form; to organize the literature on alternative estimators; and to explore what policy questions commonly used estimators in the treatment effect literature answer. A fundamental asymmetry intrinsic to the method of instrumental variables (IV) is noted. Recent advances in IV estimation allow for heterogeneity in responses but not in choices, and the method breaks down when both choice and response equations are heterogeneous in a general way.","['Heckman, James J.', 'Vytlacil, Edward']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],"Structural Equations, Treatment Effects, and Econometric Policy Evaluation",0,0,0,0,0,2005,05,01
73,2,2005-03-01,"We consider an exchange economy in which there are infinitely many consumers and some commodities are bads, that is, cause disutility to consumers. We give an example of such an economy for which there is no competitive equilibrium or its variants (quasi- or pseudo-equilibrium), and an example of the failure of the so-called uniform integrability condition of equilibrium allocations of increasingly populous finite economies.","['Hara, Chiaki']",['Exchange and Production Economies'],['D51'],Existence of Equilibria in Economies with Bads,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"Repeated games with unknown payoff distributions are analogous to a single decision maker's ""multi-armed bandit"" problem. Each state of the world corresponds to a different payoff matrix of a stage game. When monitoring is perfect, information about the state is public, and players are sufficiently patient, the following result holds: for any function that maps each state to a payoff vector that is feasible and individually rational in that state, there is a sequential equilibrium in which players experiment to learn the realized state and achieve a payoff close to the one specified for that state.","['Wiseman, Thomas']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",A Partial Folk Theorem for Games with Unknown Payoff Distributions,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"We investigate the effect of employer-provided health insurance on job mobility rates and economic welfare using a search, matching, and bargaining framework. In our model, health insurance coverage decisions are made in a cooperative manner that recognizes the productivity effects of health insurance as well as its nonpecuniary value to the employee. The resulting equilibrium is one in which not all employment matches are covered by health insurance, wages at jobs providing health insurance are larger (in a stochastic sense) than those at jobs without health insurance, and workers at jobs with health insurance are less likely to leave those jobs, even after conditioning on the wage rate. We estimate the model using the 1996 panel of the Survey of Income and Program Participation, and find that the employer-provided health insurance system does not lead to any serious inefficiencies in mobility decisions.","['Dey, Matthew S.', 'Flinn, Christopher J.']","['Insurance; Insurance Companies; Actuarial Studies', 'Analysis of Health Care Markets', 'Wage Level and Structure; Wage Differentials', 'Nonwage Labor Costs and Benefits; Retirement Plans; Private Pensions', 'Job, Occupational, and Intergenerational Mobility; Promotion']","['G22', 'I11', 'J31', 'J32', 'J62']",An Equilibrium Model of Health Insurance Provision and Wage Determination,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"In many trading environments, any incentive compatible and individually rational market mechanism will be either inefficient or will run a deficit. We prove that as the market size m gets large, for any fixed surplus (or deficit) x, m times the minimal absolute inefficiency converges to c(x) where c([middot]) is essentially a quadratic function of x. We introduce a new mechanism, the double auction with a fixed transaction fee. By choosing the size of the fee appropriately, any level of deficit or surplus can be implemented and the resulting mechanisms achieve the above bound. Corollaries include: an asymptotic version of the Myerson-Satterthwaite Impossibility Theorem; a description of the minimal subsidy required to implement the efficient trading rule; a characterization of the minimal inefficiency obtainable with budget-balanced market mechanisms; recommendations on the optimal organization of trade; and insights on the effects of taxation.","['Tatur, Tymon']","['Auctions', 'Allocative Efficiency; Cost-Benefit Analysis', 'Asymmetric and Private Information; Mechanism Design', 'Taxation and Subsidies: Efficiency; Optimal Taxation']","['D44', 'D61', 'D82', 'H21']",On the Trade Off between Deficit and Inefficiency and the Double Auction with a Fixed Transaction Fee,0,0,1,0,0,2005,03,01
73,2,2005-03-01,"This paper brings together the microeconomic-labor and the macroeconomic-equilibrium views of matching in labor markets. We nest a job matching model a la Jovanovic (1984) into a Mortensen and Pissarides (1994)-type equilibrium search environment. The resulting framework preserves the implications of job matching theory for worker turnover and wage dynamics, and it also allows for aggregation and general equilibrium analysis. We obtain two new equilibrium implications of job matching and search frictions for wage inequality. First, learning about match quality and worker turnover map Gaussian output noise into an ergodic wage distribution of empirically accurate shape: unimodal, skewed, with a Paretian right tail. Second, high idiosyncratic productivity risk hinders learning and sorting, and reduces wage inequality. The equilibrium solutions for the wage distribution and for the aggregate worker flows--quits to unemployment and to other jobs, displacements, hires--provide the likelihood function of the model in closed form.","['Moscarini, Giuseppe']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Wage Level and Structure; Wage Differentials', 'Labor Contracts', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J24', 'J31', 'J41', 'J64']",Job Matching and the Wage Distribution,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"Consider a two-player discounted infinitely repeated game. A player's belief is a probability distribution over the opponent's repeated game strategies. This paper shows that, for a large class of repeated games, there are no beliefs that satisfy three properties: learnability, a diversity of belief condition called CSP, and consistency. Loosely, if players learn to forecast the path of play whenever each plays a strategy that the other anticipates (in the sense of being in the support of that player's belief) and if the sets of anticipated strategies are sufficiently rich, then neither anticipates any of his opponent's best responses. This generalizes results in Nachbar (1997).","['Nachbar, John H.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Beliefs in Repeated Games,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"This paper disentangles the impact of schools and teachers in influencing achievement with special attention given to the potential problems of omitted or mismeasured variables and of student and school selection. Unique matched panel data from the UTD Texas Schools Project permit the identification of teacher quality based on student performance along with the impact of specific, measured components of teachers and schools. Semiparametric lower bound estimates of the variance in teacher quality based entirely on within-school heterogeneity indicate that teachers have powerful effects on reading and mathematics achievement, though little of the variation in teacher quality is explained by observable characteristics such as education or experience. The results suggest that the effects of a costly ten student reduction in class size are smaller than the benefit of moving one standard deviation up the teacher quality distribution, highlighting the importance of teacher effectiveness in the determination of school quality.","['Kain, John F.', 'Hanushek, Eric A.', 'Rivkin, Steven G.']",['Analysis of Education'],['I21'],"Teachers, Schools, and Academic Achievement",0,0,0,0,0,2005,03,01
73,2,2005-03-01,"We introduce a class of strategies that generalizes examples constructed in two-player games under imperfect private monitoring. A sequential equilibrium is belief-free if, after every private history, each player's continuation strategy is optimal independently of his belief about his opponents' private histories. We provide a simple and sharp characterization of equilibrium payoffs using those strategies. While such strategies support a large set of payoffs, they are not rich enough to generate a folk theorem in most games besides the prisoner's dilemma, even when noise vanishes.","['Ely, Jeffrey C.', 'Olszewski, Wojciech', 'Horner, Johannes']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Belief-Free Equilibria in Repeated Games,0,0,0,0,0,2005,03,01
73,2,2005-03-01,"The paper studies the optimal tax-subsidy schedules in an economy where the only decision of the agents is to work, or not, with an application to the case of France. Given an income guarantee provided by the welfare state, the tax schedule that maximizes government revenue provides a benchmark, the Laffer bound, above which it is inefficient to tax. In fact, under mild conditions, a feasible allocation is second best optimal if and only if the associated taxes are lower than the Laffer bound. The only restriction that efficiency puts on the shape of the tax scheme is this upper Laffer bound. The Laffer tax scheme itself can be computed from the joint distribution of the agents' productivities and work opportunity costs. Depending on the economy, it can take widely different forms, and exhibit, for instance, negative marginal tax rates. After estimating the joint distribution of productivities and work opportunity costs on French data, I compute the Laffer bound for two subpopulations, single women and married women with two children or more. Quite surprisingly, the actual incentives to work appear to be very close to the bound.","['Laroque, Guy']","['Taxation and Subsidies: Efficiency; Optimal Taxation', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs', 'Time Allocation and Labor Supply', 'Wage Level and Structure; Wage Differentials', 'Wages, Compensation, and Labor Costs: Public Policy']","['H21', 'H23', 'I38', 'J22', 'J31', 'J38']",Income Maintenance and Labor Force Participation,0,0,0,0,0,2005,03,01
73,1,2005-01-01,"We develop general model-free adjustment procedures for the calculation of unbiased volatility loss functions based on practically feasible realized volatility benchmarks. The procedures, which exploit recent nonparametric asymptotic distributional results, are both easy-to-implement and highly accurate in empirically realistic situations. We also illustrate that properly accounting for the measurement errors in the volatility forecast evaluations reported in the existing literature can result in markedly higher estimates for the true degree of return volatility predictability.","['Bollerslev, Tim', 'Andersen, Torben G.', 'Meddahi, Nour']","['Forecasting Models; Simulation Methods', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'International Financial Markets']","['C53', nan, 'G15']",Correcting the Errors: Volatility Forecast Evaluation Using High-Frequency Data and Realized Volatilities,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"We study the monotonicity of the equilibrium bid with respect to the number of bidders n in affiliated private-value models of first-price sealed-bid auctions and prove the existence of a large class of such models in which the equilibrium bid function is not increasing in n. We moreover decompose the effect of a change in n on the bid level into a competition effect and an affiliation effect. The latter suggests to the winner of the auction that competition is less intense than she had thought before the auction. Since the affiliation effect can occur in both private- and common-value models, a negative relationship between the bid level and n does not allow one to distinguish between the two models and is also not necessarily (only) due to bidders taking account of the winner's curse.","['Pinkse, Joris', 'Tan, Guofu']",['Auctions'],['D44'],The Affiliation Effect in First-Price Auctions,0,0,1,0,0,2005,01,01
73,1,2005-01-01,"The ability of quantile regression models to characterize the heterogeneous impact of variables on different points of an outcome distribution makes them appealing in many economic applications. However, in observational studies, the variables of interest (e.g., education, prices) are often endogenous, making conventional quantile regression inconsistent and hence inappropriate for recovering the causal effects of these variables on the quantiles of economic outcomes. In order to address this problem, we develop a model of quantile treatment effects (QTE) in the presence of endogeneity and obtain conditions for identification of the QTE without functional form assumptions. The principal feature of the model is the imposition of conditions that restrict the evolution of ranks across treatment states. This feature allows us to overcome the endogeneity problem and recover the true QTE through the use of instrumental variables. The proposed model can also be equivalently viewed as a structural simultaneous equation model with nonadditive errors, where QTE can be interpreted as the structural quantile effects (SQE).","['Chernozhukov, Victor', 'Hansen, Christian']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions']","['C21', 'C35']",An IV Model of Quantile Treatment Effects,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"This paper considers a general equilibrium model in which the distinction between uncertainty and risk is formalized by assuming agents have incomplete preferences over state-contingent consumption bundles, as in Bewley (1986). Without completeness, individual decision making depends on a set of probability distributions over the state space. A bundle is preferred to another if and only if it has larger expected utility for all probabilities in this set. When preferences are complete this set is a singleton, and the model reduces to standard expected utility. In this setting, we characterize Pareto optima and equilibria, and show that the presence of uncertainty generates robust indeterminacies in equilibrium prices and allocations for any specification of initial endowments. We derive comparative statics results linking the degree of uncertainty with changes in equilibria. Despite the presence of robust indeterminacies, we show that equilibrium prices and allocations vary continuously with underlying fundamentals. Equilibria in a standard risk economy are thus robust to adding small degrees of uncertainty. Finally, we give conditions under which some assets are not traded due to uncertainty aversion.","['Rigotti, Luca', 'Shannon, Chris']","['Exchange and Production Economies', 'Criteria for Decision-Making under Risk and Uncertainty']","['D51', 'D81']",Uncertainty and Risk in Financial Markets,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"We compare three market structures for monetary economies: bargaining (search equilibrium); price taking (competitive equilibrium); and price posting (competitive search equilibrium). We also extend work on the microfoundations of money by allowing a general matching technology and entry. We study how equilibrium and the effects of policy depend on market structure. Under bargaining, trade and entry are both inefficient, and inflation implies first-order welfare losses. Under price taking, the Friedman rule solves the first inefficiency but not the second, and inflation may actually improve welfare. Under posting, the Friedman rule yields the first best, and inflation implies second-order welfare losses.","['Wright, Randall', 'Rocheteau, Guillaume']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Price Level; Inflation; Deflation', 'Money and Interest Rates: General']","['D83', 'E31', 'E40']","Money in Search Equilibrium, in Competitive Equilibrium, and in Competitive Search Equilibrium",0,0,0,0,0,2005,01,01
73,1,2005-01-01,"Fix finite pure strategy sets S[subscript 1], . . . ,S[subscript n], and let S = S[subscript 1] x . . . x S[subscript n]. In our model of a random game the agents' payoffs are statistically independent, with each agent's payoff uniformly distributed on the unit sphere in R[open][superscript] S. For given nonempty T[subscript 1 is a subset of S[subscript 1], . . . , T[subscript n is a subset of S[subscript n] we give a computationally implementable formula for the mean number of Nash equilibria in which each agent i's mixed strategy has support T[subscript i]. The formula is the product of two expressions. The first is the expected number of totally mixed equilibria for the truncated game obtained by eliminating pure strategies outside the sets T[subscript i].","['McLennan, Andrew']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",The Expected Number of Nash Equilibria of a Normal Form Game,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"We show existence of equilibria in distributional strategies for a wide class of private value auctions, including the first general existence result for double auctions. The set of equilibria is invariant to the tie-breaking rule. The model incorporates multiple unit demands, all standard pricing rules, reserve prices, entry costs, and stochastic demand and supply. Valuations can be correlated and asymmetrically distributed. For double auctions, we show further that at least one equilibrium involves a positive volume of trade. The existence proof establishes new connections among existence techniques for discontinuous Bayesian games.","['Jackson, Matthew O.', 'Swinkels, Jeroen M.']",['Auctions'],['D44'],Existence of Equilibrium in Single and Double Private Value Auctions,0,0,1,0,0,2005,01,01
73,1,2005-01-01,"We study a one-sided offers bargaining game in which the buyer has private information about the value of the object and the seller has private information about his beliefs about the buyer's valuation. We show that this uncertainty about uncertainties dramatically changes the set of outcomes. In particular, second order beliefs can lead to a delay in reaching agreement even when the seller makes frequent offers. We show that not all types of second order beliefs lead to a delay. When the buyer assigns positive probability to the seller knowing the buyer's value, then delay not only can occur, but it must occur for a class of equilibria. However, in all other cases delay will never occur.","['Skrzypacz, Andrzej', 'Feinberg, Yossi']","['Bargaining Theory; Matching Theory', 'Asymmetric and Private Information; Mechanism Design']","['C78', 'D82']",Uncertainty about Uncertainty and Delay in Bargaining,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"We analyze a game of strategic experimentation with two-armed bandits whose risky arm might yield payoffs after exponentially distributed random times. Free-riding causes an inefficiently low level of experimentation in any equilibrium where the players use stationary Markovian strategies with beliefs as the state variable. We construct the unique symmetric Markovian equilibrium of the game, followed by various asymmetric ones. There is no equilibrium where all players use simple cut-off strategies. Equilibria where players switch finitely often between experimenting and free-riding all yield a similar pattern of information acquisition, greater efficiency being achieved when the players share the burden of experimentation more equitably. When players switch roles infinitely often, they can acquire an approximately efficient amount of information, but still at an inefficient rate. In terms of aggregate payoffs, all these asymmetric equilibria dominate the symmetric one wherever the latter prescribes simultaneous use of both arms.","['Keller, Godfrey', 'Rady, Sven', 'Cripps, Martin']","['Cooperative Games', 'Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C71', 'C72', 'D83']",Strategic Experimentation with Exponential Bandits,0,0,0,0,0,2005,01,01
73,1,2005-01-01,"We extend the standard model of general equilibrium with incomplete markets to allow for default and punishment by thinking of assets as pools. The equilibrating variables include expected delivery rates, along with the usual prices of assets and commodities. By reinterpreting the variables, our model encompasses a broad range of adverse selection and signalling phenomena in a perfectly competitive, general equilibrium framework. Perfect competition eliminates the need for lenders to compute how the size of their loan or the price they quote might affect default rates. It also makes for a simple equilibrium refinement, which we propose in order to rule out irrational pessimism about deliveries of untraded assets. We show that refined equilibrium always exists in our model, and that default, in conjunction with refinement, opens the door to a theory of endogenous assets. The market chooses the promises, default penalties, and quantity constraints of actively traded assets.","['Geanakoplos, John', 'Dubey, Pradeep', 'Shubik, Martin']","['Incomplete Markets', 'Asymmetric and Private Information; Mechanism Design', 'Bankruptcy; Liquidation']","['D52', 'D82', 'G33']",Default and Punishment in General Equilibrium,0,0,0,0,0,2005,01,01
72,6,2004-11-01,"This paper investigates asymptotic properties of the maximum likelihood estimator and the quasi-maximum likelihood estimator for the spatial autoregressive model. The rates of convergence of those estimators may depend on some general features of the spatial weights matrix of the model. It is important to make the distinction with different spatial scenarios. Under the scenario that each unit will be influenced by only a few neighboring units, the estimators may have alphan-rate of convergence and be asymptotically normal. When each unit can be influenced by many neighbors, irregularity of the information matrix may occur and various components of the estimators may have different rates of convergence.","['Lee, Lung-Fei']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Asymptotic Distributions of Quasi-maximum Likelihood Estimators for Spatial Autoregressive Models,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"Conditional moment restrictions can be combined through GMM estimation to construct more efficient semiparametric estimators. This paper is about attainable efficiency for such estimators. We define and use a moment tangent set, the directions of departure from the truth allowed by the moments, to characterize when the semiparametric efficiency bound can be attained. The efficiency condition is that the moment tangent set equals the model tangent set. We apply these results to transformed, censored, and truncated regression models, e.g., finding that the conditional moment restrictions from Powell's (1986) censored regression quantile estimators can be combined to approximate efficiency when the disturbance is independent of regressors.","['Newey, Whitney K.']","['Single Equation Models; Single Variables: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models']","['C20', 'C24']",Efficient Semiparametric Estimation via Moment Restrictions,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"This paper extends the conditional logit approach (Rasch, Andersen, Chamberlain) used in panel data models of binary variables with correlated fixed effects and strictly exogenous regressors. In a two-period two-state model, necessary and sufficient conditions on the joint distribution function of the individual-and-period specific shocks are given such that the sum of individual binary variables across time is a sufficient statistic for the individual effect. By extending a result of Chamberlain, it is shown that root-n consistent regular estimators can be constructed in panel binary models if and only if the property of sufficiency holds. In applied work, the estimation method amounts to quasi-differencing the binary variables as if they were continuous variables and transforming a panel data model into a cross-section model. Semiparametric approaches can then be readily applied.","['Magnac, Thierry']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions']","['C23', 'C25', 'C35']",Panel Binary Variables and Sufficiency: Generalizing Conditional Logit,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"Recently a growing body of research has studied inference in settings where parameters of interest are partially identified. In many cases the parameter is real-valued and the identification region is an interval whose lower and upper bounds may be estimated from sample data. For this case confidence intervals (CIs) have been proposed that cover the entire identification region with fixed probability. Here, we introduce a conceptually different type of confidence interval. Rather than cover the entire identification region with fixed probability, we propose CIs that asymptotically cover the true value of the parameter with this probability. However, the exact coverage probabilities of the simplest version of our new CIs do not converge to their nominal values uniformly across different values for the width of the identification region. To avoid the problems associated with this, we modify the proposed CI to ensure that its exact coverage probabilities do converge uniformly to their nominal values. We motivate this modified CI through exact results for the Gaussian case.","['Manski, Charles F.', 'Imbens, Guido W.']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models']","['C12', 'C24']",Confidence Intervals for Partially Identified Parameters,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"In this paper we investigate methods for testing the existence of a cointegration relationship among the components of a nonstationary fractionally integrated (NFI) vector time series. Our framework generalizes previous studies restricted to unit root integrated processes and permits simultaneous analysis of spurious and cointegrated NFI vectors. We propose a modified F-statistic, based on a particular studentization, which converges weakly under both hypotheses, despite the fact that OLS estimates are only consistent under cointegration. This statistic leads to a Wald-type test of cointegration when combined with a narrow band GLS-type estimate. Our semiparametric methodology allows consistent testing of the spurious regression hypothesis against the alternative of fractional cointegration without prior knowledge on the memory of the original series, their short run properties, the cointegrating vector, or the degree of cointegration. This semiparametric aspect of the modelization does not lead to an asymptotic loss of power, permitting the Wald statistic to diverge faster under the alternative of cointegration than when testing for a hypothesized cointegration vector. In our simulations we show that the method has comparable power to customary procedures under the unit root cointegration setup, and maintains good properties in a general framework where other methods may fail. We illustrate our method testing the cointegration hypothesis of nominal GNP and simple-sum (M1, M2, M3) monetary aggregates.","['Velasco, Carlos', 'Marmol, Francesc']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Monetary Policy']","['C32', 'E52']",Consistent Testing of Cointegrating Relationships,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"We introduce a family of generalized-method-of-moments estimators of the parameters of a continuous-time Markov process observed at random time intervals. The results include strong consistency, asymptotic normality, and a characterization of standard errors. Sampling is at an arrival intensity that is allowed to depend on the underlying Markov process and on the parameter vector to be estimated. We focus on financial applications, including tick-based sampling, allowing for jump diffusions, regime-switching diffusions, and reflected diffusions.","['Glynn, Peter', 'Duffie, Darrell']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Estimation of Continuous-Time Markov Processes Sampled at Random Time Intervals,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"We develop the measurement theory of polarization for the case in which income distributions can be described using density functions. The main theorem uniquely characterizes a class of polarization measures that fits into what we call the ""identity-alienation"" framework, and simultaneously satisfies a set of axioms. Second, we provide sample estimators of population polarization indices that can be used to compare polarization across time or entities. Distribution-free statistical inference results are also used in order to ensure that the orderings of polarization across entities are not simply due to sampling noise. An illustration of the use of these tools using data from 21 countries shows that polarization and inequality orderings can often differ in practice.","['Ray, Debraj', 'Duclos, Jean-Yves', 'Esteban, Joan']","['Personal Income, Wealth, and Their Distributions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D31', 'D63']","Polarization: Concepts, Measurement, Estimation",0,0,0,0,0,2004,11,01
72,6,2004-11-01,"A speaker wishes to persuade a listener to accept a certain request. The conditions under which the request is justified, from the listener's point of view, depend on the values of two aspects. The values of the aspects are known only to the speaker and the listener can check the value of at most one. A mechanism specifies a set of messages that the speaker can send and a rule that determines the listener's response, namely, which aspect he checks and whether he accepts or rejects the speaker's request. We study mechanisms that maximize the probability that the listener accepts the request when it is justified and rejects the request when it is unjustified, given that the speaker maximizes the probability that his request is accepted. We show that a simple optimal mechanism exists and can be found by solving a linear programming problem in which the set of constraints is derived from what we call the L-principle.","['Rubinstein, Ariel', 'Glazer, Jacob']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D82', 'D83']",On Optimal Rules of Persuasion,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"This paper proposes an asymptotically efficient method for estimating models with conditional moment restrictions. Our estimator generalizes the maximum empirical likelihood estimator (MELE) of Qin and Lawless (1994). Using a kernel smoothing method, we efficiently incorporate the information implied by the conditional moment restrictions into our empirical likelihood-based procedure. This yields a one-step estimator which avoids estimating optimal instruments. Our likelihood ratio-type statistic for parametric restrictions does not require the estimation of variance, and achieves asymptotic pivotalness implicitly. The estimation and testing procedures we propose are normalization invariant. Simulation results suggest that our new estimator works remarkably well in finite samples.","['Kitamura, Yuichi', 'Tripathi, Gautam', 'Ahn, Hyungtaik']","['Hypothesis Testing: General', 'Estimation: General', 'Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C12', 'C13', 'C20', 'C30']",Empirical Likelihood-Based Inference in Conditional Moment Restriction Models,0,0,0,0,0,2004,11,01
72,6,2004-11-01,"With many semi-anonymous players, the equilibria of simultaneous-move games are extensively robust. This means that the equilibria survive even if the simultaneous-play assumption is relaxed to allow for a large variety of extensive modifications. Such modifications include sequential play with partial and differential revelation of information, commitments, multiple revisions of choices, cheap talk announcements, and more.","['Kalai, Ehud']",['Noncooperative Games'],['C72'],Large Robust Games,0,0,0,0,0,2004,11,01
72,5,2004-09-01,"Agents' valuations are interdependent if they depend on the signals, or types, of all agents. Under the implicit assumption that agents cannot observe their outcome-decision payoffs, previous literature has shown that with interdependent valuations and independent signals, efficient design is impossible. This paper shows that an efficient mechanism exists in an environment where first the final outcome (e.g., allocation of the goods) is determined, then the agents observe their own outcome-decision payoffs, and then final transfers are made.","['Mezzetti, Claudio']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Mechanism Design with Interdependent Valuations: Efficiency,0,0,1,0,0,2004,09,01
72,5,2004-09-01,"In econometrics, models stated as conditional moment restrictions are typically estimated by means of the generalized method of moments (GMM). The GMM estimation procedure can render inconsistent estimates since the number of arbitrarily chosen instruments is finite. In fact, consistency of the GMM estimators relies on additional assumptions that imply unclear restrictions on the data generating process. This article introduces a new, simple and consistent estimation procedure for these models that is directly based on the definition of the conditional moments. The main feature of our procedure is its simplicity, since its implementation does not require the selection of any user-chosen number, and statistical inference is straightforward since the proposed estimator is asymptotically normal. In addition, we suggest an asymptotically efficient estimator constructed by carrying out one Newton-Raphson step in the direction of the efficient GMM estimator.","['Lobato, Ignacio N.', 'Dominguez, Manuel A.']","['Estimation: General', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C13', 'C22', 'C32']",Consistent Estimation of Models Defined by Conditional Moment Restrictions,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"The theory of global games has shown that coordination games with multiple equilibria may have a unique equilibrium if certain parameters of the payoff function are private information instead of common knowledge. We report the results of an experiment designed to test the predictions of this theory. Comparing sessions with common and private information, we observe only small differences in behavior. For common information, subjects coordinate on threshold strategies that deviate from the global game solution towards the payoff-dominant equilibrium. For private information, thresholds are closer to the global game solution than for common information. Variations in the payoff function affect behavior as predicted by comparative statics of the global game solution. Predictability of coordination points is about the same for both information conditions.","['Nagel, Rosemarie', 'Ockenfels, Peter', 'Heinemann, Frank']","['Cooperative Games', 'Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C71', 'D82', 'D83']",The Theory of Global Games on Test: Experimental Analysis of Coordination Games with Public and Private Information,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"An extension of Condorcet's paradox by McGarvey (1953) asserts that for every asymmetric relation R on a finite set of candidates there is a strict-preferences voter profile that has the relation R as its strict simple majority relation. We prove that McGarvey's theorem can be extended to arbitrary neutral monotone social welfare functions that can be described by a strong simple game G if the voting power of each individual, measured by the Shapley-Shubik power index, is sufficiently small. Our proof is based on an extension to another classic result concerning the majority rule. Condorcet studied an election between two candidates in which the voters' choices are random and independent and the probability of a voter choosing the first candidate is p > 1/2. Condorcet's jury theorem asserts that if the number of voters tends to infinity then the probability that the first candidate will be elected tends to one. We prove that this assertion extends to a sequence of arbitrary monotone strong simple games if and only if the maximum voting power for all individuals tends to zero.","['Kalai, Gil']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Social Indeterminacy,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"Wavelet analysis is a new mathematical method developed as a unified field of science over the last decade or so. As a spatially adaptive analytic tool, wavelets are useful for capturing serial correlation where the spectrum has peaks or kinks, as can arise from persistent dependence, seasonality, and other kinds of periodicity. This paper proposes a new class of generally applicable wavelet-based tests for serial correlation of unknown form in the estimated residuals of a panel regression model, where error components can be one-way or two-way, individual and time effects can be fixed or random, and regressors may contain lagged dependent variables or deterministic/stochastic trending variables. Our tests are applicable to unbalanced heterogenous panel data. They have a convenient null limit N(0,1) distribution. No formulation of an alternative model is required, and our tests are consistent against serial correlation of unknown form even in the presence of substantial inhomogeneity in serial correlation across individuals. This is in contrast to existing serial correlation tests for panel models, which ignore inhomogeneity in serial correlation across individuals by assuming a common alternative, and thus have no power against the alternatives where the average of serial correlations among individuals is close to zero. We propose and justify a data-driven method to choose the smoothing parameter--the finest scale in wavelet spectral estimation, making the tests completely operational in practice. The data-driven finest scale automatically converges to zero under the null hypothesis of no serial correlation and diverges to infinity as the sample size increases under the alternative, ensuring the consistency of our tests. Simulation shows that our tests perform well in small and finite samples relative to some existing tests.","['Hong, Yongmiao', 'Kao, Chihwa']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Wavelet-Based Testing for Serial Correlation of Unknown Form in Panel Models,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"GARCH models are commonly used as latent processes in econometrics, financial economics, and macroeconomics. Yet no exact likelihood analysis of these models has been provided so far. In this paper we outline the issues and suggest a Markov chain Monte Carlo algorithm which allows the calculation of a classical estimator via the simulated EM algorithm or a Bayesian solution in O(T) computational operations, where T denotes the sample size. We assess the performance of our proposed algorithm in the context of both artificial examples and an empirical application to 26 UK sectorial stock returns, and compare it to existing approximate solutions.","['Sentana, Enrique', 'Shephard, Neil', 'Fiorentini, Gabriele']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Likelihood-Based Estimation of Latent Generalized Arch Structures,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"We study inference in structural models with a jump in the conditional density, where location and size of the jump are described by regression curves. Two prominent examples are auction models, where the bid density jumps from zero to a positive value at the lowest cost, and equilibrium job-search models, where the wage density jumps from one positive level to another at the reservation wage. General inference in such models remained a long-standing, unresolved problem, primarily due to nonregularities and computational difficulties caused by discontinuous likelihood functions. This paper develops likelihood-based estimation and inference methods for these models, focusing on optimal (Bayes) and maximum likelihood procedures. We derive convergence rates and distribution theory, and develop Bayes and Wald inference. We show that Bayes estimators and confidence intervals are attractive both theoretically and computationally, and that Bayes confidence intervals, based on posterior quantiles, provide a valid large sample inference method.","['Chernozhukov, Victor', 'Hong, Han']","['Single Equation Models; Single Variables: General', 'Model Construction and Estimation']","['C20', 'C51']",Likelihood Estimation and Inference in a Class of Nonregular Econometric Models,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"This paper uses political reservations for women in India to study the impact of women's leadership on policy decisions. Since the mid-1990's, one third of Village Council head positions in India have been randomly reserved for a woman: In these councils only women could be elected to the position of head. Village Councils are responsible for the provision of many local public goods in rural areas. Using a dataset we collected on 265 Village Councils in West Bengal and Rajasthan, we compare the type of public goods provided in reserved and unreserved Village Councils. We show that the reservation of a council seat affects the types of public goods provided. Specifically, leaders invest more in infrastructure that is directly relevant to the needs of their own genders.","['Duflo, Esther', 'Chattopadhyay, Raghabendra']","['Public Goods', 'Economics of Gender; Non-labor Discrimination', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Formal and Informal Sectors; Shadow Economy; Institutional Arrangements', 'Economic Development: Urban, Rural, Regional, and Transportation Analysis; Housing; Infrastructure']","['H41', 'J16', 'O15', 'O17', 'O18']",Women as Policy Makers: Evidence from a Randomized Policy Experiment in India,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"Previous research has shown that under a suitable no-jump condition, the price of a defaultable security is equal to its risk-neutral expected discounted cash flows if a modified discount rate is introduced to account for the possibility of default. Below, we generalize this result by demonstrating that one can always value defaultable claims using expected risk-adjusted discounting provided that the expectation is taken under a slightly modified probability measure. This new probability measure puts zero probability on paths where default occurs prior to the maturity, and is thus only absolutely continuous with respect to the risk-neutral probability measure. After establishing the general result and discussing its relation with the existing literature, we investigate several examples for which the no-jump condition fails. Each example illustrates the power of our general formula by providing simple analytic solutions for the prices of defaultable securities.","['Collin-Dufresne, P.', 'Goldstein, R.', 'Hugonnier, J.']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],A General Formula for Valuing Defaultable Securities,0,0,0,0,0,2004,09,01
72,5,2004-09-01,"To predict choice behavior, the standard practice of economists has been to infer decision processes from data on observed choices. When decision makers act with partial information, economists typically assume that persons form probabilistic expectations for unknown quantities and maximize expected utility. Observed choices may be consistent with many alternative specifications of preferences and expectations, so researchers commonly assume particular sorts of expectations. It would be better to measure expectations in the form called for by modern economic theory; that is, subjective probabilities. Data on expectations can be used to relax or validate assumptions about expectations. Since the early 1990s, economists have increasingly undertaken to elicit from survey respondents probabilistic expectations of significant personal events. This article discusses the history underlying the new literature, describes some of what has been learned thus far, and looks ahead towards making further progress.","['Manski, Charles F.']","['Survey Methods; Sampling Methods', 'Criteria for Decision-Making under Risk and Uncertainty', 'Expectations; Speculations']","['C83', 'D81', 'D84']",Measuring Expectations,0,0,0,0,0,2004,09,01
72,4,2004-07-01,"Fixed effects estimators of panel models can be severely biased because of the well-known incidental parameters problem. We show that this bias can be reduced by using a panel jackknife or an analytical bias correction motivated by large T. We give bias corrections for averages over the fixed effects, as well as model parameters. We find large bias reductions from using these approaches in examples. We consider asymptotics where T grows with n, as an approximation to the properties of the estimators in econometric applications. We show that if T grows at the same rate as n, the fixed effects estimator is asymptotically biased, so that asymptotic confidence intervals are incorrect, but that they are correct for the panel jackknife. We show T growing faster than n[superscript 1/3] suffices for correctness of the analytic correction, a property we also conjecture for the jackknife.","['Newey, Whitney', 'Hahn, Jinyong']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],Jackknife and Analytical Bias Reduction for Nonlinear Panel Models,0,0,0,0,0,2004,07,01
72,4,2004-07-01,"An asymptotically efficient likelihood-based semiparametric estimator is derived for the censored regression (Tobit) model, based on a new approach for estimating the density function of the residuals in a partially observed regression. Smoothing the self-consistency equation for the nonparametric maximum likelihood estimator of the distribution of the residuals yields an integral equation, which in some cases can be solved explicitly. The resulting estimated density is smooth enough to be used in a practical implementation of the profile likelihood estimator, but is sufficiently close to the nonparametric maximum likelihood estimator to allow estimation of the semiparametric efficient score. The parameter estimates obtained by solving the estimated score equations are then asymptotically efficient. A summary of analogous results for truncated regression is also given.","['Cosslett, Stephen R.']",['Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models'],['C24'],Efficient Semiparametric Estimation of Censored and Truncated Regressions via a Smoothed Self-Consistency Equation,0,0,0,0,0,2004,07,01
72,4,2004-07-01,"In an environment where trading volume affects security prices and where prices are uncertain when trades are submitted, quasi-arbitrage is the availability of a series of trades that generate infinite expected profits with an infinite Sharpe ratio. We show that when the price impact of trades is permanent and time-independent, only linear price-impact functions rule out quasi-arbitrage and thus support viable market prices. When trades have also a temporary price impact, only the permanent price impact must be linear while the temporary one can be of a more general form. We also extend the analysis to a time-dependent framework.","['Stanzl, Werner', 'Huberman, Gur']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Price Manipulation and Quasi-arbitrage,0,0,0,0,0,2004,07,01
72,4,2004-07-01,"An important objective of empirical research on treatment response is to provide decision makers with information useful in choosing treatments. This paper studies minimax-regret treatment choice using the sample data generated by a classical randomized experiment. Consider a utilitarian social planner who must choose among the feasible statistical treatment rules, these being functions that map the sample data and observed covariates of population members into a treatment allocation. If the planner knew the population distribution of treatment response, the optimal treatment rule would maximize mean welfare conditional on all observed covariates. The appropriate use of covariate information is a more subtle matter when only sample data on treatment response are available. I consider the class of conditional empirical success rules; that is, rules assigning persons to treatments that yield the best experimental outcomes conditional on alternative subsets of the observed covariates. I derive a closed-form bound on the maximum regret of any such rule. Comparison of the bounds for rules that condition on smaller and larger subsets of the covariates yields sufficient sample sizes for productive use of covariate information. When the available sample size exceeds the sufficiency boundary, a planner can be certain that conditioning treatment choice on more covariates is preferable (in terms of minimax regret) to conditioning on fewer covariates.","['Manski, Charles F.']",['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions'],['C21'],Statistical Treatment Rules for Heterogeneous Populations,0,0,0,0,0,2004,07,01
72,4,2004-07-01,"In a one-principal two-agent model with adverse selection and collusion among agents, we show that delegating to one agent the right to subcontract with the other agent always earns lower profit for the principal compared with centralized contracting. Delegation to an intermediary is also not in the principal's interest if the agents supply substitutes. It can be beneficial if the agents produce complements and the intermediary is well informed.","['Tsumagari, Masatoshi', 'Mookherjee, Dilip']","['Asymmetric and Private Information; Mechanism Design', 'Transactional Relationships; Contracts and Reputation; Networks']","['D82', 'L14']",The Organization of Supplier Networks: Effects of Delegation and Intermediation,1,0,0,0,0,2004,07,01
72,4,2004-07-01,"This paper develops a new methodology that makes use of the factor structure of large dimensional panels to understand the nature of nonstationarity in the data. We refer to it as PANIC--Panel Analysis of Nonstationarity in Idiosyncratic and Common components. PANIC can detect whether the nonstationarity in a series is pervasive, or variable-specific, or both. It can determine the number of independent stochastic trends driving the common factors. PANIC also permits valid pooling of individual statistics and thus panel tests can be constructed. A distinctive feature of PANIC is that it tests the unobserved components of the data instead of the observed series. The key to PANIC is consistent estimation of the space spanned by the unobserved common factors and the idiosyncratic errors without knowing a priori whether these are stationary or integrated processes. We provide a rigorous theory for estimation and inference and show that the tests have good finite sample properties.","['Bai, Jushan', 'Ng, Serena']","['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models', 'Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models']","['C23', 'C33']",A Panic Attack on Unit Roots and Cointegration,0,0,0,0,0,2004,07,01
72,4,2004-07-01,"We establish the existence of pure strategy equilibria in monotone bidding functions in first-price auctions with asymmetric bidders, interdependent values, and affiliated one-dimensional signals. By extending a monotonicity result due to Milgrom and Weber (1982), we show that single crossing can fail only when ties occur at winning bids or when bids are individually irrational. We avoid these problems by considering limits of ever finer finite bid sets such that no two bidders have a common serious bid, and by recalling that single crossing is needed only at individually rational bids. Two examples suggest that our results cannot be extended to multidimensional signals or to second-price auctions.","['Zamir, Shmuel', 'Reny, Philip J.']",['Auctions'],['D44'],On the Existence of Pure Strategy Monotone Equilibria in Asymmetric First-Price Auctions,0,0,1,0,0,2004,07,01
72,4,2004-07-01,"The holdup problem arises when parties negotiate to divide the surplus generated by their relationship specific investments. We study this problem in a dynamic model of bargaining and investment which, unlike the stylized static model, allows the parties to continue to invest until they agree on the terms of trade. The investment dynamics overturns the conventional wisdom dramatically. First, the holdup problem need not entail underinvestment when the parties are sufficiently patient. Second, inefficiencies can arise unambiguously in some cases, but they are not caused by the sharing of surplus per se but rather by a failure of an individual rationality constraint.","['Sakovics, Jozsef', 'Che, Yeon-Koo']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Bargaining Theory; Matching Theory', 'Transactional Relationships; Contracts and Reputation; Networks']","['C73', 'C78', 'L14']",A Dynamic Theory of Holdup,1,0,0,0,0,2004,07,01
72,4,2004-07-01,"A complex financial system comprises both financial markets and financial intermediaries. We distinguish financial intermediaries according to whether they issue complete contingent contracts or incomplete contracts. Intermediaries such as banks that issue incomplete contracts, e.g., demand deposits, are subject to runs, but this does not imply a market failure. A sophisticated financial system--a system with complete markets for aggregate risk and limited market participation--is incentive-efficient, if the intermediaries issue complete contingent contracts, or else constrained-efficient, if they issue incomplete contracts. We argue that there may be a role for regulating liquidity provision in an economy in which markets for aggregate risks are incomplete.","['Gale, Douglas', 'Allen, Franklin']","['General Financial Markets: General (includes Measurement and Data)', 'Financial Institutions and Services: General']","[nan, 'G20']",Financial Intermediaries and Markets,0,0,0,0,0,2004,07,01
72,3,2004-05-01,"This paper examines the problem of measuring intellectual influence based on data on citations between scholarly publications. We follow an axiomatic approach and find that the properties of invariance to reference intensity, weak homogeneity, weak consistency, and invariance to splitting of journals characterize a unique ranking method. This method is different from those regularly used in economics and other social sciences.","['Volij, Oscar', 'Palacios-Huerta, Ignacio']",['Sociology of Economics'],['A14'],The Measurement of Intellectual Influence,0,0,0,0,0,2004,05,01
72,3,2004-05-01,The purpose of this note is to show how semiparametric estimators with a small bias property can be constructed. The small bias property (SBP) of a semiparametric estimator is that its bias converges to zero faster than the pointwise and integrated bias of the nonparametric estimator on which it is based. We show that semiparametric estimators based on twicing kernels have the SBP. We also show that semiparametric estimators where nonparametric kernel estimation does not affect the asymptotic variance have the SBP. In addition we discuss an interpretation of series and sieve estimators as idempotent transformations of the empirical distribution that helps explain the known result that they lead to the SBP. In Monte Carlo experiments we find that estimators with the SBP have mean-square error that is smaller and less sensitive to bandwidth than those that do not have the SBP.,"['Hsieh, Fushing', 'Robins, James M.', 'Newey, Whitney K.']","['Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions']","['C14', 'C21']",Twicing Kernels and a Small Bias Property of Semiparametric Estimators,0,0,0,0,0,2004,05,01
72,3,2004-05-01,"A new class of autocorrelation robust test statistics is introduced. The class of tests generalizes the Kiefer, Vogelsang, and Bunzel (2000) test in a manner analogous to Anderson and Darling's (1952) generalization of the Cramer-von Mises goodness of fit test. In a Gaussian location model, the error in rejection probability of the new tests is found to be O(T[superscript -1] log T), where T denotes the sample size.","['Jansson, Michael']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],The Error in Rejection Probability of Simple Autocorrelation Robust Tests,0,0,0,0,0,2004,05,01
72,3,2004-05-01,"An asymmetric information model of a finite horizon ""nth order"" rational asset price bubble is presented, where (all agents know that)n the asset is worthless. Also, the model has only two agents, so the first order version of the bubble is simpler than other first order bubbles in the literature.","['Conlon, John R.']","['Asymmetric and Private Information; Mechanism Design', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D82', 'D83', nan]",Simple Finite Horizon Bubbles Robust to Higher Order Knowledge,0,0,0,0,0,2004,05,01
72,3,2004-05-01,"This paper analyses multivariate high frequency financial data using realized covariation. We provide a new asymptotic distribution theory for standard methods such as regression, correlation analysis, and covariance. It will be based on a fixed interval of time (e.g., a day or week), allowing the number of high frequency returns during this period to go to infinity. Our analysis allows us to study how high frequency correlations, regressions, and covariances change through time. In particular we provide confidence intervals for each of these quantities.","['Shephard, Neil', 'Barndorff-Nielsen, Ole E.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Econometric Modeling: General', 'General Financial Markets: General (includes Measurement and Data)']","['C22', 'C32', 'C50', nan]","Econometric Analysis of Realized Covariation: High Frequency Based Covariance, Regression, and Correlation in Financial Economics",0,0,0,0,0,2004,05,01
72,3,2004-05-01,"This paper investigates the effects of financial market globalization on the inequality of nations. The world economy consists of inherently identical countries, which differ only in their levels of capital stock. Each country is represented by the standard overlapping generations model, modified only to incorporate credit market imperfection. An integration of financial markets affects the set of stable steady states, as it changes the balance between the equalizing force of the diminishing returns technology and the unequalizing force of the wealth-dependent borrowing constraint. The model is tractable enough to allow for a complete characterization of the stable steady states. In the absence of the international financial market, the world economy has a unique steady state, which is symmetric and stable. In the presence of the international financial market, symmetry-breaking occurs under some conditions. That is, the symmetric steady state loses its stability and stable asymmetric steady states come to exist. In the stable asymmetric steady states, the world economy is endogenously divided into the rich and poor countries; the borrowing constraints are binding in the poor but not in the rich; the world output is smaller, the rich are richer and the poor are poorer in any of the stable asymmetric steady states than in the (unstable) symmetric steady state.","['Matsuyama, Kiminori']","['International Monetary Arrangements and Institutions', 'Open Economy Macroeconomics', 'International Financial Markets']","['F33', 'F41', 'G15']","Financial Market Globalization, Symmetry-Breaking and Endogenous Inequality of Nations",0,0,0,0,0,2004,05,01
72,3,2004-05-01,"We investigate two-player infinitely repeated games where the discount factor is less than but close to unity. Monitoring is private and players cannot communicate. We require no condition concerning the accuracy of players' monitoring technology. We show the folk theorem for the prisoners' dilemma with conditional independence. We also investigate more general games where players' private signals are correlated only through an unobservable macro shock. We show that efficiency is sustainable for generic private signal structures when the size of the set of private signals is sufficiently large. Finally, we show that cartel collusion is sustainable in price-setting duopoly.","['Matsushima, Hitoshi']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C73', 'D43']",Repeated Games with Private Monitoring: Two Players,0,0,1,0,0,2004,05,01
72,3,2004-05-01,"Different people may use different strategies, or decision rules, when solving complex decision problems. We provide a new Bayesian procedure for drawing inferences about the nature and number of decision rules present in a population, and use it to analyze the behaviors of laboratory subjects confronted with a difficult dynamic stochastic decision problem. Subjects practiced before playing for money. Based on money round decisions, our procedure classifies subjects into three types, which we label ""Near Rational,"" ""Fatalist,"" and ""Confused."" There is clear evidence of continuity in subjects' behaviors between the practice and money rounds: types who performed best in practice also tended to perform best when playing for money. However, the agreement between practice and money play is far from perfect. The divergences appear to be well explained by a combination of type switching (due to learning and/or increased effort in money play) and errors in our probabilistic type assignments.","['McCabe, Kevin', 'Houser, Daniel', 'Keane, Michael']","['Design of Experiments: Laboratory, Individual', 'Criteria for Decision-Making under Risk and Uncertainty', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Expectations; Speculations']","['C91', 'D81', 'D83', 'D84']",Behavior in a Dynamic Decision Problem: An Analysis of Experimental Evidence Using a Bayesian Type Classification Algorithm,0,0,0,0,0,2004,05,01
72,3,2004-05-01,"We provide evidence that long-term relationships between trading parties emerge endogenously in the absence of third party enforcement of contracts and are associated with a fundamental change in the nature of market interactions. Without third party enforcement, the vast majority of trades are initiated with private offers and the parties share the gains from trade equally. Low effort or bad quality is penalized by the termination of the relationship, wielding a powerful effect on contract enforcement. Successful long-term relations exhibit generous rent sharing and high effort (quality) from the very beginning of the relationship. In the absence of third-party enforcement, markets resemble a collection of bilateral trading islands rather than a competitive market. If contracts are third party enforceable, rent sharing and long-term relations are absent and the vast majority of trades are initiated with public offers. Most trades take place in one-shot transactions and the contracting parties are indifferent with regard to the identity of their trading partner.","['Brown, Martin', 'Fehr, Ernst', 'Falk, Armin']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Conflict; Conflict Resolution; Alliances; Revolutions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Labor Contracts', 'Transactional Relationships; Contracts and Reputation; Networks']","['D63', 'D74', 'D83', 'J41', 'L14']",Relational Contracts and the Nature of Market Interactions,1,0,0,0,0,2004,05,01
72,3,2004-05-01,"This paper studies the impact of credit markets on optimal contracting, when the agent's ""interim preference"" over upcoming contracts is private information because personal financial decisions affect it via the wealth effect. The main result is a severe loss of incentive provision: equilibrium contracts invariably cause the agent to shirk (i.e., exert minimal effort) if the agent's private financial decision precedes moral hazard contracting. The basic intuition is that committing on another private variable, other than the effort level, exposes the parties to further exploitation of efficient risk-sharing by relaxing the incentive constraint that was binding ex ante, unless the risk-sharing was fully efficient to begin with.","['Park, In-Uck']","['Asymmetric and Private Information; Mechanism Design', 'Labor Contracts']","['D82', 'J41']",Moral Hazard Contracting and Private Credit Markets,0,0,0,0,0,2004,05,01
72,3,2004-05-01,"The asymptotic refinements attributable to the block bootstrap for time series are not as large as those of the nonparametric iid bootstrap or the parametric bootstrap. One reason is that the independence between the blocks in the block bootstrap sample does not mimic the dependence structure of the original sample. This is the join-point problem. In this paper, we propose a method of solving this problem. The idea is not to alter the block bootstrap. Instead, we alter the original sample statistics to which the block bootstrap is applied. We introduce block statistics that possess join-point features that are similar to those of the block bootstrap versions of these statistics. We refer to the application of the block bootstrap to block statistics as the block-block bootstrap. The asymptotic refinements of the block-block bootstrap are shown to be greater than those obtained with the block bootstrap and close to those obtained with the nonparametric iid bootstrap and parametric bootstrap.","['Andrews, Donald W. K.']",['Statistical Simulation Methods: General'],['C15'],The Block-Block Bootstrap: Improved Asymptotic Refinements,0,0,0,0,0,2004,05,01
72,2,2004-03-01,A systems cointegration rank test is proposed that is applicable for vector autoregressive (VAR) processes with a structural shift at unknown time. The structural shift is modeled as a simple shift in the level of the process. It is proposed to estimate the break date first on the basis of a full unrestricted VAR model. Two alternative estimators are considered and their asymptotic properties are derived. In the next step the deterministic part of the process including the shift size is estimated and the series are adjusted by subtracting the estimated deterministic part. A Johansen type test for the cointegrating rank is applied to the adjusted series. The test statistic is shown to have a well-known asymptotic null distribution that does not depend on the break date. The performance of the procedure in small samples is investigated by simulations.,"['Trenkler, Carsten', 'Lutkepohl, Helmut', 'Saikkonen, Pentti']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Testing for the Cointegrating Rank of a VAR Process with Level Shift at Unknown Time,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"We establish consistency and asymptotic normality of the quasi-maximum likelihood estimator in the linear ARCH model. Contrary to the existing literature, we allow the parameters to be in the region where no stationary version of the process exists. This implies that the estimator is always asymptotically normal.","['Jensen, Soren Tolver', 'Rahbek, Anders']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Asymptotic Normality of the QMLE Estimator of ARCH in the Nonstationary Case,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"We study fairness in economies with one private good and one partially excludable nonrival good. A social ordering function determines for each profile of preferences an ordering of all conceivable allocations. We propose the following Free Lunch Aversion condition: if the private good contributions of two agents consuming the same quantity of the nonrival good have opposite signs, reducing that gap improves social welfare. This condition, combined with the more standard requirements of Unanimous Indifference and Responsiveness, delivers a form of welfare egalitarianism in which an agent's welfare is measured by the quantity of the nonrival good that, consumed at no cost, would leave her indifferent to the bundle she is assigned.","['Maniquet, Francois', 'Sprumont, Yves']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Social Choice; Clubs; Committees; Associations']","['D63', 'D71']",Fair Production and Allocation of an Excludable Nonrival Good,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"Several experimental studies have provided evidence that suggest indifference curves have a kink around the current endowment level. These results, which clearly contradict closely held economic doctrines, have led some influential commentators to call for an entirely new economic paradigm to displace conventional neoclassical theory--e.g., prospect theory, which invokes psychological effects. This paper pits neoclassical theory against prospect theory by investigating data drawn from more than 375 subjects actively participating in a well-functioning marketplace. The pattern of results suggests that prospect theory adequately organizes behavior among inexperienced consumers, but consumers with intense market experience behave largely in accordance with neoclassical predictions. Moreover, the data are consistent with the notion that consumers learn to overcome the endowment effect in situations beyond specific problems they have previously encountered. This ""transference of behavior"" across domains has important implications in both a positive and normative sense.","['List, John A.']","['Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis']","['D11', 'D12']",Neoclassical Theory versus Prospect Theory: Evidence from the Marketplace,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"The local Whittle (or Gaussian semiparametric) estimator of long range dependence, proposed by Kunsch (1987) and analyzed by Robinson (1995a), has a relatively slow rate of convergence and a finite sample bias that can be large. In this paper, we generalize the local Whittle estimator to circumvent these problems. Instead of approximating the short-run component of the spectrum, phi(lambda), by a constant in a shrinking neighborhood of frequency zero, we approximate its logarithm by a polynomial. This leads to a ""local polynomial Whittle"" (LPW) estimator. We specify a data-dependent adaptive procedure that adjusts the degree of the polynomial to the smoothness of phi(lambda) at zero and selects the bandwidth. The resulting ""adaptive LPW"" estimator is shown to achieve the optimal rate of convergence, which depends on the smoothness of phi(lambda) at zero, up to a logarithmic factor.","['Sun, Yixiao', 'Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Adaptive Local Polynomial Whittle Estimation of Long-Range Dependence,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"We show that optimal monetary and fiscal policies are time consistent for a class of economies often used in applied work, economies appealing because they are consistent with the growth facts. We establish our results in two steps. We first show that for this class of economies, the Friedman rule of setting nominal interest rates to zero is optimal under commitment. We then show that optimal policies are time consistent if the Friedman rule is optimal. For our benchmark economy in which the time consistency problem is most severe, the converse also holds: if optimal policies are time consistent, then the Friedman rule is optimal.","['Kehoe, Patrick J.', 'Neumeyer, Pablo Andres', 'Alvarez, Fernando']","['Monetary Policy', 'Policy Objectives; Policy Designs and Consistency; Policy Coordination', 'Fiscal Policy', 'Comparative or Joint Analysis of Fiscal and Monetary Policy; Stabilization; Treasury Policy']","['E52', 'E61', 'E62', 'E63']",The Time Consistency of Optimal Monetary and Fiscal Policies,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"We study strategic voting after weakening the notion of strategy-proofness to Ordinal Bayesian Incentive Compatibility (OBIC). Under OBIC, truth-telling is required to maximize the expected utility of every voter, expected utility being computed with respect to the voter's prior beliefs and under the assumption that everybody else is also telling the truth. We show that for a special type of priors, i.e., the uniform priors, there exists a large class of social choice functions that are OBIC. However, for priors that are generic in the set of independent beliefs, a social choice function is OBIC only if it is dictatorial. This result underlines the robustness of the Gibbard-Satterthwaite Theorem.","['Sen, Arunava', 'Majumdar, Dipjyoti']",['Social Choice; Clubs; Committees; Associations'],['D71'],Ordinally Bayesian Incentive Compatible Voting Rules,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"This paper investigates a generalized method of moments (GMM) approach to the estimation of autoregressive roots near unity with panel data and incidental deterministic trends. Such models arise in empirical econometric studies of firm size and in dynamic panel data modeling with weak instruments. The two moment conditions in the GMM approach are obtained by constructing bias corrections to the score functions under OLS and GLS detrending, respectively. It is shown that the moment condition under GLS detrending corresponds to taking the projected score on the Bhattacharya basis, linking the approach to recent work on projected score methods for models with infinite numbers of nuisance parameters (Waterman and Lindsay (1998)). Assuming that the localizing parameter takes a nonpositive value, we establish consistency of the GMM estimator and find its limiting distribution. A notable new finding is that the GMM estimator has convergence rate n[superscript 1/6], slower than square-root-of-n, when the true localizing parameter is zero (i.e., when there is a panel unit root) and the deterministic trends in the panel are linear. These results, which rely on boundary point asymptotics, point to the continued difficulty of distinguishing unit roots from local alternatives, even when there is an infinity of additional data.","['Phillips, Peter C. B.', 'Moon, Hyungsik Roger']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models']","['C22', 'C23']",GMM Estimation of Autoregressive Roots Near Unity with Panel Data,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"This paper analyzes models of securities markets with a single strategic informed trader and competitive market makers. In one version, uninformed trades arrive as a Brownian motion and market makers see only the order imbalance, as in Kyle (1985). In the other version, uninformed trades arrive as a Poisson process and market makers see individual trades. This is similar to the Glosten-Milgrom (1985) model, except that we allow the informed trader to optimize his times of trading. We show there is an equilibrium in the Glosten-Milgrom-type model in which the informed trader plays a mixed strategy (a point process with stochastic intensity). In this equilibrium, informed and uninformed trades arrive probabilistically, as Glosten and Milgrom assume. We study a sequence of such markets in which uninformed trades become smaller and arrive more frequently, approximating a Brownian motion. We show that the equilibria of the Glosten-Milgrom model converge to the equilibrium of the Kyle model.","['Back, Kerry', 'Baruch, Shmuel']",['Information and Market Efficiency; Event Studies; Insider Trading'],['G14'],Information in Securities Markets: Kyle Meets Glosten and Milgrom,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"We study the long-run sustainability of reputations in games with imperfect public monitoring. It is impossible to maintain a permanent reputation for playing a strategy that does not play an equilibrium of the game without uncertainty about types. Thus, a player cannot indefinitely sustain a reputation for noncredible behavior in the presence of imperfect monitoring.","['Cripps, Martin W.', 'Mailath, George J.', 'Samuelson, Larry']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Imperfect Monitoring and Impermanent Reputations,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"This paper considers learning rules for environments in which little prior and feedback information is available to the decision maker. Two properties of such learning rules are studied: absolute expediency and monotonicity. Both require that some aspect of the decision maker's performance improves from the current period to the next. The paper provides some necessary, and some sufficient conditions for these properties. It turns out that there is a large variety of learning rules that have the properties. However, all learning rules that have these properties are related to the replicator dynamics of evolutionary game theory. For the case in which there are only two actions, it is shown that one of the absolutely expedient learning rules dominates all others.","['Morales, Antonio J.', 'Sarin, Rajiv', 'Borgers, Tilman']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Expedient and Monotone Learning Rules,0,0,0,0,0,2004,03,01
72,2,2004-03-01,"This paper examines direct broadcast satellites (DBS) as a competitor to cable. We first estimate a structural consumer level demand system for satellite, basic cable, premium cable and local antenna using micro data on almost 30,000 households in 317 markets, including extensive controls for unobserved product quality and allowing the distribution of unobserved tastes to follow a fully flexible multivariate normal distribution. The estimated elasticity of expanded basic is about -1.5, with the demand for premium cable and DBS more elastic. The results identify strong correlations in the taste for different products not captured in conventional logit models. Estimates of the supply response of cable suggest that without DBS entry cable prices would be about 15 percent higher and cable quality would fall. We find a welfare gain of between $127 and $190 per year (aggregate $2.5 billion) for satellite buyers, and about $50 (aggregate $3 billion) for cable subscribers.","['Goolsbee, Austan', 'Petrin, Amil']","['Consumer Economics: Empirical Analysis', 'Production, Pricing, and Market Structure; Size Distribution of Firms', 'Entertainment; Media']","['D12', 'L11', 'L82']",The Consumer Gains from Direct Broadcast Satellites and the Competition with Cable TV,1,0,0,0,0,2004,03,01
72,1,2004-01-01,"In this paper we propose a new estimator for a model with one endogenous regressor and many instrumental variables. Our motivation comes from the recent literature on the poor properties of standard instrumental variables estimators when the instrumental variables are weakly correlated with the endogenous regressor. Our proposed estimator puts a random coefficients structure on the relation between the endogenous regressor and the instruments. The variance of the random coefficients is modelled as an unknown parameter. In addition to proposing a new estimator, our analysis yields new insights into the properties of the standard two-stage least squares (TSLS) and limited-information maximum likelihood (LIML) estimators in the case with many weak instruments. We show that in some interesting cases, TSLS and LIML can be approximated by maximizing the random effects likelihood subject to particular constraints. We show that statistics based on comparisons of the unconstrained estimates of these parameters to the implicit TSLS and LIML restrictions can be used to identify settings when standard large sample approximations to the distributions of TSLS and LIML are likely to perform poorly. We also show that with many weak instruments, LIML confidence intervals are likely to have under-coverage, even though its finite sample distribution is approximately centered at the true value of the parameter. In an application with real data and simulations around this data set, the proposed estimator performs markedly better than TSLS and LIML, both in terms of coverage rate and in terms of risk.","['Chamberlain, Gary', 'Imbens, Guido']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Analysis of Education']","['C30', 'I21']",Random Effects Estimators with Many Instrumental Variables,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"The Amsterdam auction has been used to sell real estate in the Dutch capital for centuries. By awarding a premium to the highest losing bidder, the Amsterdam auction favors weak bidders without having the implementation difficulties of Myerson's (1981) optimal auction. In a series of experiments, we compare the standard first-price and English auctions, the optimal auction, and two variants of the Amsterdam auction. With strongly asymmetric bidders, the second-price Amsterdam auction raises substantially more revenues than standard formats and only slightly less than the optimal auction.","['Goeree, Jacob K.', 'Offerman, Theo']",['Auctions'],['D44'],The Amsterdam Auction,0,0,1,0,0,2004,01,01
72,1,2004-01-01,"We consider bilateral matching problems where each person views those on the other side of the market as either acceptable or unacceptable: an acceptable mate is preferred to remaining single, and the latter to an unacceptable mate; all acceptable mates are welfare-wise identical. Using randomization, many efficient and fair matching methods define strategyproof revelation mechanisms. Randomly selecting a priority ordering of the participants is a simple example. Equalizing as much as possible the probability of getting an acceptable mate across all participants stands out for its normative and incentives properties: the profile of probabilities is Lorenz dominant, and the revelation mechanism is group-strategyproof for each side of the market.","['Moulin, Herve', 'Bogomolnaia, Anna']",['Bargaining Theory; Matching Theory'],['C78'],Random Matching under Dichotomous Preferences,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"In an effort to improve the small sample properties of generalized method of moments (GMM) estimators, a number of alternative estimators have been suggested. These include empirical likelihood (EL), continuous updating, and exponential tilting estimators. We show that these estimators share a common structure, being members of a class of generalized empirical likelihood (GEL) estimators. We use this structure to compare their higher order asymptotic properties. We find that GEL has no asymptotic bias due to correlation of the moment functions with their Jacobian, eliminating an important source of bias for GMM in models with endogeneity. We also find that EL has no asymptotic bias from estimating the optimal weight matrix, eliminating a further important source of bias for GMM in panel data models. We give bias corrected GMM and GEL estimators. We also show that bias corrected EL inherits the higher order property of maximum likelihood, that it is higher order asymptotically efficient relative to the other bias corrected estimators.","['Smith, Richard J.', 'Newey, Whitney K.']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Higher Order Properties of GMM and Generalized Empirical Likelihood Estimators,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"Intestinal helminths--including hookworm, roundworm, whipworm, and schistosomiasis--infect more than one-quarter of the world's population. Studies in which medical treatment is randomized at the individual level potentially doubly underestimate the benefits of treatment, missing externality benefits to the comparison group from reduced disease transmission, and therefore also underestimating benefits for the treatment group. We evaluate a Kenyan project in which school-based mass treatment with deworming drugs was randomly phased into schools, rather than to individuals, allowing estimation of overall program effects. The program reduced school absenteeism in treatment schools by one-quarter, and was far cheaper than alternative ways of boosting school participation. Deworming substantially improved health and school participation among untreated children in both treatment schools and neighboring schools, and these externalities are large enough to justify fully subsidizing treatment. Yet we do not find evidence that deworming improved academic test scores.","['Kremer, Michael', 'Miguel, Edward']","['Analysis of Health Care Markets', 'Health Behavior', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration']","['I11', 'I12', 'O15']",Worms: Identifying Impacts on Education and Health in the Presence of Treatment Externalities,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"To study the behavior of agents who are susceptible to temptation in infinite horizon consumption problems under uncertainty, we define and characterize dynamic self-control (DSC) preferences. DSC preferences are recursive and separable. In economies with DSC agents, equilibria exist but may be inefficient; in such equilibria, steady state consumption is independent of initial endowments and increases in self-control. Increasing the preference for commitment while keeping self-control constant increases the equity premium. Removing nonbinding constraints changes equilibrium allocations and prices. Debt contracts can be sustained even if the only feasible punishment for default is the termination of the contract.","['Pesendorfer, Wolfgang', 'Gul, Faruk']","['Consumer Economics: Theory', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D11', 'D15']",Self-Control and the Theory of Consumption,0,0,0,0,0,2004,01,01
72,1,2004-01-01,Preferences exhibit relative consumption effects if a person's satisfaction with their own consumption appears to depend upon how much others are consuming. This paper examines a model of an evolutionary environment in which Nature optimally builds relative consumption effects into preferences in order to compensate for incomplete environmental information.,"['Samuelson, Larry']",['Consumer Economics: Theory'],['D11'],Information-Based Relative Consumption Effects,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"We analyze bidding behavior in auctions when risk-averse buyers bid for a good whose value is risky. We show that when the risk in the valuations increases, DARA bidders will reduce their bids by more than the appropriate increase in the risk premium. Ceteris paribus, buyers will be better off bidding for a more risky object in first price, second price, and English auctions with affiliated common (interdependent) values. This ""precautionary bidding"" effect arises because the expected marginal utility of income increases with risk, so buyers are reluctant to bid so highly. We also show that precautionary bidding behavior can make DARA bidders prefer bidding in a common values setting to bidding in a private values one when risk-neutral or CARA bidders would be indifferent. Thus the potential for a ""winner's curse"" can be a blessing for rational DARA bidders.","['Eso, Peter', 'White, Lucy']","['Auctions', 'Criteria for Decision-Making under Risk and Uncertainty']","['D44', 'D81']",Precautionary Bidding in Auctions,0,0,1,0,0,2004,01,01
72,1,2004-01-01,"This paper presents a solution to an important econometric problem, namely the root n consistent estimation of nonlinear models with measurement errors in the explanatory variables, when one repeated observation of each mismeasured regressor is available. While a root n consistent estimator has been derived for polynomial specifications (see Hausman, Ichimura, Newey, and Powell (1991)), such an estimator for general nonlinear specifications has so far not been available.","['Schennach, Susanne M.']","['Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Consumer Economics: Empirical Analysis']","['C21', 'D12']",Estimation of Nonlinear Models with Measurement Error,0,0,0,0,0,2004,01,01
72,1,2004-01-01,"Recent theoretical work has shown the importance of measuring microeconomic uncertainty for models of both general and partial equilibrium under imperfect insurance. In this paper the assumption of i.i.d. income innovations used in previous empirical studies is removed and the focus of the analysis is placed on models for the conditional variance of income shocks, which is related to the measure of risk emphasized by the theory. We first discriminate amongst various models of earnings determination that separate income shocks into idiosyncratic transitory and permanent components. We allow for education- and time-specific differences in the stochastic process for earnings and for measurement error. The conditional variance of the income shocks is modelled as a parsimonious ARCH process with both observable and unobserved heterogeneity. The empirical analysis is conducted on data drawn from the 1967-1992 Panel Study of Income Dynamics. We find strong evidence of sizeable ARCH effects as well as evidence of unobserved heterogeneity in the variances.","['Meghir, Costas', 'Pistaferri, Luigi']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis', 'Personal Income, Wealth, and Their Distributions']","['C51', 'D12', 'D31']",Income Variance Dynamics and Heterogeneity,0,0,0,0,0,2004,01,01
80,2,2012-03-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 80 Iss. 2.,0,0,0,0,0,2012,03,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Frontmatter of Econometrica Vol. 80 Iss. 1.,0,0,0,0,0,2012,01,01
71,6,2003-11-01,"We provide a simple behavioral definition of ""subjective mixture"" of acts for a large class of (not necessarily expected-utility) preferences. Subjective mixtures enjoy the same algebraic properties as the ""objective mixtures"" used to great advantage in the decision setting introduced by Anscombe and Aumann (1963). This makes it possible to formulate mixture-space axioms in a fully subjective setting. For illustration, we present simple subjective axiomatizations of some models of choice under uncertainty, including Bewley's model of choice with incomplete preferences (2002).","['Ghirardato, Paolo']","['Consumer Economics: Theory', 'Criteria for Decision-Making under Risk and Uncertainty']","['D11', 'D81']",A Subjective Spin on Roulette Wheels,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"We consider the bootstrap unit root tests based on finite order autoregressive integrated models driven by iid innovations, with or without deterministic time trends. A general methodology is developed to approximate asymptotic distributions for the models driven by integrated time series, and used to obtain asymptotic expansions for the Dickey-Fuller unit root tests. The second-order terms in their expansions are of stochastic orders O[subscript p](n[superscript -1/4]) and O[subscript p](n[superscript -1/2]) and involve functionals of Brownian motions and normal random variates. The asymptotic expansions for the bootstrap tests are also derived and compared with those of the Dickey-Fuller tests. We show in particular that the bootstrap offers asymptotic refinements for the Dickey-Fuller tests, i.e., it corrects their second-order errors. More precisely, it is shown that the critical values obtained by the bootstrap resampling are correct up to the second-order terms, and the errors in rejection probabilities are of order o(n[superscript -1/2]) if the tests are based upon the bootstrap critical values. Through simulations, we investigate how effective is the bootstrap correction in small samples.","['Park, Joon Y.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Bootstrap Unit Root Tests,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"We propose an estimation method for models of conditional moment restrictions, which contain finite dimensional unknown parameters (theta) and infinite dimensional unknown functions (h). Our proposal is to approximate h with a sieve and to estimate theta and the sieve parameters jointly by applying the method of minimum distance. We show that: (i) the sieve estimator of h is consistent with a rate faster than n[superscript -1/4] under certain metric; (ii) the estimator of theta is square-root-of-n consistent and asymptotically normally distributed; (iii) the estimator for the asymptotic covariance of the theta estimator is consistent and easy to compute; and (iv) the optimally weighted minimum distance estimator of theta attains the semiparametric efficiency bound. We illustrate our results with two examples: a partially linear regression with an endogenous nonparametric part, and a partially additive IV regression with a link function.","['Ai, Chunrong', 'Chen, Xiaohong']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Efficient Estimation of Models with Conditional Moment Restrictions Containing Unknown Functions,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"We consider an infinite-horizon exchange economy with incomplete markets and collateral constraints. As in the two-period model of Geanakoplos and Zame (2002), households can default on their liabilities at any time, and financial securities are only traded if the promises associated with these securities are backed by collateral.","['Schmedders, Karl', 'Kubler, Felix']","['Incomplete Markets', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D52', nan]",Stationary Equilibria in Asset-Pricing Models with Incomplete Markets and Collateral,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"Cointegrated bivariate nonstationary time series are considered in a fractional context, without allowance for deterministic trends. Both the observable series and the cointegrating error can be fractional processes. The familiar situation in which the respective integration orders are 1 and 0 is nested, but these values have typically been assumed known. We allow one or more of them to be unknown real values, in which case Robinson and Marinucci (2001, 2003) have justified least squares estimates of the cointegrating vector, as well as narrow-band frequency-domain estimates, which may be less biased. While consistent, these estimates do not always have optimal convergence rates, and they have nonstandard limit distributional behavior. We consider estimates formulated in the frequency domain, that consequently allow for a wide variety of (parametric) autocorrelation in the short memory input series, as well as time-domain estimates based on autoregressive transformation. Both can be interpreted as approximating generalized least squares and Gaussian maximum likelihood estimates. The estimates share the same limiting distribution, having mixed normal asymptotics (yielding Wald test statistics with chi[superscript 2] null limit distributions), irrespective of whether the integration orders are known or unknown, subject in the latter case to their estimation with adequate rates of convergence. The parameters describing the short memory stationary input series are square-root-of-n-consistently estimable, but the assumptions imposed on these series are much more general than ones of autoregressive moving average type. A Monte Carlo study of finite-sample performance is included.","['Hualde, J.', 'Robinson, P. M.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Cointegration in Fractional Systems with Unknown Integration Orders,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"This paper develops a dynamic industry model with heterogeneous firms to analyze the intra-industry effects of international trade. The model shows how the exposure to trade will induce only the more productive firms to enter the export market (while some less productive firms continue to produce only for the domestic market) and will simultaneously force the least productive firms to exit. It then shows how further increases in the industry's exposure to trade lead to additional inter-firm reallocations towards more productive firms. The paper also shows how the aggregate industry productivity growth generated by the reallocations contributes to a welfare gain, thus highlighting a benefit from trade that has not been examined theoretically before. The paper adapts Hopenhayn's (1992a) dynamic industry model to monopolistic competition in a general equilibrium setting. In so doing, the paper provides an extension of Krugman's (1980) trade model that incorporates firm level productivity differences. Firms with different productivity levels coexist in an industry because each firm faces initial uncertainty concerning its productivity before making an irreversible investment to enter the industry. Entry into the export market is also costly, but the firm's decision to export occurs after it gains knowledge of its productivity.","['Melitz, Marc J.']","['Models of Trade with Imperfect Competition and Scale Economies; Fragmentation', 'Industrial Organization and Macroeconomics: Industrial Structure and Structural Change; Industrial Price Indices', 'Multinational Firms; International Business', 'Open Economy Macroeconomics', 'Production, Pricing, and Market Structure; Size Distribution of Firms']","['F12', 'L16', 'F23', 'F41', 'L11']",The Impact of Trade on Intra-industry Reallocations and Aggregate Industry Productivity,1,0,0,0,0,2003,11,01
71,6,2003-11-01,"This paper considers tests for structural instability of short duration, such as at the end of the sample. The key feature of the testing problem is that the number, m, of observations in the period of potential change is relatively small--possibly as small as one. The well-known F test of Chow (1960) for this problem only applies in a linear regression model with normally distributed iid errors and strictly exogenous regressors, even when the total number of observations, n + m, is large. We generalize the F test to cover regression models with much more general error processes, regressors that are not strictly exogenous, and estimation by instrumental variables as well as least squares. In addition, we extend the F test to nonlinear models estimated by generalized method of moments and maximum likelihood. Asymptotic critical values that are valid as n -> infinity with m fixed are provided using a subsampling-like method. The results apply quite generally to processes that are strictly stationary and ergodic under the null hypothesis of no structural instability.","['Andrews, D. W. K.']",['Single Equation Models; Single Variables: General'],['C20'],End-of-Sample Instability Tests,0,0,0,0,0,2003,11,01
71,6,2003-11-01,"With cheap talk, more can be achieved by long conversations than by a single message--even when one side is strictly better informed than the other. (""Cheap talk"" means plain conversation--unmediated, nonbinding, and payoff-irrelevant.) This work characterizes the equilibrium payoffs for all two-person games in which one side is better informed than the other and cheap talk is permitted.","['Hart, Sergiu', 'Aumann, Robert J.']","['Game Theory and Bargaining Theory: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Asymmetric and Private Information; Mechanism Design']","['C70', 'D83', 'D82']",Long Cheap Talk,0,0,0,0,0,2003,11,01
79,6,2011-11-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2011,11,01
79,6,2011-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2011,11,01
79,4,2011-07-01,ECONLIT None Found,"['Acemoglu, Daron']",['Introductory Material'],['Y20'],Editorial,0,0,0,0,0,2011,07,01
66,6,1998-11-01,ECONLIT None Found,"['Edlin, Aaron S.', 'Shannon, Chris']","['Mathematical Methods; Programming Models; Mathematical and Simulation Modeling: General', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C60', 'C73']",Strict Single Crossing and the Strict Spence-Mirrlees Condition: A Comment on Monotone Comparative Statics,0,0,0,0,0,1998,11,01
66,6,1998-11-01,ECONLIT None Found,"['Karni, Edi']",['Social Choice; Clubs; Committees; Associations'],['D71'],Impartiality: Definition and Representation,0,0,0,0,0,1998,11,01
66,6,1998-11-01,"The authors consider the problem of making asymptotically valid inference on structural parameters in instrumental variables regression with weak instruments. Using local-to-zero asymptotics, they derive the asymptotic distributions of likelihood ratio (LR) and Lagrange multiplier (LM) type statistics for testing simple hypotheses on structural parameters based on maximum likelihood and generalized methods of moments estimation methods. In contrast to the nonstandard limiting behavior of Wald statistics, the limiting distributions of certain LR and LM statistics are bounded by a chi-square distribution with degrees of freedom given by the number of instruments.","['Zivot, Eric', 'Wang, Jiahui']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Inference on Structural Parameters in Instrumental Variables Regression with Weak Instruments,0,0,0,0,0,1998,11,01
66,6,1998-11-01,"The authors examine a bargaining setting where heterogeneous buyers and sellers are repeatedly matched and time is costly. They characterize efficiency and then, using an implementation approach, study the allocations that can result in equilibrium when the matched buyers and sellers bargain through some extensive game form. The authors are particularly concerned with the impact of making trade voluntary: buyers and sellers have the option of being rematched in the market. Finally, they compare and contrast the efficient allocations with those that could ever arise as the equilibria of some voluntary negotiation procedure.","['Jackson, Matthew O.', 'Palfrey, Thomas R.']",['Bargaining Theory; Matching Theory'],['C78'],Efficiency and Voluntary Implementation in Markets with Repeated Pairwise Bargaining,0,0,0,0,0,1998,11,01
66,6,1998-11-01,"The least-absolute-deviations (LAD) estimator for a median-regression or censored median-regression model does not satisfy the standard conditions for obtaining asymptotic refinements through use of the bootstrap because the LAD objective function is not smooth. This paper overcomes this problem by smoothing the objective function. The smoothed estimator is asymptotically equivalent to the ordinary LAD estimator. With bootstrap critical values, the rejection probabilities of symmetrical t and chi-square tests based on the smoothed estimator are correct to nearly order 1/n under the null hypothesis. In contrast, first-order asymptotic approximations make errors of this size.","['Horowitz, Joel L.']",['Single Equation Models; Single Variables: General'],['C20'],Bootstrap Methods for Median Regression Models,0,0,0,0,0,1998,11,01
66,6,1998-11-01,Some new tools for analyzing spurious regressions are presented. The theory utilizes the general representation of a stochastic process in terms of an orthonormal system and provides an extension of the Weierstrass theorem to include the approximation of continuous functions and stochastic processes by Wiener processes. The theory is applied to two classic examples of spurious regressions: regressions of stochastic trends on time polynomials and regressions among independent random walks. It is shown that such regressions reproduce in part and in whole the underlying orthonormal representations.,"['Phillips, Peter C. B.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],New Tools for Understanding Spurious Regressions,0,0,0,0,0,1998,11,01
66,6,1998-11-01,"This paper is about the economic theory of biodiversity preservation. A cost-effectiveness methodology is constructed, which results in a ranking criterion sufficiently operational to be useful in suggesting what to look at when determining actual conservation priorities. The formula is firmly rooted in a mathematically rigorous optimization framework, so that its theoretical underpinnings are clear. The underlying model, called the 'Noah's Ark Problem,' is intended to be a kind of canonical form that hones down to its analytical essence the problem of best preserving diversity under a limited budget constraint.","['Weitzman, Martin L.']",['Renewable Resources and Conservation: General'],['Q20'],The Noah's Ark Problem,0,0,0,0,0,1998,11,01
66,6,1998-11-01,ECONLIT None Found,"['Chiappori, P. A.', 'Browning, M.']","['Household Production and Intrahousehold Allocation', 'Consumer Economics: Theory', 'Consumer Economics: Empirical Analysis']","['D13', 'D11', 'D12']",Efficient Intra-household Allocations: A General Characterization and Empirical Tests,0,0,0,0,0,1998,11,01
66,5,1998-09-01,ECONLIT None Found,"['Chapman, David A.']","['Financial Markets and the Macroeconomy', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['E44', nan]",Habit Formation and Aggregate Consumption,0,0,0,0,0,1998,09,01
66,5,1998-09-01,"The authors investigate whether an equilibrium search model, in which the wage offer distribution is endogenous, is able to describe observed labor market histories. They find that the distributions of job and unemployment spells are consistent with the data, and qualitative predictions of the model for the wages set by employers are confirmed. The authors distinguish between separate segments of the labor market, and they show that productivity heterogeneity is important to obtain an acceptable fit to the data. The results are used to estimate the firms' monopsony power. The effects of changes in the mandatory minimum wage are examined.","['van den Berg, Gerard J.', 'Ridder, Geert']","['Unemployment: Models, Duration, Incidence, and Job Search']",['J64'],An Empirical Equilibrium Search Model of the Labor Market,0,0,0,0,0,1998,09,01
66,5,1998-09-01,"The author gives conditions under which nonparametric autocorrelation-consistent variance estimation is possible without smoothing. The conditions are relevant to inference on slope parameters in models with an intercept and strictly exogenous regressors, and allow regressors and disturbances to collectively have considerable stationary long memory and to satisfy only mild, in some cases minimal, moment conditions. His estimate dominates smoothed ones in the sense that it can have mean squared error proportional to the reciprocal of sample size. Under standard additional regularity conditions, the author shows that the estimate can validly studentize asymptotically normal estimates of structural parameters in linear simultaneous equations systems.","['Robinson, P. M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Inference-without-Smoothing in the Presence of Nonparametric Autocorrelation,0,0,0,0,0,1998,09,01
66,5,1998-09-01,"This paper proposes a new statistical model for the analysis of data which arrives at irregular intervals. The model treats the time between events as a stochastic process and proposes a new class of point processes with dependent arrival rates. The conditional intensity is developed and compared with other self-exciting processes. The model is applied to the arrival times of financial transactions and therefore is a model of transaction volume, and also to the arrival of other events such as price changes. Models for the volatility of prices are estimated, and examined from a market microstructure point of view.","['Engle, Robert F.', 'Russell, Jeffrey R.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C22', nan]",Autoregressive Conditional Duration: A New Model for Irregularly Spaced Transaction Data,0,0,0,0,0,1998,09,01
66,5,1998-09-01,"Causality in Granger's sense is defined in terms of predictibility one period ahead. The notion of causality is generalized by considering causality at any given horizon 1 <= h <= inifinity, providing a rigorous formalization of indirect causal effects and causality chains in (possibly) nonstationary time series. The authors derive necessary and sufficient conditions for noncausality between vectors up to any given horizon. They observe that coefficients of lagged variables in forecasts at various horizons can be interpreted as generalized impulse response coefficients yielding a complete picture of linear causality, in contrast with usual impulse coefficients which can be misleading.","['Renault, Eric', 'Dufour, Jean-Marie']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C32', 'C22']",Short Run and Long Run Causality in Time Series: Theory,0,0,0,0,0,1998,09,01
66,5,1998-09-01,"Semiparametric methods are developed to estimate the bias that arises from using nonexperimental comparison groups to evaluate social programs and to test the identifying assumptions that justify matching, selection models and the method of difference in differences. Using data from an experiment on a prototypical social program and data from nonexperimental comparison groups, the authors reject the assumptions justifying matching and their extensions of it. The evidence supports the selection bias model and the assumptions that justify a semiparametric version of the method of difference-in-differences. The authors extend their analysis to consider applications of the methods to ordinary observational data. Coauthors are Hidehiko Ichimura, Jeffrey Smith and Petra Todd.","['Heckman, James']","['Model Construction and Estimation', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['C51', 'C14', 'C24', 'J24']",Characterizing Selection Bias Using Experimental Data,0,0,0,0,0,1998,09,01
66,4,1998-07-01,ECONLIT None Found,"['Aumann, Robert J.']",['Game Theory and Bargaining Theory: General'],['C70'],Common Priors: A Reply to Gul,0,0,0,0,0,1998,07,01
66,4,1998-07-01,ECONLIT None Found,"['Gul, Faruk']",['Game Theory and Bargaining Theory: General'],['C70'],A Comment on Aumann's Bayesian View,0,0,0,0,0,1998,07,01
66,4,1998-07-01,"The authors examine the welfare properties of surplus maximization by embedding a perfectly discriminating monopoly in an otherwise standard Arrow-Debreu economy. Although they discover an inefficient equilibrium, the authors validate partial equilibrium intuition by showing that equilibria are efficient provided that the monopoly goods are costly and that a natural monopoly can typically use personalized two-part tariffs in these equilibria. However, they find that Pareto optima are sometimes incompatible with surplus maximization, even when transfer payments are used. The authors provide insight into the source of this difficulty and give some instructive examples of economies where a second welfare theorem holds.","['Edlin, Aaron S.', 'Epelbaum, Mario', 'Heller, Walter P.']","['Allocative Efficiency; Cost-Benefit Analysis', 'Market Structure, Pricing, and Design: Monopoly']","['D61', 'D42']",Is Perfect Price Discrimination Really Efficient? Welfare and Existence in General Equilibrium,0,0,1,0,0,1998,07,01
66,4,1998-07-01,"The method of simulated scores (MSS) is presented for estimating limited dependent variables models (LDV) with flexible correlation structure in the unobservables. The authors propose simulators that are continuous in the unknown parameter vectors, and hence standard optimization methods can be used to compute the MSS estimators that employ these simulators. The first continuous method relies on a recursive conditioning of the multivariate normal density through a Cholesky triangularization of its variance-covariance matrix. The second method combines results about the conditionals of the multivariate normal distribution with Gibbs resampling techniques. The authors establish consistency and asymptotic normality of the MSS estimators and derive suitable rates at which the number of simulations must rise if biased simulators are used.","['Hajivassiliou, Vassilis A.', 'McFadden, Daniel L.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models']","['C25', 'C24']",The Method of Simulated Scores for the Estimation of LDV Models,0,0,0,0,0,1998,07,01
66,4,1998-07-01,"The 1980s tax reforms and the changing dispersion of wages offer one of the best opportunities yet to estimate labor supply effects. Nevertheless, changing sample composition, aggregate shocks, the changing composition of the tax paying population, and discontinuities in the tax system create serious identification and estimation problems. The authors develop grouping estimators that address these issues. Their results reveal positive and moderately sized wage elasticities. The authors also find negative income effects for women with children.","['Blundell, Richard', 'Meghir, Costas', 'Duncan, Alan']","['Time Allocation and Labor Supply', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['J22', 'H24']",Estimating Labor Supply Responses Using Tax Reforms,0,0,0,0,0,1998,07,01
66,4,1998-07-01,"The authors provide existence proofs and characterization results for the multidimensional version of the multiproduct monopolist problem of M. Mussa and S, Rosen (1978). These results a are also directly applicable to the multidimensional nonlinear pricing problems studied by R. Wilson (1993) and M. Armstrong (1996). The authors establish that bunching is robust in these multidimensional screening problems, even with very regular distributions of types. They consequently design a new technique, the sweeping procedure, for dealing with bunching in multidimensional contexts. This technique extends the ironing procedure of Mussa and Rosen to several dimensions.","['Chone, Philippe', 'Rochet, Jean-Charles']","['Asymmetric and Private Information; Mechanism Design', 'Market Structure, Pricing, and Design: Monopoly']","['D82', 'D42']","Ironing, Sweeping, and Multidimensional Screening",0,0,1,0,0,1998,07,01
66,4,1998-07-01,"This paper attempts to identify some of the basic reasons why adaptive learning may or may not lead to stability and convergence to self-fulfilling expectations. It is shown that, if agents are somewhat uncertain about the local stability of the system, the learning dynamics is locally divergent. On the other hand, if agents are fairly sure of the local stability of the system, one may indeed get local stability. This 'uncertainty principle' does show up in a wide variety of contexts.","['Grandmont, Jean-Michel']","['Expectations; Speculations', 'Criteria for Decision-Making under Risk and Uncertainty']","['D84', 'D81']",Expectations Formation and Stability of Large Socioeconomic Systems,0,0,0,0,0,1998,07,01
66,3,1998-05-01,ECONLIT None Found,"['Abdulkadiroglu, Atila', 'Sonmez, Tayfun']",['Bargaining Theory; Matching Theory'],['C78'],Random Serial Dictatorship and the Core from Random Endowments in House Allocation Problems,0,0,0,0,0,1998,05,01
66,3,1998-05-01,"Methods of indirect, simulation-based inference for nested and nonnested hypotheses are developed. The methods make use of instrumental models and are applicable in cases where likelihood-based inference is numerically unfeasible. The asymptotic normality of an indirect Wald vector is shown and the implicit null hypotheses of the proposed tests are characterized as generalizations of the standard encompassing hypothesis. Some of the tests generalize well-known instrumental variable methods and Hausman-Wu specification tests.","['Scaillet, Olivier', 'Gourieroux, Christian', 'Dhaene, Geert']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Evaluation, Validation, and Selection']","['C22', 'C52']",Instrumental Models and Indirect Encompassing,0,0,0,0,0,1998,05,01
66,3,1998-05-01,"This paper introduces an alternative estimator for the linear censored quantile regression model. The estimator also applies to cases where the censoring point is unknown. Since the objective function is globally convex and the estimator is a solution to a linear programming problem, a global minimizer is obtained in a finite number of simplex iterations. The estimator has a square root of n-convergence rate and is asymptotically normal. A Monte Carlo study performed shows that the suggested estimator has very desirable small sample properties.","['Buchinsky, Moshe', 'Hahn, Jinyong']",['Single Equation Models; Single Variables: Truncated and Censored Models; Switching Regression Models; Threshold Regression Models'],['C24'],An Alternative Estimator for the Censored Quantile Regression Model,0,0,0,0,0,1998,05,01
66,3,1998-05-01,The authors examine discounted repeated games where players privately observe different signals. A leading example is secret price cutting; a firm cannot directly observe rival firms' price cutting but its own sales can imperfectly indicate what is going on. The characterization of equilibria in this class of games has been an open question. The authors construct equilibria where players voluntarily communicate what they have observed and prove folk theorems. Their results thus provide a theoretical support for the conventional wisdom that communication facilitates collusion.,"['Kandori, Michihiro', 'Matsushima, Hitoshi']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Antitrust Law', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['C73', 'K21', 'D43']","Private Observation, Communication and Collusion",0,1,1,0,0,1998,05,01
66,3,1998-05-01,"This paper examines repeated games in which each player observes a private and imperfect signal on the actions played and in which players are allowed to communicate using public messages. Providing incentives for players to reveal their observations generate revelation constraints which, combined with signal imperfections, may be a source of inefficiencies. However, the author shows that, by delaying the revelation of their observations, players may reduce the cost of deterring deviations. With at least three players, he obtains a Nash threat version of the folk theorem. With two players, the author shows that an efficient outcome can (almost) always be approximated.","['Compte, Olivier']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",Communication in Repeated Games with Imperfect Private Monitoring,0,0,0,0,0,1998,05,01
66,3,1998-05-01,"In an ultimatum game experiment, financial incentives were varied by a factor of twenty-five. Consistent with prior results, changes in stakes had only a small effect on play for inexperienced players. However, rejections were less frequent the higher the stakes and proposals in the high stakes declined slowly as proposers gained experience. The lower rejection frequency when stakes were higher can be explained by the added power of multiple observations per subject in this experiment. A model of learning suggests that the lower rejection frequency is the reason proposers in higher stakes learn to make lower offers.","['Slonim, Robert', 'Roth, Alvin E.']","['Bargaining Theory; Matching Theory', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C78', 'D83']",Learning in High Stakes Ultimatum Games: An Experiment in the Slovak Republic,0,0,0,0,0,1998,05,01
66,3,1998-05-01,"The authors show that quasimaximum likelihood (QML) estimators for conditional dispersion models can be severely affected by a small number of outliers such as market crashes and rallies, and they propose new estimation strategies (the two-stage Hampel estimators and two-stage S-estimators) resistant to the effects of outliers and study the properties of these estimators. They apply their methods to estimate models of the conditional volatility of the daily returns of the S&P 500 Cash Index series. In contrast to QML estimators, the authors' proposed method resists outliers, revealing an informative new picture of volatility dynamics during 'typical' daily market activity.","['White, Halbert', 'Sakata, Shinichi']","['Estimation: General', 'Asset Pricing; Trading Volume; Bond Interest Rates', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation']","['C13', nan, 'C22', 'C51']",High Breakdown Point Conditional Dispersion Estimation with Application to S&P 500 Daily Returns Volatility,0,0,0,0,0,1998,05,01
66,3,1998-05-01,"A probability weighting function w(p) is a prominent feature of several nonexpected utility theories, including prospect theory and rank-dependent models. Empirical estimates indicate that w(p) is regressive with respect to the diagonal (w(p) > p for small p, and w(p) < p for large p), s-shaped (concave near p = 0, convex near p = 1), and asymmetrical (intersecting the diagonal at about p = l/3). The paper provides axioms for several families of weighting functions, including a 'compound invariant' form, w(p) = exp{-{-ln p}[superscript alpha]}, 0 < alpha < 1, which is regressive, s-shaped, and which has invariant fixed and inflection points at p = 1/e.","['Prelec, Drazen']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],The Probability Weighting Function,0,0,0,0,0,1998,05,01
66,2,1998-03-01,ECONLIT None Found,"['Brown, Bryan W.', 'Newey, Whitney K.']","['Model Construction and Estimation', 'Expectations; Speculations', 'Semiparametric and Nonparametric Methods: General']","['C51', 'D84', 'C14']",Efficient Semiparametric Estimation of Expectations,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"This study establishes two main results in a dynamic general equilibrium model. The first is to demonstrate the dual Liapounov stability of a von Neumann facet without the restrictive assumptions on the structure of underlying technologies adopted commonly in the optimal growth literature. The second is to demonstrate that a temporary change in fiscal policy has almost no effect on present and future consumption. While such a result has been discussed in the context of permanent income hypothesis, in this study it is proved in the dynamic general equilibrium framework under a set of basic assumptions of general equilibrium theory.","['Yano, Makoto']","['One, Two, and Multisector Growth Models']",['O41'],On the Dual Stability of a von Neumann Facet and the Inefficacy of Temporary Fiscal Policy,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"In this paper, the authors develop a discretized version of the dynamic programming algorithm and study its convergence and stability properties. They show that the computed value function converges quadratically to the true value function and that the computed value function converges linearly, as the mesh size of the discretization converges to zero; further, the algorithm is stable. The authors also discuss several aspects of the implementation of their procedures as applied to some commonly studied growth models.","['Vigo-Aguiar, Jesus', 'Santos, Manuel S.']",['Computational Techniques; Simulation Modeling'],['C63'],Analysis of a Numerical Dynamic Programming Algorithm Applied to Economic Models,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"This paper concerns inferring how self-interested subjects, as opposed to altruistic investigators, evaluate treatments in social experiments. The authors argue that the attrition behavior of subjects reveals their evaluation and discuss the usefulness of using such data in performing subject-based evaluation. The authors study the causes of disagreements between investigators and subjects in evaluating treatments and empirically assess the degree to which they disagree. The paper provides an empirical framework for estimating the systematic level of disagreement in the presence of such errors. Using clinical trials, the authors find substantial evidence of overapproval by investigators in about one-third of the trials analyzed.","['Hedges, Larry V.', 'Philipson, Tomas']","['Model Construction and Estimation', 'Health: General']","['C51', 'I10']",Subject Evaluation in Social Experiments,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"Asymptotic normality of posterior is a well understood result for dynamic as well as non-dynamic models based on sets of abstract conditions that are hard to verify especially for the case of nonstationarity. In this paper the authors provide a set of conditions by which they can relatively easily prove the asymptotic posterior normality under quite general situations of possible nonstationarity. This result reinforces and generalizes the validity of inference based on the likelihood principle. On the other hand, the authors' conditions allow them to generalize Bayesian decision criterion to the case of possible nonstationarity. In addition, the authors have shown that consistency of the maximum likelihood estimator, not the asymptotic normality of the estimator, with some minor additional assumptions is sufficient for the asymptotic posterior normality.","['Kim, Jae-Young']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],"Large Sample Properties of Posterior Densities, Bayesian Information Criterion and the Likelihood Principle in Nonstationary Time Series Models",0,0,0,0,0,1998,03,01
66,2,1998-03-01,"This paper develops a variant of one-step efficient GMM based on the KLIC rather than empirical likelihood. As in other one-step methods, the authors introduce M (the number of moments) auxiliary 'tilting' parameters which are used to construct a reweighting of the data so that the reweighted sample obeys all the moment conditions at the parameter estimates. Parameter and overidentification tests can be recast in terms of these tilting parameters; such tests are often startlingly more effective than their conventional counterparts. These performance differences cannot be completely explained by the leading terms of the statistics' asymptotic expansions.","['Spady, Richard H.', 'Imbens, Guido W.', 'Johnson, Phillip']",['Hypothesis Testing: General'],['C12'],Information Theoretic Approaches to Inference in Moment Condition Models,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"The role of propensity score in the efficient estimation of the average treatment effects is examined. If the treatment is ignorable given some observed characteristics, it is shown that the propensity score is ancillary for estimation of the average treatment effects but not for estimation of average treatment effects on the treated. Efficient semiparametric estimators take the form of relevant sample averages of the data completed by the nonparametric imputation method. Projection on the propensity score is not necessary for efficient semiparametric estimation of the average treatment effects on the treated even if the propensity score is known.","['Hahn, Jinyong']",['Semiparametric and Nonparametric Methods: General'],['C14'],On the Role of the Propensity Score in Efficient Semiparametric Estimation of Average Treatment Effects,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"Many non/semiparametric time series estimates may be regarded as different forms of sieve extremum estimates. For stationary absolute regular mixing observations, the authors obtain convergence rates of sieve extremurn estimates and root-n asymptotic normality of 'plug-in' sieve extremum estimates of smooth functionals. As applications to time series models, they give convergence rates for nonparametric ARX(p,q) regression via neural networks, splines, wavelets; root-n asymptotic normality for partial linear additive AR(p) models, and monotone transformation AR(1) models.","['Shen, Xiaotong', 'Chen, Xiaohong']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Sieve Extremum Estimates for Weakly Dependent Data,0,0,0,0,0,1998,03,01
66,2,1998-03-01,"Effects of military service on veterans' earnings are estimated using Social Security administrative records to fit models with heterogeneous potential outcomes. The first estimation strategy uses matching and regression to compare applicants who enlisted with applicants who did not enlist. The second uses instrumental variables generated by an error in military entrance exams. The empirical results suggest that military service led to higher employment rates for veterans. But in spite of this employment gain, voluntary military service led to only a modest increase in the civilian earnings of nonwhite veterans while actually reducing the civilian earnings of white veterans.","['Angrist, Joshua D.']","['Wage Level and Structure; Wage Differentials', 'National Security and War']","['J31', 'H56']",Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants,0,0,0,0,0,1998,03,01
66,1,1998-01-01,ECONLIT None Found,"['Lipman, Barton L.', 'Rustichini, Aldo', 'Dekel, Eddie']","['Information, Knowledge, and Uncertainty: General']",['D80'],Standard State-Space Models Preclude Unawareness,0,0,0,0,0,1998,01,01
66,1,1998-01-01,ECONLIT None Found,"['Elliott, Graham']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],On the Robustness of Cointegration Methods When Regressors Almost Have Unit Roots,0,0,0,0,0,1998,01,01
66,1,1998-01-01,Test statistics are proposed for testing hypotheses about the parameters of the deterministic trend function of a univariate time series. The tests are valid for general forms of serial correlation in the errors and do not require estimates (parametric or nonparametric) of serial correlation parameters. The tests are valid for stationary and unit root errors. Allowable trend functions include linear polynomials of time that may have structural change. Asymptotic results are applied to a model with a simple linear trend and are used to construct confidence intervals for average GNP growth rates for eight industrialized countries using postwar data.,"['Vogelsang, Timothy J.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Trend Function Hypothesis Testing in the Presence of Serial Correlation,0,0,0,0,0,1998,01,01
66,1,1998-01-01,"A simple root n consistent, asymptotically normal semiparametric estimator of the coefficient vector beta in the latent variable specification y = L (beta'x + e) is constructed. The distribution of e is unknown and may be correlated with x or be conditionally heteroscedastic, e.g., x can contain measurement error. The function L can also be unknown. The identification assumption is that e is uncorrelated with instruments u and that the conditional distribution of e given x and u does not depend on one of the regressors, which has some special properties. Extensions to more general latent variable specifications are provided.","['Lewbel, Arthur']",['Single Equation Models; Single Variables: General'],['C20'],Semiparametric Latent Variable Model Estimation with Endogenous or Mismeasured Regressors,0,0,0,0,0,1998,01,01
66,1,1998-01-01,"Exact tests and confidence sets are obtained for general transformations of the coefficients in linear first-order autoregressive models with exogenous variables and i.i.d. disturbances. The tests proposed have known level and are either similar (constant rejection probability under all processes consistent with the null hypothesis) or use bounds which are free of nuisance parameters. Correspondingly, the confidence sets are either similar with known size or conservative. These exact methods are asymptotically valid under weak regularity conditions. Their usefulness is illustrated by power comparisons and by applications to a dynamic trend model of money velocity and a model of money demand.","['Kiviet, Jan F.', 'Dufour, Jean-Marie']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Exact Inference Methods for First-Order Autoregressive Distributed Lag Models,0,0,0,0,0,1998,01,01
66,1,1998-01-01,"This paper develops the statistical theory for testing and estimating multiple change points in regression models. The rate of convergence and limiting distribution for the estimated parameters are obtained. Several test statistics are proposed to determine the existence as well as the number of change points. A partial structural change model is considered. The authors study both fixed and shrinking magnitudes of shifts. In addition, the models allow for serially correlated disturbances (mixingales). An estimation strategy for which the location of the breaks need not be simultaneously determined is discussed. Instead, the authors' method successively estimates each break point.","['Bai, Jushan', 'Perron, Pierre']",['Single Equation Models; Single Variables: General'],['C20'],Estimating and Testing Linear Models with Multiple Structural Changes,0,0,0,0,0,1998,01,01
66,1,1998-01-01,"This research explores the medical care consumption and absenteeism decisions of employed individuals with acute illnesses in an effort to better understand health care behavior. Using data from the 1987 National Medical Expenditure Survey, the author estimates the structural parameters of an individual's discrete choice stochastic optimization problem, as opposed to employing conventional reduced form estimation methods that are prevalent in the health care literature. The estimates allow for predictions of the change in physician services use and illness-related absenteeism that arise with the introduction of new public policy initiatives involving health insurance and sick-leave coverage.","['Gilleskie, Donna B.']","['Health: General', 'Safety; Job Satisfaction; Related Public Policy']","['I10', 'J28']",A Dynamic Stochastic Model of Medical Care Use and Work Absence,0,0,0,0,0,1998,01,01
65,6,1997-11-01,ECONLIT None Found,"['Matsui, Akihiko', 'Lagunoff, Roger']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Asynchronous Choice in Repeated Coordination Games,0,0,0,0,0,1997,11,01
65,6,1997-11-01,ECONLIT None Found,"['Davidson, Russell', 'Duclos, Jean-Yves']",['Taxation and Subsidies: Incidence'],['H22'],Statistical Inference for the Measurement of the Incidence of Taxes and Transfers,0,0,0,0,0,1997,11,01
65,6,1997-11-01,ECONLIT None Found,"['Gordon, Robert J.']",['Sociology of Economics'],['A14'],"What Is the Econometric Society? History, Organization, and Basic Procedures",0,0,0,0,0,1997,11,01
65,6,1997-11-01,"This paper establishes a set of conditions for the uniqueness and stability of the equilibrium price in exchange and production economies. Building on the earlier work of J. M. Grandmont and W. Hildenbrand, it shows that increasing heterogeneity in preferences (in some well-defined sense) causes aggregate Engel curves to become increasingly linear. So sufficient dispersion, together with the assumption that preferences and endowments are independently distributed, leads to the aggregate excess demand function satisfying the law of demand. Uniqueness and stability of the equilibrium price follows.","['Quah, John K.-H.']",['Exchange and Production Economies'],['D51'],The Law of Demand When Income Is Price Dependent,0,0,0,0,0,1997,11,01
65,6,1997-11-01,"This paper develops a search-theoretic model of technological change to explain why both patenting and the growth of productivity have remained roughly constant while research employment in the United States has increased by a factor of six over the past four decades. In the model, researchers sample from probability distributions determining the efficiency of potential new production techniques. Technological breakthroughs, resulting in patents, become increasingly hard to find as the level of technology advances. Given certain restrictions on the search distributions, the equilibrium of the model replicates the U.S. time-series pattern of research, patenting, and productivity.","['Kortum, Samuel S.']",['Innovation; Research and Development; Technological Change; Intellectual Property Rights: General'],['O30'],"Research, Patenting, and Technological Change",0,0,0,1,0,1997,11,01
65,6,1997-11-01,"General characterizations of valid confidence sets and tests in problems involving (locally almost) unidentified (LAU) parameters are presented. In particular, any valid confidence set for an unbounded LAU parameter must be unbounded with positive probability. Consequently, almost surely bounded confidence sets, like Wald-type confidence sets, have zero coverage probability and Wald-type test statistics cannot be pivotal functions. The results are applied to simultaneous equations (weak instruments), regressions with autoregressive errors, long-run multipliers, and cointegrating vectors. For such models, Wald-type procedures are not recommended while LR procedures can be shown to be valid.","['Dufour, Jean-Marie']",['Estimation: General'],['C13'],Some Impossibility Theorems in Econometrics with Applications to Structural and Dynamic Models,0,0,0,0,0,1997,11,01
65,6,1997-11-01,"The author considers the problem of estimation in a panel data sample selection model, where both the selection and the regression equation of interest contain unobservable individual-specific effects. He proposes a two-step estimation procedure, which 'differences out' the sample selection effect and the unobservable individual effect from the equation of interest. In the first step, the unknown coefficients of the 'selection' equation are consistently estimated. The estimates are then used to estimate the regression equation of interest. The estimator proposed in this paper is shown to be consistent and asymptotically normal. The proposed estimator is shown to be consistent and asymptotically normal. Its finite sample properties are investigated in a small Monte Carlo simulation.","['Kyriazidou, Ekaterini']",['Multiple or Simultaneous Equation Models: Panel Data Models; Spatio-temporal Models'],['C33'],Estimation of a Panel Data Sample Selection Model,0,0,0,0,0,1997,11,01
65,6,1997-11-01,"This paper investigates what may be learned about treatment response when it is assumed that response functions are monotone, semimonotone, or concave-monotone. Nothing is assumed about the process of treatment selection and cross-individual restrictions on response are not imposed. The idea is to determine, for every member of the population, the response functions that pass through the realized (treatment, outcome) pair and that are consistent with the assumption imposed. These findings are then aggregated to determine what can be learned about the population distribution of response. The analysis is applied to the econometrics of demand and production.","['Manski, Charles F.']","['Semiparametric and Nonparametric Methods: General', 'Model Construction and Estimation']","['C14', 'C51']",Monotone Treatment Response,0,0,0,0,0,1997,11,01
65,6,1997-11-01,"A number of papers have shown that a strict Nash equilibrium action profile of a game may never be played if there is a small amount of incomplete information. The authors present a general approach to analyzing the robustness of equilibria to a small amount of incomplete information. A Nash equilibrium of a complete information game is said to be robust to incomplete information if every incomplete information game with payoffs almost always given by the complete information game has an equilibrium which generates behavior close to the Nash equilibrium. The authors show that many games with strict equilibria have no robust equilibrium and examine why they get such different results from existing refinements. If a game has a unique correlated equilibrium, it is robust. A natural many-player many-action generalization of risk dominance is a sufficient condition for robustness.","['Kajii, Atsushi', 'Morris, Stephen']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design']","['C72', 'D82']",The Robustness of Equilibria to Incomplete Information,0,0,0,0,0,1997,11,01
65,6,1997-11-01,The authors consider an auction in which k identical objects of unknown value are auctioned off to n bidders. The k highest bidders get an object and pay the k + 1st bid. Bidders receive a signal that provides information about the value of the object. The authors characterize the unique symmetric equilibrium of this auction. They then consider a sequence of auctions A[subscript]r with n[subscript]r bidders and k[subscript]r objects. The authors show that price converges in probability to the true value of the object if and only if both the number of objects (k) and the number of bidders who do not receive an object (n - k) go to infinity.,"['Swinkels, Jeroen M.', 'Pesendorfer, Wolfgang']",['Auctions'],['D44'],The Loser's Curse and Information Aggregation in Common Value Auctions,0,0,1,0,0,1997,11,01
65,5,1997-09-01,ECONLIT None Found,"['Anderson, Robert M.', 'Trockel, Walter', 'Zhou, Lin']",['Exchange and Production Economies'],['D51'],Nonconvergence of the Mas-Colell and Zhou Bargaining Sets,0,0,0,0,0,1997,09,01
65,5,1997-09-01,ECONLIT None Found,"['Rockinger, Michael', 'Abadir, Karim M.']",['Estimation: General'],['C13'],The 'Devil's Horns' Problem of Inverting Confluent Characteristic Functions,0,0,0,0,0,1997,09,01
65,5,1997-09-01,ECONLIT None Found,"['Fleurbaey, M.', 'Maniquet, F.']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],Implementability and Horizontal Equity Imply No-Envy,0,0,0,0,0,1997,09,01
65,5,1997-09-01,ECONLIT None Found,"['Lewbel, Arthur']","['Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models', 'Management of Technological Innovation and R&D', 'Intellectual Property and Intellectual Capital']","['C31', 'O32', 'O34']","Constructing Instruments for Regressions with Measurement Error When No Additional Data Are Available, with an Application to Patents and R&D",0,0,0,1,0,1997,09,01
65,5,1997-09-01,"Allowing for incomplete information, this paper characterizes the social choice functions that can be approximated by the equilibrium outcomes of a mechanism: incentive compatibility is necessary and almost sufficient for virtual Bayesian implementability. In conjunction with a second condition, Bayesian incentive consistency, incentive compatibility is also sufficient. This new condition is weak--under standard topological and informational assumptions it is satisfied by every social choice function. The type sets of the agents are taken to be arbitrary (possibly infinite) measurable spaces. An example shows that there are virtually (in fact, exactly) Bayesian implementable social choice functions that are not virtually implementable in iteratively undominated strategies.","['Duggan, John']","['Asymmetric and Private Information; Mechanism Design', 'Social Choice; Clubs; Committees; Associations']","['D82', 'D71']",Virtual Bayesian Implementation,0,0,0,0,0,1997,09,01
65,5,1997-09-01,"The authors consider a repeated game between two long-run players, one of whom is relatively patient. Each player has a small amount of uncertainty about the other's strategy. Given a weak assumption about the support of this uncertainty, the more patient player obtains (in any Nash equilibrium) approximately the highest payoff consistent with the individual rationality of the other player, if the latter is patient enough. If the less patient player is relatively impatient, any Nash equilibrium gives the more patient player at least the Stackelberg payoff: this generalizes K. M. Schmidt's (1993) result, which applies only to games of conflicting interests.","['Thomas, Jonathan P.', 'Evans, Robert']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Reputation and Experimentation in Repeated Games with Two Long-Run Players,0,0,0,0,0,1997,09,01
65,5,1997-09-01,"In this article, the authors show that a generalized version of H. J. Bierens' integrated conditional moment (ICM) test of functional form has nontrivial root-n local power, where n is the sample size, and that for a class of large local alternatives the consistent ICM test is more powerful than the parametric t test in a neighborhood of the parametric alternative involved. Moreover, they show that, under the assumption of normal errors, the ICM test is asymptotically admissible. Furthermore, since the null distribution of the ICM test is case dependent, the authors derive case-independent upperbounds of the critical values.","['Ploberger, Werner', 'Bierens, Herman J.']",['Hypothesis Testing: General'],['C12'],Asymptotic Theory of Integrated Conditional Moment Tests,0,0,0,0,0,1997,09,01
65,5,1997-09-01,This paper introduces a conditional Kolmogorov test of model specification for parametric models with covariates (regressors). The test is an extension of the Kolmogorov test of goodness-of-fit for distribution functions. The test is shown to have power against 1/[square root of n] local alternatives and all fixed alternatives to the null hypothesis. A parametric bootstrap procedure is used to obtain critical values for the test.,"['Andrews, Donald W. K.']",['Hypothesis Testing: General'],['C12'],A Conditional Kolmogorov Test,0,0,0,0,0,1997,09,01
65,5,1997-09-01,"Adaptively rational equilibrium is introduced, where agents adapt their beliefs by choosing from a finite set of predictor functions. Agents make a rational predictor choice, based upon a publically available performance measure such as realized past profits. This results in an adaptive belief system, where predictor choice is coupled to the market equilibrium dynamics. As a typical example, the cobweb model with rational versus naive expectations is analyzed. If the market is locally unstable and rational expectations are costly to obtain, a high intensity of choice for predictor selection leads to chaos and strange attractors.","['Brock, William A.', 'Hommes, Cars H.']","['Business Fluctuations; Cycles', 'Expectations; Speculations']","['E32', 'D84']",A Rational Route to Randomness,0,0,0,0,0,1997,09,01
65,5,1997-09-01,"The authors analyze two-candidate elections in which voters are uncertain about the realization of a state variable that affects the utility of all voters. They assume each voter has noisy private information about the state variable. The authors show that, in equilibrium, almost all voters ignore their private signal when voting. Nevertheless, elections fully aggregate information in the sense that the chosen candidate would not change if all private information were common knowledge.","['Feddersen, Timothy', 'Pesendorfer, Wolfgang']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Asymmetric and Private Information; Mechanism Design']","['D72', 'D82']",Voting Behavior and Information Aggregation in Elections with Private Information,0,0,0,0,0,1997,09,01
65,5,1997-09-01,"A model of social distance is presented that is useful for understanding social decisions. An example is constructed of class stability. Agents who are initially close interact strongly while those who are socially distant have little interaction. In this example, inherited social position, which may be interpreted as social class, plays a dominant role. The relevance of this model to social decisions, such as the choice of educational attainment and childbearing, is discussed in the context of specific ethnographic examples. Class position may play a dominant role in these decisions.","['Akerlof, George A.']",['Microeconomics: General'],['D00'],Social Distance and Social Decisions,0,0,0,0,0,1997,09,01
65,4,1997-07-01,ECONLIT None Found,"['Kajii, Atsushi']","['Exchange and Production Economies', 'Contingent Pricing; Futures Pricing; option pricing']","['D51', 'G13']",On the Role of Options in Sunspot Equilibria,0,0,0,0,0,1997,07,01
65,4,1997-07-01,A maximum likelihood estimator for models containing nuisance parameters is proposed. The estimator is shown to be asymptotically normal and attain the semiparametric efficiency bounds for a number of important econometric models. The idea is to find a parametric model that passes through the true model. The score for the parametric model is then estimated nonparametrically and the estimator is obtained by setting the estimated score to zero.,"['Ai, Chunrong']",['Semiparametric and Nonparametric Methods: General'],['C14'],A Semiparametric Maximum Likelihood Estimator,0,0,0,0,0,1997,07,01
65,4,1997-07-01,"To obtain consistency and asymptotic normality, a generalized method of moments (GAM) estimator typically is defined to be an approximate global minimizer of a GAM criterion function. To compute such an estimator, however, can be problematic because of the difficulty of global optimization. To alleviate this problem, the author proposes a stopping-rule (SR) procedure for computing GAM estimators. The SR procedure eliminates the need for global search with high probability. And, it provides an explicit SR for problems of stability that may arise with local optimization problems.","['Andrews, Donald W. K.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Computational Techniques; Simulation Modeling']","['C22', 'C63']",A Stopping Rule for the Computation of Generalized Method of Moments Estimators,0,0,0,0,0,1997,07,01
65,4,1997-07-01,"When applied to groups, the revelation principle postulates a Bayesian-Nash behavior between agents. Their binding agreements are unenforceable or the principal can prevent them at no cost. The authors analyze instead a mechanism design problem in which the agents can communicate between themselves and collude under asymmetric information. They characterize the set of implementable collusion-proof contracts both when the principal offers anonymous and nonanonymous contracts. After having isolated the nexi and the stakes of collusion, the authors proceed to normative analysis, do some comparative statics, discuss their concept of collusion-proofness, and provide some insights about transaction costs in side-contracting.","['Martimort, David', 'Laffont, Jean-Jacques']","['Asymmetric and Private Information; Mechanism Design', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['D82', 'D43']",Collusion under Asymmetric Information,0,0,1,0,0,1997,07,01
65,4,1997-07-01,"While optimally weighted generalized method of moments (GAM) estimation has desirable large sample properties, its small sample performance is poor in some applications. The authors propose a computationally simple alternative, for weakly dependent data generating mechanisms, based on minimization of the Kullback-Leibler information criterion. Conditions are derived under which the large sample properties of this estimator are similar to GAM, i.e., the estimator will be consistent and asymptotically normal, with the same asymptotic covariance matrix as GAM. In addition, the authors propose overidentifying and parametric restrictions tests as alternatives to analogous GAM procedures.","['Kitamura, Yuichi', 'Stutzer, Michael']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation']","['C22', 'C51']",An Information-Theoretic Alternative to Generalized Method of Moments Estimation,0,0,0,0,0,1997,07,01
65,4,1997-07-01,"Numerous experimental studies indicate that people tend to reciprocate favors and punish unfair behavior. It is hypothesized that these behavioral responses contribute to the enforcement of contracts and increase gains from trade. It turns out that, if only one side of the market has opportunities for reciprocal responses, the impact of reciprocity on contract enforcement depends on the details of the pecuniary incentive system. If both sides of the market have opportunities for reciprocal responses, robust and powerful reciprocity effects occur. In particular, reciprocal behavior causes a substantial increase in the set of enforceable actions and large efficiency gains.","['Kirchsteiger, Georg', 'Fehr, Ernst', 'Gachter, Simon']","['Labor Contracts', 'Transactional Relationships; Contracts and Reputation; Networks', 'Asymmetric and Private Information; Mechanism Design']","['J41', 'L14', 'D82']",Reciprocity as a Contract Enforcement Device: Experimental Evidence,1,0,0,0,0,1997,07,01
65,4,1997-07-01,"This paper provides an empirical analysis of how the U.S. Social Security and Medicare system affects the labor supply of older males in the presence of incomplete markets. The authors estimate a dynamic programming model of the joint labor supply and Social Security acceptance decision. The model is able to account for a wide variety of phenomena observed in the data, including the pronounced peaks in the distribution of retirement ages at sixty-two and sixty-five. Overall, the authors' model suggests that several puzzling aspects of retirement behavior can be viewed as artifacts of particular details of the Social Security rules.","['Rust, John', 'Phelan, Christopher']","['Retirement; Retirement Policies', 'Fiscal Policies and Behavior of Economic Agents: Household', 'Social Security and Public Pensions', 'Economics of the Elderly; Economics of the Handicapped; Non-labor Market Discrimination', 'Time Allocation and Labor Supply']","['J26', 'H31', 'H55', 'J14', 'J22']",How Social Security and Medicare Affect Retirement Behavior in a World of Incomplete Markets,0,0,0,0,0,1997,07,01
65,4,1997-07-01,"The act of choosing can have particular relevance in maximizing behavior for at least two distinct reasons: (1) process significance (preferences may be sensitive to the choice process, including the identity of the chooser) and (2) decisional inescapability (choices may have to be made whether or not the judgmental process has been completed). The general approach of maximizing behavior can--appropriately formulated--accommodate both concerns, but the regularities of choice behavior assumed in standard models of rational choice will need significant modification. These differences have considerable relevance in studies of economic, social, and political behavior.","['Sen, Amartya']","['Microeconomics: General', 'Economic Methodology']","['D00', 'B41']",Maximization and the Act of Choice,0,0,0,0,0,1997,07,01
65,3,1997-05-01,ECONLIT None Found,"['Zhou, Lin']",['Bargaining Theory; Matching Theory'],['C78'],The Nash Bargaining Theory with Non-convex Problems,0,0,0,0,0,1997,05,01
65,3,1997-05-01,ECONLIT None Found,"['Abadir, Karim M.', 'Paruolo, Paolo']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Two Mixed Normal Densities from Cointegration Analysis,0,0,0,0,0,1997,05,01
65,3,1997-05-01,"The author demonstrates that despite variables that are integrated, the fundamental issues on structural equation modeling raised by the Cowles Commission remain valid and standard estimation and testing procedures can still be applied. A basic framework linking the multiple time series model and the dynamic simultaneous equation model is provided and implications under the long-run cointegrating relations are discussed. Conditions for identifying both the short-run dynamics and long-run equilibrium conditions are given. Limiting properties of the least squares and simultaneous equation estimators under cointegration are derived. Implications for hypothesis testing are also discussed.","['Hsiao, Cheng']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Cointegration and Dynamic Simultaneous Equations Model,0,0,0,0,0,1997,05,01
65,3,1997-05-01,"Moment based tests for mispecification of parametric models (e.g., of mean equals variance in a Poisson model) are studied. The moment restrictions under test are embedded in an extension of the model so that the moment test is a score test of the hypothesis that a vector of added parameters is zero. Second-order asymptotic properties of the likelihood ratio version of this test are studied. Unlike the conventional test, the likelihood ratio version is Bartlett correctable. The correction depends on the curvature at the origin of the function used to incorporate the moment restriction in the extended model.","['Chesher, Andrew', 'Smith, Richard J.']",['Hypothesis Testing: General'],['C12'],Likelihood Ratio Specification Tests,0,0,0,0,0,1997,05,01
65,3,1997-05-01,"The literature on the aggregation of (S,s) policies has generally ignored the impact of aggregates on individual decisions. In the case of pricing, the feedback effects are clear. Not only do pricing strategies determine the evolution of the price level, the evolution of the price level influences pricing strategies. The authors provide a consistent treatment of aggregation and optimization and study three issues in the pricing literature: the relationship between strategic complementarity and the real effects of money; the relationship between the variance of money and the correlation between money and output; and the relationship between the cost and size of price adjustment.","['Caplin, Andrew', 'Leahy, John']","['Business Fluctuations; Cycles', 'Market Structure, Pricing, and Design: General', 'Price Level; Inflation; Deflation']","['E32', 'D40', 'E31']",Aggregation and Optimization with State-Dependent Pricing,0,0,1,0,0,1997,05,01
65,3,1997-05-01,"For conditional heteroskedasticity models, the authors study the identification condition that is required for consistency of a non-Gaussian quasi-maximum-likelihood estimator. They show that, if the conditional mean is zero or if a symmetry condition is satisfied, then the identification condition is satisfied. Without symmetry, an additional parameter, for the location of the innovation density, must be added for identification. For the conditional variance parameters of a GARCH process, there is no efficiency loss from adding the parameter under symmetry, when the parameter is not needed.","['Steigerwald, Douglas G.', 'Newey, Whitney K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Asymptotic Bias for Quasi-Maximum-Likelihood Estimators in Conditional Heteroskedasticity Models,0,0,0,0,0,1997,05,01
65,3,1997-05-01,"This paper develops asymptotic distribution theory for instrumental variables regression when the partial correlations between the instruments and the endogenous variables are weak, here modeled as local to zero. Asymptotic representation are provided for various statistics, including two-stage least squares and limited information maximum likelihood estimators, Wald statistics, and statistics testing overidentification and endogeneity. The asymptotic distributions provide good approximations to sampling distributions with ten-twenty observations per instrument. The theory suggests concrete guidelines for applied work, including using nonstandard methods for construction of confidence regions. These results are used to interpret J. D. Angrist and A. B. Krueger's (1991) estimates of the returns to education.","['Staiger, Douglas', 'Stock, James H.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Instrumental Variables Regression with Weak Instruments,0,0,0,0,0,1997,05,01
65,3,1997-05-01,"This paper reports a strategy study on a twenty-period supergame of a numerically specified asymmetric Cournot duopoly. The subjects were twenty-three participants of a student seminar. Three rounds of game playing were followed by three rounds of strategy programming with computer tournaments. The final strategies show a typical approach to the strategic problem: subjects first select an 'ideal point,' a cooperative goal based on fairness criteria, and then design a 'measure for measure policy' that reciprocates movements to the ideal point or away from it; no quantitative expectations are formed and nothing is optimized. Typicalness is positively correlated with success.","['Selten, Reinhard', 'Uhlich, Gerald R.', 'Mitzkewitz, Michael']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Noncooperative Games']","['D43', 'C72']",Duopoly Strategies Programmed by Experienced Players,0,0,1,0,0,1997,05,01
65,3,1997-05-01,This paper introduces random versions of successive approximations and multigrid algorithms for computing approximate solutions to a class of finite and infinite horizon Markovian decision problems. The author proves that these algorithms succeed in breaking the 'curse of dimensionality' for a subclass of Markovian decision problems known as discrete decision processes.,"['Rust, John']","['Computational Techniques; Simulation Modeling', 'Index Numbers and Aggregation; Leading indicators', 'Optimization Techniques; Programming Models; Dynamic Analysis']","['C63', 'C43', 'C61']",Using Randomization to Break the Curse of Dimensionality,0,0,0,0,0,1997,05,01
65,2,1997-03-01,ECONLIT None Found,"['Vega-Redondo, Fernando']","['Market Structure, Pricing, and Design: Perfect Competition', 'Exchange and Production Economies', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['D41', 'D51', 'C73']",The Evolution of Walrasian Behavior,0,0,1,0,0,1997,03,01
65,2,1997-03-01,ECONLIT None Found,"['Battigalli, Pierpaolo', 'Watson, Joel C.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'C72', 'D82']",On 'Reputation' Refinements with Heterogeneous Beliefs,0,0,0,0,0,1997,03,01
65,2,1997-03-01,"This paper develops a general framework for modeling choice under uncertainty that extends subjective expected utility to include nonseparabilities, state-dependence, and the effect of subjective or ill defined consequences. This is accomplished by not including consequences among the formal primitives. Instead, the effect of consequences is modeled indirectly, through conditional preferences over acts. The main results concern the aggregation of conditional utilities to form an unconditional utility, including the case of additive aggregation. Applications, obtained by further specifying the structure of acts and conditional preferences, include disappointment, regret, and the subjective value of information.","['Skiadas, Costis']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Conditioning and Aggregation of Preferences,0,0,0,0,0,1997,03,01
65,2,1997-03-01,"This paper reports a laboratory experiment that examines price formation in the single call market. The experiment design is intended to enhance the predictive power of the Bayesian Nash equilibrium (BNE) theory for this trading institution. The data support several qualitative implications of the BNE, especially when subjects compete against Nash 'robot' opponents, but subjects' behavior is not as responsive to changes in the pricing rule as the BNE predictions. Offers tend to reveal more of the underlying values and costs than predicted, particularly when subjects are experienced. A simple learning model accounts for several of the deviations from BNE.","['Cason, Timothy N.', 'Friedman, Daniel']","['Auctions', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['D44', nan]",Price Formation in Single Call Markets,0,0,1,0,0,1997,03,01
65,2,1997-03-01,"This paper shows that, in many infinitely repeated games, if players optimize with respect to beliefs that satisfy a diversity condition termed neutrality, then each player will choose a strategy that his opponent was certain would not be played. This is an obstacle to formulation of a learning theory in which Nash equilibrium behavior is a necessary long-run consequence of optimization by cautious players.","['Nachbar, John H.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'C72', 'D83']","Prediction, Optimization, and Learning in Repeated Games",0,0,0,0,0,1997,03,01
65,2,1997-03-01,"The authors examine core convergence for economies with a large finite number of agents and an infinite number of commodities. They find a serious disconnection between economies with a large finite number of agents and economies with a continuum of agents: the authors provide examples of nonconvergence of the core for large finite economies in L[superscript 1], a commodity space for which core equivalence holds for continuum economies. In addition, they show that, if preferences exhibit uniformly vanishing marginal utility of consumption at infinity, core convergence is restored.","['Zame, William R.', 'Anderson, Robert M.']","['Exchange and Production Economies', 'Market Structure, Pricing, and Design: Perfect Competition']","['D51', 'D41']",Edgeworth's Conjecture with Infinitely Many Commodities: L[supscript 1],0,0,1,0,0,1997,03,01
65,1,1997-01-01,ECONLIT None Found,"['Chaudhuri, Shubham', 'Ravallion, Martin']","['Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Microeconomic Analyses of Economic Development']","['O15', 'D12', 'D81', 'O12']",Risk and Insurance in Village India: Comment,0,0,0,0,0,1997,01,01
65,1,1997-01-01,ECONLIT None Found,"['Winter, Eyal', 'Seidmann, Daniel J.']",['Noncooperative Games'],['C72'],Strategic Information Transmission with Verifiable Messages,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"The authors consider a family of rank tests based on the regression rank score process introduced by C. Gutenbrunner and J. Jureckova (1992) to test the unit root hypothesis in economic time series. In contrast to tests based on least-squares methods, the rank tests are asymptotically Gaussian under the null hypothesis, and have excellent power--particularly under innovation exhibiting heavy tails. These regression rank scores arise as a vector of solutions of the dual form of the linear program required to compute the regression quantile statistics of R. W. Koenker and G. Bassett (1978). For location model, they are simple ranks of the sample observations.","['Koenker, R. W.', 'Hasan, M. N.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Robust Rank Tests of the Unit Root Hypothesis,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"This paper considers the problem of determining the number of factors in a multivariate nonparametric relationship. The definition of factors given is broad enough to encompass a number of potential applications in econometrics, including inferring the rank of demand, consistent tests for lack of identification in linear instrumental variable models, and testing arbitrage pricing theory. The paper gives both series and kernel methods for testing hypotheses concerning, and consistent estimation of, the number of factors. The methods are compared in a small simulation study and in an application to determining the rank of demand systems.","['Donald, Stephen G.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Construction and Estimation']","['C30', 'C51']",Inference Concerning the Number of Factors in a Multivariate Nonparametric Relationship,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"This paper extends the Kiyotaki-Wright model of fiat money to allow for divisible money and goods. By severing the artificial link in the Kiyotaki-Wright model between the money supply and the number of money holders, the author shows that money is neutral but not superneutral. Money growth changes the composition of agents in the market and can increase agents' probability of having a successful match. This trading opportunity effect of money growth can dominate its conventional negative effect on real money balances and so can imply a positive optimal money growth rate.","['Shi, Shouyong']",['Money and Interest Rates: General'],['E40'],A Divisible Search Model of Fiat Money,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"This paper proposes a Bayesian approach to a vector autoregression with stochastic volatility, where the multiplicative evolution of the precision matrix is driven by a multivariate beta variate. Exact updating formulas are given to the nonlinear filtering of the precision matrix. Estimation of the autoregressive parameters requires numerical methods: an importance-sampling-based approach is explained here.","['Uhlig, Harald']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Bayesian Vector Autoregressions with Stochastic Volatility,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"This paper provides a fairly systematic study of rational asset pricing bubbles in an intertemporal competitive equilibrium framework that allows for incomplete markets, productive assets, borrowing limits, and incomplete participation of agents in markets. The main results are concerned with nonexistence of asset pricing bubbles. These results imply that the conditions under which bubbles are possible--including some well-known examples of monetary equilibria--are relatively fragile.","['Santos, Manuel S.', 'Woodford, Michael']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Rational Asset Pricing Bubbles,0,0,0,0,0,1997,01,01
65,1,1997-01-01,"There are several solutions to the Nash bargaining problem in the literature. Since various authors have expressed preferences for one solution over another, the authors find it useful to study preferences over solutions in their own right. They identify a set of appealing axioms on such preferences that lead to unanimity in the choice of solution, which turns out to be the solution of Nash. The key axiom is mixture symmetry, implying that if two solutions are equally attractive, then the half-half mixture of them is (weakly) preferred to any other mixture of the two.","['Border, Kim C.', 'Segal, Uzi']",['Bargaining Theory; Matching Theory'],['C78'],Preferences over Solutions to the Bargaining Problem,0,0,0,0,0,1997,01,01
82,2,2014-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,03,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2014,01,01
82,1,2014-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2014,01,01
64,6,1996-11-01,"This paper examines how proportional transaction costs, short-sale constraints, and margin requirements affect inferences based on asset return data about intertemporal marganil rates of substitution (IMRSs). Small transaction costs greatly reduce the required variability of IMRSs, suggesting that the low variability of many parametric, aggregate consumption based IMRSs need not be inconsistent with asset return data. Euler inequalities for a transaction cost economy with power utility are tested using aggregate consumption data and returns on stocks and U.S. Treasury bills. In the majority of cases, there is little evidence against power utility specifications with a low risk-aversion parameter.","['Luttmer, Erzo G. J.']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Asset Pricing in Economies with Frictions,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"The authors introduce and analyze 'multistage situations,' which generalize 'multistage games' (which, in turn, generalize 'repeated games'). One reason for this generalization is to avoid the perhaps unrealistic constraints--inherent to noncooperative games--that the set of strategy tuples must be a Cartesian product of the strategy sets of the players. Another reason is that, in most economic and social activities (e.g., in sequential bargaining without a rigid protocol), the 'rules of the game' are rather amorphous; the procedures are rarely pinned down. Such social environments can, however, be represented as multistage situations and be effectively analyzed through the theory of social situations.","['Shitovitz, Benyamin', 'Monderer, Dov', 'Greenberg, Joseph']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games']","['C73', 'C72']",Multistage Situations,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"The authors show in this paper that renegotiable short-term contracts can be as efficient as long-term renegotiation-proof contracts even in situations of asymmetric information. They do so by extending their earlier results on symmetric information models. Some limited commitment thus seems to be a necessary and sufficient condition to achieve long-run efficiency. The authors moreover show that, due to ratchet effects and time inconsistencies in the structure of informational rents, spot contracts are much less efficient under asymmetric information, even is there is no need for intertemporal smoothing.","['Salanie, Bernard', 'Rey, Patrick']",['Asymmetric and Private Information; Mechanism Design'],['D82'],On the Value of Commitment with Asymmetric Information,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"This paper presents a new, probabilistic model of learning in games. The model is set in the usual repeated game framework but the two key assumptions are framed in terms of the likelihood of beliefs and actions conditional on the history of play. The first assumption formalizes the basic intuition of the learning approach; the second, the indeterminacy that inspired resort to learning models in the first place. Together the assumptions imply that, almost surely, play will remain almost always within one of the stage game's 'minimal inclusive sets.' In important classes of games, all such sets are singleton Nash.","['Sanchirico, Chris William']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'D83', 'C73']",A Probabilistic Model of Learning in Games,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"This paper constructs a space of states of the world representing the exhaustive uncertainty facing each player in a strategic situation. The innovation is that preferences are restricted primarily by 'regularity' conditions and need not conform with subjective expected utility theory. The construction employs a hierarchy of preferences, rather than of beliefs as in the standard Bayesian model. Applications include the provision of foundations for a Harsanyi-style game of incomplete information and a rich framework for the axiomatization of solution concepts for complete information normal form games.","['Wang, Tan', 'Epstein, Larry G.']","['Criteria for Decision-Making under Risk and Uncertainty', 'Game Theory and Bargaining Theory: General']","['D81', 'C70']",'Beliefs about Beliefs' without Probabilities,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"This paper extends the spatial theory of voting to the case in which policy choices depend upon the interaction between executive and the legislature. Voters are strategic and to analyze equilibrium the authors apply 'coalition proof' type refinements. The model has implications consistent with voting behavior in the United States: (1) split-ticket with some voters choosing one party for the presidency and the other for Congress; (2) for some parameter values, a divided government with different parties controlling the executive and the majority of the legislature; and (3) the mid-term electoral cycle with the party holding the presidency always losing votes in mid-term legislative elections.","['Rosenthal, Howard', 'Alesina, Alberto']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']",['D72'],A Theory of Divided Government,0,0,0,0,0,1996,11,01
64,6,1996-11-01,"In a Bayesian model of learning, the more an agent uses a technology, the better he learns its parameters. This expertise is a form of human capital. Switching to a new technology temporarily reduces expertise: the bigger the leap, the bigger the loss. This may prevent the agent from climbing the technological ladder too fast. Someone skilled may want to stick to his technology and experience no growth in the long run. But someone less skilled may want to switch technologies over and over again and, therefore, enjoy long-run growth in output. Thus, the model can give rise to overtaking.","['Nyarko, Yaw', 'Jovanovic, Boyan']","['Technological Change: Choices and Consequences; Diffusion Processes', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['O33', 'D83']",Learning by Doing and the Choice of Technology,0,0,0,1,0,1996,11,01
64,6,1996-11-01,"Technological change and deregulation have caused a major restructuring telecommunications equipment industry over the last two decades. Our empirical focus is on estimating the parameters of a production function for the equipment industry, and then using those estimates to analyze the evolution of plant-level productivity. The restructuring involved significant entry and exit and large changes in the sizes of incumbents. This generates a selection and a simultaneity problem when estimating production functions. Our theoretical focus is on providing an estimation algorithm which takes explicit account of these issues. We find that our algorithm produces markedly different estimates of production function coefficients than do traditional estimation procedures, and that the productivity increases that followed deregulation were primarily a result of a reallocation of capital towards more productive establishments.","['Olley, G. Steven', 'Pakes, Ariel']","['Microelectronics; Computers; Communications Equipment', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity']","['L63', 'D24']",The Dynamics of Productivity in the Telecommunications Equipment Industry,1,0,0,0,0,1996,11,01
64,6,1996-11-01,"The authors present a finite system of polynomial inequalities in unobservable variables and market data that observations on market prices, individual incomes and, aggregate endowments must satisfy to be consistent with the equilibrium behavior of some pure trade economy. Quantifier elimination is used to derive testable restrictions on finite data sets for the pure trade model. A characterization of observations on aggregate endowments and market prices that are consistent with a Robinson Crusoe's economy is also provided.","['Matzkin, Rosa L.', 'Brown, Donald J.']","['Exchange and Production Economies', 'Existence and Stability Conditions of Equilibrium']","['D51', 'C62']",Testable Restrictions on the Equilibrium Manifold,0,0,0,0,0,1996,11,01
64,5,1996-09-01,ECONLIT None Found,"['Marriott, Paul', 'Salmon, Mark', 'Critchley, Frank']",['Hypothesis Testing: General'],['C12'],On the Differential Geometry of the Wald Test with Nonlinear Restrictions,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"Different concepts of noncausality for continuous time processes, using conditional independence and decomposition of semimartingales, are defined. As in the discrete-time setup, continuous time noncausality is a property concerned with the prediction horizon (global versus instantaneous noncausality) and the nature of the prediction (strong versus weak noncausality). Relations between the resulting continuous time noncausality concepts are then studied for the class of decomposable semimartingales for which, in general, the weak instantaneous noncausality does not imply the strong global noncausality. The paper then characterizes these different concepts in the case of counting processes and Markov processes.","['Florens, Jean-Pierre', 'Fougere, Denis']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Noncausality in Continuous Time,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"A class of tests for first, second, and third order stochastic dominance, together with modifications to the Pearson goodness of fit test are proposed for the nonparametric comparison of income distributions. They are implemented and compared with tests for generalised Lorenz dominance (which is the indirect test of second order stochastic dominance currently employed in income distribution studies) utilizing Canadian family income data.","['Anderson, Gordon']","['Personal Income, Wealth, and Their Distributions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Model Evaluation, Validation, and Selection', 'Measurement and Analysis of Poverty']","['D31', 'D63', 'C52', 'I32']",Nonparametric Tests of Stochastic Dominance in Income Distributions,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"The authors propose a method to test for liquidity constraints that relies on using the within period marginal rate of substitution condition as a benchmark to evaluate the intertemporal Euler equation. If spot markets for nondurable goods exist but financial markets are imperfect, the comparison of first-order conditions involving the relevant spot and intertemporal prices can be used to detect the imperfection. The authors apply their methodology to a large sample of U.S. households, allowing for a general nonseparable preference structure. Their estimates do not indicate the presence of liquidity constraints, with the possible exception of young households.","['Meghir, Costas', 'Weber, Guglielmo']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Consumer Economics: Empirical Analysis']","['D15', 'D12']",Intertemporal Nonseparability or Borrowing Restrictions? A Disaggregate Analysis Using a U.S. Consumption Panel,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"The authors consider a single consumer buying a stream of goods from different sellers over time. The true value of each seller's product is initially unknown. Additional information is obtained by experimentation. For exogenous prices, this is a multiarmed bandit problem. The innovation here is to endogenize the cost of experimentation by allowing for price competition between the sellers. Prices determine the intertemporal costs and benefits of learning for buyer and sellers. All Markov perfect equilibria are efficient. Prices below marginal cost sustain experimentation. Intertemporal exchange of the gains of learning is necessary to support efficient experimentation.","['Bergemann, Dirk', 'Valimaki, Juuso']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Learning and Strategic Pricing,0,0,0,0,0,1996,09,01
64,5,1996-09-01,ECONLIT None Found,"['Gollier, Christian', 'Pratt, John W.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Risk Vulnerability and the Tempering Effect of Background Risk,0,0,0,0,0,1996,09,01
64,5,1996-09-01,This paper presents optimal tests for parameter instability in the generalized method of moments (GMM) framework. The new tests include tests that are optimal for both one-sided and two-sided alternatives. One of the optimal tests for two-sided alternatives is the GMM generalization of the test presented in Andrews and Ploberger (1994) for the likelihood framework. The new tests include a class of optimal tests that direct the test's power to specific locations in the sample. One of these optimal tests has the attractive feature of a normal distribution under the null hypothesis.,"['Sowell, Fallaw']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Optimal Tests for Parameter Instability in the Generalized Method of Moments Framework,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"This paper develops procedures for inference about the moments of smooth functions of out-of-sample predictions and prediction errors when there is a long time series of predictions and realizations. The aim is to provide tools for analysis of predictive accuracy and efficiency and, more generally, of predictive ability. The paper allows for nonnested and nonlinear models as well as for possible dependence of predictions and prediction errors on estimated regression parameters. Simulations indicate that the procedures can work well in samples of size typically available.","['West, Kenneth D.']",['Forecasting Models; Simulation Methods'],['C53'],Asymptotic Inference about Predictive Ability,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"Contemporary tests for structural change are designed to detect a structural break within a given historical data set of fixed size. Due to the law of the iterated logarithm, these one-shot tests cannot be applied to monitor out-of-sample stability each time new data arrive. The authors propose and analyze two real-time monitoring procedures with controlled size asymptotically: the fluctuation and CUSUM monitoring procedures. Simulation results show that the proposed monitoring procedures indeed have controlled asymptotic size and that detection timing depends on the magnitude of parameter change, the signal to noise ratio, and the location of the out-of-sample break point.","['White, Halbert', 'Stinchcombe, Maxwell', 'Chu, Chia-Shang James']","['Model Evaluation, Validation, and Selection', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C52', 'C22']",Monitoring Structural Change,0,0,0,0,0,1996,09,01
64,5,1996-09-01,"This paper provides evidence that the decline in the real value of the minimum wage and in the rate of unionization account for a significant share of the increase in wage inequality in the United States between 1979 and 1988. The role of the minimum wage is particularly important for women, while deunionization has the largest impact on men. The authors develop a semiparametric procedure that applies kernel density methods to appropriately weighted samples. The procedure provides a visually clear representation of where in the density of wages institutional and labor market forces exert the greatest impact.","['DiNardo, John', 'Fortin, Nicole M.', 'Lemieux, Thomas']",['Wage Level and Structure; Wage Differentials'],['J31'],"Labor Market Institutions and the Distribution of Wages, 1973-1992: A Semiparametric Approach",0,0,0,0,0,1996,09,01
64,4,1996-07-01,ECONLIT None Found,"['Kimball, Miles S.', 'Carroll, Christopher D.']",['Consumer Economics: Theory'],['D11'],On the Concavity of the Consumption Function,0,0,0,0,0,1996,07,01
64,4,1996-07-01,This paper studies the effects of unions on the structure of wages using an estimation technique that accounts for misclassification errors in reported union status and potential correlations between union status and unobserved productivity. The model is estimated separately for five skill groups using a panel data set formed from the U.S. Current Population Survey. The results suggest that unions raise wages more for workers with lower levels of observed skills. Union workers are positively selected from the population of workers with lower levels of observed skill and negatively selected from the population with higher observed skills.,"['Card, David']","['Trade Unions: Objectives, Structure, and Effects', 'Wage Level and Structure; Wage Differentials']","['J51', 'J31']",The Effect of Unions on the Structure of Wages: A Longitudinal Analysis,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"Recent evolutionary models have introduced 'small mutation rates' as a way of refining predictions of long-run behavior. The authors show that this refinement effect can only be obtained by restrictions on how the magnitude of the effect of mutation on evolution varies across states of the system. In particular, given any model of the effect of mutations, any invariant distribution of the 'mutationless' process is close to an invariant distribution of the process with appropriately chosen small mutation rates.","['Bergin, James', 'Lipman, Barton L.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games']","['C73', 'C72']",Evolution with State-Dependent Mutations,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"Well-behaved infinite signaling games may have no sequential equilibria. The author proves that adding cheap talk to these games 'solves' the nonexistence problem: the limit of sequential equilibrium outcomes of finite approximating games is a sequential equilibrium outcome of the cheap-talk extension of the limit game. In addition, when the signaling space has no isolated points, any cheap-talk sequential equilibrium outcome can be approximated by a sequential [epsilon]-equilibrium of the game without cheap talk.","['Manelli, Alejandro M.']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design']","['C72', 'D82']",Cheap Talk and Sequential Equilibria in Signaling Games,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"Tests based on generalized-method-of-moments estimators often have true levels that differ greatly from their nominal levels when asymptotic critical values are used. This paper gives conditions under which the bootstrap provides asymptotic refinements to the critical values of t tests and the test of overidentifying restrictions. Particular attention is given to the case of dependent data. It is shown that, with such data, the bootstrap must sample blocks of data and that the formulae for the bootstrap versions of the test statistics differ from the formulae that apply with the original data.","['Horowitz, Joel L.', 'Hall, Peter']",['Single Equation Models; Single Variables: General'],['C20'],Bootstrap Critical Values for Tests Based on Generalized-Method-of-Moments Estimators,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"By using nonparametric kernel estimation method and a central limit theorem for degenerate U-statistics of order higher than two, the authors develop several consistent model specification tests in the context of a nonparametric regression model. These include tests for omitted variables, tests for a partially linear model, and tests for a semiparametric single index model. The asymptotic normality of the test statistics are established under the respective null hypotheses and consistent estimators of the asymptotic variances are provided.","['Fan, Yanqin', 'Li, Qi']","['Model Construction and Estimation', 'Single Equation Models; Single Variables: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions', 'Semiparametric and Nonparametric Methods: General']","['C51', 'C21', 'C14']",Consistent Model Specification Tests: Omitted Variables and Semiparametric Functional Forms,0,0,0,0,0,1996,07,01
64,4,1996-07-01,This paper proposes three classes of consistent tests for serial correlation of the residuals from a linear dynamic regression model. The tests are obtained by comparing a kernel-based spectral density estimator and the null spectral density using three divergence measures. The null normal distributions are invariant whether the regressors include lagged dependent variables. Both asymptotic local and global power properties are investigated. G. Box and D. Pierce's (1970) test can be viewed as a test based on the truncated kernel; many other kernels deliver better power than Box and Pierce's test. A simulation study shows that the new tests have good power against weak and strong dependence.,"['Hong, Yongmiao']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Consistent Testing for Serial Correlation of Unknown Form,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"The asymptotic power envelope is derived for point-optimal tests of a unit root in the autoregressive representation of a Gaussian time series. The authors propose a family of tests whose asymptotic power functions are tangent to the power envelope at one point and are never far below. When the series has an unknown mean or linear trend, commonly used tests are found to be dominated by members of the family of point-optimal invariant tests. The authors propose a modified version of the Dickey-Fuller t test which has desirable size properties and substantially improved power when an unknown mean or trend is present.","['Elliott, Graham', 'Stock, James H.', 'Rothenberg, Thomas J.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Evaluation, Validation, and Selection']","['C22', 'C52']",Efficient Tests for an Autoregressive Unit Root,0,0,0,0,0,1996,07,01
64,4,1996-07-01,"This paper is concerned with model determination methods and their use in the prediction of economic time series. The methods are Bayesian but they can be justified by classical arguments as well. The paper continues some recent work on Bayesian asymptotic, develops embedding techniques for vector martingales, and implements the modeling ideas in a multivariate regression framework that includes Bayesian vector autoregression (BVAR's) and reduced rank regressions (RRR's). It is shown how the theory in the paper can be used; (i) to construct optimized BVAR's; (ii) to compare models such as BVAR's, optimized BVAR's and RRR's; (iii) to perform joint order selection of cointegrating rank, lag length and trend degree in a VAR; and (iv) to discard data that may be irrelevant and reset the initial conditions of a model.","['Phillips, Peter C. B.']","['Model Construction and Estimation', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C51', 'C32']",Econometric Model Determination,0,0,0,0,0,1996,07,01
64,3,1996-05-01,ECONLIT None Found,"['Gallant, A. Ronald', 'Fenton, Victor M.']",['Estimation: General'],['C13'],Convergence Rates of SNP Density Estimators,0,0,0,0,0,1996,05,01
64,3,1996-05-01,ECONLIT None Found,"['Andrews, Donald W. K.']",['Hypothesis Testing: General'],['C12'],Admissibility of the Likelihood Ratio Test When the Parameter Space Is Restricted under the Alternative,0,0,0,0,0,1996,05,01
64,3,1996-05-01,ECONLIT None Found,"['Celentani, Marco']","['Noncooperative Games', 'Asymmetric and Private Information; Mechanism Design']","['C72', 'D82']",Maintaining a Reputation against a Long-Lived Opponent,0,0,0,0,0,1996,05,01
64,3,1996-05-01,ECONLIT None Found,"['Eeckhoudt, Louis', 'Schlesinger, Harris', 'Gollier, Christian']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Changes in Background Risk and Risk-Taking Behavior,0,0,0,0,0,1996,05,01
64,3,1996-05-01,"In most states, unemployment insurance recipients accepting part-time work can earn up to a specific amount (the 'disregard') with no reduction in benefits. For earnings above the disregard, benefits are reduced dollar for dollar. This paper analyzes the effects of changes in the disregard on job search behavior. Using data from the Current Population Survey's Displaced Worker Supplements and a competing risks model with correlated risks and time-varying coefficients, an increase in the disregard is found to significantly increase the conditional probability of part-time reemployment during the first three months of joblessness.","['McCall, Brian P.']","['Unemployment Insurance; Severance Pay; Plant Closings', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J65', 'J64']","Unemployment Insurance Rules, Joblessness, and Part-Time Work",0,0,0,0,0,1996,05,01
64,3,1996-05-01,"The authors study collective choice of fiscal policy in 'federations.' Local policy redistributes across individuals and affects the probability of local shocks. Federal policy shares international risk but may induce local governments to enact policies that increase local risk. The resulting trade-off between risk-sharing and moral hazard is different under alternative fiscal constitutions because the constitutions create different incentives for policymakers and voters and give rise to different political equilibria. The authors specifically contrast vertically ordered systems, like the European Community, with horizontally ordered systems, like the United States. Under appropriate institutions, centralization of functions and power can mitigate the moral hazard problem.","['Tabellini, Guido', 'Persson, Torsten']","['Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior', 'Policy Objectives; Policy Designs and Consistency; Policy Coordination', 'Structure, Scope, and Performance of Government']","['D72', 'E61', 'H11']",Federal Fiscal Constitutions: Risk Sharing and Moral Hazard,0,0,0,0,0,1996,05,01
64,3,1996-05-01,"This paper proposes some tests for parameter constancy in linear regressions. The tests use weighted empirical distribution functions of estimated residuals and are asymptotically distribution free. The proposed tests have nontrivial local power against a wide range of alternatives. In particular, the tests are capable of detecting error heterogeneity that is not necessarily manifested in the form of changing variances. The model allows for both dynamic and trending regressors. As an intermediate result, some weak convergence for (stochastically) weighted sequential empirical processes is established.","['Bai, Jushan']",['Single Equation Models; Single Variables: General'],['C20'],Testing for Parameter Constancy in Linear Regressions: An Empirical Distribution Function Approach,0,0,0,0,0,1996,05,01
64,3,1996-05-01,"This paper provides a proof of the consistency and asymptotic normality of the quasi-maximum likelihood estimator in GARCH(1,1) and IGARCH(1,1) models. In contrast to the case of a unit root in the conditional mean, the presence of a 'unit root' in the conditional variance does not affect the limiting distribution of the estimators; in both models, estimators are normally distributed. In addition, a consistent estimator of the covariance matrix is available, enabling the use of standard test statistics for inference.","['Lumsdaine, Robin L.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],"Consistency and Asymptotic Normality of the Quasi-maximum Likelihood Estimator in IGARCH(1,1) and Covariance Stationary GARCH(1,1) Models",0,0,0,0,0,1996,05,01
64,3,1996-05-01,"Suppose an observed time series is generated by a stochastic volatility model. As shown by D. B. Nelson (1992) and D. B. Nelson and D. P. Foster (1994), a misspecified ARCH model will often be able to consistently (as a continuous time limit is approached) estimate the unobserved volatility process using information in the lagged residuals. This paper shows how to more efficiently estimate such a volatility process using information in both lagged and led residuals. In particular, this paper expands the optimal filtering results of Nelson and Foster (1994) and Nelson (1994) to smoothing and to filtering with a random initial condition.","['Nelson, Daniel B.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Asymptotically Optimal Smoothing with ARCH Models,0,0,0,0,0,1996,05,01
64,3,1996-05-01,"The author proposes a nonparametric estimation procedure for continuous-time stochastic models. Because prices of derivative securities depend crucially on the form of the instantaneous volatility of the underlying process, he leaves the volatility function unrestricted and estimates it nonparametrically. Only discrete data are used but the estimation procedure still does not rely on replacing the continuous-time model by some discrete approximation. Instead, the drift and volatility functions are forced to match the densities of the process. The author estimates the stochastic differential equation followed by the short-term interest rate and computes nonparametric prices for bonds and bond options.","['Ait-Sahalia, Yacine']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Model Construction and Estimation']","[nan, 'C51']",Nonparametric Pricing of Interest Rate Derivative Securities,0,0,0,0,0,1996,05,01
81,6,2013-11-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2013,11,01
81,5,2013-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2013,09,01
81,4,2013-07-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2013,07,01
78,3,2010-05-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2010,05,01
64,2,1996-03-01,ECONLIT None Found,"['Stegeman, Mark', 'Rhode, Paul']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']","Learning, Mutation, and Long-Run Equilibria in Games: A Comment",0,0,0,0,0,1996,03,01
64,2,1996-03-01,ECONLIT None Found,"['Goto, Fumihiro']",['Duration Analysis; Optimal Timing Strategies'],['C41'],Achieving Semiparametric Efficiency Bounds in Left-Censored Duration Models,0,0,0,0,0,1996,03,01
64,2,1996-03-01,ECONLIT None Found,"['Mundlak, Yair']","['Model Construction and Estimation', 'Production; Cost; Capital; Capital, Total Factor, and Multifactor Productivity; Capacity']","['C51', 'D24']",Production Function Estimation: Reviving the Primal,0,0,0,0,0,1996,03,01
64,2,1996-03-01,"The authors study the asymptotic distribution of econometric tests involving nuisance parameters that are not identified under the null hypotheses. In general, the asymptotic distributions depend upon a large number of unknown parameters. The authors show that a transformation based upon a conditional probability measure yields an asymptotic distribution free of nuisance parameters and they show that this transformation can be easily approximated via simulation. The theory is applied to threshold models. Monte Carlo methods are used to assess the finite sample distributions. The authors' tests show that S. M. Potter's (1995) finding of a threshold effect in U.S. GNP growth rates can be possibly explained by sampling variation.","['Hansen, Bruce E.']","['Single Equation Models; Single Variables: General', 'Macroeconomics: Production']","['C20', 'E23']",Inference When a Nuisance Parameter Is Not Identified under the Null Hypothesis,0,0,0,0,0,1996,03,01
64,2,1996-03-01,"A limiting representation of the Bayesian data density is obtained and shown to be the same general exponential form for a wide class of likelihoods and prior distributions. An embedding theorem is given which shows how to embed the exponential density in a continuous time process. From the embedding, the authors obtain a large sample approximation to the model of the data that corresponds to the exponential density. This has the form of discrete observations drawn from a nonlinear stochastic differential equation driven by Brownian motion. No assumptions concerning stationarity or rates of convergence are required in the asymptotics. Some implications for statistical testing are explored.","['Phillips, Peter C. B.', 'Ploberger, Werner']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Bayesian Analysis: General']","['C22', 'C11']",An Asymptotic Theory of Bayesian Inference for Time Series,0,0,0,0,0,1996,03,01
64,2,1996-03-01,"The authors present and analyze a model of noncooperative bargaining among n participants, applied to situations describable as games in coalitional form. This leads to a unified solution theory for such games that have as special cases the Shapley value in the transferable utility case, the Nash bargaining solution in the pure bargaining case, and the recently introduced Maschler-Owen consistent value in the general nontransferable utility case. Moreover, the authors show that any variation (in a certain class) of their bargaining procedure which generates the Shapley value in the transferable utility setup must yield the consistent value in the general nontransferable utility setup.","['Hart, Sergiu', 'Mas-Colell, Andreu']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining and Value,0,0,0,0,0,1996,03,01
64,2,1996-03-01,The aim of this paper is to explain the fact that certain properties of binary relations are frequently observed in natural language while others do not appear at all. Three features of binary relation are studied: (1) The ability to use the relation to indicate nameless elements. (2) The accuracy with which the vocabulary spanned by the relation can be used to approximate the actual terms to which a user of the language wishes to refer. (3) The ease with which the relation can be described by means of examples. It is argued that linear orderings are optimal according to the first criteria while asymmetric relations are optimal according to second. From among complete and asymmetric relations (tournaments) those which are transitive are optimal according to the third criterion.,"['Rubinstein, Ariel']",['Mathematical Methods; Programming Models; Mathematical and Simulation Modeling: General'],['C60'],Why Are Certain Properties of Binary Relations Relatively More Common in Natural Language?,0,0,0,0,0,1996,03,01
64,2,1996-03-01,"This paper examines how, in the presence of individual risk, economic efficiency can be achieved without an unrealistically large number of contingent markets. The authors show that consistency of beliefs and optimality of allocation can be guaranteed with an appropriate array of Arrow securities to spread collective risk and Malinvaud mutual insurance policies to pool individual risk. If there are N households (consisting of H types), each facing the possibility of being in S individual states together with T collective states, then ensuring Pareto optimality requires only H(S - 1)T independent mutual insurance policies plus T pure Arrow securities.","['Wu, Ho-Mou', 'Cass, David', 'Chichilnisky, Graciela']","['Exchange and Production Economies', 'Criteria for Decision-Making under Risk and Uncertainty']","['D51', 'D81']",Individual Risk and Mutual Insurance,0,0,0,0,0,1996,03,01
64,2,1996-03-01,"This paper examines the effect of cash transfers and food stamp benefits on welfare participation and the labor supply of husbands and wives in two-parent families. The estimates are used to determine the magnitude of the work disincentive effects of the Aid to Families with Dependent Children Unemployed Parent (AFDC-UP) program, and to simulate the effects of changes in AFDC-UP benefit and eligibility rules on family labor supply and welfare participation. The results suggest that labor supply and welfare participation among two-parent families are highly responsive to changes in the benefit structure under the AFDC-UP program.","['Hoynes, Hilary Williamson']","['Time Allocation and Labor Supply', 'Welfare, Well-Being, and Poverty: Government Programs; Provision and Effects of Welfare Programs']","['J22', 'I38']",Welfare Transfers in Two-Parent Families: Labor Supply and Welfare Participation under AFDC-UP,0,0,0,0,0,1996,03,01
64,2,1996-03-01,This paper uses the Panel Study of Income Dynamics to test whether risk-sharing is complete between or within American families. The tests accommodate wide variety in the configuration and availability of family data. The test results reject inter- as well as intra-family full risk-sharing even assuming that leisure is endogenous or that leisure and consumption are nonseparable.,"['Kotlikoff, Laurence', 'Altonji, Joseph', 'Hayashi, Fumio']","['Consumer Economics: Empirical Analysis', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['D12', 'D15']",Risk-Sharing between and within Families,0,0,0,0,0,1996,03,01
64,1,1996-01-01,ECONLIT None Found,"['Vuong, Quang H.', 'Lavergne, Pascal']","['Single Equation Models; Single Variables: General', 'Semiparametric and Nonparametric Methods: General']","['C20', 'C14']",Nonparametric Selection of Regressors: The Nonnested Case,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"The authors investigate the separate effects of a training program on the duration of participants' subsequent employment and unemployment spells. This program randomly assigned volunteers to treatment and control groups. However, the treatments and controls experiencing subsequent employment and unemployment spells are not generally comparable subsets of the initial groups. Standard practice in duration models ignores this issue, leading to a sample selection problem and misleading estimates of the training effects. The authors propose an estimator that addresses this problem and find that the program studied, the National Supported Work Demonstration, raised trainees' employment rates solely by lengthening their employment durations.","['Ham, John C.', 'LaLonde, Robert J.']","['Human Capital; Skills; Occupational Choice; Labor Productivity', 'Duration Analysis; Optimal Timing Strategies', 'Unemployment: Models, Duration, Incidence, and Job Search']","['J24', 'C41', 'J64']",The Effect of Sample Selection and Initial Conditions in Duration Models: Evidence from Experimental Data on Training,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"It is widely known that conditional covariances of asset returns change over time. Researchers doing empirical work have adopted many strategies for accommodating conditional heteroskedasticity. One popular strategy is performing rolling regressions in which only data from, say, the preceding five year period is used to estimate the conditional covariance of returns at a given date. The authors develop continuous record asymptotic approximations for the measurement error in conditional variances when using these methods. They derive asymptotically optimal window lengths for the standard rolling regressions and optimal weights for weighted rolling regressions. The S&P 500 is used as an empirical example.","['Foster, Dean P.', 'Nelson, Daniel B.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Continuous Record Asymptotics for Rolling Sample Variance Estimators,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"This paper shows how to estimate a model in which an unknown transformation of the dependent variable is a linear function of explanatory variables plus an unobserved random variable, U, whose distribution is unknown. The model nests many familiar parametric and semiparametric models, including models with Box-Cox transformed dependent variables and proportional hazards models with and without unobserved heterogeneity. The paper develops root-n consistent, asymptotically normal estimators of the transformation function, coefficients of the explanatory variables, and distribution of U. The results of Monte Carlo experiments indicate that the estimators work well in samples of size one hundred.","['Horowitz, Joel L.']","['Single Equation Models; Single Variables: General', 'Semiparametric and Nonparametric Methods: General']","['C20', 'C14']",Semiparametric Estimation of a Regression Model with an Unknown Transformation of the Dependent Variable,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"Inequality measures are often used to summarize information about empirical income distributions. However the resulting picture of the distribution and of changes in the distribution can be severely distorted if the data are contaminated. The nature of this distortion will in general depend upon the underlying properties of the inequality measure. This issue is investigated theoretically using a technique based on the influence function, and the magnitude of the effect is illustrated using a simulation. Both direct nonparametric estimation from the sample, and indirect estimation using a parametric model are considered; in the latter case the application of a robust estimation procedure is demonstrated. The results are applied to two micro-data examples.","['Victoria-Feser, Maria-Pia', 'Cowell, Frank A.']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Personal Income, Wealth, and Their Distributions']","['D63', 'D31']",Robustness Properties of Inequality Measures,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"Typically, work on mechanism design has assumed that all private information can be captured in a single scalar variable. This paper explores one way in which this assumption can be relaxed in the context of the multiproduct nonlinear pricing problem. It is shown that the firm will choose to exclude some low-value consumers from all markets. A class of cases that allow explicit solution is derived by making use of a multivariate form of 'integration by parts.' In such cases the optimal tariff is cost-based.","['Armstrong, Mark']","['Asymmetric and Private Information; Mechanism Design', 'Market Structure, Pricing, and Design: Monopoly', 'Firm Behavior: Theory']","['D82', 'D42', 'D21']",Multiproduct Nonlinear Pricing,0,0,1,0,0,1996,01,01
64,1,1996-01-01,"A random price adjustment model is developed for an exchange economy which is decentralized in that the trades permitted to an agent and the resulting price changes depend only on the commodity vector currently held by that agent, and not on the whole economy. We obtain asymptotic results as the number of agents goes to infinity, subject to stability assumptions on the price paths. With probability arbitrarily close to one the price path in our model will approximate the price path of the corresponding tatonnement process on a rapid time scale, and will then remain close to a limit price. Moreover, the economy will approach a competitive equilibrium, and the process will be feasible in the sense that the market maker's inventory is approximately constant over time.","['Keisler, H. Jerome']",['Exchange and Production Economies'],['D51'],Getting to a Competitive Equilibrium,0,0,0,0,0,1996,01,01
64,1,1996-01-01,"Existence of equilibrium with incomplete markets is problematic because demand functions are typically not continuous. Discontinuities occur at prices for which a marketed asset suddenly becomes redundant. The authors show that this discontinuity disappears if they allow an agent in the economy to introduce a new asset when such redundancies occur. This enables them to prove generic existence with incomplete markets using a standard path-following argument. Moreover, the authors' approach suggests a simple algorithm for computing equilibria when markets are incomplete. They demonstrate this by computing equilibrium for a numerical example.","['DeMarzo, Peter M.', 'Eaves, B. Curtis', 'Brown, Donald J.']",['Incomplete Markets'],['D52'],Computing Equilibria When Asset Markets Are Incomplete,0,0,0,0,0,1996,01,01
78,2,2010-03-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS: 2010 WORLD CONGRESS OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2010,03,01
63,6,1995-11-01,ECONLIT None Found,"['Mora, Juan', 'Delgado, Miguel A.']",['Single Equation Models; Single Variables: General'],['C20'],Nonparametric and Semiparametric Estimation with Discrete Regressors,0,0,0,0,0,1995,11,01
63,6,1995-11-01,The authors apply nonparametric regression models to estimation of demand curves of the type most often used in applied research. From the demand curve estimators they derive estimates of exact consumers surplus and deadweight loss. The authors also develop tests of the symmetry and downward sloping properties of compensated demand. They work out asymptotic normal sampling theory for kernel and series nonparametric estimators as well as for the parametric case. The paper includes an application to gasoline demand that estimates the shape of the demand curve and the average magnitude of welfare loss from a tax on gasoline.,"['Hausman, Jerry A.', 'Newey, Whitney K.']","['Model Construction and Estimation', 'Consumer Economics: Empirical Analysis']","['C51', 'D12']",Nonparametric Estimation of Exact Consumers Surplus and Deadweight Loss,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"The authors present three distinct approaches to perfect and proper equilibria for infinite normal form games. In the first two approaches, players 'tremble' in the infinite game playing full support approximate best responses to others' strategies. In the strong approach, a tremble assigns high probability to the set of pure best responses; in the weak approach, it assigns high probability to a neighborhood of this set. The third, limit-of-finite approach applies traditional refinements to sequences of successively larger finite games. Overall, the strong approach to equilibrium refinement most fully respects the structure of infinite games.","['Stinchcombe, Maxwell B.', 'Simon, Leo K.']",['Noncooperative Games'],['C72'],Equilibrium Refinement for Infinite Normal-Form Games,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"Two-person repeated games with no discounting are considered where there is uncertainty about the type of the players. If there is a possibility that a player is an automaton committed to a particular pure or mixed stage-game action, then this provides a lower bound on the Nash equilibrium payoffs to a normal type of this player. The lower bound is the best available and is robust to the existence of other types. The results are extended to the case of two-sided uncertainty. This work extends Schmidt (1993) who analyzed the restricted class of conflicting interest games.","['Cripps, Martin W.', 'Thomas, Jonathan P.']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Reputation and Commitment in Two-Person Repeated Games without Discounting,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"This paper investigates stability properties of evolutionary selection dynamics in normal-form games. The analysis is focused on deterministic dynamics in continuous time and on asymptotic stability of sets of population states, more precisely of faces of the mixed-strategy space. The main result is a characterization of those faces that are asymptotically stable in all dynamics from a certain class, and the authors show that every such face contains an essential component of the set of Nash equilibria and, hence, a strategically stable set in the sense of E. Kohlberg and J. F. Mertens (1986).","['Weibull, Jorgen W.', 'Ritzberger, Klaus']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",Evolutionary Selection in Normal-Form Games,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"A common interest game is a game in which there exists a unique pair of payoffs which strictly Pareto dominates all other payoffs. The authors consider the undiscounted repeated game obtained by the infinite repetition of such a two-player stage game. They show that, if supergame strategies are restricted to be computable within Church's thesis, the only pair of payoffs that survives any computable tremble with sufficiently large support is the Pareto-efficient pair. The result is driven by the ability of the players to use the early stages of the game to communicate their intention to play cooperatively in the future.","['Sabourian, Hamid', 'Anderlini, Luca']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",Cooperation and Effective Computability,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"The authors study the strategic equilibria of a negotiation game where potential buyers are affected by identity-dependent, negative externalities. The unique equilibrium of long, finitely repeated generic games can either display delay--where a transaction can take place only in several stages before the deadline--or, in spite of the random element in the game, a well-defined buyer exists that obtains the object with probability close to one.","['Moldovanu, Benny', 'Jehiel, Philippe']","['Bargaining Theory; Matching Theory', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C78', 'C73']",Negative Externalities May Cause Delay in Negotiation,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"This paper considers the problem of social evaluation in a model where population size, individual lifetime utilities, lengths of life, and birth dates vary across states. In an intertemporal framework, the authors investigate principles for social evaluation that allow history to matter to some extent. Using an axiom called independence of the utilities of the dead, they provide a characterization of critical-level generalized utilitarian rules. As a by-product of their analysis, the authors show that social discounting is ruled out in an intertemporal welfarist environment. A simple population-planning example is also discussed.","['Blackorby, Charles', 'Bossert, Walter', 'Donaldson, David']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],Intertemporal Population Ethics: Critical-Level Utilitarian Principles,0,0,0,0,0,1995,11,01
63,6,1995-11-01,"This paper reconsiders the theory of market versus optimal product diversity using a discrete choice approach to product differentiation. The authors analyze oligopoly with price competition and free entry with integer firm numbers. Under the Chamberlinian symmetry assumption, they show that log-concavity of the taste density function implies excessive market provision of diversity when each consumer buys one unit. This result is extended to price-sensitive individual demands by proving that the equilibrium number of firms exceeds that provided at the second-best optimum subject to zero profits.","['Nesterov, Yurii', 'Anderson, Simon P.', 'de Palma, Andre']","['Oligopoly and Other Imperfect Markets', 'Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']","['L13', 'D43']",Oligopolistic Competition and the Optimal Provision of Products,1,0,1,0,0,1995,11,01
63,6,1995-11-01,"To accommodate the observed pattern of risk-aversion and risk-seeking, as well as common violations of expected utility (e.g., the certainty effect), the authors introduce and characterize a weighting function according to which an event has greater impact when it turns impossibility into possibility, or possibility into certainty, than when it merely makes a possibility more or less likely. The authors show how to compare such weighting functions (of different individuals) with respect to the degree of departure from expected utility and they present a method for comparing an individual's weighting functions for risk and for uncertainty.","['Wakker, Peter', 'Tversky, Amos']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Risk Attitudes and Decision Weights,0,0,0,0,0,1995,11,01
63,5,1995-09-01,ECONLIT None Found,"['Kajii, Atsushi', 'Grant, Simon']",['Bargaining Theory; Matching Theory'],['C78'],A Cardinal Characterization of the Rubinstein-Safra-Thomson Axiomatic Bargaining Theory,0,0,0,0,0,1995,09,01
63,5,1995-09-01,ECONLIT None Found,"['Lippman, Steven A.', 'Cantor, David G.']","['Intertemporal Firm Choice: Investment, Capacity, and Financing', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity']","['D25', 'G31']",Optimal Investment Selection with a Multitude of Projects,0,0,0,0,0,1995,09,01
63,5,1995-09-01,ECONLIT None Found,"['Shorrocks, Anthony F.']",['Measurement and Analysis of Poverty'],['I32'],Revisiting the Sen Poverty Index,0,0,0,0,0,1995,09,01
63,5,1995-09-01,ECONLIT None Found,"['Al-Najjar, Nabil Ibraheem']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Decomposition and Characterization of Risk with a Continuum of Random Variables,0,0,0,0,0,1995,09,01
63,5,1995-09-01,"We add a round of pre-play communication to a finite two-player game played by a population of players. Pre-play communication is cheap talk in the sense that it does not directly enter the payoffs. The paper characterizes the set of strategies that are stable with respect to a stochastic dynamic adaptive process. Periodically players have an opportunity to change their strategy with a strategy that is more successful against the current population. Any strategy that weakly improves upon the current poorest performer in the population enters with positive probability. When there is no conflict of interest between the players, only the efficient outcome is stable with respect to these dynamics. For general games the set of stable payoffs is typically large. Every efficient payoff recurs infinitely often.","['Kim, Yong-Gwan', 'Sobel, Joel']",['Noncooperative Games'],['C72'],An Evolutionary Approach to Pre-play Communication,0,0,0,0,0,1995,09,01
63,5,1995-09-01,"Sufficient conditions for Nash equilibrium in an 'n'-person game are given in terms of what the players know and believe - about the game, and about each other's rationality, actions, knowledge, and beliefs. Mixed strategies are treated not as conscious randomizations, but as conjectures, on the part of other players, as to what a player will do. Common knowledge plays a smaller role in characterizing Nash equilibrium than had been supposed. When 'n' = 2, mutual knowledge of the payoff functions, of rationality, and of the conjectures implies that the conjectures form a Nash equilibrium. When 'n [greater than or equal to] 3 and there is a common prior, mutual knowledge of the payoff functions and of rationality, and common knowledge of the conjectures, imply that the conjectures form a Nash equilibrium. Examples show the results to be tight.","['Aumann, Robert', 'Brandenburger, Adam']",['Noncooperative Games'],['C72'],Epistemic Conditions for Nash Equilibrium,0,0,0,0,0,1995,09,01
63,5,1995-09-01,"This paper proposes two consistent one-sided specification tests for parametric regression models, one based on the sample covariance between the residual from the parametric model and the discrepancy between the parametric and nonparametric fitted values; the other based on the difference in sums of squared residuals between the parametric and nonparametric models. The authors estimate the nonparametric model by series regression. The new test statistics converge in distribution to a unit normal under correct specification and grow to infinity faster than the parametric rate [square root of] n under misspecification, while avoiding weighting, sample splitting, and nonnested testing procedures used elsewhere.","['White, Halbert', 'Hong, Yongmiao']","['Model Evaluation, Validation, and Selection', 'Semiparametric and Nonparametric Methods: General', 'Single Equation Models; Single Variables: General']","['C52', 'C14', 'C20']",Consistent Specification Testing via Nonparametric Series Regression,0,0,0,0,0,1995,09,01
63,5,1995-09-01,A new asymptotic theory of regression is introduced for possibly nonstationary time series. The regressors are assumed to be generated by a linear process with martingale difference innovations. The conditional variances of these martingale differences are specified as autoregressive stochastic volatility processes with autoregressive roots that are local to unity. The author finds conditions under which the least squares estimates are consistent and asymptotically normal. A simple adaptive estimator is proposed which achieves the same asymptotic distribution as the generalized least squares estimator without requiring parameter assumptions for the stochastic volatility process.,"['Hansen, Bruce E.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Regression with Nonstationary Volatility,0,0,0,0,0,1995,09,01
63,5,1995-09-01,"The author examines the second order properties of various quantities of interest in the partially linear regression model: a stochastic expansion with remainder of order n[superscript -2 mu] in distribution, where mu < 1/2, is obtained for the standardized semiparametric least squares estimator, a standard error estimator, and a studentized statistic. He uses second order expansions to correct the standard error estimates for second order effects, and to define a method of bandwidth choice. A Monte Carlo experiment provides favorable evidence on the author's method of bandwidth choice.","['Linton, Oliver']","['Single Equation Models; Single Variables: General', 'Semiparametric and Nonparametric Methods: General']","['C20', 'C14']",Second Order Approximation in the Partially Linear Regression Model,0,0,0,0,0,1995,09,01
63,5,1995-09-01,"This paper provides a general framework which makes it possible to study the asymptotic behavior of FM regression in models with I(1) and I(0) regressors, models with unit roots, and models with only stationary regressors. This framework enables us to consider the use of FM regression in the context of vector autoregressions with some unit roots and some cointegrating relations. The resulting FM-VAR regressions are shown to produce optimal estimates of the cointegration space without prior knowledge of the number of unit roots in the system, without pretesting to determine the dimension of the cointegration space and without the use of restricted regression techniques like reduced rank regression. The paper also develops an asymptotic theory for inference. It is shown that conventional chi-squared critical values can be used to construct valid (but conservative) asymptotic tests in quite general FM time series regression.","['Phillips, Peter C. B.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Fully Modified Least Squares and Vector Autoregression,0,0,0,0,0,1995,09,01
63,4,1995-07-01,"This study demonstrates the possibility of ergodically chaotic optimal accumulation in the case in which future utilities are discounted arbitrarily weakly. For this purpose, the authors use a two-sector model with Leontief production functions and construct a condition under which the optimal transition function is unimodal and expansive. They demonstrate that the set of parameter values satisfying that condition is nonempty no matter how weakly the future utilities are discounted.","['Nishimura, Kazuo', 'Yano, Makoto']","['Business Fluctuations; Cycles', 'One, Two, and Multisector Growth Models']","['E32', 'O41']",Nonlinear Dynamics and Chaos in Optimal Growth: An Example,0,0,0,0,0,1995,07,01
63,4,1995-07-01,This paper proposes a convenient estimation method for the empirical study of auction models. The authors focus on first-price sealed-bid and descending auctions within the private value paradigm. The method relies upon a simulated nonlinear least squares objective function appropriately adjusted. Asymptotic properties are established and some extensions are discussed. The method is applied to a market of agricultural products. The structural modeling takes into account the heterogeneity of the auctioned objects and the fact that only the winning bid is observed. Estimates of the parameters characterizing the distribution of the unobserved private values are provided.,"['Vuong, Quang', 'Laffont, Jean-Jacques', 'Ossard, Herve']","['Auctions', 'Model Construction and Estimation']","['D44', 'C51']",Econometrics of First-Price Auctions,0,0,1,0,0,1995,07,01
63,4,1995-07-01,"This paper develops and estimates a model of the U.S. automobile industry. On the demand side, a discrete choice model is adopted, which is estimated using micro data from the Consumer Expenditure Survey. The estimation results are used in conjunction with population weights to derive aggregate demand. On the supply side, the automobile industry is modeled as an oligopoly with product differentiation. Equilibrium is characterized by the first-order conditions of the profit-maximizing firms. The estimation results are used in counterfactual simulations to investigate two trade policy issues: the effects of the voluntary export restraint, and exchange rate pass-through.","['Goldberg, Pinelopi Koujianou']","['Automobiles; Other Transportation Equipment; Related Parts and Equipment', 'Trade Policy; International Trade Organizations', 'Consumer Economics: Empirical Analysis']","['L62', 'F13', 'D12']",Product Differentiation and Oligopoly in International Markets: The Case of the U.S. Automobile Industry,1,0,0,0,0,1995,07,01
63,4,1995-07-01,"This paper develops techniques for empirically analyzing demand and supply in differentiated product markets and then applies these techniques to the U.S. automobile industry. The authors' framework enables one to obtain estimates of demand and cost parameters for a class of oligopolistic differentiated products markets. These estimates can be obtained using only widely available product-level and aggregate consumer-level data, and they are consistent with a structural model of equilibrium in an oligopolistic industry. Applying these techniques, the authors obtain parameters for essentially all autos sold over a twenty-year period.","['Berry, Steven', 'Levinsohn, James', 'Pakes, Ariel']","['Oligopoly and Other Imperfect Markets', 'Automobiles; Other Transportation Equipment; Related Parts and Equipment']","['L13', 'L62']",Automobile Prices in Market Equilibrium,1,0,0,0,0,1995,07,01
63,4,1995-07-01,"Models of life-cycle consumption are studied in which individuals react optimally to their own income process but have incomplete or no information on economywide variables. Since individual income is less persistent than aggregate income, consumers will react too little to aggregate income variation generating excess smoothness. Since aggregate information is slowly incorporated into consumption, aggregate consumption is correlated with lagged income. Model predictions using estimated income processes qualitatively correspond to empirical findings for aggregate consumption but differ in magnitude. Individual income processes are estimated from the Survey of Income and Program Participation, making various adjustments for measurement error.","['Pischke, Jorn-Steffen']","['Macroeconomics: Consumption; Saving; Wealth', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['E21', 'D15']","Individual Income, Incomplete Information, and Aggregate Consumption",0,0,0,0,0,1995,07,01
63,4,1995-07-01,Continuous-time Markov processes can be characterized conveniently by their infinitesimal generators. For such processes there exist forward and reverse-time generators. The authors show how to use these generators to construct moment conditions implied by stationary Markov processes. Generalized method of moments estimators and tests can be constructed using these moment conditions. The resulting econometric methods are designed to be applied to discrete-time data obtained by sampling continuous-time Markov processes.,"['Scheinkman, Jose Alexandre', 'Hansen, Lars Peter']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Estimation: General']","['C22', 'C13']",Back to the Future: Generating Moment Implications for Continuous-Time Markov Processes,0,0,0,0,0,1995,07,01
63,4,1995-07-01,"This article relates the events that led to the establishment of the journal Econometrica, with particular emphasis on the role played by Ragnar Frisch. The origin of the name of the journal is explained. The editorial views, style, and habits of Ragnar Frisch as Editor of Econometrica is recounted.","['Bjerkholt, Olav']",['History of Economic Thought: Individuals'],['B31'],"Ragnar Frisch, Editor of Econometrica 1933-1954",0,0,0,0,0,1995,07,01
63,3,1995-05-01,"Using a simulated method of moments approach, the author evaluates a representative consumer asset pricing model in which the consumer is assumed to have time nonseparable preferences of several forms. Examining the model's implications for several moments of asset returns, he finds evidence for the local substitution of consumption with habit formation occurring over longer periods of time. The interaction between these two effects is important. The author also shows that, when accounting for sampling error, a model with local substitution and long-run habit persistence is consistent with the Hansen and Jagannathan (1991) bounds.","['Heaton, John']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],An Empirical Investigation of Asset Pricing with Temporally Dependent Preference Specifications,0,0,0,0,0,1995,05,01
63,3,1995-05-01,"With the same normalization as that for standard parametric statistics, and centered at a parameter of interest, many semiparametric estimates based on n observations have been shown to be root-n-consistent and asymptotically normal. In the context of semiparametric averaged derivative estimates, the author goes further by showing that the rate of convergence of the finite-sample distribution to the normal limit distribution can equal that of standard parametric statistics.","['Robinson, P. M.']",['Semiparametric and Nonparametric Methods: General'],['C14'],The Normal Approximation for Semiparametric Averaged Derivatives,0,0,0,0,0,1995,05,01
63,3,1995-05-01,"Under certain regularity conditions, if the distribution of income is price independent and satisfies a condition on the shape of its graph, then total market demand is monotone. The author's methods allow for density functions increasing on some intervals, like unimodal distributions or even densities with more than one peak. Similar assumptions on the distribution of endowments yield a restricted monotonicity property on the aggregate excess demand function of a Walrasian pure exchange economy with wealth determined by market prices. It follows that the unique equilibrium price is stable.","['Marhuenda, F.']","['Exchange and Production Economies', 'Macroeconomics: Consumption; Saving; Wealth', 'Personal Income, Wealth, and Their Distributions', 'Consumer Economics: Theory']","['D51', 'E21', 'D31', 'D11']",Distribution of Income and Aggregation of Demand,0,0,0,0,0,1995,05,01
63,3,1995-05-01,"The authors consider a model where two agents, privately informed about their own characteristics, play a game on behalf of two uninformed principals. They analyze the existence of recommitment effects through public announcement of contracts in a model where agency contracts, designed ex-ante, can always be secretly renegotiated. The authors show that the existence of precommitment effects depends both on the strategic complementarity of the agents' actions and on the direct effect of the opponents' actions on each principal's welfare. The results are introduced through an example of Cournot and Bertrand competition between firms, viewed as vertical structures.","['Jullien, B.', 'Caillaud, Bernard', 'Picard, P.']","['Firm Organization and Market Structure', 'Asymmetric and Private Information; Mechanism Design', 'Transactional Relationships; Contracts and Reputation; Networks']","['L22', 'D82', 'L14']",Competing Vertical Structures: Precommitment and Renegotiation,1,0,0,0,0,1995,05,01
63,3,1995-05-01,"The properties of optimal mechanisms in environments where sellers are privately informed about quality are analyzed. A methodology is provided for deriving conditions that are necessary and sufficient to determine when two simple trading environments maximize either social or private surplus. The commonly used auction mechanism is frequently inefficient in procurement environments. Often, the optimal mechanism is simply to order potential suppliers and to tender take-it-or-leave-it offers to each sequentially. The environments in which either mechanism is optimal are completely characterized.","['Manelli, Alejandro M.', 'Vincent, Daniel R.']","['Auctions', 'National Government Expenditures and Related Policies: Procurement']","['D44', 'H57']",Optimal Procurement Mechanisms,0,0,1,0,0,1995,05,01
63,3,1995-05-01,"This paper studies moral hazard contracts that may be renegotiated after an agent chooses an unobservable effort. Unlike in previous models, a contract contains just one scheme and the agent has the renegotiation bargaining power. All equilibria satisfying a weak forward-induction refinement are shown to be (second-best) efficient. Renegotiation necessarily occurs. If the effort set is rich, the initial contract must be a sales contract 'selling the project' to the agent. Thus, a party (the principal) who has an inherently weak renegotiation position should sometimes insist on a simple initial contract.","['Matthews, Steven A.']","['Asymmetric and Private Information; Mechanism Design', 'Transactional Relationships; Contracts and Reputation; Networks']","['D82', 'L14']",Renegotiation of Sales Contracts,1,0,0,0,0,1995,05,01
63,3,1995-05-01,"An alternating-offers bargaining model in which a normal-form game determines players' payoffs in disagreement periods can have multiple perfect equilibria, provided that players are sufficiently patient. Even though there is perfect information, delay can arise and the length of delay depends only on the payoff structure of the disagreement game and not on the discount factor. On the other hand, not all feasible and individually rational payoffs of the disagreement game can be supported as average payoffs in equilibrium and some negotiation games have a unique perfect equilibrium with immediate agreement.","['Wen, Quan', 'Busch, Lutz-Alexander']",['Bargaining Theory; Matching Theory'],['C78'],Perfect Equilibria in Negotiation Model,0,0,0,0,0,1995,05,01
63,3,1995-05-01,"The starting point of this paper is a simple, regular, dynamic game in which a subgame-perfect equilibrium fails to exist. Examination of this example shows that existence would be restored if players were allowed to observe the output of a public-randomization device. The main result of the paper shows that the introduction of public randomization yields existence not only in the example but also in a large class of dynamic games. It is also argued that the introduction of public randomization is the minimal robust extension of subgame-perfect equilibrium in this class of games.","['Harris, Christopher', 'Robson, Arthur', 'Reny, Philip']",['Noncooperative Games'],['C72'],The Existence of Subgame-Perfect Equilibrium in Continuous Games with Almost Perfect Information: A Case for Public Randomization,0,0,0,0,0,1995,05,01
63,2,1995-03-01,ECONLIT None Found,"['Mukherji, Anjan']",['Exchange and Production Economies'],['D51'],A Locally Stable Adjustment Process,0,0,0,0,0,1995,03,01
63,2,1995-03-01,ECONLIT None Found,"['Blackorby, Charles', 'Russell, R. Robert']",['National Budget; Budget Systems'],['H61'],Proportional Budgeting and Decentralization,0,0,0,0,0,1995,03,01
63,2,1995-03-01,ECONLIT None Found,"['Smith, Lones']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Necessary and Sufficient Conditions for the Perfect Finite Horizon Folk Theorem,0,0,0,0,0,1995,03,01
63,2,1995-03-01,"An allocation in an infinite horizon capital accumulation model is a recursive core allocation provided no coalition can improve upon its consumption stream at any time given its accumulation of assets up to that period. The authors show for every allocation of consumption in the initial core, one can find a distribution of capital stocks among the agents where no coalition of agents will break the initial core contract at any date. The recursive core links the distribution of capital, the problem of trust in the sense of D. Gale, and time consistent intertemporal contracts.","['Becker, Robert A.', 'Chakrabarti, Subir K.']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],The Recursive Core,0,0,0,0,0,1995,03,01
63,2,1995-03-01,"The authors consider a k-player sequential bargaining model in which the size of the cake and the order in which players move follow a general Markov process. For games in which one agent makes an offer in each period and agreement must be unanimous, the authors provide characterizations of the sets of subgame perfect and stationary subgame perfect payoffs. With these characterizations, they investigate the uniqueness and efficiency of the equilibrium outcomes, the conditions under which agreement is delayed, and the advantage to proposing.","['Wilson, Charles A.', 'Merlo, Antonio']",['Bargaining Theory; Matching Theory'],['C78'],A Stochastic Model of Sequential Bargaining with Complete Information,0,0,0,0,0,1995,03,01
63,2,1995-03-01,"This paper models and estimates congestion prices and capacity for large hub airports with stochastic queues, time-varying traffic rates, and endogenous intertemporal adjustment of traffic in response to queuing delay and fees. Relative costs of queuing and schedule delays are estimated using data from Minneapolis-St. Paul. Simulations calculate equilibrium traffic patterns, queuing delays, schedule delays, congestion fees, airport revenues, airport capacity, and efficiency gains. The paper also investigates whether a dominant airline internalizes delays its aircraft impose. It tests game-theoretic specifications with atomistic, Nash-dominant, Stackelberg-dominant, and collusive-airline traffic.","['Daniel, Joseph I.']","['Air Transportation', 'Transportation: Demand, Supply, and Congestion; Travel Time; Safety and Accidents; Transportation Noise']","['L93', 'R41']",Congestion Pricing and Capacity of Large Hub Airports: A Bottleneck Model with Stochastic Queues,1,0,0,0,0,1995,03,01
63,2,1995-03-01,"A statistical model of dynamic intrafamily investment behavior incorporating endowment heterogeneity is estimated to evaluate alternative estimation procedures that have exploited family and kinship data. These procedures, which place alternative restrictions on the endowment structure and on behavior, include generalized least squares, fixed-effects based on the children of sisters and siblings, and instrumental variables. The framework is applied to data on birth outcomes, with focus on the effects of teen-age childbearing net of other maternal behavior. The empirical results imply that the least restrictive statistical formulation, consistent with dynamic behavior and heterogeneity among siblings, fits the data best.","['Wolpin, Kenneth I.', 'Rosenzweig, Mark R.']","['Household Production and Intrahousehold Allocation', 'Fertility; Family Planning; Child Care; Children; Youth']","['D13', 'J13']","Sisters, Siblings, and Mothers: The Effect of Teen-Age Childbearing on Birth Outcomes in a Dynamic Family Context",0,0,0,0,0,1995,03,01
63,2,1995-03-01,"Robust estimation aims at developing point estimators that are not highly sensitive to errors in data. However, the population parameters of interest are not identified under the assumptions of robust estimation, so the rationale for point estimation is not apparent. This paper shows that, under error models used in robust estimation, unidentified population parameters can often be bounded. The bounds provide information that is not available in robust estimation. For example, it is possible to bound the population mean under contaminated sampling. It is argued that estimating the bounds is more natural than attempting point estimation of unidentified parameters.","['Horowitz, Joel L.', 'Manski, Charles F.']","['Estimation: General', 'Econometric Modeling: General']","['C13', 'C50']",Identification and Robustness with Contaminated and Corrupted Data,0,0,0,0,0,1995,03,01
63,2,1995-03-01,"A definition of extended memory is provided, generalizing the ideas of long memory and persistence, based on the properties of forecasts over long horizons. Specification of nonlinear models with variables having extended memory is considered in terms of the balance of an equation and it is suggested that many more types of misspecification can occur than with usual situations and could produce important specification errors. Tests of linearity and standard methods of nonlinear modeling are briefly considered and advice is given on circumstances in which they can be used.","['Granger, Clive W. J.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Model Construction and Estimation']","['C22', 'C51']",Modelling Nonlinear Relationships between Extended-Memory Variables,0,0,0,0,0,1995,03,01
63,1,1995-01-01,ECONLIT None Found,"['Chesher, Andrew']",['Estimation: General'],['C13'],A Mirror Image Invariance for M-Estimators,0,0,0,0,0,1995,01,01
63,1,1995-01-01,ECONLIT None Found,"['Evans, George W.', 'Honkapohja, Seppo']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Local Convergence of Recursive Learning to Steady States and Cycles in Stochastic Nonlinear Models,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"If an agent's preferences over subjectively uncertain acts are consistent with him having a subjective probability distribution over the states of nature, then those preferences can induce consistent preferences over 'objectively' risky lotteries. Such 'probabilistically sophisticated' behavior allows us to treat decision making under uncertainty as though it is under risk. This paper first characterizes exactly what probabilistic sophistication entails for an agent's beliefs about the likelihood of states of nature. Secondly, it presents characterizations of probabilistically sophisticated individuals whose induced lottery preferences obey neither the independence axiom nor a monotonicity property that is shown to share some of the nature of independence.","['Grant, Simon']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Subjective Probability without Monotonicity: Or How Machina's Mom May Also Be Probabilistically Sophisticated,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"This paper elucidates on the logic behind recent papers which show that a unique equilibrium is selected in the presence of higher order uncertainty, i.e., when players lack common knowledge. We introduce two new concepts: stochastic potential of the information system and p-dominance of Nash-equilibria of the game, and show that a Nash-equilibrium is uniquely selected whenever its p-dominance is below the stochastic potential. This criterion applies to many-action games, not merely 2 by 2 games. It also applies to games without dominant strategies, where the set of equilibria is shown to be smaller and simpler than might be initially conjectured. Finally, the new concepts help understand the circumstances under which the set of equilibria varies with the amount of common knowledge among players.","['Shin, Hyun Song', 'Morris, Stephen', 'Rob, Rafael']",['Noncooperative Games'],['C72'],Dominance and Belief Potential,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"A model of the process by which players learn to play repeated coordination games is proposed with the goal of understanding the results of recent experiments. In those experiments, the dynamics of subjects' strategy choices and the resulting patterns of discrimination among equilibria varied systematically with the rule for determining payoffs and the size of the interacting groups in ways that are not adequately explained by available methods of analysis. The model suggests a possible explanation by showing how the dispersion of subjects' beliefs interacts with the learning process to determine the probability distribution of its dynamics and limiting outcome.","['Crawford, Vincent P.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Adaptive Dynamics in Coordination Games,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"Different information systems are compared in terms of their relative efficiencies in an agency model. The mean preserving spread relation between the likelihood ratio distributions derived from the original information systems is found to be sufficient to rank information systems under quite general assumptions about the agent's utility function. Furthermore, it is shown that the mean preserving spread criterion can be applied to a broader set of information systems than Holmstrom's informativeness criterion and Blackwell's theorem.","['Kim, Son Ku']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Efficiency of an Information System in an Agency Model,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"The authors consider the allocation of goods in exchange economies with a finite number of agents who may have private information about their preferences. They characterize the set of allocation rules that are compatible with individual incentives or, in other words, the set of strategy-proof social choice functions. Social choice functions that are strategy-proof are those that can be obtained from trading according to a finite number of prespecified proportions. The number of proportions that can be accommodated is proportional to the number of agents. Such rules are necessarily inefficient even in the limit as the economy grows.","['Jackson, Matthew O.', 'Barbera, Salvador']","['Social Choice; Clubs; Committees; Associations', 'Exchange and Production Economies']","['D71', 'D51']",Strategy-Proof Exchange,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"This paper examines the effect on health outcomes of moving from cost-based to prospective reimbursement of hospitals. The paper reaches two conclusions. First, hospitals that experienced average price declines had a greater share of deaths occur in the hospital or shortly after discharge. By one year postdischarge, however, this increased mortality was eliminated. Second, there was an increase in readmission rates as hospitals were no longer reimbursed for marginal units of care they provided. This increased readmission appears to be due to accounting changes on the part of hospitals rather than changes in patient morbidity.","['Cutler, David M.']","['Health: Government Policy; Regulation; Public Health', 'Analysis of Health Care Markets']","['I18', 'I11']",The Incidence of Adverse Medical Outcomes under Prospective Payment,0,0,0,0,0,1995,01,01
63,1,1995-01-01,"This paper describes the U.S. offshore oil and gas lease sales conducted by the Department of the Interior since 1954. Several decision variables are discussed, including bidding for leases, the government's decision whether to accept the highest bid, the incidence and timing of exploratory drilling, and the formation of bidding consortia. Equilibrium models of these decisions that emphasize informational and strategic issues and that account for institutional features of the leasing program are analyzed and their predictions compared to outcomes in the data.","['Porter, Robert H.']","['Auctions', 'Mining, Extraction, and Refining: Hydrocarbon Fuels']","['D44', 'L71']",The Role of Information in U.S. Offshore Oil and Gas Lease Auctions,1,0,1,0,0,1995,01,01
77,5,2009-09-01,ECONLIT None Found,"['Swensen, Anders Rygh']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Bootstrap Algorithms for Testing and Determining the Cointegration Rank in VAR Models: Corrigendum,0,0,0,0,0,2009,09,01
77,1,2009-01-01,ECONLIT None Found,"['Rincon-Zapatero, Juan Pablo', 'Rodriguez-Palmero, Carlos']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],Existence and Uniqueness of Solutions to the Bellman Equation in the Unbounded Case: Corrigendum,0,0,0,0,0,2009,01,01
62,6,1994-11-01,ECONLIT None Found,"['Zheng, Buhong']",['Measurement and Analysis of Poverty'],['I32'],Can a Poverty Index Be Both Relative and Absolute?,0,0,0,0,0,1994,11,01
62,6,1994-11-01,ECONLIT None Found,"['Krulce, Darrell L.', 'Chakravorty, Ujjayant']",['Nonrenewable Resources and Conservation: Demand and Supply; Prices'],['Q31'],Heterogeneous Demand and Order of Resource Extraction,0,0,0,0,0,1994,11,01
62,6,1994-11-01,"The authors analyze a first-price, sealed bid auction of an object with unknown common value, but one buyer has better information. The reservation price is correlated with the informed buyer's assessment of the value and of the probability of rejection. If all random variables are affiliated, the rate of increase in the distribution of the uninformed bid is never greater than that of the informed bid, the distributions are identical above the support of the reservation price, and the informed buyer is more likely to submit low bids. Bids for offshore oil and gas leases on drainage tracts satisfy these restrictions.","['Porter, Robert H.', 'Wilson, Charles A.', 'Hendricks, Kenneth']","['Auctions', 'Industry Studies: Primary Products and Construction: General']","['D44', 'L70']",Auctions for Oil and Gas Leases with an Informed Bidder and a Random Reservation Price,1,0,1,0,0,1994,11,01
62,6,1994-11-01,"This paper derives asymptotically optimal tests for testing problems in which a nuisance parameter exists under the alternative hypothesis but not under the null. For example, the results apply to tests of structural change with unknown changepoint. The testing problem considered is nonstandard and the classical asymptotic optimality results for the Lagrange multiplier, Wald, and likelihood ratio do not apply. A weighted average power criterion is used here to generate optimal tests. This criterion is similar to that used by A. Wald (1943) to obtain the classical asymptotic optimality properties of Wald tests in 'regular' testing problems.","['Ploberger, Werner', 'Andrews, Donald W. K.']",['Hypothesis Testing: General'],['C12'],Optimal Tests When a Nuisance Parameter Is Present Only under the Alternative,0,0,0,0,0,1994,11,01
62,6,1994-11-01,"This paper derives a general formula for the asymptotic variance of semiparametric estimators that accounts for the presence of nonparametric estimators of functions. The general formula is specialized to show invariance of the asymptotic variance to the type of nonparametric estimator and to obtain correction terms for estimation of densities and mean-square projections (including conditional expectations). Regularity conditions for the validity of the formula are also given, including primitive conditions for asymptotic normality when series estimators are present. New examples considered include a semiparametric panel probit estimator and a series estimator of the average derivative.","['Newey, Whitney K.']",['Semiparametric and Nonparametric Methods: General'],['C14'],The Asymptotic Variance of Semiparametric Estimators,0,0,0,0,0,1994,11,01
62,6,1994-11-01,"'No trade' theorems have shown that new information will not lead to trade when agents share the same prior beliefs. This paper explores the structure of no trade theorems with heterogeneous prior beliefs. It is shown how different notions of efficiency under asymmetric information--ex ante, interim, ex post--are related to agents' prior beliefs as well as incentive compatible and public versions of those efficiency concepts. These efficiency results are used to characterize necessary and sufficient conditions on agents' beliefs for no trade theorems in different trading environments.","['Morris, Stephen']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Trade with Heterogeneous Prior Beliefs and Asymmetric Information,0,0,0,0,0,1994,11,01
62,6,1994-11-01,"A number of generalizations of the expected utility preference functional are estimated using experimentally generated data involving 100 pairwise choice questions repeated on two separate occasions. Likelihood ratio tests are conducted to investigate the statistical superiority of the various generalizations and the Akaike information criterion is used to distinguish between them. The economic superiority of the various generalizations is also explored and the paper concludes that, for many subjects, the superiority of several of the generalizations is not established.","['Orme, Chris', 'Hey, John D.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Investigating Generalizations of Expected Utility Theory Using Experimental Data,0,0,0,0,0,1994,11,01
62,6,1994-11-01,"Recent experimental choice studies compare expected utility with competing theories of decision-making under risk. Formal tests used to judge the theories usually count the number of consistent responses, ignoring systematic variation in inconsistent responses. A maximum-likelihood estimation method is developed that extracts more information from the data and enables one to judge the predictive utility--fit and parsimony--of utility theories. Analyses of twenty-three data sets suggest a menu of theories that sacrifice the least parsimony for the biggest improvement in fit. The menu is mixed fanning, prospect theory, expected utility, and expected value.","['Camerer, Colin F.', 'Harless, David W.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],The Predictive Utility of Generalized Expected Utility Theories,0,0,0,0,0,1994,11,01
62,5,1994-09-01,ECONLIT None Found,"['Leung, Siu Fai']",['Intertemporal Household Choice; Life Cycle Models and Saving'],['D15'],"Uncertain Lifetime, the Theory of the Consumer, and the Life Cycle Hypothesis",0,0,0,0,0,1994,09,01
62,5,1994-09-01,"This paper establishes a correspondence in large samples between classical hypothesis tests and Bayesian posterior odds tests for models without trends. More specifically, tests of point null hypotheses and one- or two-sided alternatives are considered (where nuisance parameters may be present under both hypotheses). It is shown that, for certain priors, the Bayesian posterior odds test is equivalent in large samples to classical Wald, Lagrange multiplier, and likelihood ratio tests for some significance level and vice versa. The priors considered under the alternative hypothesis are taken to shrink to the null hypothesis at rate n[superscript -1/2] as the sample size n increases.","['Andrews, Donald W. K.']",['Hypothesis Testing: General'],['C12'],The Large Sample Correspondence between Classical Hypothesis Tests and Bayesian Posterior Odds Tests,0,0,0,0,0,1994,09,01
62,5,1994-09-01,"The generalized extreme value model was developed by D. McFadden for the case with discrete choice sets. The present paper extends this model to cases with both discrete and continuous choice sets and choice sets that are unobservable by the analyst. The author also proposes behavioral assumptions that justify random utility functions (processes) that have a max-stable structure, i.e., utility processes where the finite dimensional distributions are of the multivariate extreme value type. Finally, he derives nonparametrically testable implications for the choice probabilities in the continuous case.","['Dagsvik, John K.']","['Multiple or Simultaneous Equation Models: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions', 'Consumer Economics: Theory']","['C35', 'D11']","Discrete and Continuous Choice, Max-Stable Processes, and Independence from Irrelevant Attributes",0,0,0,0,0,1994,09,01
62,5,1994-09-01,"This paper introduces and characterizes a new class of solutions to cooperative bargaining problems that can be rationalized by generalized Gini orderings defined on the agents' utility gains. Generalized Ginis are orderings that can be represented by quasi-concave, nondecreasing functions that are linear in rank-ordered subspaces of Euclidean space. In the case of three or more agents, the authors' characterization of (multivalued) generalized Gini bargaining solutions uses a linear invariance requirement in addition to some standard conditions. In the two-person case, the generalized Gini bargaining solutions can be characterized with a weakening of linear invariance.","['Blackorby, Charles', 'Bossert, Walter', 'Donaldson, David']",['Bargaining Theory; Matching Theory'],['C78'],Generalized Ginis and Cooperative Bargaining Solutions,0,0,0,0,0,1994,09,01
62,5,1994-09-01,"The author proves an equivalence between large games with effective small groups of players and games generated by markets. Small groups are effective if all or almost all gains to collective activities can be achieved by groups bounded in size of membership. A market is an exchange economy where all participants have concave, quasi-linear payoff functions. The market approximating a game is socially homogeneous--all participants have the same monotonic nondecreasing, and 1-homogeneous payoff function. The author's results imply that any market (more generally, any economy with effective small groups) can be approximated by a socially homogeneous market.","['Wooders, Myrna Holtz']","['Game Theory and Bargaining Theory: General', 'General Equilibrium and Disequilibrium: General']","['C70', 'D50']",Equivalence of Games and Markets,0,0,0,0,0,1994,09,01
62,5,1994-09-01,"Strategic implications of the learning curve hypothesis are analyzed in the context of a price-setting, differentiated duopoly selling to a sequence of heterogeneous buyers with uncertain demands. A unique Markov perfect equilibrium is characterized and sufficient conditions are provided for market dominance to be self-reinforcing. Increasing market dominance implies that learning is privately disadvantageous. Finally, introducing avoidable fixed costs and possible exit into the model yields a new theory of predatory pricing based on the learning curve hypothesis.","['Riordan, Michael H.', 'Cabral, Luis M. B.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['D43', 'D83']","The Learning Curve, Market Dominance, and Predatory Pricing",0,0,1,0,0,1994,09,01
62,5,1994-09-01,"The authors provide a convergence theory for adaptive learning algorithms useful for the study of learning by economic agents. Their results extend the framework of L. Ljung previously utilized by A. Marcet-T. J. Sargent and M. Woodford by permitting nonlinear laws of motion driven by stochastic processes that may exhibit moderate dependence, such as mixing and mixingale processes. The authors draw on previous work by H. J. Kushner and D. S. Clark to provide readily verifiable and/or interpretable conditions ensuring algorithm convergence, chosen for their suitability in the context of adaptive learning.","['White, Halbert', 'Kuan, Chung-Ming']","['Econometric and Statistical Methods and Methodology: General', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C10', 'D83']",Adaptive Learning with Nonlinear Dynamics Driven by Dependent Processes,0,0,0,0,0,1994,09,01
62,5,1994-09-01,"The authors characterize the symmetric equilibria of an investment game with a pure informational externality. When the period length is very short, the game ends very quickly; with positive probability, an informational cascade (herding) causes an investment collapse. As the period length increases, the possibility of herding disappears. As the number of players increases, the rate of investment and the information flow are eventually independent of the number of players; adding more players simply increases the number who delay. In the limit, a period of low investment is followed by either an investment surge or a collapse.","['Gale, Douglas', 'Chamley, Christophe']","['Investment; Capital; Intangible Capital; Capacity', 'Asymmetric and Private Information; Mechanism Design']","['E22', 'D82']",Information Revelation and Strategic Delay in a Model of Investment,0,0,0,0,0,1994,09,01
62,5,1994-09-01,"A model with m buyers and m sellers is considered in which price is set to equate revealed demand and supply. In a Bayesian Nash equilibrium, each trader acts not as a price-taker but instead misrepresents his true demand/supply to influence price in his favor. This causes inefficiency. The authors show that, in any equilibrium, the amount by which a trader misreports is O(1/m) and the corresponding inefficiency is O(1/m[squared]). The indeterminacy and the inefficiency that is caused by the traders' bargaining behavior in small markets, thus, rapidly vanishes as the market increases in size.","['Satterthwaite, Mark A.', 'Rustichini, Aldo', 'Williams, Steven R.']","['Auctions', 'Exchange and Production Economies']","['D44', 'D51']",Convergence to Efficiency in a Simple Market with Incomplete Information,0,0,1,0,0,1994,09,01
62,5,1994-09-01,"The authors study repeated games in which players observe a public outcome that imperfectly signals the actions played. They provide conditions guaranteeing that any feasible, individually rational payoff vector of the stage game can arise as a perfect equilibrium of the repeated game with sufficiently little discounting. The central condition requires that there exist action profiles with the property that, for any two players, no two deviations--one by either player--give rise to the same probability distribution over public outcomes. The results apply to principal-agent, partnership, oligopoly, and mechanism-design models, and to one-shot games with transferable utilities.","['Maskin, Eric', 'Fudenberg, Drew', 'Levine, David I.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",The Folk Theorem with Imperfect Public Information,0,0,0,0,0,1994,09,01
62,4,1994-07-01,ECONLIT None Found,"['Austen-Smith, David']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Strategic Transmission of Costly Information,0,0,0,0,0,1994,07,01
62,4,1994-07-01,ECONLIT None Found,"['Wen, Quan']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],The 'Folk Theorem' for Repeated Games with Complete Information,0,0,0,0,0,1994,07,01
62,4,1994-07-01,ECONLIT None Found,"['Smith, Lones', 'Dutta, Prajit K.', 'Abreu, Dilip']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],The Folk Theorem for Repeated Games: A NEU Condition,0,0,0,0,0,1994,07,01
62,4,1994-07-01,ECONLIT None Found,"['Nehring, Klaus']","['Criteria for Decision-Making under Risk and Uncertainty', 'Consumer Economics: Theory']","['D81', 'D11']",On the Interpretation of Sarin and Wakker's 'A Simple Axiomatization of Nonadditive Expected Utility.',0,0,0,0,0,1994,07,01
62,4,1994-07-01,"The authors attempt to account for the covariances between stock markets and to assess their integration. They estimate a factor model for sixteen national stock market returns whose volatility is induced by changing volatility in the factors. Unanticipated returns depend on innovations in economic variables and 'unobservable' factors. Assets risk premia are linear combinations of the factors risk premia. The authors find that idiosyncratic risk is priced and the 'price of risk' is different across stock markets. Besides, only a small proportion of their covariances can be accounted for by 'observable' economic variables. Correlation changes are driven primarily by movements in 'unobservables.'","['Sentana, Enrique', 'King, Mervyn', 'Wadhwani, Sushil']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Volatility and Links between National Stock Markets,0,0,0,0,0,1994,07,01
62,4,1994-07-01,The authors analyze the Shapley value allocation of an economy with differential information. They address the following questions: How do coalitions of agents share their private information? How can one measure the information advantage or superiority of an agent? Is each agent's private information verifiable by other members of a coalition? Do coalitions of agents pool their private information? Do agents have an incentive to report their true private information? Do value allocations exist in an economy with differential information? The authors provide answers to each of these questions.,"['Krasa, Stefan', 'Yannelis, Nicholas C.']","['Asymmetric and Private Information; Mechanism Design', 'Cooperative Games']","['D82', 'C71']",The Value Allocation of an Economy with Differential Information,0,0,0,0,0,1994,07,01
62,4,1994-07-01,"This paper extends the general equilibrium model with incomplete markets to an open-ended future, thereby providing a natural setting for analyzing problems in macroeconomics. Two concepts of equilibrium are defined that prevent agents from entering into Ponzi schemes: the first is based on debt constraints and the second is based on a transversality condition that limits the rate of growth of debt. Under the assumption that agents are impatient (Mackey continuity of preferences) and have a degree of impatience that is bounded below, the two concepts of equilibrium are shown to coincide and lead to existence of equilibrium.","['Quinzii, Martine', 'Magill, Michael']",['Incomplete Markets'],['D52'],Infinite Horizon Incomplete Markets,0,0,0,0,0,1994,07,01
62,4,1994-07-01,"Suppose that the authors are interested in the distribution of a set of characteristics over a population. They study a precise sense in which this distribution can be said to be polarized and provide a theory of measurement. Polarization, as conceptualized here, is closely related to the generation of social tensions, to the possibilities of revolution and revolt, and to the existence of social unrest in general. The authors take special care to distinguish their theory from the theory of inequality measurement. They derive measures of polarization that are easily applicable to distributions of characteristics such as income and wealth.","['Ray, Debraj', 'Esteban, Joan']","['Conflict; Conflict Resolution; Alliances; Revolutions', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['D74', 'D63']",On the Measurement of Polarization,0,0,0,0,0,1994,07,01
62,4,1994-07-01,"A noncooperative implementation of the core is provided for games with transferable utility. The implementation obtained here is meant to reflect the standard motivation for the core as closely as possible. In the model proposed, time is continuous. This idealized treatment of time is most amenable for capturing an essential feature of the core--there is always time to reject a noncore proposal before it is consumated.","['Reny, Philip J.', 'Perry, Motty']",['Noncooperative Games'],['C72'],A Noncooperative View of Coalition Formation and the Core,0,0,0,0,0,1994,07,01
62,4,1994-07-01,"Two of the most important refinements of the Nash equilibrium concept for extensive form games are (trembling hand) perfect equilibrium and sequential equilibrium. It is shown here that, for almost all assignments of payoffs to outcomes, the sets of sequential and perfect equilibrium strategy profiles are identical. This result is obtained by exploiting the semialgebraic nature of equilibrium correspondences, following from a deep theorem of mathematical logic.","['Zame, William R.', 'Blume, Lawrence E.']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Existence and Stability Conditions of Equilibrium']","['C72', 'C73', 'C62']",The Algebraic Geometry of Perfect and Sequential Equilibrium,0,0,0,0,0,1994,07,01
62,4,1994-07-01,"Conditions are established under which there are equilibria (in various settings) described by ergodic Markov processes with a Borel state space S. Let [Rho](S) denote the probability measures on S, and let s [approaching] G(s) [is a subset of] [Rho](S) be a (possibly empty-valued) correspondence with closed graph. A non-empty measurable set J [is a subset of] S is self-justified if G(s) [intersects] [Rho](J) is not empty for all s [an element of] J. A Time-Homogeneous Markov Equilibrium (THME) for G is a self-justified set J and a measurable selection II: J [approaching] [Rho] (J) from the restriction of G to J. The paper gives sufficient conditions for existence of compact self-justified sets, and applies the theorem: If G is convex-valued and has a compact self-justified set, then G has an THME with an ergodic measure. Coauthors are J. Geanakoplos, A. Mas-Colell, and A. McLennan.","['Duffie, Darrell']","['Existence and Stability Conditions of Equilibrium', 'General Equilibrium and Disequilibrium: General']","['C62', 'D50']",Stationary Markov Equilibria,0,0,0,0,0,1994,07,01
62,3,1994-05-01,ECONLIT None Found,"['Smith, Richard J.', 'Pesaran, M. Hashem']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],A Generalized R[superscript]2 Criterion for Regression Models Estimated by the Instrumental Variables Method,0,0,0,0,0,1994,05,01
62,3,1994-05-01,ECONLIT None Found,"['Krishnan, Murugappa', 'Caballe, Jordi']",['General Financial Markets: General (includes Measurement and Data)'],[nan],Imperfect Competition in a Multi-security Market with Risk Neutrality,0,0,0,0,0,1994,05,01
62,3,1994-05-01,ECONLIT None Found,"['Sundaram, Rangarajan K.', 'Banks, Jeffrey S.']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],Switching Costs and the Gittins Index,0,0,0,0,0,1994,05,01
62,3,1994-05-01,"This paper considers the instrument variable and method-of-moments estimators, as generalizations of two-stage least squares and limited information maximum likelihood, of the coefficients of a single equation. Motivated by a simple principle, asymptotic distributions are derived based on a parameter sequence where both the number of instruments and the sample size increase. The approximations to the distributions provided by this sequence are more accurate than traditional ones. The instrument variable estimator appears to be inconsistent. The asymptotic covariance matrix of the method-of-moments estimator can be consistently estimated under the alternative parameter sequence. The resulting approximate confidence regions have exact levels very close to their nominal levels.","['Bekker, Paul A.']",['Multiple or Simultaneous Equation Models; Multiple Variables: General'],['C30'],Alternative Approximations to the Distributions of Instrumental Variable Estimators,0,0,0,0,0,1994,05,01
62,3,1994-05-01,The computation of large-scale nonlinear intertemporal optimization problems requires time aggregation. A procedure generally adopted is shown to introduce a dependency of the solution steady state to a specific choice of sequence of time intervals. The authors establish necessary and sufficient conditions to avoid this dependency. The result is a considerable improvement in the numerical accuracy of the time-aggregated approximation. The conditions apply to a broad class of models and prove useful in large-scale applied general-equilibrium modeling. This conclusion is highlighted by a comparison with a spectral-projection method using optimal orthogonal collocation as in K. L. Judd (1992).,"['Mercenier, Jean', 'Michel, Philippe']",['Computational Techniques; Simulation Modeling'],['C63'],Discrete-Time Finite Horizon Appromixation of Infinite Horizon Optimization Problems with Steady-State Invariance,0,0,0,0,0,1994,05,01
62,3,1994-05-01,"The distinction between nonatomicity and thick markets as the source of perfect competition is examined. The authors construct a model of an imperfectly competitive economy with a nonatomic continuum of traders and a continuum of differentiated commodities for which Walrasian equilibria exist. The failure of perfect competition is identified in two ways: individuals can affect prices and the core is strictly larger than the set of Walrasian allocations. By contrast, it is shown that, when markets are physically or economically thick (or both), then individuals cannot typically affect prices and the core always coincides with the set of Walrasian allocations.","['Zame, William R.', 'Ostroy, Joseph M.']",['Exchange and Production Economies'],['D51'],Nonatomic Economies and the Boundaries of Perfect Competition,0,0,0,0,0,1994,05,01
62,3,1994-05-01,"The full insurance model is tested using data from three poor, high-risk villages in the semi-arid tropics of southern India. The model presented here incorporates a number of salient features of the actual village economies. Although the model is rejected statistically, it does provide a surprisingly good benchmark. Household consumptions comove with village average consumption. More clearly, household consumptions are not much influenced by contemporaneous own income, sickness, unemployment, or other idiosyncratic shocks, controlling for village consumption (i.e., for village-level risk). There is evidence that the landless are less well insured than their village neighbors in one of the three villages.","['Townsend, Robert M.']","['Consumer Economics: Empirical Analysis', 'Criteria for Decision-Making under Risk and Uncertainty', 'Economic Development: Human Resources; Human Development; Income Distribution; Migration', 'Microeconomic Analyses of Economic Development']","['D12', 'D81', 'O15', 'O12']",Risk and Insurance in Village India,0,0,0,0,0,1994,05,01
62,3,1994-05-01,"After a critique of the traditional paradigms of regulation from the point of view of information economics, a canonical model of regulation under asymmetric information is developed. A survey of the main results obtained in the new economics of regulation is then provided, in particular concerning the implementation of optimal contracts by a menu of linear contracts, the dichotomy between pricing and cost reimbursement rules, the auctioning of incentive contracts, the dynamics of contracting under limited commitment, and the hierarchical problems in regulation. Empirical implications are then discussed and avenues of further research are described in the conclusion.","['Laffont, Jean-Jacques']",['Economics of Regulation'],['L51'],The New Economics of Regulation Ten Years After,1,0,0,0,0,1994,05,01
62,2,1994-03-01,ECONLIT None Found,"['Angrist, Joshua D.', 'Imbens, Guido W.']",['Model Construction and Estimation'],['C51'],Identification and Estimation of Local Average Treatment Effects,0,0,0,0,0,1994,03,01
62,2,1994-03-01,ECONLIT None Found,"['Sinclair-Desgagne, Bernard']",['Asymmetric and Private Information; Mechanism Design'],['D82'],The First-Order Approach to Multi-signal Principal-Agent Problems,0,0,0,0,0,1994,03,01
62,2,1994-03-01,"A recently developed quantile regression technique, which parsimoniously describes the entire conditional distribution, is applied to every March Current Population Survey since 1964. The study examines changes in the returns to schooling and experience at different points of the wage distribution and changes in within-group wage inequality. The results from the one-group and sixteen-group linear models show that the returns to schooling and experience differ across quantiles of the wage distribution but that their patterns of change are similar. Significant differences in wage inequality are also found across the various skill groups.","['Buchinsky, Moshe']",['Wage Level and Structure; Wage Differentials'],['J31'],Changes in the U.S. Wage Structure 1963-1987: Application of Quantile Regression,0,0,0,0,0,1994,03,01
62,2,1994-03-01,"This paper is concerned with the refined asymptotic properties of several tests for the admissibility of a subset of (overidentifying) instrumental variables. It derives maximum likelihood and linearized maximum likelihood tests and calculates size corrections to the order 1/T. The local power function of the size-corrected tests is the same to the order 1/T, irrespectively of the form of the test statistic or the limited information estimator used in its computation. Futher, it compares these tests with two previously proposed tests. The size and the power of the original and the size-corrected tests are compared by Monte Carlo experiments.","['Magdalinos, Michael A.']","['Multiple or Simultaneous Equation Models; Multiple Variables: General', 'Model Evaluation, Validation, and Selection']","['C30', 'C52']",Testing Instrument Admissibility: Some Refined Asymptotic Results,0,0,0,0,0,1994,03,01
62,2,1994-03-01,"The Bertrand-Edgeworth model describes competition among price setting sellers with production capacity constraints. The authors report on laboratory experiments that permit evaluation of different theories of Bertrand-Edgeworth competition: competitive pricing, Edgeworth cycles in prices, mixed strategy Nash equilibrium pricing, and tacit collusion. Each of the theories helps to explain some aspects of the data. However, none of these theories are completely consistent with the data. In relative terms, the Edgeworth cycle theory provides better predictions of key aspects of the data than the other theories. Coauthors are Stephen Rassenti, Stanley S. Reynolds, and Vernon L. Smith.","['Brown-Kruse, Jamie']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D43', 'L13']",Bertrand-Edgeworth Competition in Experimental Markets,1,0,1,0,0,1994,03,01
62,2,1994-03-01,"In this paper we study the indeterminacy of equilibria in infinite horizon capital accumulation models with technological externalities. Our investigation encompasses both models with bounded and unbounded accumulation paths, and models with one and two sectors of production. Under reasonable assumptions we find that equilibria are locally unique in the one sector economies. The situation is different in economies with two sectors of production. Here it is very easy to construct analytical examples where a positive external effect induces a two dimensional manifold of equilibria converging to the same steady state (in the bounded case) or to the constant growth rate (in the unbounded case). For the latter we also point out that the dynamic behavior of these equilibria is quite complicated and that persistent fluctuations in their growth rates are possible.","['Boldrin, Michele', 'Rustichini, Aldo']","['One, Two, and Multisector Growth Models']",['O41'],Growth and Indeterminacy in Dynamic Models with Externalities,0,0,0,0,0,1994,03,01
62,2,1994-03-01,"The R. E. Lucas (1978) general equilibrium model of asset prices is extended to admit beliefs that are represented by a (nonsingleton) set of probability measures. A primary motivation is evidence, such as the Ellsberg paradox, that people are averse to vague or imprecise probabilities. Intertemporal utility functions embodying such aversion are formulated and then, in the context of a Lucas-style economy, the existence and characterization of equilibria are addressed. A noteworthy feature is that (under specified conditions) equilibria are indeterminate. Therefore, 'animal spirits' may play a role and sizable price volatility may result.","['Wang, Tan', 'Epstein, Larry G.']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Intertemporal Asset Pricing Under Knightian Uncertainty,0,0,0,0,0,1994,03,01
62,2,1994-03-01,"It has been emphasized that when contracts are incomplete (e.g., because some relevant variables are not verifiable by outsiders), the possibility of contract negotiation may prevent achieving desirable allocations that could be implemented otherwise. The authors analyze a situation where renegotiation is always possible but contracts can influence the renegotiation process; they show that some flexibility in the choice of this process allows to achieve efficiency in a variety of situations, including optimal risk-sharing and investment decisions.","['Aghion, Philippe', 'Rey, Patrick', 'Dewatripont, Mathias']","['Transactional Relationships; Contracts and Reputation; Networks', 'Asymmetric and Private Information; Mechanism Design']","['L14', 'D82']",Renegotiation Design with Unverifiable Information,1,0,0,0,0,1994,03,01
62,1,1994-01-01,ECONLIT None Found,"['Mehta, Ghanshyam B.', 'Beardon, Alan F.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],"The Utility Theorems of Wold, Debreu, and Arrow-Hahn",0,0,0,0,0,1994,01,01
62,1,1994-01-01,"The authors derive a necessary and sufficient condition for the solution set of an optimization problem to be monotonic in the parameters of the problem. In addition, they develop practical methods for checking the condition and demonstrate its applications to the classical theories of the competitive firm, the monopolist, the Bertrand oligopolist, consumer and growth theory, game theory, and general equilibrium analysis.","['Shannon, Chris', 'Milgrom, Paul']","['Mathematical Methods; Programming Models; Mathematical and Simulation Modeling: General', 'Noncooperative Games']","['C60', 'C72']",Monotone Comparative Statics,0,0,0,0,0,1994,01,01
62,1,1994-01-01,This paper analyzes movements of older men among labor force states using quarterly observations from the Retirement History Survey. These data indicate that the incidence of labor force movements at older ages has been underestimated previously. The quarterly data reveal a much sharper spike in the exit rate at exact age 65 than is found in annual or biannual data. Estimates of a model of labor force transitions indicate that social security benefits have strong effects on transition rates but that changes in social security benefits over time have not contributed much to the trend toward earlier labor force exit.,"['Blau, David M.']","['Retirement; Retirement Policies', 'Economics of Gender; Non-labor Discrimination']","['J26', 'J16']",Labor Force Dynamics of Older Men,0,0,0,0,0,1994,01,01
62,1,1994-01-01,"The author develops a practical extension of D. McFadden's method of simulated moments estimator for limited dependent variable models to the panel data case. The method is based on factorization of the method of simulated moments first order condition into transition probabilities, along with development of an accurate new method for simulating transition probabilities. Monte Carlo tests indicate that this method of simulated moments estimator performs quite well relative to quadrature-based maximum likelihood estimators. It allows estimation of complex panel data models involving random effects and ARMA errors in computational time similar to those necessary for estimation of random effects models via maximum likelihood quadrature.","['Keane, Michael P.']",['Single Equation Models; Single Variables: Panel Data Models; Spatio-temporal Models'],['C23'],A Computationally Practical Simulation Estimator for Panel Data,0,0,0,0,0,1994,01,01
62,1,1994-01-01,"The author derives some exact finite sample disbibutions and characterizes the tail behavior of maximum likelihood estimators of the cointegrating coefficients in error correction models. The reduced rank regression estimator has a distribution with Cauchy-like tails and no finite moments of integer order. The maximum likelihood estimator of the coefficients in a particular triangular system representation has matrix t-distribution tails with finite integer moments to order T - n + r, where T is the sample size, n is the total number of variables, and r is the dimension of cointegration space. This helps explain some recent simulation studies where extreme outliers occur more frequently for the reduced rank regression estimator than for alternative asymptotically efficient procedures based on triangular representation.","['Phillips, Peter C. B.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Some Exact Distribution Theory for Maximum Likelihood Estimators of Cointegrating Coefficients in Error Correction Models,0,0,0,0,0,1994,01,01
62,1,1994-01-01,"This paper provides a general framework for proving the ""square root of"" T-consistency and asymptotic normality of a wide variety of semiparametric estimators. The class of estimators considered consists of estimators that can be defined as the solution to a minimization problem based on a criterion function that may depend on a preliminary infinite dimensional nuisance parameter estimator. The method of proof exploits results concerning the stochastic equicontinuity of stochastic processes. The results are applied to the problem of semiparametric weighted least squares estimation of partially parametric regression models. Primitive conditions are given for ""square root of"" T-consistency and asymptotic normality of this estimator.","['Andrews, Donald W. K.']",['Semiparametric and Nonparametric Methods: General'],['C14'],Asymptotics for Semiparametric Econometric Models via Stochastic Equicontinuity,0,0,0,0,0,1994,01,01
62,1,1994-01-01,"Researchers often employ ARCH models to estimate conditional variances and covariances. How successfully can misspecified ARCH models carry out this estimation? This paper employs continuous record asymptotics to approximate the distribution of the measurement error. This allows the authors to (1) compare the efficiency of various ARCH models, (2) characterize the impact of different kinds of misspecification on efficiency, and (3) characterize asymptotically optimal ARCH conditional variance estimates. They apply their results to derive optimal ARCH filters for three diffusion models, and to examine in detail the filtering properties of GARCH(1,1), AR(1) EGARCH, and the model of S. Taylor (1986) and G. W. Schwert (1989).","['Foster, Dean P.', 'Nelson, Daniel B.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Asymptotic Filtering Theory for Univariate ARCH Models,0,0,0,0,0,1994,01,01
76,5,2008-09-01,ECONLIT None Found,"['Hansen, Lars Peter']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2007 REPORT OF THE PRESIDENT.",0,0,0,0,0,2008,09,01
76,3,2008-05-01,ECONLIT None Found,"['Moulines, Eric', 'Hurvich, Clifford M.', 'Soulier, Philippe']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models']","['C22', 'C32']",Corrigendum to 'Estimating Long Memory in Volatility',0,0,0,0,0,2008,05,01
61,6,1993-11-01,ECONLIT None Found,"['Gary-Bobo, Robert J.', 'Bensaid, Bernard']","['Cooperative Games', 'Transactional Relationships; Contracts and Reputation; Networks']","['C71', 'L14']",Commitment Value of Contracts under Renegotiation Constraints,1,0,0,0,0,1993,11,01
61,6,1993-11-01,"Systems of consumer expenditure functions are estimated from Norwegian household panel data. Total consumption expenditure is modeled as a latent variable, as indicators of it are purchase expenditures on different goods and two income measures. The usual assumption of no measurement error in total expenditure is clearly rejected while a parsimonious alternative is not. The authors test hypotheses regarding the distribution of measurement errors, the evolution of the distribution of latent total expenditure across households, the distribution of individual differences in preferences, and the possible correlation between preferences and latent total expenditure.","['Biorn, Erik', 'Skjerpen, Terje', 'Aasness, Jorgen']","['Consumer Economics: Empirical Analysis', 'Model Construction and Estimation']","['D12', 'C51']","Engel Functions, Panel Data, and Latent Variables",0,0,0,0,0,1993,11,01
61,6,1993-11-01,"A limit theory for Wald tests of Granger causality in levels vector autoregressions (VAR's) and error correction models (ECM's) is developed, which allows for stochastic trends and cointegration. Earlier work is extended to the general case, thereby characterizing when these Wald tests are asymptotically valid as 'x'(superscript 2) criteria. Our results for inference from unrestricted levels VAR are not encouraging: the limit theory often involves nuisance parameters and nonstandard distributions, a situation offering no satisfactory statistical basis for these tests. Granger causality tests in ECM's also suffer from nuisance parameter dependencies asymptotically and in some cases nonstandard limit theory. Both these results are somewhat surprising in light of earlier research.","['Phillips, Peter C. B.', 'Toda, Hiro Y.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Vector Autoregressions and Causality,0,0,0,0,0,1993,11,01
61,6,1993-11-01,"A social welfare function f is Arrowian if it has transitive values and satisfies Arrow's independence axiom. For any fraction t and any Arrowian f, either there will be some individual who dictates on a subset containing at least the fraction t of outcomes, or at least the fraction 1 minus t of the pairs of outcomes have their social ranking fixed independently of individual preference. And for any Arrowian f, there is a set containing a large fraction of the citizens whose preferences are never consulted in determining the social ranking of a large fraction of the pairs of alternatives.","['Kelly, Jerry S.', 'Campbell, Donald E.']",['Social Choice; Clubs; Committees; Associations'],['D71'],t or 1 minus t. That Is the Trade-Off,0,0,0,0,0,1993,11,01
61,6,1993-11-01,"This paper considers economies involving one public good, one private good, and convex technology and proposes an informationally decentralized dynamic nontatonnement procedure that converges in general from the initial endowments to an allocation in the core. The procedure may be seen as enunciating a plausible method of cooperation among the agents for achieving an optimal provision of a public good and an equitable sharing of its cost. The viewpoint of noncooperative game theory is also considered and it is shown that there exists a trade-off between the requirements of local incentive compatibility and equitable cost sharing.","['Chander, Parkash']",['Public Goods'],['H41'],Dynamic Procedures and Incentives in Public Good Economies,0,0,0,0,0,1993,11,01
61,6,1993-11-01,"This paper presents a game of strategic bargaining under deadlines whose equilibrium conforms to anecdotal and experimental information about real-life bargaining sessions. The model operates in continuous time and incorporates possible strategic delay and imperfect player control over the timing of offers (modeled by means of an exogenous random delay). In the unique symmetric Markov-perfect equilibrium, players adopt strategic delay early in the game, make and reject offers later on, and usually reach agreements late in the game, though they miss the deadline with positive probability. The expected division of the surplus is close to an even split.","['Manove, Michael', 'Ma, Ching-To Albert']",['Bargaining Theory; Matching Theory'],['C78'],Bargaining with Deadlines and Imperfect Player Control,0,0,0,0,0,1993,11,01
61,6,1993-11-01,"A dynamic model with many sellers and buyers is constructed. Agents failing to trade may trade in the next period. An equilibrium is found where sellers hold identical auctions and buyers randomize over the sellers they visit. The distribution of buyer valuations is endogenous. An auction with efficient reserve is an optimal mechanism from each seller's point of view, in spite of the ability of any seller to alter the distribution of buyer types participating in the seller's mechanism by altering the mechanism.","['McAfee, R. Preston']","['Auctions', 'Asymmetric and Private Information; Mechanism Design']","['D44', 'D82']",Mechanism Design by Competing Sellers,0,0,1,0,0,1993,11,01
61,6,1993-11-01,"The debate between the North and the South about the enforcement of intellectual property rights is examined within a dynamic general equilibrium framework in which the North invents new products and the South imitates them. A welfare evaluation of a policy of tighter intellectual property rights is provided by decomposing its response into four items: (1) terms of trade; (2) production composition; (3) available products; and (4) intertemporal allocation of consumption The paper proceeds in stages. It begins with an exogenous rate of innovation in order to focus on the first two elements. The following two components are added by endogenizing the rate of innovation. Finally, foreign direct investment is added to the model.","['Helpman, Elhanan']","['Intellectual Property and Intellectual Capital', 'Innovation and Invention: Processes and Incentives']","['O34', 'O31']","Innovation, Imitation, and Intellectual Property Rights",0,0,0,1,0,1993,11,01
61,5,1993-09-01,ECONLIT None Found,"['Kalai, Ehud', 'Lehrer, Ehud']",['Noncooperative Games'],['C72'],Subjective Equilibrium in Repeated Games,0,0,0,0,0,1993,09,01
61,5,1993-09-01,ECONLIT None Found,"['Fraysse, Jean']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Common Agency: Existence of an Equilibrium in the Case of Two Outcomes,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"Weighted average derivatives are useful parameters for semiparametric index models and nonparametric demand analysis. This paper gives efficiency results for average derivative estimators, including formulating estimators that have high efficiency. The authors derive the efficiency bound for weighted average derivatives of conditional location functionals, such as the conditional mean and median. They also derive the efficiency bound for semiparametric index models, where the location measure depends on indices or linear combinations of the regressors. The authors derive the efficient weight function when the distribution of the regressors is elliptically symmetric. They also discuss how to combine estimators with different known weight functions to achieve efficiency.","['Stoker, Thomas M.', 'Newey, Whitney K.']","['Semiparametric and Nonparametric Methods: General', 'Model Construction and Estimation']","['C14', 'C51']",Efficiency of Weighted Average Derivative Estimators and Index Models,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"This paper reports estimates of the primitive parameters of a stochastic control model describing the labor decisions of West African small farmers. Maximum likelihood estimates are computed although optimal labor decision rules cannot be derived analytically. Vuong's non-nested model specification test shows that this method yields estimates superior to those derived by assuming that farmers solve a deterministic control problem. Low levels of labor effort are shown to be a consequence of low labor productivity in archaic rain-fed agriculture and of farmers' awareness that, in the absence of a labor market, overly ambitious production plans lead to seasonal manpower shortages.","['Fafchamps, Marcel']","['Micro Analysis of Farm Firms, Farm Households, and Farm Input Markets', 'Agricultural Labor Markets']","['Q12', 'J43']",Sequential Labor Decisions under Uncertainty: An Estimable Household Model of West-African Farmers,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"It is shown that any informationally decentralized mechanism that realizes fair allocations over the class of classical pure exchange environments has a message space of dimension no smaller than the number of agents times the number of commodities. Since the equal income Walrasian mechanism, in which all agents take prices parametrically and maximize utility subject to the average income constraint, realizes fair outcomes over the class of classical pure exchange environments and has a message space of that dimension, it is informationally efficient. Further, it is shown that it is the unique informationally efficient mechanism realizing fair allocations.","['Kirman, Alan', 'Calsamiglia, Xavier']","['Asymmetric and Private Information; Mechanism Design', 'Allocative Efficiency; Cost-Benefit Analysis']","['D82', 'D61']",A Unique Informationally Efficient and Decentralized Mechanism with Fair Outcomes,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"In a decision-theoretic model of a firm, the author represents managers as information processors of limited capacity; efficiency is measured in terms of (1) the number of processors and (2) the delay between the receipt of information by the organization and the implementation of the decision. The author characterizes efficient networks for both one-shot and repeated regimes, as well as the corresponding 'production function' relating the number of items processed to the number of processors and the delay. He sketches some applications to common decision paradigms, and implications for decentralization and organizational returns to scale.","['Radner, Roy']","['Firm Organization and Market Structure', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['L22', 'D83']",The Organization of Decentralized Information Processing,1,0,0,0,0,1993,09,01
61,5,1993-09-01,"The authors design and study an OLG experimental economy where the government finances a fixed real deficit through seigniorage. The economy has continua of nonstationary rational expectations equilibria and two stationary rational expectations equilibria. The authors do not observe nonstationary rational expectations paths. Observed paths tend to converge close to, or somewhat below, the low inflation stationary state. The adaptive learning hypothesis is consistent with the data in selecting the low inflation stationary state rational expectations equilibrium as a long-run stationary equilibrium. Nevertheless, simple adaptive learning models do not capture the market uncertainty or the biases observed in the data.","['Marimon, Ramon', 'Sunder, Shyam']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Price Level; Inflation; Deflation']","['D83', 'E31']",Indeterminacy of Equilibria in a Hyperinflationary World: Experimental Evidence,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"This paper discusses the dynamic implications of learning in a large population coordination game, focusing on the structure of the matching process that describes how players meet. As in M. Kandori, G. Mailath, and R. Rob (1992), experimentation and myopia create 'evolutionary' forces that lead players to coordinate on the risk dominant equilibrium. To describe play with finite time horizons, it is necessary to consider the rates at which the dynamic systems converge. In large populations with uniform matching, play is determined largely by historical factors. When players interact with small sets of neighbors, evolutionary forces may determine the outcome.","['Ellison, Glenn']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']","Learning, Local Interaction, and Coordination",0,0,0,0,0,1993,09,01
61,5,1993-09-01,"Subjective utility maximizers, in an infinitely repeated game, will learn to predict opponents' future strategies and will converge to play according to a Nash equilibrium of the repeated game. Players' initial uncertainty is placed directly on opponents' strategies and the above result is obtained under the assumption that the individual beliefs are compatible with the chosen strategies. An immediate corollary is that, when playing a Harsanyi-Nash equilibrium of a repeated game of incomplete information about opponents' payoff matrices, players will eventually play a Nash equilibrium of the real game, as if they had complete information.","['Kalai, Ehud', 'Lehrer, Ehud']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']",Rational Learning Leads to Nash Equilibrium,0,0,0,0,0,1993,09,01
61,5,1993-09-01,"A global game is an incomplete information game where the actual payoff structure is determined by a random draw from a given class of games and where each player makes a noisy observation of the selected game. For 2 x 2 games, it is shown that, when the noise vanishes, iterated elimination of dominated strategies in the global game forces the players to conform to J. C. Harsanyi and R. Selten's risk dominance criterion.","['Carlsson, Hans', 'van Damme, Eric']",['Noncooperative Games'],['C72'],Global Games and Equilibrium Selection,0,0,0,0,0,1993,09,01
61,4,1993-07-01,ECONLIT None Found,"['Back, Kerry', 'Brown, David P.']",['Estimation: General'],['C13'],Implied Probabilities in GMM Estimators,0,0,0,0,0,1993,07,01
61,4,1993-07-01,ECONLIT None Found,"['Erickson, Timothy']","['Single Equation Models; Single Variables: General', 'Model Construction and Estimation']","['C20', 'C51']",Restricting Regression Slopes in the Errors-in-Variables Model by Bounding the Error Correlation,0,0,0,0,0,1993,07,01
61,4,1993-07-01,ECONLIT None Found,"['Dana, Rose Anne']",['Exchange and Production Economies'],['D51'],Existence and Uniqueness of Equilibria When Preferences Are Additively Separable,0,0,0,0,0,1993,07,01
61,4,1993-07-01,"This paper provides a simulated moments estimator of the parameters of dynamic models in which the state vector follows a time-homogeneous Markov process. Conditions are provided for both weak and strong consistency as well as asymptotic normality. Various trade-offs among the regularity conditions underlying the large sample properties of the simulated moments estimator are discussed in the context of an asset-pricing model. Geometric ergodicity of the underlying Markov process plays a central role in the analysis, ensuring that the simulated processes are asymptotically stationary with an ergodic distribution that is independent of starting values.","['Singleton, Kenneth J.', 'Duffie, Darrell']","['Model Construction and Estimation', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', 'C22', nan]",Simulated Moments Estimation of Markov Models of Asset Prices,0,0,0,0,0,1993,07,01
61,4,1993-07-01,"The authors derive low frequency, say weekly, models implied by high frequency, say daily, ARMA models with symmetric GARCH errors. They show that low frequency models exhibit conditional heteroskedasticity of the GARCH form as well. The parameters in the conditional variance equation of the low frequency model depend upon mean, variance, and kurtosis parameters of the corresponding high frequency model. Moreover, strongly consistent estimators of the parameters in the high frequency model can be derived from low frequency data. The common assumption in applications that rescaled innovations are independent is disputable, since it depends upon the available data frequency.","['Drost, Feike C.', 'Nijman, Theo E.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Temporal Aggregation of GARCH Processes,0,0,0,0,0,1993,07,01
61,4,1993-07-01,Methods for nonlinear impulse response analysis are introduced. The methods are based on conditional moment profiles defined for a stationary time series. Comparing conditional moment profiles to baseline profiles is the nonlinear analog of conventional impulse-response analysis. The bootstrap may be used for statistical inference. Profile bundles may be examined for evidence of damping or persistence. Application to bivariate NYSE price and volume series from 1928 to 1987 finds evidence of a heavily damped 'leverage effect' and a differential response of trading volume to 'common-knowledge' price shocks.,"['Tauchen, George', 'Rossi, Peter E.', 'Gallant, A. Ronald']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Nonlinear Dynamic Structures,0,0,0,0,0,1993,07,01
61,4,1993-07-01,"Formulas are derived for computing asymptotic covariance matrices of sets of impulse responses, step responses, or variance decompositions of estimated dynamic simultaneous-equations models in vector autoregressive moving-average (VARMA) form. Computed covariances would be used to test linear restrictions on sets of impulse responses, step responses, or variance decompositions. The results unify and extend previous formulas to handle any model in VARMA form, provide accurate computations based on analytic derivates, and provide insights into the structures of the asymptotic covariances.","['Mittnik, Stefan', 'Zadrozny, Peter A.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],"Asymptotic Distributions of Impulse Responses, Step Responses, and Variance Decompositions of Estimated Linear Dynamic Models",0,0,0,0,0,1993,07,01
61,4,1993-07-01,This paper considers tests for parameter instability and structural change with unknown change point. The results apply to a wide class of parametric models that are suitable for estimation by generalized method of moments procedures. The asymptotic distributions of the test statistics considered here are nonstandard because the change point parameter only appears under the alternative hypothesis and not under the null. The tests considered here are shown to have nontrivial asymptotic local power against all alternatives for which the parameters are nonconstant. The tests are found to perform quite well in a Monte Carlo experiment reported elsewhere.,"['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Tests for Parameter Instability and Structural Change with Unknown Change Point,0,0,0,0,0,1993,07,01
61,4,1993-07-01,"Efficient estimators of cointegrating vectors are presented for systems involving deterministic components and variables of differing, higher orders of integration. The estimators are computed using GLS or OLS, and Wald statistics constructed from these estimators have asymptotic x [superscript] 2 distributions. These and previously proposed estimators of cointegrating vectors are used to study long-run U.S. money (M1) demand. M1 demand is found to be stable over 1900-1989; the 95 percent confidence intervals for the income elasticity and interest rate semielasticity are (0.88, 1.06) and (-0.13, -0.08), respectively. Estimates based on the postwar data alone, however, are unstable, with variances which indicate substantial sampling uncertainty.","['Stock, James H.', 'Watson, Mark W.']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Demand for Money']","['C32', 'E41']",A Simple Estimator of Cointegrating Vectors in Higher Order Integrated Systems,0,0,0,0,0,1993,07,01
61,4,1993-07-01,"This paper examines how the possibility of renegotiation affects contractual outcomes in signaling games when an infinite number of rounds of renegotiations are allowed before contracts are executed. The main results of the paper are (1) contracts may still contain distortions, (2) the popular 'efficient' separating-equilibrium outcome is never an equilibrium outcome with renegotiation, (3) incentive-compatibility constraints can be generalized to incorporate renegotiation, (4) equilibrium outcomes can be separating and nevertheless depend on the uninformed player's prior, and (5) renegotiation in signaling games may lead to outcomes similar to equilibrium outcomes of screening games in which multiple contract purchases are allowed.","['Beaudry, Paul', 'Poitevin, Michel']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Signalling and Renegotiation in Contractual Relationships,0,0,0,0,0,1993,07,01
61,3,1993-05-01,ECONLIT None Found,"['Robinson, P. M.']",['Hypothesis Testing: General'],['C12'],Highly Insignificant F-Ratios,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"This paper studies the role and implications of price advertising when shopping trips are costly to consumers. The authors present a model where consumers search sequentially and where stores advertise the price. Their model has a unique equilibrium exhibiting price dispersion. The model generates predictions about the shape of the price distribution and firms' advertising behavior. Also when the initial advertising costs are precisely zero, entry drives the equilibrium to the perfectly competitive outcome; while otherwise entry drives prices higher. Finally, when advertising costs shrink, prices become competitive; however, when search costs shrink, prices remain bounded above marginal production costs.","['Robert, Jacques', 'Stahl, Dale O., II']","['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness', 'Advertising']","['D83', 'M37']",Informative Price Advertising in a Sequential Search Model,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"In this model, shareholders can use auditors' reports to contract with a privately-informed manager. Imperfect audit technology allows the auditor and the manager to collude. Auditors are useful when they have good information and the manager's liability is high. Expected maximum deterrence is not desirable and production is suboptimal, even with unbounded punishments. Raising the manager's punishment raises the bribe he may offer the auditor, which raises the cost of preventing collusion. The authors also distinguish internal auditors (costless but collusive) from external ones (costly but not collusive) and show that the optimal contract may specify random external audits.","['Kofman, Fred', 'Lawarree, Jacques']","['Asymmetric and Private Information; Mechanism Design', 'Accounting', 'Organizational Behavior; Transaction Costs; Property Rights']","['D82', 'M41', 'D23']",Collusion in Hierarchical Agency,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"Three theorems state conditions sufficient for the inessentiality of equilibrium in a pure exchange, sequence economy. The agents have uncommon priors, state-contingent utility functions, and asymmetric information in every trading period, and they trade different sets of event-contingent claims in different periods. The theorems provide alternative interpretations of the concept of market completeness, reveal two fundamentally different ways to obtain inessentiality, and shed light on the conditions permitting speculation and the role of price-contingent trading. None of the theorems requires ex ante Pareto optimality or the absence of arbitrage opportunities.","['Stegeman, Mark']",['Exchange and Production Economies'],['D51'],Sufficient Conditions for Inessentiality,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"This paper introduces the concept of standard risk aversion. A von Neumann-Morgenstern utility function has standard risk aversion if every risk that has a negative interaction with a small reduction in wealth also has a negative interaction with any undesirable, independent risk. It is shown that, given monotonicity and concavity, the combination of decreasing absolute risk aversion and decreasing absolute prudence is necessary and sufficient for standard risk aversion. Standard risk aversion is shown to imply not only Pratt and Zeckhauser's 'proper risk aversion' (an undesirable risk always remaining undesirable in the presence of an independent undesirable risk), but also that being forced to face an undesirable risk reduces the optimal investment in a risky security with an independent return.","['Kimball, Miles S.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Standard Risk Aversion,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"The authors consider the problem of allocating a bundle of commodities among a group of agents who are collectively entitled to them. It is proved that, for an atomless economy with possibly satiated preferences, any solution that is efficient, equitable, and consistent must select allocations that are supported by equal-budget Walrasian equilibria with slack.","['Thomson, William', 'Zhou, Lin']",['Exchange and Production Economies'],['D51'],Consistent Solutions in Atomless Economies,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"The authors study the steady states of a system in which players learn about the strategies their opponents are playing by updating their Bayesian priors in light of their observations. Players are matched at random to play a fixed extensive-form game and each player observes the realized actions in his own matches but not the intended off-path play of his opponents or the realized actions in other matches. Because players are assumed to live finite lives, there are steady states in which learning continually takes place. If lifetimes are long and players are very patient, the steady state distribution of actions approximates those of a Nash equilibrium.","['Fudenberg, Drew', 'Levine, David K.']","['Noncooperative Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D83']",Steady State Learning and Nash Equilibrium,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"In a self-confining equilibrium, each player's strategy is a best response to his beliefs about the play of his opponents and each player's beliefs are correct along the equilibrium path of play. Thus, if a self-confirming equilibrium occurs repeatedly, no player ever observes play that contradicts his beliefs, even though beliefs about play at off-path information sets need not be correct. The authors characterize the ways in which self-confirming equilibria and Nash equilibria can differ and provide conditions under which self-confirming equilibria correspond to standard solution concepts.","['Fudenberg, Drew', 'Levine, David K.']",['Noncooperative Games'],['C72'],Self-Confirming Equilibrium,0,0,0,0,0,1993,05,01
61,3,1993-05-01,"Internal consistency of choice has been a central concept in economics, decision theory, and social choice. This idea is essentially confused. We cannot determine whether a choice function is consistent without referring to something external to choice (e.g., objectives, values). The standard results have to be reexamined in this light. Kenneth J. Arrow's general possibility theorem is extended in this paper without demanding any internal consistency of social choice or any notion of 'social rationality.'","['Sen, Amartya']","['Microeconomics: General', 'Social Choice; Clubs; Committees; Associations']","['D00', 'D71']",Internal Consistency of Choice,0,0,0,0,0,1993,05,01
61,2,1993-03-01,ECONLIT None Found,"['Borgers, Tilman']","['Noncooperative Games', 'Stochastic and Dynamic Games; Evolutionary Games; Repeated Games']","['C72', 'C73']",Pure Strategy Dominance,0,0,0,0,0,1993,03,01
61,2,1993-03-01,"This paper proposes an estimator for discrete choice models that makes no assumption concerning the functional form of th e choice probability function where this function can be characterized by an index. The estimator is shown to be consistent, asymptotically normally distributed, and to achieve the semiparametric efficiency bound. Monte Carlo evidence indicates that there may be only modest efficiency losses relative to maximum likelihood estimation when the distribution of the disturbances is known and that the small-sample behavior of the estimator in other cases is good.","['Spady, Richard H.', 'Klein, Roger W.']",['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities'],['C25'],An Efficient Semiparametric Estimator for Binary Response Models,0,0,0,0,0,1993,03,01
61,2,1993-03-01,"This paper specifies and empirically analyzes a continuous-time, linear-quadratic, representative consumer model wit h time-nonseparable preferences of several forms. Within this framewor k, the author shows how time aggregation and time nonseparabilities in preferences over consumption streams can interact. The behavior of b oth seasonally adjusted and unadjusted consumption data is consistent wi th time-nonseparable preferences if consumption goods are durable and i f individuals develop habit over the flow of services from the good. T he data do not support a version of the model that ignores time nonseparabilities in preferences and focuses solely upon time aggregation.","['Heaton, John']","['Macroeconomics: Consumption; Saving; Wealth', 'Intertemporal Household Choice; Life Cycle Models and Saving']","['E21', 'D15']",The Interaction between Time-Nonseparable Preferences and Time Aggregation,0,0,0,0,0,1993,03,01
61,2,1993-03-01,"A two-person game is of conflicting interests if the strategy to which player one would most like to commit herself holds player two down to his minimax payoff. Suppose there is a positive prior probability that player one is a ""commitme nt type"" who will always play this strategy. Then player one will get a t least her commitment payoff in any Nash equilibrium of the repeated game if her discount factor approaches one. This result is robust against further perturbations of the informational structure and in striking contrast to the message of the Folk theorem for games with incomplete information.","['Schmidt, Klaus M.']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Noncooperative Games']","['C73', 'C72']",Reputation and Equilibrium Characterization in Repeated Games with Conflicting Interests,0,0,0,0,0,1993,03,01
61,2,1993-03-01,Perfect equilibria of finitely repeated games may be vulnerable to the possibility of renegotiation among players. The authors study the limiting properties of the set of payoffs from equilibria that are immune to renegotiation. Their main result is th at the limit of the set of payoffs from renegotiation-proof equilibria is either a singleton or a connected subset of the Pareto efficient frontier. A simple sufficient condition for the latter to occur is a lso provided.,"['Krishna, Vijay', 'Benoit, Jean-Pierre']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Cooperative Games']","['C73', 'C71']",Renegotiation in Finitely Repeated Games,0,0,0,0,0,1993,03,01
61,2,1993-03-01,"There is a tension between a belief in the strategic relevance of information sets and subgames and a belief in the sufficiency of the reduced normal form. The authors identify a prope rty of extensive form information sets and subgames termed strategic independence. Strategic independence is captured by the reduced norm al form and can be used to define normal form information sets and subgames. The authors prove a close relationship between these norma l form structures and their extensive form namesakes. They then motiva te and implement solution concepts corresponding to subgame perfection, sequential equilibrium, and forward induction entirely in the reduce d normal form.","['Swinkels, Jeroen M.', 'Mailath, George J.', 'Samuelson, Larry']",['Noncooperative Games'],['C72'],Extensive Form Reasoning in Normal Form Games,0,0,0,0,0,1993,03,01
61,2,1993-03-01,This lecture surveys recent models of growth and trade in search of descriptions of technologies that are consistent with episodes of very rapid income growth. Emphasis is placed on the on-the-job accumulation of human capital: learning by doing. Possib le connections between learning rates and international trade are discussed,"['Lucas, Robert E., Jr.']","['One, Two, and Multisector Growth Models', 'Economic Growth of Open Economies', 'Macroeconomic Analyses of Economic Development', 'Technological Change: Choices and Consequences; Diffusion Processes', 'Human Capital; Skills; Occupational Choice; Labor Productivity']","['O41', 'F43', 'O11', 'O33', 'J24']",Making a Miracle,0,0,0,1,0,1993,03,01
61,1,1993-01-01,ECONLIT None Found,"['Watson, Joel']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Asymmetric and Private Information; Mechanism Design']","['C73', 'D82']",A 'Reputation' Refinement without Equilibrium,0,0,0,0,0,1993,01,01
61,1,1993-01-01,ECONLIT None Found,"['Karni, Edi']",['Bayesian Analysis: General'],['C11'],A Definition of Subjective Probabilities with State-Dependent Preferences,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"A common finding in many of the recent empirical studies with the ARCH class of models applied to high frequency financial data concerns the apparent persistence of shocks for forecast of the future conditional variances. It is likely that several different variables share this same implied long-run component, however. In that situation, the variables are defined to be copersistent in variance. Conditions for copersistence to occur in the linear multivariate GARCH model are presented. These conditions parallel the conditions for linear cointegration in the mean. A simple empirical example with foreign exchange rate data illustrates the ideas.","['Bollerslev, Tim', 'Engle, Robert F.']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes']","['C32', 'C22']",Common Persistence in Conditional Variances,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"First-order autoregressive/unit root models with independent identically distributed normal errors are considered, including those without an intercept, those with an intercept, and those with an intercept and time trend. The autoregressive parameter is allowed to lie in the interval (-1, 1], which includes the unit root case. Exactly median-unbiased estimators and exact confidence intervals of the autoregressive parameter are introduced. Corresponding exactly median-unbiased estimators and exact confidence intervals are also provided for the impulse response function, the cumulative impulse response, and the half life of a unit shock. An unbiased model selection procedure is discussed. The introduced procedures are applied to several data series.","['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Exactly Median-Unbiased Estimation of First Order Autoregressive/Unit Root Models,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"Han's maximum rank correlation estimator is shown to be square-root n-consistent and asymptotically normal. The proof rests on a general method for determining the asymptotic distribution of a maximization estimator, a simple U-statistic decomposition, and a uniform bound for degenerate U-processes. A consistent estimator of the asymptotic covariance matrix is provided, along with a result giving the explicit form of this matrix for any model within the scope of the maximum rate correlation estimator. The latter result is applied to the binary choice model, and it is found that the maximum rate correlation estimator does not achieve the semiparametric efficiency bound.","['Sherman, Robert P.']",['Semiparametric and Nonparametric Methods: General'],['C14'],The Limiting Distribution of the Maximum Rank Correlation Estimator,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"A model of optimal consumption and portfolio choice that captures the notions of local substitution and irreversible purchases of durable goods is studied. Necessary and sufficient conditions for a consumption and portfolio policy to be optimal are provided. A closed-form solution of the optimal consumption and portfolio policy is given. The optimal consumption policy consists of a possible initial ""gulp"" of consumption, or a period of no consumption, followed by a process of accumulated consumption with singular sample paths. The equilibrium risk premium in a representative investor economy with a single physical production technology is computed.","['Hindy, Ayman', 'Huang, Chi-fu']","['Consumer Economics: Theory', 'Portfolio Choice; Investment Decisions']","['D11', 'G11']",Optimal Consumption and Portfolio Rules with Durability and Local Substitution,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"The author shows how a group of individuals can learn to play a coordination game without any common knowledge and with only a small amount of rationality. The game is repeated many times by different players. Each player chooses an optimal reply based on incomplete information about what other players have done in the past. Occasionally they make mistakes. When the likelihood of mistakes is very small, typically one coordination equilibrium will be played almost all of the time over the long run. This stochastically stable equilibrium can be computed analytically using a general theorem the author proves on perturbed Markov processes.","['Young, H. Peyton']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],The Evolution of Conventions,0,0,0,0,0,1993,01,01
61,1,1993-01-01,"An evolutionary model with a finite number of players and with stochastic mutations is analyzed. The expansion and contraction of strategies is linked to their current relative success, but mutuation, perturbing the system from its deterministic evolution, are present as well. The focus is on the long run implications of ongoing mutations, which drastically reduce the set of equilibria. For 2 by 2 symmetric games with two symmetric strict Nash equilibria the risk dominant equilibrium is selected. In particular, if both strategies have equal security levels, the Pareto dominant Nash equilibrium is selected. In particular, if both strategies have equal security levels, the Pareto dominant Nash equilibrium is selected, even though there is another strict Nash equilibrium.","['Kandori, Michihiro', 'Mailath, George J.', 'Rob, Rafael']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']","Learning, Mutation, and Long Run Equilibria in Games",0,0,0,0,0,1993,01,01
61,1,1993-01-01,"Several types of rationing and queue mechanisms are compared in a framework of general equilibrium type models under gross substitutability and normality assumptions about consumers' Walrasian demand. During transition from rationing and queues to a market system, a group of low income people loses. The transition involves larger losses for this group if black markets prevail under rationing or queues, while a group of high income consumers gains. Some other comparative statics results are developed for a queue model with black markets.","['Polterovich, Victor']","['Rationing; Licensing', 'Socialist Systems and Transitional Economies: Planning, Coordination, and Reform']","['D45', 'P21']","Rationing, Queues, and Black Markets",0,0,1,0,0,1993,01,01
75,5,2007-09-01,ECONLIT None Found,[nan],[nan],[nan],SUBMISSION OF MANUSCRIPTS TO ECONOMETRICA.,0,0,0,0,0,2007,09,01
81,1,2013-01-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2013,01,01
74,6,2006-11-01,ECONLIT None Found,"['Sargent, Thomas J.']",[nan],[nan],"THE ECONOMETRIC SOCIETY ANNUAL REPORTS, 2005 REPORT OF THE PRESIDENT.",0,0,0,0,0,2006,11,01
74,6,2006-11-01,ECONLIT None Found,"['de Castro, Luciano I.']",['Auctions'],['D44'],Corrigendum to 'Existence of Equilibrium in Single and Double Private Value Auctions',0,0,1,0,0,2006,11,01
74,4,2006-07-01,ECONLIT None Found,"['Dekel, Eddie']",['Introductory Material'],['Y20'],Editorial,0,0,0,0,0,2006,07,01
59,6,1991-11-01,ECONLIT None Found,"['Wakker, Peter', 'Peters, Hans']",['Consumer Economics: Theory'],['D11'],Independence of Irrelevant Alternatives and Revealed Group Preferences,0,0,0,0,0,1991,11,01
59,6,1991-11-01,ECONLIT None Found,"['Matzkin, Rosa L.']",['Consumer Economics: Theory'],['D11'],Axioms of Revealed Preference for Nonlinear Choice Sets,0,0,0,0,0,1991,11,01
59,6,1991-11-01,ECONLIT None Found,"['Besley, Timothy', 'Jewitt, Ian']",['Public Goods'],['H41'],Decentralizing Public Good Supply,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"The authors study fair allocation in economies with indivisible goods. They look for subsolutions of the no-envy solution satisfying the property of consistency which says that the desirability of an allocation for some economy is unaffected by the departure of some of the agents with their allotted bundles. The authors show that essentially there is no proper subsolution of the no-envy solution satisfying consistency. However, many subsolutions satisfy a bilateral version of the condition and many satisfy its converse. But again, there is essentially no proper subsolution satisfying bilateral consistency and converse consistency together.","['Thomson, William', 'Tadenuma, Koichi']","['Equity, Justice, Inequality, and Other Normative Criteria and Measurement']",['D63'],No-Envy and Consistency in Economies with Indivisible Goods,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"The authors examine the effects of renegotiation in an agency relationship. They show how renegotiation affects (1) the set of actions the principal can induce the agent to take and (2) the cost of implementing a given action. The authors show that, when the principal receives an unverifiable signal of the agent's action, renegotiation can improve welfare. This result stands in contrast to earlier findings that renegotiation lowers welfare when the principal receives no signal about the agent's action prior to renegotiation.","['Hermalin, Benjamin E.', 'Katz, Michael L.']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Moral Hazard and Verifiability: The Effects of Renegotiation in Agency,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"In a repeated partnership game with imperfect monitoring, the authors distinguish among the effects of (1) reducing the interest rate, (2) shortening the period over which actions are held fixed, and (3) shortening the lag with which accumulated information is reported. All three changes are equivalent in games with perfect monitoring. With imperfect monitoring, reducing the interest rate always increases the possibilities for cooperation, but the other two changes always have the reverse effect when the interest rate is small.","['Pearce, David', 'Milgrom, Paul', 'Abreu, Dilip']","['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C73', 'D83']",Information and Timing in Repeated Partnerships,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"Recent work demonstrates that dynastic assumptions guarantee the irrelevance of redistributional policies, distortionary taxes, and prices--the neutrality of fiscal policy (Ricardian equivalence) is only the ""tip of the iceberg."" This paper investigates the possibility of reinstating approximate Ricardian equivalence by introducing a small amount of friction in intergenerational links. If Ricardian equivalence depends upon significantly shorter chains of links than do these stronger neutrality results, then friction may dissipate the effects that generate strong neutrality, without significantly affecting the Ricardian result. However, models with friction have other untenable implications and, thus, the theoretical case for Ricardian equivalence remains tenuous.","['Abel, Andrew B.', 'Bernheim, B. Douglas']","['Fiscal Policy', 'Fiscal Policies and Behavior of Economic Agents: Household']","['E62', 'H31']",Fiscal Policy with Impure Intergenerational Altruism,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"In this paper, the authors provide a framework to study the aggregate dynamic behavior of an economy where individual units follow (S, s) policies and are subject to aggregate and idiosyncratic shocks. They characterize structural and stochastic heterogeneities that ensure convergence of the economy's aggregate to that of its (stochastic) frictionless counterpart, determine the speed at which convergence takes place, and describe the transitional dynamics of this economy. They study the evolution of the economy's aggregate and the evolution of the difference between this aggregate and that of the difference between this aggregate and that of an economy without microeconomic friction, where the latter pertains to a situation where individual units adjust with no delay to all shocks.","['Caballero, Ricardo J.', 'Engel, Eduardo M. R. A.']",['General Aggregative Models: General'],['E10'],"Dynamic (S, s) Economies",0,0,0,0,0,1991,11,01
59,6,1991-11-01,"This paper analyzes asset prices in a representative agent exchange economy with habit-forming preferences. For a general class of utility indices and endowment processes, the authors characterize the optimal demand for consumption and derive explicit solutions for the interest rate and asset risk premia. They show that consumption smoothness may obtain even when the interest rate is stochastic. The consumption capital asset pricing model may not hold when the endowment process has stochastic coefficients; asset risk premia are larger under mild assumptions. The interest rate depends on the growth in the standard of living. Malliavin calculus is employed in the analysis.","['Zapatero, Fernando', 'Detemple, Jerome B.']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Financial Markets and the Macroeconomy', 'Macroeconomics: Consumption; Saving; Wealth']","[nan, 'E44', 'E21']",Asset Prices in an Exchange Economy with Habit Formation,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"This paper demonstrates that an optimizing model of a monetary economy can produce perfect foresight equilibria in which the price level fluctuates forever. Cyclically or chaotically fluctuating equilibria are more likely to exist when the rate of money supply growth is high. Furthermore, the set of equilibrium prices may have a complicated topological structure, which poses a more serious problem concerning the validity of comparative statics method than any sort of indeterminacy previously discussed in the literature.","['Matsuyama, Kiminori']","['Business Fluctuations; Cycles', 'Business Administration: General']","['E32', 'M10']",Endogenous Price Fluctuations in an Optimizing Model of a Monetary Economy,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"The invariance properties of several asymptotic tests are studied: invariance to hypothesis representation, reparameterization, and rescaling. Noninvariant tests include Wald tests, variants of LM tests, and Neyman's C("" alpha"") tests. For all these tests, simply changing measurement units can lead to vastly different results, e.g. in models with Box-Cox transformations. Various consistent estimators of the information matrix produce tests with different invariance properties. Sufficient conditions are established under which a generalized C("" alpha"") test becomes invariant to hypothesis reformulations, reparameterizations, and rescaling. In many practical cases, invariant C("" alpha"") tests are much cheaper to compute than other invariant tests (e.g., LR tests).","['Dagenais, Marcel G.', 'Dufour, Jean-Marie']","['Hypothesis Testing: General', 'Single Equation Models; Single Variables: General']","['C12', 'C20']","Invariance, Nonlinear Models, and Asymptotic Tests",0,0,0,0,0,1991,11,01
59,6,1991-11-01,"For the first-order univariate autoregression without constant term, the joint density (corresponding to a flat prior) for the true coefficient and its least squares estimate is estimated by Monte Carlo and graphically displayed. The graphs show how a symmetric distribution for the coefficient conditional on the estimate coexists with an asymmetric distribution for the estimate conditional on the coefficient. Prior densities implicit in treating classical significance levels as if they were Bayesian posterior probabilities are calculated. They are shown to depend sensitively on the estimated coefficient and to put substantial probability on values of the coefficient above one.","['Uhlig, Harald', 'Sims, Christopher A.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Bayesian Analysis: General']","['C22', 'C11']",Understanding Unit Rooters: A Helicopter Tour,0,0,0,0,0,1991,11,01
59,6,1991-11-01,A Bayesian analysis of the linear regression model with only parts of the prior distribution specified or a robust Bayesian analysis lead to sets of posterior distributions. E. E. Leamer (1978) describes the region of posterior means for conjugate priors and varying prior covariance matrices. As an extension to Bayesian confidence sets (HPD regions) the authors introduce the concept of HiFi (high fiduciary) regions. The Hifi region is a union of HPD regions and is a tool for describing the dependence of the posterior distribution on the prior covariance. The authors assume that the prior covariance matrix varies in an interval of matrices.,"['Potzelberger, Klaus', 'Polasek, Wolfgang']","['Single Equation Models; Single Variables: General', 'Bayesian Analysis: General']","['C20', 'C11']",Robust HPD Regions in Bayesian Regression Models,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"This paper contains the likelihood analysis of vector autoregressive models allowing for cointegration. The author derives the likelihood ratio test for cointegrating rank and finds it asymptotic distribution. He shows that the maximum likelihood estimator of the cointegrating relations can be found by reduced rank regression and derives the likelihood ratio test of structural hypotheses about these relations. The author shows that the asymptotic distribution of the maximum likelihood estimator is mixed Gaussian, allowing inference for hypotheses on the cointegrating relation to be conducted using the Chi("" squared"") distribution.","['Johansen, Soren']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models,0,0,0,0,0,1991,11,01
59,6,1991-11-01,"For market demand to satisfy the law of demand, it is sufficient that the mean of all households' income effect matrices is positive definite. The authors show how this mean income effect matrix can be estimated from cross section data under metonymy, an assumption about the distribution of household characteristics. The estimation uses the nonparametric method of average derivatives. When the method is applied to U.K. family expenditure data, the estimated mean income effect matrices are positive definite. This can be explained by a special form of heteroskedasticity in the data: households' demands are more dispersed at higher income levels.","['Hardle, Wolfgang', 'Jerison, Michael', 'Hildenbrand, Werner']",['Consumer Economics: Empirical Analysis'],['D12'],Empirical Evidence on the Law of Demand,0,0,0,0,0,1991,11,01
59,5,1991-09-01,ECONLIT None Found,"['Madden, Paul']",['Consumer Economics: Theory'],['D11'],A Generalization of Hicksian q Substitutes and Complements with Application to Demand Rationing,0,0,0,0,0,1991,09,01
59,5,1991-09-01,ECONLIT None Found,"['Carlsson, Hans']",['Bargaining Theory; Matching Theory'],['C78'],A Bargaining Model Where Parties Make Errors,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"A dynamic monopolist produces at constant unit cost. Each period a new cohort of consumers enters the market. Each entering cohort is identical. Consumers within a cohort have different tastes. The paper shows that if players are sufficiently patient, any positive average profit less than the maximum feasible level can be attained in a subgame-perfect equilibrium; in stationary subgame-perfect equilibria, the seller cannot make sales at prices sufficiently greater than the lowest willingness-to-pay when period length goes to zero; and the seller attains the maximum commitment profit by charging the same (static monopoly) price in every period.","['Sobel, Joel']","['Monopoly; Monopolization Strategies', 'Market Structure, Pricing, and Design: Monopoly']","['L12', 'D42']",Durable Goods Monopoly with Entry of New Consumers,1,0,1,0,0,1991,09,01
59,5,1991-09-01,"A matching problem is considered in which sellers can publicly commit to a trading price that differs from the price at which buyers expect to trade elsewhere in the market. When demand and supply are nearly equal, the equilibrium ex ante price offer lies below the price associated with the Nash bargaining split. This relationship reverses when the level of excess demand is large. Sellers always have an incentive to make ex ante offers when prices elsewhere are determined by Nash bargaining. This can be interpreted to mean that Nash bargaining is an unstable pricing institution.","['Peters, Michael']",['Bargaining Theory; Matching Theory'],['C78'],Ex Ante Price Offers in Matching Games Non-steady States,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"An allocation for an exchange economy with smooth preferences is shown to be Walrasian if there is a set of net trades that is closed under addition, contains the negations of net trades that would improve any agent's final bundle, and is such that each agent's final bundle is weakly preferred to the sum of the initial endowment and any allowed net trade. These conditions characterize the sets of net trades available in equilibria of market games in which randomly paired agents bargain repeatedly and imply that steady state equilibria are Walrasian.","['McLennan, Andrew', 'Sonnenschein, Hugo']","['Exchange and Production Economies', 'Bargaining Theory; Matching Theory']","['D51', 'C78']",Sequential Bargaining as a Noncooperative Foundation for Walrasian Equilibrium,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"It is shown that an increasing policy function that is the solution of a C(superscript ""2"") dynamic programming problem is always C(superscript ""1""). This implies that the value function is C(superscript ""2""). Examples are given to show that the policy function might not be twice differentiable and therefore the value might not be three times differentiable, even if the program is C(superscript ""3"").","['Araujo, A.']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],The Once but Not Twice Differentiability of the Policy Function,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"The theory applying to dynamic programming has furnished a useful set of techniques for the analysis of many types of sequential models. This theory, however, has not yielded heretofore much information about the differentiability properties of optimal solutions. This aspect is of particular interest as regards the qualitative analysis of optimal paths, where differentiable methods are often called into play. This paper shows roughly that if the objective is twice continuously differentiable and strongly concave, then any interior optimal path is continuously differentiable with respect to the initial state.","['Santos, Manuel S.']",['Optimization Techniques; Programming Models; Dynamic Analysis'],['C61'],Smoothness of the Policy Function in Discrete Time Economic Models,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"The author considers frequency domain time series analysis, where smoothing in nonparametric spectrum estimation is data-dependent. Uniform convergence of spectrum estimates is established and applied to a semiparametric model, parameterized over possibly only a subset of the frequencies, in which disturbances have nonparametric autocorrelation. Optimal instruments depend on the disturbance spectrum and frequency response function, which is nonparametric in incomplete systems. The author justifies feasible, optimal parameter estimates. The degree of smoothing is allowed to depend on the data in a general way. The author proves consistency of a cross-validation method of automatic smoothing and applies it to a semiparametric model.","['Robinson, P. M.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Semiparametric and Nonparametric Methods: General']","['C22', 'C14']",Automatic Frequency Domain Inference on Semiparametric and Nonparametric Models,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"This paper introduces a semiparametric estimation method for Polychotomous Choice models. The method does not require a parametric structure for the systematic subutility of observable exogenous variables. The distribution of the random terms is assumed to be known up to a finite-dimensional parameter vector. In contrast, previous semiparametric methods of estimating discrete choice models have concentrated on relaxing parametric subutility parametrically specified. The systematic subutility is assumed to possess properties such as monotonicity and concavity that are typically assumed in microeconomic theory. The estimator for the systematic subutility and the parameter vector of the distribution is shown to be strongly consistent. A computational technique to calculate the estimators is developed.","['Matzkin, Rosa L.']","['Single Equation Models; Single Variables: Discrete Regression and Qualitative Choice Models; Discrete Regressors; Proportions; Probabilities', 'Semiparametric and Nonparametric Methods: General', 'Consumer Economics: Theory']","['C25', 'C14', 'D11']",Semiparametric Estimation of Monotone and Concave Utility Functions for Polychotomous Choice Models,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"A test for long-term memory that is robust to short-range dependence is developed. It is a modification of the R/S statistic, and the relevant asymptotic sampling theory is derived via functional central limit theory. Contrary to previous findings, when applied to daily and monthly stock returns indexes over several time periods this test yields no evidence of long-range dependence once short-range dependence is accounted for. Monte Carlo experiments show that the modified R/S test has power against at least two specific models of long-term memory, suggesting that models with short-range dependence may adequately capture the behavior of historical stock returns.","['Lo, Andrew W.']",['Asset Pricing; Trading Volume; Bond Interest Rates'],[nan],Long-Term Memory in Stock Market Prices,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"Using Monte Carlo methodology, this paper investigates the effect of dynamics and simultaneity on the finite sample properties of instrumental variables statistics for testing nested and nonnested hypotheses. Simple numerical-analytical formulae (response surfaces) are obtained which closely approximate the statistics' unknown size and power functions for a dynamic simultaneous-equations model. The analysis illustrates the value and limitations of asymptotic theory in interpreting finite sample properties. Two practical results arise. The F form and the Wald statistic is favored over its chi-squared form, and ""large-sigma"" and small ""effective"" sample size strongly affect the test of over-identifying restrictions and the Cox-type test.","['Ericsson, Neil R.']","['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models', 'Statistical Simulation Methods: General']","['C32', 'C15']",Monte Carlo Methodology and the Finite Sample Properties of Instrumental Variables Statistics for Testing Nested and Non-nested Hypotheses,0,0,0,0,0,1991,09,01
59,5,1991-09-01,"This paper is concerned with the theory of saving when consumers are not permitted to borrow, and with the ability of such a theory to account for some of the stylized facts of saving behavior. The models presented in the paper seem to account for important aspects of reality that are not explained by traditional life-cycle models.","['Deaton, Angus']","['Intertemporal Household Choice; Life Cycle Models and Saving', 'Consumer Economics: Theory', 'Macroeconomics: Consumption; Saving; Wealth']","['D15', 'D11', 'E21']",Saving and Liquidity Constraints,0,0,0,0,0,1991,09,01
59,4,1991-07-01,ECONLIT None Found,"['Border, Kim C.']",['Auctions'],['D44'],Implementation of Reduced Form Auctions: A Geometric Approach,0,0,1,0,0,1991,07,01
59,4,1991-07-01,ECONLIT None Found,"['Allingham, Michael']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Existence and Stability Conditions of Equilibrium']","[nan, 'C62']",Existence Theorems in the Capital Asset Pricing Model,0,0,0,0,0,1991,07,01
59,4,1991-07-01,ECONLIT None Found,"['Newey, Whitney K.']",['Econometric and Statistical Methods and Methodology: General'],['C10'],Uniform Convergence in Probability and Stochastic Equicontinuity,0,0,0,0,0,1991,07,01
59,4,1991-07-01,ECONLIT None Found,"['Kobayashi, Masahito']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Testing for Autocorrelated Disturbances in Nonlinear Regression Analysis,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"Starting from a tariff-distorted equilibrium of international trade, the authors examine the welfare effects of a gradual multilateral reform of tariffs (and other trade taxes and subsidies). Necessary and sufficient conditions for the existence of strict Pareto improving multilateral (differential) tariff reforms, accompanied by international transfers of income, are obtained. These results are then applied to various concrete tariff reform proposals such as proportional reductions in tariffs and the reduction of the highest ad valorem tariff rates. Some of the authors' theorems extend the generality of previously obtained results and some new tariff reform proposals are also made.","['Woodland, Alan D.', 'Turunen-Red, Arja H.']",['Trade Policy; International Trade Organizations'],['F13'],Strict Pareto-Improving Multilateral Reforms of Tariffs,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"It seems inconsistent to model boundedly rational action choice by assuming that the agent chooses the optimal decision procedure. This criticism is not avoided by assuming that he chooses the optimal procedure to choose a procedure to . . . to choose an action. The author shows that, properly interpreted, this regress, continued transfinitely, generates a model representing the agent's perception of all his options, including every way to refine his perceptions. In this model, the agent surely must choose the perceived best option. Hence, it is not inconsistent to model limited rationality by assuming that the agent uses the ""optimal"" decision procedure.","['Lipman, Barton L.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],How to Decide How to Decide How to. . . : Modeling Limited Rationality,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"This paper develops a method to study an infinite-horizon production economy distorted by a state-dependent income tax. This setting permits taxes to depend on the capital stock, an endogenous state variable, and thus captures situations where the evolution for capital and taxes is jointly determined. To solve this model, the consumption function is represented as a fixed point of a nonlinear monotone operator that is defined such that its nth iteration computes the consumption function n steps away from the horizon for a corresponding finite-horizon economy. The oparator's monotonicity is exploited in proving the existence of, and constructing, an equilibrium.","['Coleman, Wilbur John, II']","['Fiscal Policy', 'Existence and Stability Conditions of Equilibrium', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes']","['E62', 'C62', 'H24']",Equilibrium in a Production Economy with an Income Tax,0,0,0,0,0,1991,07,01
59,4,1991-07-01,The author examines the optimal pattern of lending in an environment in which there are two impediments to contracting. The first impediment is that lenders cannot observe whether borrowers invest or consume borrowed funds. This impediment leads to a moral hazard problem in investment. The second impediment is that the borrower may choose to repudiate his debts. The optimal contract is shown to specify that the borrowing country experience a capital outflow when the worst realizations of output occur. This seemingly perverse pattern of capital outflow forms a necessary part of the optimal solution to the moral hazard problem in investment.,"['Atkeson, Andrew']","['International Lending and Debt Problems', 'Asymmetric and Private Information; Mechanism Design', 'International Investment; Long-term Capital Movements']","['F34', 'D82', 'F21']",International Lending with Moral Hazard and Risk of Repudiation,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"The authors describe a model of general equilibrium with incomplete markets in which firms can innovate by issuing arbitrary, costly securities. When short sales are prohibited, firms behave competitively and equilibrium is efficient. When short sales are allowed, these classical properties may fail. If unlimited short sales are allowed, imperfect competition may persist even when the number of potential innovators is large. If limited short sales are allowed, perfect competition may obtain in the limit, but equilibrium can be inefficient because of the presence of an externality: the private benefits of innovation for firms differ from the social benefits.","['Gale, Douglas', 'Allen, Franklin']","['Incomplete Markets', 'Information and Market Efficiency; Event Studies; Insider Trading']","['D52', 'G14']","Arbitrage, Short Sales, and Financial Innovation",0,0,0,0,0,1991,07,01
59,4,1991-07-01,"A set of n objects and an amount M of money is to be distributed among m people. Example: the objects are tasks and the money is compensation from a fixed budget. An elementary argument via constrained optimization shows that for M sufficiently large the set of efficient, envy free allocations is nonempty and has a nice structure. In particular, various criteria of justice lead to unique best fair allocations that are well behaved with respect to changes of M. This is in sharp contrast to the usual fair division theory with divisible goods.","['Demange, Gabrielle', 'Alkan, Ahmet', 'Gale, David']","['Allocative Efficiency; Cost-Benefit Analysis', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement', 'Exchange and Production Economies']","['D61', 'D63', 'D51']",Fair Allocation of Indivisible Goods and Criteria of Justice,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"Consider a social choice correspondence as a mapping from preference profiles to lotteries over some finite set of alternatives. A virtually implementable social choice function in Nash equilibrium is defined, under mild domain restrictions it is shown that in societies with at least three individuals all social choice correspondences are virtually implementable in Nash equilibrium. This contrasts with Maskin's classic characterization, which requires monotonicity as a necessary condition for exact implementation in Nash equilibrium. The two person case is considered seperately. While not all two-person social choice functions are virtually implementable, our necessary and sufficient condition is simple, which contrasts with the complex necessary and sufficient conditions for exact implementation.","['Sen, Arunava', 'Abreu, Dilip']","['Social Choice; Clubs; Committees; Associations', 'Game Theory and Bargaining Theory: General']","['D71', 'C70']",Virtual Implementation in Nash Equilibrium,0,0,0,0,0,1991,07,01
59,4,1991-07-01,This paper derives several properties unique to nonlinear model hypothesis testing problems involving linear or nonlinear inequality constraints in the null or alternative hypothesis. The paper is organized around a lemma that characterizes the set containing the least favorable parameter value for a nonlinear model inequality constraints hypothesis test. The author then presents two examples that illustrate several implications of this lemma. He also discusses the impact of these properties on the empirical implementation and interpretation of these test procedures.,"['Wolak, Frank A.']",['Hypothesis Testing: General'],['C12'],The Local Nature of Hypothesis Tests Involving Inequality Constraints in Nonlinear Models,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"This paper deals with error correction models (ECM's) and cointegrated systems that are formulated in continuous time. Long-run equilibrium coefficients in the continuous system are always identified in the discrete time reduced form, so that there is no aliasing problem for these parameters. The long- run relationships are also preserved under quite general data filtering. Frequency domain procedures are outlined for estimation and inference. These methods are asymptotically optimal under Gaussian assumptions and they have the advantages of simplicity of computation and generality of specification, thereby avoiding some methodological problems of dynamic specification. In addition, they facilitate the treatment of data irregularities such as mixed stock and flow data and temporally aggregate partial equilibrium formulations. Models with restricted cointegrating matrices are also considered.","['Phillips, P. C. B.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Error Correction and Long-Run Equilibrium in Continuous Time,0,0,0,0,0,1991,07,01
59,4,1991-07-01,This paper discusses economic processes that may give rise to spatial patterns in data and explores the relative merits of alternative modeling approaches when data are spatially correlated. An estimation scheme is presented that allows for spatial random effects and attention is focused on cases in which such a framework may be preferred to the more general fixed effects framework that nests it. The models presented are used together with information on the location of households in an Indonesian socioeconomic survey to test spatial relationships in Indonesian demand for rice.,"['Case, Anne C.']","['Urban, Rural, Regional, Real Estate, and Transportation Economics: Other Demand', 'General Regional Economics: Econometric and Input-Output Models; Other Models', 'Model Construction and Estimation']","['R22', 'R15', 'C51']",Spatial Patterns in Household Demand,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"The authors examine the effects of male and female labor supply on household demands and present a simple and robust test for the separability of demands from labor supply. Using data on individual households from six years of the U.K. Family Expenditure Survey, they estimate a demand system for seven goods that includes hours and participation dummies as conditioning variables. Allowance is made for the possible endogeneity of theses conditioning labor-supply variables. The authors find that separability is rejected. Furthermore, they present evidence that ignoring labor supply leads to bias in the parameter estimates.","['Browning, Martin', 'Meghir, Costas']","['Consumer Economics: Empirical Analysis', 'Household Production and Intrahousehold Allocation', 'Time Allocation and Labor Supply']","['D12', 'D13', 'J22']",The Effects of Male and Female Labor Supply on Commodity Demands,0,0,0,0,0,1991,07,01
59,4,1991-07-01,"The paper is a discussion of the interpretation of game theory. The first half of the paper deals with the notion of ""strategy"". The paper endorses the view that equilibrium strategy describes a player's plan of action, as well as those considerations which support the optimality of his plan rather than being merely described as a ""plan of action"". In the second half of the paper it is argued that a good model in game theory has to be realistic in the sense that it provides a model for the perception of real life social phenomena. It should incorporate a description of the relevant factors involved, as perceived by the decision makers.","['Rubinstein, Ariel']",['Game Theory and Bargaining Theory: General'],['C70'],Comments on the Interpretation of Game Theory,0,0,0,0,0,1991,07,01
59,3,1991-05-01,ECONLIT None Found,"['Svensson, Lars-Gunnar']","['Exchange and Production Economies', 'Noncooperative Games']","['D51', 'C72']",Nash Implementation of Competitive Equilibria in a Model with Indivisible Goods,0,0,0,0,0,1991,05,01
59,3,1991-05-01,ECONLIT None Found,"['Gilboa, Itzhak', 'Matsui, Akihiko']",['Noncooperative Games'],['C72'],Social Stability and Equilibrium,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"This paper is concerned with the estimation of covariance matrices in the presence of heteroskedasticity and autocorrelation of unknown forms. Currently available estimators that are designed for this context depend upon the choice of a lag truncation parameter and a weighting scheme. No results are available regarding the choice of lag truncation parameter for a fixed sample size, regarding data-dependent automatic lag truncation parameters, or regarding the choice of weighting scheme. This paper addresses these problems. Asymptotically optimal kernel/weighting scheme and bandwidth/lag truncation parameters are obtained. Using these results, data-dependent automatic bandwidth/lag truncation parameters are introduced.","['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: General'],['C20'],Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"Conventional chi(superscript ""2"") approximations to the distribution of the information matrix test are shown to be inaccurate in models and with sample sizes commonly encountered. Interpreting a version of the information matrix test as an efficient score test leads to an alternative Edgeworth type approximation. This is calculated for the normal regression model and shown to be an improvement. Generally, the quality of the approximations is sensitive to the covariate design. However, the authors are able to provide design-independent, second-order size corrections for the widely used information matrix tests which detect nonnormal skewness and kurtosis in regression models.","['Chesher, Andrew', 'Spady, Richard']",['Hypothesis Testing: General'],['C12'],Asymptotic Expansions of the Information Matrix Test Statistic,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"A method is presented for estimating nonlinear simultaneous equations and transformation models in the presence of disturbance distribution of unknown form. It asymptotically achieves the lower variance bound for instrumental variables estimates. The author avoids smoothed nonparametric estimation, his instruments averaging over the unsmoothed empirical distribution of preliminary residuals. He allows for stationary serial dependence. In various settings, estimates are proposed and large-sample inference rules justified, these being unaffected if the optimal instruments use only an arbitrarily small vanishing fraction of the residuals. The author investigates theoretically the effect of such computational savings on the goodness of the normal approximation.","['Robinson, P. M.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Best Nonlinear Three-Stage Least Squares Estimation of Certain Econometric Models,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"The authors derive, from a model of investment with multiple capital goods, a one-to-one relation between the growth rate of the capital aggregate and the stock-market-based Q. The authors estimate the growth-Q relation using a panel of Japanese manufacturing firms taking into account the endogeneity of Q. For early years of their sample, cash flow has significant explanatory power over and above Q. The estimated Q coefficient implies that the adjustment cost is less than a half of gross profits net of the adjustment costs.","['Inoue, Tohru', 'Hayashi, Fumio']","['Firm Behavior: Theory', 'Capital Budgeting; Fixed Investment and Inventory Studies; Capacity', 'Intertemporal Firm Choice: Investment, Capacity, and Financing']","['D21', 'G31', 'D25']",The Relation between Firm Growth and Q with Multiple Capital Goods: Theory and Evidence from Panel Data on Japanese Firms,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"W. M. Gorman's (1981) concept of Engel curve ""rank"" is extended to apply to any demand system. Rank is shown to have implications for specification, separability, and aggregation of demands. A simple nonparametric test of rank using Engel curve data is described and applied to U.S. and U.K. consumer survey data. The test employs a new general method for testing the rank of estimated matrices. The results are used to assess theoretical and empirical aggregation error in representative consumer models, and to explain a representative consumer paradox.","['Lewbel, Arthur']",['Consumer Economics: Empirical Analysis'],['D12'],The Rank of Demand Systems: Theory and Nonparametric Estimation,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"It seems desirable that the overall level of poverty should fall whenever poverty decreases within some subgroup of the population and is unchanged outside that group. Yet this simple and attractive property, which we call ""subgroup consistency,"" is violated by many of the poverty indices suggested in recent years. This paper characterizes the class of subgroup consistent poverty indices, and identifies the special features associated with this property.","['Foster, James E.', 'Shorrocks, Anthony F.']","['Measurement and Analysis of Poverty', 'Equity, Justice, Inequality, and Other Normative Criteria and Measurement']","['I32', 'D63']",Subgroup Consistent Poverty Indices,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"An axiomatic model of preferences over lotteries is developed. It is shown that this model is consistent with the Allais paradox, includes expected utility theory as a special case, and is only one parameter ("" beta"") richer than the expected utility model. Allais paradox type behavior is identified with positive values of ""beta."" Preferences with positive ""beta"" are said to be disappointment averse. It is shown that risk aversion implies disappointment aversion and that the Arrow-Pratt measures of risk aversion can be generalized in a straight-forward manner to the current framework.","['Gul, Faruk']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],A Theory of Disappointment Aversion,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"Evolutionary games are introduced as models for repeated anonymous strategic interaction: actions (or behaviors) which are more ""fit,"" given the current distribution of behaviors, tend over time to displace less fit behaviors. Cone fields characterize the continuous-time processes compatible with a given fitness (or payoff) function. For large classes of dynamics, it is shown that all stable steady states are Nash equilibria and that all Nash equilibria are steady states. The biologists' evolutionarily stable strategy condition is shown to be less closely related to the dynamic equilibria. Economic examples and a literature survey are also provided.","['Friedman, Daniel']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Evolutionary Games in Economics,0,0,0,0,0,1991,05,01
59,3,1991-05-01,"This paper concerns moral hazard problems in multiagent situations where cooperation is an issue. Each agent allocates effort to his own task and to other tasks as ""help."" The principal may prefer an unambiguous division of labor by inducing each agent to specialize in his own task, or prefer teamwork where each agent is motivated to help other agents. A sufficient condition for teamwork to be optimal is presented. A nonconvexity of the optimal task structure is also shown: the principal wants either strict specialization or substantial teamwork.","['Itoh, Hideshi']",['Asymmetric and Private Information; Mechanism Design'],['D82'],Incentives to Help in Multi-agent Situations,0,0,0,0,0,1991,05,01
59,3,1991-05-01,The main result of this paper characterizes voting by committees. There are n voters and K objects. Voters must choose a subset of K. Voting by committees is defined by one monotone family of winning coalitions for each object; an object is chosen if it is supported by one of its winning coalitions. This is proven to be the class of all voting schemes satisfying voter sovereignty and nonmanipulability on the domain of separable preferences. The result is analogous to the characterization of Clarke-Groves schemes in that it exhibits the class of all nonmanipulable schemes on an important domain.,"['Barbera, Salvador', 'Sonnenschein, Hugo', 'Zhou, Lin']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Voting by Committees,0,0,0,0,0,1991,05,01
59,2,1991-03-01,ECONLIT None Found,"['Sprumont, Yves']",['Allocative Efficiency; Cost-Benefit Analysis'],['D61'],The Division Problem with Single-Peaked Preferences: A Characterization of the Uniform Allocation Rule,0,0,0,0,0,1991,03,01
59,2,1991-03-01,ECONLIT None Found,"[""O'Neill, Barry""]",['Noncooperative Games'],['C72'],"Comments on Brown and Rosenthal's Reexamination [Testing the Minimax Hypothesis, A Reexamination of O'Neill's Game Experiment].",0,0,0,0,0,1991,03,01
59,2,1991-03-01,"The authors study the problem of implementing social choice correspondences via Nash equilibrium in which no one uses a weakly dominated strategy. The main result is that if there are at least three agents in society, then any correspondence that satisfies no veto power is implementable unless some agents are completely indifferent over all possible outcomes. Many common welfare criteria, such as the Pareto correspondence, and several familiar voting rules satisfy the authors' conditions. This possibility result stands in sharp contrast to the more restrictive findings with implementation in either Nash equilibrium or subgame perfect equilibrium","['Srivastava, Sanjay', 'Palfrey, Thomas R.']","['Social Choice; Clubs; Committees; Associations', 'Asymmetric and Private Information; Mechanism Design']","['D71', 'D82']",Nash Implementation Using Undominated Strategies,0,0,0,0,0,1991,03,01
59,2,1991-03-01,The decentralization of decision-making is analyzed when agents may have information that is incomplete and possibly exclusive. Theorems provide conditions under which there exists a mechanism whose Bayesian equilibria coincide with a desired collection of social choice functions. The first theorem characterizes Bayesian implementation in economic environments with three or more individuals. The second theorem extends the analysis to noneconomic environments. An example exhibits differences between Bayesian implementation and Nash implementation.,"['Jackson, Matthew O.']","['Asymmetric and Private Information; Mechanism Design', 'Social Choice; Clubs; Committees; Associations']","['D82', 'D71']",Bayesian Implementation,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"The authors demonstrate existence of a perfect foresight equilibrium under borrowing constraints in a one-sector model with infinitely-lived heterogeneous agents. The class of admissible preferences includes, but is not limited to, recursive preferences. Existence is proven using a t$2Ctonnement argument under appropriate conditions on preferences and technology. A new measure of discounting, the norm of marginal impatience, is used to determine which technologies are admissible. Depending on the norm of marginal impatience, the admissible technology may either allow for permanent growth or have a maximum sustainable stock.","['Becker, Robert A.', 'Boyd, John H., III', 'Foias, Ciprian']",['Exchange and Production Economies'],['D51'],The Existence of Ramsey Equilibrium,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"The preference reversal phenomenon is usually interpreted as evidence of nontransitivity of preference, but has also been explained as the result of the difference between individuals' responses to choice and valuation problems; the devices used by experimenters to elicit valuations; and the ""random lottery selection"" incentive system. This paper reports an experiment designed so that none of these factors could generate systematic nontransitivities; yet systematic violations of transitivity were still found. The pattern of violation was analogous with that found in previous preference reversal experiments and is consistent with regret theory.","['Starmer, Chris', 'Sugden, Robert', 'Loomes, Graham']","['Microeconomics: General', 'Criteria for Decision-Making under Risk and Uncertainty']","['D00', 'D81']",Observing Violations of Transitivity by Experimental Methods,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"Measured aggregate U.S. consumption does not behave like a martingale. The authors develop and test two variants of the permanent income model which reflect that. In both, agents make decisions in continuous time. In one variant, martingale behavior holds; serial persistence in measured consumption reflects only time aggregation. In the other, serial persistence also reflects technology shocks, and martingale behavior does not hold. Using both structural and atheoretical econometric models, the authors find little evidence against either variant: aggregate quarterly U.S. data do not convincingly distinguish between their continuous time models.","['Eichenbaum, Martin', 'Christiano, Lawrence J.', 'Marshall, David']","['Macroeconomics: Consumption; Saving; Wealth', 'Model Evaluation, Validation, and Selection']","['E21', 'C52']",The Permanent Income Hypothesis Revisited,0,0,0,0,0,1991,03,01
59,2,1991-03-01,This paper develops a discrete state space solution method for a class of nonlinear rational expectations models. The method works by using numerical quadrature rules to approximate the integral operators that arise in stochastic intertemporal models. It is particularly useful for approximating asset pricing models and has potential applications in other problems as well. An empirical application uses the method to study the relationship between the risk premium and the conditional variability of the equity returns under ARCH endowment processes.,"['Tauchen, George', 'Hussey, Robert']","['Model Construction and Estimation', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', nan]",Quadrature-Based Methods for Obtaining Approximate Solutions to Nonlinear Asset Pricing Models,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"This paper introduces an ARCH model (exponential ARCH) that (1) allows correlation between returns and volatility innovations (an important feature of stock market volatility changes), (2) eliminates the need for inequality constraints on parameters, and (3) allows for a straightforward interpretation of the ""persistence"" of shocks to volatility. In the above respects, it is an improvement over the widely-used GARCH model. The model is applied to study volatility changes and the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987.","['Nelson, Daniel B.']","['Model Construction and Estimation', 'Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Asset Pricing; Trading Volume; Bond Interest Rates']","['C51', 'C22', nan]",Conditional Heteroskedasticity in Asset Returns: A New Approach,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"This paper establishes the asymptotic normality of series estimators for nonparametric regression models. Gallant's Fourier flexible form estimators, trigonometric series estimators, and polynomial series estimators are prime examples of the estimators covered by the results. The results apply to a wide variety of estimates in the regression model under consideration, including derivatives and integrals of the regression function. The errors in the model may be homoskedastic or heteroskedastic. The paper also considers series estimators for additive interactive regression, semiparametric regression, and semiparametric index regression models, and shows them to be consistent and asymptotically normal.","['Andrews, Donald W. K.']",['Single Equation Models; Single Variables: General'],['C20'],Asymptotic Normality of Series Estimators for Nonparametric and Semiparametric Regression Models,0,0,0,0,0,1991,03,01
59,2,1991-03-01,"Properties of maximum likelihood estimates of cointegrated systems are studied. Alternative formulations are considered, including a new triangular system error correction mechanism. We demonstrate that full system maximum likelihood brings the problem of inference within the family covered by the locally asymptotically mixed normal asymptotic theory, provided all unit roots have been eliminated by specification and data transformation. Methodological issues provide a major focus of the paper. Our results favor use of full system estimation in error correction mechanisms or subsystem methods that are asymptotically equivalent. They also point to disadvantages in the use of unrestricted VAR's formulated in levels and of certain single equation approaches to estimation of error correction mechanisms.","['Phillips, P. C. B.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Optimal Inference in Cointegrated Systems,0,0,0,0,0,1991,03,01
59,1,1991-01-01,ECONLIT None Found,"['Froot, Kenneth A.', 'Obstfeld, Maurice']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Foreign Exchange']","[nan, 'F31']",Stochastic Process Switching: Some Simple Solutions,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"We consider a first-order autoregression with i.i.d. errors and a fixed initial condition. The asymptotic distribution of the normalized least-squares estimator as the sampling interval converges to zero is shown to be the same as the exact distribution of the continuous-time estimator in an Ornstein-Uhlenbeck process. This asymptotic distribution permits explicit consideration of the effect of the initial condition. The appropriate moment-generating function is derived and used to tabulate the limiting distribution and probability density functions, the moments and some power functions. The adequacy of this asymptotic approximation is found to be excellent for values of the autoregressive parameter near one and any fixed initial condition.","['Perron, Pierre']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],A Continuous Time Approximation to the Unstable First-Order Autoregressive Process: The Case without an Intercept,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"A dynamic programming model of job exit behavior and retirement is constructed and estimated using the method of simulated moments. The model and estimation method allow for both unobserved individual effects and unobserved job-specific ""match"" effects. The model is estimated using two different assumptions about individual discount factors. First, a static model, with the discount factor equal to zero, is estimated. Then a dynamic model, with the discount factor equal to .95 is estimated. In both models, it is found that bad health, age, and lack of education increase the probability of retirement. The dynamic model performs better than the static model and has different implications for retirement behavior. The job-specific effects are an important source of unobserved heterogeneity.","['Berkovec, James', 'Stern, Steven']",['Retirement; Retirement Policies'],['J26'],Job Exit Behavior of Older Men,0,0,0,0,0,1991,01,01
59,1,1991-01-01,A normal Roy model with four sectors is developed. It allows to derive tests of several assumptions on the working of the labor market: strongly or weakly competitive or segmented. It shows that more important a feature of labor markets than segmentation is the presence of comparative advantages for individuals between the various economic sectors. The model is applied to data on women's labor-force participation in the main towns of Colombia in 1980. It uses multivariate probit and Tobit techniques.,"['Magnac, Th.']","['Monopsony; Segmented Labor Markets', 'Labor Force and Employment, Size, and Structure']","['J42', 'J21']",Segmented or Competitive Labor Markets,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"The independence axiom of expected utility theory has recently been weakened to the betweenness axiom. In this paper, an even weaker axiom, called mixture symmetry, is presented. The corresponding functional structure is such that utility is a betweenness functional on part of this domain and quadratic in probabilities elsewhere. The experimental evidence against betweenness provides one motivation for the more general theory presented here. Another advantage of the mixture symmetric class of utility functions is that it is sufficiently flexible to permit the disentangling of attitudes toward risk and toward randomization.","['Chew, S. H.', 'Segal, U.', 'Epstein, Larry G.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Mixture Symmetry and Quadratic Utility,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"Examples of well-behaved sequences of economies, without monotonic preferences, are constructed. These economies have core allocations that cannot be decentralized by prices, even in a weak sense. Relaxing the monotonicity assumption results in core allocations that are not uniformly integrable, breaking the connection between the continuum and the large finite model. If, in addition, preferences are nonconvex, even uniformly bounded core allocations may fail to converge in a well sense. Sufficient conditions to restore convergence are provided.","['Manelli, Alejandro M.']",['Exchange and Production Economies'],['D51'],Monotonic Preferences and Core Equivalence,0,0,0,0,0,1991,01,01
59,1,1991-01-01,Consider an economy with one public enterprise that is subject to a budgetary constraint and charges prices according to the first-order necessary conditions suggested by M. Boiteux (1956) or F. P. Ramsey (1927). The authors state conditions sufficient to ensure that the resulting allocation is second best. The proof builds on arguments used to demonstrate the Pareto efficiency of marginal cost pricing under appropriate assumptions.,"['Dierker, Egbert']","['Allocative Efficiency; Cost-Benefit Analysis', 'Public Enterprises; Public-Private Enterprises']","['D61', 'L32']",The Optimality of Boiteux-Ramsey Pricing,1,0,0,0,0,1991,01,01
59,1,1991-01-01,This paper develops a decision-theoretic approach to normal-form refinements of Nash equilibrium and provides characterizations of (normal-form) perfect equilibrium and proper equilibrium. The approach relies on a theory of single-person decision-making that is a non-Archimedean version of subjective expected utility theory.,"['Brandenburger, Adam', 'Blume, Lawrence', 'Dekel, Eddie']",['Stochastic and Dynamic Games; Evolutionary Games; Repeated Games'],['C73'],Lexicographic Probabilities and Equilibrium Refinements,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"Conventional Bayesian theory of choice under uncertainty, subjective expected utility theory, fails to satisfy the properties of admissibility and existence of well-defined conditional probabilities; weakly dominated acts may be chosen, and the usual definition of conditional probabilities applies only to nonnull events. This paper develops a non-Archimedean variant of subjective expected utility where decisionmakers have lexicographic beliefs. This generalization can be made to satisfy admissibility and yield well-defined conditional probabilities and at the same time allow for ""null"" events.","['Brandenburger, Adam', 'Blume, Lawrence', 'Dekel, Eddie']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Lexicographic Probabilities and Choice under Uncertainty,0,0,0,0,0,1991,01,01
59,1,1991-01-01,"The authors present a new approach to the theory of imperfect competition and apply it to study price competition among differentiated products. The central result provides general conditions for existence and uniqueness of a pure-strategy price equilibrium given any number of firms producing any set of products. This includes products with multidimensional attributes. The authors' analysis covers location models, the characteristics approach, and probabilistic choice in a unified framework. To prove existence, they employ aggregation theorems due to A. Pr$8Ekopa (1971) and C. Borell (1975). A companion paper introduces these theorems and develops the application to super-majority voting rules.","['Caplin, Andrew', 'Nalebuff, Barry']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection']",['D43'],Aggregation and Imperfect Competition: On the Existence of Equilibrium,0,0,1,0,0,1991,01,01
59,1,1991-01-01,A celebrated result of D. Black (1948) demonstrates the existence of a simple-majority winner when preferences are single-peaked. This paper provides a multidimensional analog of Black's median voter result. The authors provide conditions under which the mean voter's most preferred outcome is unbeatable according to a 64 percent majority rule. The conditions supporting this result represent a significant generalization of A. Caplin and B. Nalebuff (1988). The shift from median voter to mean voter requires a new mathematical approach; the authors introduce to economics a mathematical aggregation theorem due to A. Pr$8Ekopa (1971) and C. Borell (1975).,"['Caplin, Andrew', 'Nalebuff, Barry']","['Social Choice; Clubs; Committees; Associations', 'Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior']","['D71', 'D72']",Aggregation and Social Choice: A Mean Voter Theorem,0,0,0,0,0,1991,01,01
80,6,2012-11-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2012,11,01
80,5,2012-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2012,09,01
80,4,2012-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2012,07,01
80,4,2012-07-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2012,07,01
80,3,2012-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2012,05,01
58,6,1990-11-01,ECONLIT None Found,"['Kamiya, Kazuya']",[nan],[nan],A Globally Stable Price Adjustment Process,0,0,0,0,0,1990,11,01
58,6,1990-11-01,ECONLIT None Found,"['Roth, Alvin E.', 'Vande Vate, John H.']",[nan],[nan],Random Paths to Stability in Two-Sided Matching,0,0,0,0,0,1990,11,01
58,6,1990-11-01,ECONLIT None Found,"['Weil, Philippe']",[nan],[nan],On the Possibility of Price Decreasing Bubbles,0,0,0,0,0,1990,11,01
58,6,1990-11-01,ECONLIT None Found,"['Veall, Michael R.']",[nan],[nan],Testing for a Global Maximum in an Econometric Context,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"In this paper, it will be shown that any conditional moment test of functional form of nonlinear regression models can be converted into a chi-square test that is consistent against all deviations from the null hypothesis that the model represents the conditional expectation of the dependent variable relative to the vector of regressors.","['Bierens, Herman J.']",[nan],[nan],A Consistent Conditional Moment Test of Functional Form,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"This paper considers the formulation, estimation, and evaluation of semiparametric multistates duration models with time-varying regressors and unobservables correlated over spells. The authors' models are applied to test a dynamic version of the neoclassical theory of fertility. Using Swedish data, they find that rising female wages over the lifecycle delay times to all conceptions, but barely affect childlessness. The authors estimate a model that predicts fertility attained at different ages as well as the aggregate time series of birth rates. Estimated cohort drift in wage and income parameters is consistent with the expansion of pronatal social programs over the sample period.","['Walker, James R.', 'Heckman, James J.']",[nan],[nan],The Relationship between Wages and Income and the Timing and Spacing of Births: Evidence from Swedish Longitudinal Data,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"This paper endogenizes the frequency of major discoveries and the extent of their refinement. Four axioms deliver a one-parameter family of beliefs that guide exploratory effort. Such effort trades off the prospect of major new discovery against the chance of successfully refining discoveries made in the past. The only other parameter is the cost of making new discoveries relative to the cost of refining old ones. The paper derives time-series properties of inventive activity as they relate to the two parameters, and it discusses several specific inventions and their subsequent refinement.","['Jovanovic, Boyan', 'Rob, Rafael']",[nan],[nan],Long Waves and Short Waves: Growth through Intensive and Extensive Search,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"A new definition of strategic stability is shown to satisfy all of the requirements given by Elon Kohlberg and Jean-Francois Mertens (1986). The definition follows the general form of the original definition of Kohlberg and Mertens, but, rather than working with perturbations of the payoffs or strategy space, works directly with perturbations to the best reply correspondence. With the appropriate topology on this space of perturbations, the resulting definition does satisfy all of the requirements given by Kohlberg and Mertens. It is shown that one does not have much freedom in the topology one uses.","['Hillas, John']",[nan],[nan],On the Definition of the Strategic Stability of Equilibria,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"A scheme of plain conversation is constructed, which is a universal mechanism for all noncooperative games with incomplete information with at least four players, in the following sense: every solution that can be achieved by means of an arbitrary communication mechanism is a correlated equilibrium payoff of the game extended by the scheme of plain conversation. By a property of the correlated equilibrium, a similar result holds also with the Nash equilibrium solution concept. The universal mechanism can be used without any loss of efficiency.","['Forges, Francoise']",[nan],[nan],Universal Mechanisms,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"This paper reports on an experimental study of the way in which individuals make inferences from publicly available information. We compare the predictions of a theoretical model of a common knowledge inference process with actual behavior. In the theoretical model, ""perfect Bayesians,"" starting with private information, take actions; an aggregate statistic is made publicly available; the individuals do optimal Bayesian updating and take new actions; and the process continues until there is a common knowledge equilibrium with complete information pooling. We find that the theoretical model roughly predicts the observed behavior, but the actual inference process is clearly less efficient that the standard of the theoretical model, and while there is some pooling, it is incomplete.","['Page, Talbot', 'McKelvey, Richard D.']",[nan],[nan],Public and Private Information: An Experimental Study of Information Pooling,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"The authors modify the standard principal-agent model with oral hazard by allowing the contract to be renegotiated after the agent's choice of action and before the observation of the action's consequences. In equilibrium, the agent randomizes over effort levels. The optimal contract gives the agent a menu of compensation schemes: safe ones intended for low-effort workers and risky ones for those whose effort is high. The optimal contract may give the agent a positive rent, in contrast to the case without renegotiation.","['Tirole, Jean', 'Fudenberg, Drew']",[nan],[nan],Moral Hazard and Renegotiation in Agency Contracts,0,0,0,0,0,1990,11,01
58,6,1990-11-01,"The authors study a rich class of noncooperative games that includes models of oligopoly competition, macroeconomic coordination failures, arms races, bank runs, technology adoption and diffusion, R&D competition, pretrial bargaining, coordination in teams, and many others. For all these games, the sets of pure strategy Nash equilibria, correlated equilibria, and rationalizable strategies have identical bounds. Also, for a class of models of dynamic adaptive choice behavior that encompasses both best-response dynamics and Bayesian learning, the players' choices lie eventually within the same bounds. These bounds are shown to vary monotonically with certain exogenous parameters.","['Roberts, John', 'Milgrom, Paul']",[nan],[nan],"Rationalizability, Learning, and Equilibrium in Games with Strategic Complementarities",0,0,0,0,0,1990,11,01
58,5,1990-09-01,ECONLIT None Found,"['Nielsen, Lars Tyge']",[nan],[nan],Common Knowledge of an Aggregate of Expectations,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"This paper develops asymptotic prediction functions that approximate the shape of the density of future observations and correct for parameter uncertainty. The functions are based on extensions to a definition of predictive likelihood originally suggested by S. L. Lauritzen (1974) and D. Hinkley (1979). The prediction function is shown to possess efficiency properties based on the Kullback-Leibler measure of information loss. Examples of the application of the prediction function and the derivation of relative efficiency are shown for linear-normal models, nonnormal models, and ARCH models.","['Cooley, Thomas F.', 'Parke, William R.']",[nan],[nan],Asymptotic Likelihood-Based Prediction Functions,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"A measure of finite sample estimator performance based on the probability of large deviations is introduced. The tail performance of the least squares estimator is studied in detail, and the authors find that it achieves good tail performance under strictly Gaussian conditions, but performance is extremely poor in the case of heavy-tailed error distributions. Turning to the tail behavior of various robust estimators, they focus on tail performance under heavy (algebraic) tail errors. Perhaps most significantly, it is shown that the authors' finite-sample measure of tail performance is, for heavy tailed error distributions, essentially the same as the finite sample concept of breakdown point introduced by D. L. Donoho and P. J. Huber (1983). Coauthors are Jana Jureckova, Roger Koenker, and Stephen Portnoy.","['He, Xuming']",[nan],[nan],Tail Behavior of Regression Estimators and Their Breakdown Points,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"In a single structural equation, only the direction of the vector of coefficients of the endogenous variables is determined. Estimators for that direction can be defined directly, but are also induced by classical estimators that embody the traditional normalization rule. Exact distribution results show that the properties of estimators that depend on the usual normalization rule--which gives special emphasis to a particular direction--are distorted by that dependence, while those of the direct estimators are not. Thus, the traditional normalization rule may serve to define the parameters of interest, but should not be embodied in the estimation procedure.","['Hillier, Grant H.']",[nan],[nan],On the Normalization of Structural Equations: Properties of Direct Estimators,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"The effects of firm pension plan provisions on the retirement decisions of older employees are analyzed. The empirical results are based on data from a large firm, with a typical defined benefit pension plan. The ""option value"" of continued work is the central feature of the analysis. Estimation relies on a retirement decision rule that is close in spirit to the dynamic programming rule, but is considerably less complex than a comprehensive implementation of that rule, thus greatly facilitating the numerical analysis.","['Wise, David A.', 'Stock, James H.']",[nan],[nan],"Pensions, the Option Value of Work, and Retirement",0,0,0,0,0,1990,09,01
58,5,1990-09-01,"This paper explores the robustness of the essential economic conclusions of the Roy model of self-selection and income inequality to relaxation of its normality assumptions. A log concave version of the model reproduces most of the main results. Log convex cases offer counterexamples. The authors show that in a Roy economy, random assignment is inegalitarian and Pareto inefficient. They consider nonparametric identifiability of latent skill distributions with cross-section and panel data. The authors' analysis proves nonparametric identifiability for the closely related competing risks model.","['Honore, Bo E.', 'Heckman, James J.']",[nan],[nan],The Empirical Content of the Roy Model,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"A model of consumer multipurpose shopping is used for studying the optimality of central places. There are two different commodities sold by two different types of firms. The shopping frequencies are exogenously given and different for the two commodities. Consumers can group their purchases of the two commodities in order to reduce transport costs. It is shown that the socially optimal configuration of firms always involves the clustering of a firm type 2 (low purchase frequency) with a firm of type 1 (high purchase frequency), assuming that the number of firms of type 2 is smaller than the number of firms of type 1.","['Quinzii, Martine', 'Thisse, Jacques-Francois']",[nan],[nan],On the Optimality of Central Places,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"The authors extend E. Maskin's results on Nash implementation. First, they establish a condition that is both necessary and sufficient for Nash implementability if there are three or more agents (the case covered by Maskin's sufficiency result). Second--and more important--they examine the two-agent case (for which there existed no general sufficiency results). The two-agent model is the leading case for applications to contracting and bargaining. For this case, too, they establish a condition that is both necessary and sufficient. The authors use their theorems to derive simpler sufficiency conditions that are applicable in a wide variety of economic environments.","['Moore, John', 'Repullo, Rafael']",[nan],[nan],Nash Implementation: A Full Characterization,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"In this paper, the authors reexamine the data from B. O'Neill's (1987) experiment involving a repeated, two-person, constant-sum game. They find that there is less evidence in support of the minimax hypothesis than indicated by O'Neill. There is strong evidence of serial correlation in players' choices, with several players displaying statistically significant dependence on the past moves of their opponents. The authors interpret this finding as evidence that the plays themselves rejected minimax play as the appropriate model for their opponents' behavior. They find no evidence that players' behavior approached minimax behavior as players became more experienced.","['Brown, James N.', 'Rosenthal, Robert W.']",[nan],[nan],Testing the Minimax Hypothesis: A Re-examination of O'Neill's Game Experiment,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"This paper investigates pure strategy sequential equilibria of repeated games with imperfect monitoring. The approach emphasizes the equilibrium value set and the static optimization problems embedded in extremal equilibria. A succession of propositions, central among which is ""self-generation,"" allow properties of constrained efficient supergame equilibria to be deduced from the solutions of the static problems. The authors show that the latter include solutions having a ""bang-bang"" property; this affords a significant simplification of the equilibria that need be considered. These results apply to a broad class of asymmetric games, thereby generalizing their earlier work on optimal cartel equilibria.","['Stacchetti, Ennio', 'Pearce, David', 'Abreu, Dilip']",[nan],[nan],Toward a Theory of Discounted Repeated Games with Imperfect Monitoring,0,0,0,0,0,1990,09,01
58,5,1990-09-01,"This paper describes a new approach to normative economics, combining the theory of social choice with econometric modeling of aggregate consumer behavior. The author first derives a system of aggregate demand functions by exact aggregation over individual demand functions. He then constructs measures of individual welfare from systems of individual demand functions. Finally, the author incorporates these measures into a social welfare function, introducing ethical assumptions based on horizontal and vertical equity. To illustrate the application of this approach, he considers the U.S. standard of living and its cost over the period 1947-85.","['Jorgenson, Dale W.']",[nan],[nan],Aggregate Consumer Behavior and the Measurement of Social Welfare,0,0,0,0,0,1990,09,01
58,4,1990-07-01,ECONLIT None Found,"['Nelson, Forrest D.', 'Savin, N. E.']",['Econometric and Statistical Methods and Models--General'],[nan],The Danger of Extrapolating Asymptotic Local Power,0,0,0,0,0,1990,07,01
58,4,1990-07-01,ECONLIT None Found,"['Nelson, Charles R.', 'Startz, Richard']",['Inferential Problems in Simultaneous Equation Systems'],[nan],Some Further Results on the Exact Small Sample Properties of the Instrumental Variable Estimator,0,0,0,0,0,1990,07,01
58,4,1990-07-01,ECONLIT None Found,"['Safra, Zvi', 'Zilcha, Itzhak', 'Zhou, Lin']",['Game Theory and Bargaining Theory'],[nan],Risk Aversion in the Nash Bargaining Problem with Risky Outcomes and Risky Disagreement Points,0,0,0,0,0,1990,07,01
58,4,1990-07-01,ECONLIT None Found,"['Thomson, William', 'Chun, Youngsub']",['Game Theory and Bargaining Theory'],[nan],Bargaining with Uncertain Disagreement Points,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"The authors analyze a continuous time model with a Walrasian labor market and a random search retail market with prices set on a take-it or leave-it basis. The equilibrium distribution of money holdings is the asymptotic steady state of this stochastic process. There is a unique uniform price steady state equilibrium. The faster the search process the higher the absolute price, wage, and real wage. The instantaneous effect of an equal per capita infusion of money is to raise the price, wage, real wage, and transactions rate. The immediate post-infusion price and wage can overshoot their new asymptotic values.","['Yellin, Joel', 'Diamond, Peter']",['General Equilibrium and Disequilibrium Theory'],[nan],Inventories and Money Holdings in a Search Economy,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"The authors compare two methods for a monopolist to sell information to traders in a financial market. In a direct sale, information buyers observe versions of the seller's signal while in an indirect sale the seller sells shares in a portfolio based on his private information. It is shown that, when traders are identical and pricing is linear, there is a trade-off between optimal surplus extraction that is possible under direct sale and more effective control of the usage of information that is possible under indirect sale. The optimal selling method depends on how much information is revealed by equilibrium prices.","['Pfleiderer, Paul', 'Admati, Anat R.']","['Microeconomics--Theory of Firm and Industry under Imperfectly Competitive Market Structures', 'Theory of Uncertainty and Information']","[nan, nan]",Direct and Indirect Sale of Information,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"Individuals with finite private information independently choose acts and messages. Their utilities may depend on all acts and information, including the center's. Incentive payments are separable and fully transferable. Implementable incentives making specified behavior a Bayesian equilibrium are derived whenever the center's information depends stochastically, however slightly, on all relevant private information, and also whenever individuals' relative valuations of acts, however divergent, are not too dissimilarly affected by different states of nature. Feasibility is resolved whenever the desired strategies reveal the agents' beliefs about the center's information. Key concepts of agent similarity are developed for nonresponsive and budget-balancing cases.","['Pratt, John W.', 'Johnson, Scott', 'Zeckhauser, Richard J.']",['Theory of Uncertainty and Information'],[nan],Efficiency Despite Mutually Payoff-Relevant Private Information: The Finite Case,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"This paper proposes a new approach to the study of economic problems that have hitherto been modeled as games with discontinuous payoffs. Typically, the discontinuities arise from indeterminacies in the underlying problem. The authors' point of departure from the conventional approach is to view the sharing rules that resolve these indeterminacies as part of the solution rather than as part of the description of the model. A solution to the authors' model is a sharing rule, together with a profile of (mixed) strategies that satisfies the usual (Nash) best response criterion. Their main result is that such a solution always exists.","['Zame, William R.', 'Simon, Leo K.']","['Game Theory and Bargaining Theory', 'Microeconomics--Theory of Firm and Industry under Imperfectly Competitive Market Structures']","[nan, nan]",Discontinuous Games and Endogenous Sharing Rules,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"The author builds a theory of the choice of techniques in joint production, at a given profit rate, considering a market algorithm. Partial results are extended by means of an abstract notion of technology, where techniques meet demand and satisfy local properties. Global results on the existence, uniqueness, and convergence towards an equilibrium technique are obtained. The author, thus, characterizes cases where a square technique is reached, which provides an answer to an old debate, initiated by W. S. Jevons, between classical and neoclassical economists. But the framework allows for a more general interpretation in terms of two-level planning procedures.","['Bidard, Christian']","['Microeconomics--Theory of Production', 'Technological Change and Innovation']","[nan, nan]",An Algorithmic Theory of the Choice of Techniques,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"This paper considers asymptotically efficient instrumental variables estimation of nonlinear models in an i.i.d. environment. The optimal instruments are estimated by nonparametric methods, either nearest neighbor or series regression. Ways of choosing the degree of approximation of the nonparametric instruments are discussed. Asymptotic efficiency is shown. The finite sample properties of the estimators are examined in a small sampling study of an endogenous dummy variable model.","['Newey, Whitney K.']",['Distributed Correlated Disturbance Terms; Inferential Problems in Single Equation Models'],[nan],Efficient Instrumental Variables Estimation of Nonlinear Models,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"In this paper, the feasibility of estimating a Nash labor market equilibrium model using only information on workers is demonstrated. The equilibrium model, adapted from Albrecht and Axell (1984), is based on workers who are homogenous in terms of market productivity and heterogeneous in terms of nonmarket productivity, and on firms that are heterogeneous in terms of productive efficiency. The equilibrium model is contrasted with an unrestricted version of the model in terms of its fit to the data.","['Wolpin, Kenneth I.', 'Eckstein, Zvi']",['Labor Economics: Theory and Empirical Studies Illustrating Theory'],[nan],Estimating a Market Equilibrium Search Model from Panel Data on Individuals,0,0,0,0,0,1990,07,01
58,4,1990-07-01,"This paper tests the effects of the level and length of unemployment insurance benefits on unemployment durations. The paper particularly studies individual behavior during the weeks just prior to when benefits lapse. Higher unemployment insurance benefits are found to have a strong negative effect on the probability of leaving unemployment. However, the probability of leaving unemployment rises dramatically just prior to when benefits lapse. Individual data are used with accurate information of spell durations, and the level and length of benefits. The semiparametric estimation techniques used in the paper yield more plausible estimates than conventional approaches and provide useful diagnostics.","['Meyer, Bruce D.']","['Unemployment Insurance', 'Employment Studies; Unemployment and Vacancies; Retirements and Quits']","[nan, nan]",Unemployment Insurance and Unemployment Spells,0,0,0,0,0,1990,07,01
58,3,1990-05-01,ECONLIT None Found,"['Thistle, Paul D.']","['Econometric and Statistical Methods and Models--General', 'Income Distribution']","[nan, nan]",Large Sample Properties of Two Inequality Indices,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"In this paper, the authors study a general concave discrete-time, infinite-horizon, optimal-control problem. They establish necessary and sufficient conditions for optimality in the weak sense of W. A. Brock and for optimality in the strong sense of D. Gale. The corresponding transversality conditions are general exhaustion properties of the limit value of the optimal state variables; these properties cover and extend the well-known results obtained in special cases.","['Michel, Philippe']",['Mathematical Methods and Models--Optimization Techniques'],[nan],Some Clarifications on the Transversality Condition,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"It is shown that if an economy's participants cannot be separated into groups across which there are no potentially conflicting interests--i.e., if the economy is ""indecomposable""--then every continuous truth-dominant allocation mechanism will attain nonoptimal allocations on an open dense set of preference profiles. Classical ""Edgeworth-box"" exchange economies (economies with no externalities and no production, but with arbitrary numbers of consumers and goods), as well as economies with public goods and economies with other kinds of externalities, are all shown via simple arguments to be indecomposable. The results are extended to cover nonrevelation mechanisms.","['Walker, Mark', 'Hurwicz, Leonid']","['Welfare Theory--General', 'Game Theory and Bargaining Theory', 'General Equilibrium and Disequilibrium Theory']","[nan, nan, nan]",On the Generic Nonoptimality of Dominant-Strategy Allocation Mechanisms: A General Theorem That Includes Pure Exchange Economies,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"This paper considers a general equilibrium model of an economy where some firms may exhibit increasing returns to scale or more general types of nonconvexities. The firms are instructed to follow the standard marginal cost pricing rule or to fulfill the first-order necessary conditions for profit maximization. A general existence theorem of equilibria is proved in the case of an arbitrary number of firms. No assumption is made to imply the aggregate productive efficiency of equilibria, a condition that must be excluded in the nonconvex case.","['Cornet, Bernard', 'Bonnisseau, Jean-Marc']",['General Equilibrium and Disequilibrium Theory'],[nan],Existence of Marginal Cost Pricing Equilibria in Economies with Several Nonconvex Firms,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"Alternating price competition between firms selling differentiated products to nonhomogeneous consumers can yield two different types of equilibria. One, which we call ""disciplined,"" arises when products are close substitutes. Another, which we call ""spontaneous,"" emerges when products are more differentiated. In disciplined equilibria, an implicit threat to cut price further, in response to an initial price cut, supports quite collusive outcomes, which become less collusive as product differentiation increases. In spontaneous equilibria, no such threat is needed. Consumers in the smaller market tend to pay a higher price, as do consumers served by the more efficient firm.","['Eaton, Jonathan', 'Engers, Maxim']",['Microeconomics--Theory of Firm and Industry under Imperfectly Competitive Market Structures'],[nan],Intertemporal Price Competition,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"Suppose that a representative downstream firm must buy relationship-specific capital before trading with an upstream monopolist. Under reasonable conditions, the monopolist would precommit to price to induce greater investment. If the monopolist were privately informed of its unit costs after the downstream firms invested, then the optimal contract would specify a maximum ("" list"") price which might be discounted (to ""transactions"" prices) if costs were low: a mode of pricing prevalent in interfirm trade. These results may explain why G. J. Stigler and J. K. Kindahl's medium-term price series tracked wholesale price indices whenever the latter were nondecreasing, but otherwise fell significantly faster.","['Seidmann, Daniel J.']","['Microeconomics--Theory of Firm and Industry under Imperfectly Competitive Market Structures', 'Market Structure: Industrial Organization and Corporate Strategy']","[nan, nan]",Transactions/List Pricing,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"Spot contracting generally involves efficiency losses relative to long-term contracting. It is proved here that short-term contracting and renegotiation allow to achieve long-run efficiency when transfers are not limited, objectives are conflicting, and no relevant asymmetric information appears at recontracting dates. This last assumption excludes adverse selection, but not moral hazard when technologies and preferences are time separable.","['Salanie, Bernard', 'Rey, Patrick']","['Theory of Uncertainty and Information', 'Microeconomics--Agent Theory']","[nan, nan]","Long-term, Short-term and Renegotiation: On the Value of Commitment in Contracting",0,0,0,0,0,1990,05,01
58,3,1990-05-01,"This paper proposes a characterization of optimal strategies for playing certain repeated coordination games whose players have identical preferences. Players' optimal coordination strategies reflect their uncertainty about how their partners will respond to multiple-equilibrium problems; this uncertainty constrains the statistical relationships between their strategy choices players can bring about. The authors show that optimality is nevertheless consistent with subgame-perfect equilibrium. Examples are analyzed in which players use precedents as focal points to achieve and maintain coordination, and in which they play dominated strategies with positive probability in early stages in the hope of generating a useful precedent.","['Crawford, Vincent P.', 'Haller, Hans']",['Game Theory and Bargaining Theory'],[nan],Learning How to Cooperate: Optimal Play in Repeated Coordination Games,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"This paper is an empirical investigation of equilibrium restrictions on household consumption and male labor supply. It exploits a simple factor structure, rationalized by two assumptions, that household allocations are Pareto optimal and that the labor market is competitive. The paper estimates household preferences, and tests how well this parsimonious factor structure represents panel data on married couples and time series data on asset returns. Most of the estimates are roughly comparable to those found in previous work; no evidence against the simple factor representation is found and the intertemporal capital asset pricing model is not rejected.","['Altug, Sumru', 'Miller, Robert A.']","['Microeconomic Theory--Theory of the Household (Consumer Demand)', 'Labor Economics: Theory and Empirical Studies Illustrating Theory', 'Employment Studies; Unemployment and Vacancies; Retirements and Quits']","[nan, nan, nan]",Household Choices in Equilibrium,0,0,0,0,0,1990,05,01
58,3,1990-05-01,"This paper seeks to explain the causes of volatility clustering in exchange rates. Careful examination of intra-daily exchange rates provides a test of two hypotheses--heat waves and meteor showers. The heat wave hypothesis is that the volatility in one market is predicted only by the past of that market. The meteor shower hypothesis is that intra-daily volatility spills over from one market to the next. Using the GARCH model to specify the heteroskedasticity across intra-daily market segments, we find that the empirical evidence is generally against the null hypothesis of the heat wave. Using a volatility type of vector autoregression we examine the impact of news in one market on the time path of per-hour volatility in other markets.","['Ito, Takatoshi', 'Lin, Wen-Ling', 'Engle, Robert F.']","['Exchange Rates and Markets--Theory and Studies', 'Capital Markets--Empirical Studies, Including Regulation']","[nan, nan]",Meteor Showers or Heat Waves? Heteroskedastic Intra-daily Volatility in the Foreign Exchange Market,0,0,0,0,0,1990,05,01
58,2,1990-03-01,ECONLIT None Found,"['Dijkstra, Theo K.', 'Bekker, P. A.']",['Inferential Problems in Simultaneous Equation Systems'],[nan],On the Nature and Number of the Constraints on the Reduced Form as Implied by the Structural Form,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"Asymptotic distributions are derived for the ordinary least squares estimate of a first order autoregression model when the series is fractionally integrated. The fractional unit root distribution is introduced to describe the limiting distribution. The unit root distribution is shown to be an atypical member of this family because its density is nonzero over the entire real line. For -1/2 < d < 0 the fractional unit root distribution has nonpositive support, while if 0 < d < 1/2 the fractional unit root distribution has nonnegative support. Any misspecification of the order of differencing leads to different limiting distributions. The t statistic only converges when d = 0. Results are proven with functional limit theorems.","['Sowell, Fallaw']",['Time Series and Spectral Analysis'],[nan],The Fractional Unit Root Distribution,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"This article proposes a general method to build exact tests and confidence sets in linear regressions with first-order autoregressive Gaussian disturbances. Because of a nuisance parameter problem, we argue that generalized bounds tests and conservative confidence sets provide natural inference procedures in such a context. Given an exact confidence set for the autocorrelation coefficient, we describe how to obtain a similar simultaneous confidence set for the autocorrelation coefficient and any subvector of regression coefficient. Conservative confidence sets for the regression coefficients are then deduced by a projection method. For any hypothesis that specifies jointly the value of the autocorrelation coefficient and any set of linear restrictions on the regression coefficients, we get exact similar tests. For testing linear hypotheses about the regression coefficients only, we suggest bounds-type procedures. Exact confidence sets for the autocorrelation coefficient are built by ""inverting"" autocorrelation tests. The method is illustrated with two examples.","['Dufour, Jean-Marie']",['Distributed Correlated Disturbance Terms; Inferential Problems in Single Equation Models'],[nan],Exact Tests and Confidence Sets in Linear Regressions with Autocorrelated Errors,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"This paper presents a simple estimator of the shape parameter in a Weibull duration model with unobserved heterogeneity. The estimator is consistent and asymptotically normal under mild conditions, and a consistent estimator of the asymptotic variance is available. A Monte Carlo study indicates that the asymptotic distribution of the estimator provides a good approximation to the finite sample distribution. The estimation strategy can be extended to a model with regressors and to a log-logistic model with unobserved heterogeneity. The advantages of the estimator are that it is easy to calculate and that its asymptotic distribution can be derived.","['Honore, Bo E.']",['Distributed Correlated Disturbance Terms; Inferential Problems in Single Equation Models'],[nan],Simple Estimation of a Duration Model with Unobserved Heterogeneity,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"This paper analyzes a competitive credit market where banks use imperfect and independent tests to assess the ability of a potential creditor to repay credit. The banks compete by announcing interest rates at which they will provide credit to those applicants who pass the banks' tests. The proportion of applicants who pass the test of at least one bank increases with the number of banks providing credit, so the average credit-worthiness decreases. It is then shown that in a situation where all banks charge the same interest rate, a bank always has the incentive to undercut in order to improve the average credit-worthiness of its own clientele. This feature represents the major difference from the situations in standard Bertrand and Bertrand-Edgeworth models.","['Broecker, Thorsten']","['Commercial Banking', 'Game Theory and Bargaining Theory']","[nan, nan]",Credit-Worthiness Tests and Interbank Competition,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"Futures hedging and pricing are examined in a model with two consumption goods, stochastic output, and sequential information arrival. Positive (negative) complementarity in consumer preferences promotes greater futures risk premia. The partial equilibrium conclusion that risk premia are a function of hedging pressure fails in the general equilibrium analysis with costless trading. As preferences are varied, producer hedging can change from long to short, while the futures risk premium remains unchanged. However, hedging pressure is reinstated as a determinant of risk premia, provided (as is usually valid) that fixed setup costs of trading deter consumers more than producers from participating in the futures market.","['Hirshleifer, David']","['Capital Markets: Theory, Including Portfolio Selection, and Empirical Studies Illustrating Theory']",[nan],Hedging Pressure and Futures Price Movements in a General Equilibrium Model,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"The authors analyze the principal-agent relationship when the principal has private information as a three-stage game: contract proposal, acceptance/refusal, and contract execution. They assume that the information does not directly affect the agent's payoff (private values). Equilibrium exists and is generically locally unique. Moreover, it is Pareto optimal for the different types of principal. The principal generically does strictly better than when the agent knows her information. Equilibrium allocations are the Walrasian equilibria of an ""economy"" where the traders are different types of principal and ""exchange"" the slack on the agent's individual rationality and incentive compatibility constraints.","['Tirole, Jean', 'Maskin, Eric']","['Microeconomics--Agent Theory', 'Game Theory and Bargaining Theory', 'General Equilibrium and Disequilibrium Theory']","[nan, nan, nan]",The Principal-Agent Relationship with an Informed Principal: The Case of Private Values,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"Preference relations over two-stage lotteries are analyzed. Empirical evidence indicates that decisionmakers do not always behave in accordance with the reduction of compound lotteries axiom, but they seem to satisfy a compound independence axiom. Although the reduction and the compound independence axioms, together with continuity, imply expected utility theory, each of them by itself is compatible with all possible preference relations over simple lotteries. Using these axioms, the author analyzes three different versions of expected utility for two-stage lotteries. The author suggests several different compound dominance axioms as possible replacements of the reduction axiom, which are strictly weaker than the reduction of compound lotteries axiom.","['Segal, Uzi']",['Theory of Uncertainty and Information'],[nan],Two-Stage Lotteries without the Reduction Axiom,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"In this study, the authors report the results from laboratory asset markets designed to test the rational expectations hypothesis that markets aggregate and transmit the information of differentially informed traders. After documenting evidence in favor of the rational expectations model, they examine which features of their environment are necessary or sufficient to achieve an rational expectations equilibrium. The authors find that trading experience and common knowledge of dividends are jointly sufficient to achieve a rational expectations equilibrium, but that neither is a sufficient condition by itself. They also present some stylized facts about the convergence process leading to a rational expectations equilibrium.","['Lundholm, Russell', 'Forsythe, Robert']","['Capital Markets: Theory, Including Portfolio Selection, and Empirical Studies Illustrating Theory', 'Experimental Economic Methods']","[nan, nan]",Information Aggregation in an Experimental Market,0,0,0,0,0,1990,03,01
58,2,1990-03-01,"An adaptive learning rule is exhibited for the Azariadis (1981) overlapping generations model of a monetary economy with multiple equilibria, under which the economy may converge to a stationary sunspot equilibrium, even if agents do not initially believe that outcomes are significantly different in different ""sunspot"" states. The learning rule studied is of the ""stochastic approximation"" form studied by H. Robbins and S. Monro (1951); methods for analyzing the convergence of this form of algorithm are presented that may be of use in many other contexts as well. Conditions are given under which convergence to a sunspot equilibrium occurs with probability one.","['Woodford, Michael']","['General Equilibrium and Disequilibrium Theory', 'Economic Fluctuations--Theory', 'Domestic Monetary Theory; Empirical Studies Illustrating Theory', 'Macroeconomics of Intertemporal Choice', 'Theory of Uncertainty and Information']","[nan, nan, nan, nan, nan]",Learning to Believe in Sunspots,0,0,0,0,0,1990,03,01
58,1,1990-01-01,"This paper develops an asymptotic theory for residual based tests for cointegration. Attention is given to the augmented Dickey-Fuller (ADF) test and the Z(subscript alpha) and Z(subscript t) unit root tests. Two new tests are also introduced. The tests are shown to be asymptotically similar, and simple representations of their limiting distributions are given and asymptotic critical values are tabulated. The ADF and Z(subscript t) tests are asymptotically equivalent. Power properties of the test are also studied. The tests are consistent if suitably constructed, but the ADF and Z(subscript t) tests have slower rates of divergence under cointegration than the other tests.","['Phillips, Peter C. B.', 'Ouliaris, S.']",['Time Series and Spectral Analysis'],[nan],Asymptotic Properties of Residual Based Tests for Cointegration,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"The authors consider the time series regression model where the error term follows a nonstable autoregressive process and present a general approach for delivering the limiting distribution of a normalized estimator for the autoregressive parameter. The present approach is quite straightforward and leads them to an accurate evaluation of the distribution function, unlike the other approaches suggested in the literature. The authors' methodology is illustrated and percent points are tabulated. The present approach produces a good approximation method for the finite sample distribution and also provides an accurate evaluation of the limiting powers of some unit root tests under a sequence of local alternatives.","['Nabeya, Seiji', 'Tanaka, Katsuto']",['Time Series and Spectral Analysis'],[nan],A General Approach to the Limiting Distribution for Estimators in Time Series Regression with Nonstable Autoregressive Errors,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"This paper considers estimation and hypothesis testing in linear time series when some or all of the variables have (possibly multiple) unit roots. The motivating example is a vector autoregression with some unit roots in the companion matrix, which might include polynomials in time as regressors. Parameters that can be written as coefficients on mean zero, nonintegrated regressors have jointly normal asymptotic distribution, converging at the rate of T(superscript one-half) In general, the other coefficients (including the coefficient on polynomials in time), and associated t and F test statistics, have nonstandard asymptotic distributions.","['Stock, James H.', 'Watson, Mark W.', 'Sims, Christopher A.']",['Time Series and Spectral Analysis'],[nan],Inference in Linear Time Series Models with Some Unit Roots,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"The authors introduce, in this paper, a method for solving nonlinear quadratic Pareto problems. The method provides the analyst with a set of time series realizations for the variables in the economy. By obtaining a large number of these realizations, they can approximate the empirical distributions of a variety of statistics, which will give a detailed description of the model's properties. In particular, those statistics can be compared with the similar ones obtained from actual data, and different criteria for goodness of fit can be defined on the basis of these comparisons.","['Novales, Alfonso']","['Construction, Analysis, and Use of Econometric Models', 'Domestic Monetary Theory; Empirical Studies Illustrating Theory']","[nan, nan]",Solving Nonlinear Rational Expectations Models: A Stochastic Equilibrium Model of Interest Rates,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"A method for computing (approximate) cost-of-living index numbers for arbitrary reference income levels is presented. It combines the use of fairly disaggregated data with a relatively modest use of econometric methods. The basis ingredients are (1) a series of chained Tornqvist price index numbers relating to per capital total expenditure, (2) price index numbers for the commodities distinguished, and (3) the income parameters of a differential demand system. This method attains second order precision and is equivalent to a full econometric method based on a translog utility function. The method is demonstrated on Netherlands data for 1952-81.","['Balk, Bert M.']","['Theory of Index Numbers and Aggregation', 'Prices']","[nan, nan]",On Calculating Cost-of-Living Index Numbers for Arbitrary Income Levels,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"The theory of precautionary saving is shown to be isomorphic to the Arrow-Pratt theory of risk aversion, making possible the application of a large body of knowledge about risk aversion to precautionary saving--and more generally, to the theory of optimal choice under risk. In particular, a measure of the strength of the precautionary saving motive analogous to the Arrow-Pratt measure of risk aversion is used to establish a number of new propositions about precautionary saving and to give a new interpretation of the Dreze-Modigliani substitution effect.","['Kimball, Miles S.']","['Microeconomic Theory--Theory of the Household (Consumer Demand)', 'Theory of Uncertainty and Information']","[nan, nan]",Precautionary Saving in the Small and in the Large,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"The authors analyze a model of optimal consumption and portfolio selection in which consumption services are generated by holding a durable good. The durable good is illiquid in that a transaction cost must be paid when the good is sold. It is shown that optimal consumption is not a smooth function of wealth; it is optimal for the consumer to wait until a large change in wealth occurs before adjusting his consumption. Hence, the consumption based capital asset pricing model fails to hold. Nevertheless, the standard, one factor, market portfolio based capital asset pricing model does hold in this environment.","['Laroque, Guy', 'Grossman, Sanford J.']","['Theory of Uncertainty and Information', 'Capital Markets: Theory, Including Portfolio Selection, and Empirical Studies Illustrating Theory', 'Microeconomic Theory--Theory of the Household (Consumer Demand)']","[nan, nan, nan]",Asset Pricing and Optimal Portfolio Choice in the Presence of Illiquid Durable Consumption Goods,0,0,0,0,0,1990,01,01
58,1,1990-01-01,"A model of a market with pairwise meetings is developed in which traders have asymmetric information about the true state of the world. The focus is on information transmission. The main questions concern the extent to which the information is revealed to uninformed agents through the trade process and, in particular, whether nearly frictionless versions of this market give rise to full revelation results, as obtained by the literature on rational expectations for centralized and competitive markets. It turns out that, in equilibrium, the information is not fully revealed to uninformed agents, even when the market is approximately frictionless.","['Wolinsky, Asher']","['Theory of Uncertainty and Information', 'Microeconomics--Theory of Firm and Industry under Imperfectly Competitive Market Structures']","[nan, nan]",Information Revelation in a Market with Pairwise Meetings,0,0,0,0,0,1990,01,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],ACCEPTED MANUSCRIPTS.,0,0,0,0,0,2003,05,01
71,2,2003-03-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2003,03,01
71,1,2003-01-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2003,01,01
71,1,2003-01-01,ECONLIT None Found,"['Tzavalis, Elias', 'Hadri, Kaddour', 'Abadir, Karim M.']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],The Influence of VAR Dimensions on Estimator Biases: Rejoinder,0,0,0,0,0,2003,01,01
70,6,2002-11-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2002,11,01
70,5,2002-09-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2002,09,01
70,3,2002-05-01,ECONLIT None Found,"['Miravete, Eugenio J.']","['General Financial Markets: General (includes Measurement and Data)', 'Asymmetric and Private Information; Mechanism Design']","[nan, 'D82']",Preserving Log-Concavity under Convolution: Comment,0,0,0,0,0,2002,05,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],The Econometric Society Research Monograph Series Report of the Editors.,0,0,0,0,0,2002,01,01
69,5,2001-09-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2001,09,01
69,2,2001-03-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2001,03,01
69,1,2001-01-01,ECONLIT None Found,"['Erickson, Timothy']","['Multiple or Simultaneous Equation Models: Cross-Sectional Models; Spatial Models; Treatment Effect Models; Quantile Regressions; Social Interaction Models', 'Management of Technological Innovation and R&D', 'Intellectual Property and Intellectual Capital']","['C31', 'O32', 'O34']",Constructing Instruments for Regression with Measurement Error When No Additional Data Are Available: Comment,0,0,0,1,0,2001,01,01
72,6,2004-11-01,ECONLIT None Found,"['Jackson, Matthew O.']","['Noncooperative Games', 'Auctions', 'Search; Learning; Information and Knowledge; Communication; Belief; Unawareness']","['C72', 'D44', 'D83']",Corrigendum to 'Communication and Equilibrium in Discontinuous Games of Incomplete Information.',0,0,1,0,0,2004,11,01
68,6,2000-11-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,11,01
68,4,2000-07-01,ECONLIT None Found,[nan],[nan],[nan],Report of the President.,0,0,0,0,0,2000,07,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 2000 European Winter Meeting of the Econometric Society.,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],Announcements.,0,0,0,0,0,2000,05,01
68,2,2000-03-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,03,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors of the Econometric Society Research Monograph Series.,0,0,0,0,0,2000,01,01
80,2,2012-03-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2012,03,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2012,01,01
80,1,2012-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2012,01,01
71,6,2003-11-01,ECONLIT None Found,"['Mariotti, Thomas', 'Luttmer, Erzo G. J.']",['Noncooperative Games'],['C72'],The Existence of Subgame-Perfect Equilibrium in Continuous Games with Almost Perfect Information: A Comment,0,0,0,0,0,2003,11,01
67,6,1999-11-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,11,01
67,5,1999-09-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,09,01
67,5,1999-09-01,ECONLIT None Found,"['Gerber, Anke']",['Bargaining Theory; Matching Theory'],['C78'],The Nash Solution and the Utility of Bargaining: A Corrigendum,0,0,0,0,0,1999,09,01
67,4,1999-07-01,ECONLIT None Found,[nan],[nan],[nan],Program of the 1999 European Winter Meeting of the Econometric Society.,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,1999,07,01
67,4,1999-07-01,ECONLIT None Found,"['Al-Najjar, Nabil I.']",['Criteria for Decision-Making under Risk and Uncertainty'],['D81'],Decomposition and Characterization of Risk with a Continuum of Random Variables: Corrigendum,0,0,0,0,0,1999,07,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Report of the Editors of the Econometric Society Research Monograph Series.,0,0,0,0,0,1999,01,01
79,5,2011-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2011,09,01
79,5,2011-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2011,09,01
79,3,2011-05-01,ECONLIT None Found,[nan],[nan],[nan],SUBMISSION OF MANUSCRIPTS TO ECONOMETRICA.,0,0,0,0,0,2011,05,01
79,3,2011-05-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2011,05,01
66,5,1998-09-01,ECONLIT None Found,"['Volij, Oscar', 'Serrano, Roberto', 'Dagan, Nir']","['Exchange and Production Economies', 'Bargaining Theory; Matching Theory']","['D51', 'C78']",Comment on McLennan and Sonnenschein 'Sequential Bargaining as a Noncooperative Foundation for Walrasian Equilibrium.',0,0,0,0,0,1998,09,01
79,1,2011-01-01,ECONLIT None Found,[nan],[nan],[nan],SUBMISSION OF MANUSCRIPTS TO THE ECONOMETRIC SOCIETY MONOGRAPH SERIES.,0,0,0,0,0,2011,01,01
79,1,2011-01-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2011,01,01
78,6,2010-11-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2010,11,01
78,6,2010-11-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2010,11,01
78,5,2010-09-01,ECONLIT None Found,[nan],[nan],[nan],THE ECONOMETRIC SOCIETY 2009 ANNUAL REPORT OF THE PRESIDENT.,0,0,0,0,0,2010,09,01
78,5,2010-09-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS.,0,0,0,0,0,2010,09,01
78,5,2010-09-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2010,09,01
78,5,2010-09-01,ECONLIT None Found,[nan],[nan],[nan],Front Matter.,0,0,0,0,0,2010,09,01
78,5,2010-09-01,ECONLIT None Found,[nan],[nan],[nan],Back Matter.,0,0,0,0,0,2010,09,01
78,5,2010-09-01,ECONLIT None Found,"['Mikusheva, Anna']",['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes'],['C22'],Uniform Inference in Autoregressive Models: Corrigendum,0,0,0,0,0,2010,09,01
78,3,2010-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2010,05,01
78,3,2010-05-01,ECONLIT None Found,[nan],[nan],[nan],Front Matter.,0,0,0,0,0,2010,05,01
78,3,2010-05-01,ECONLIT None Found,[nan],[nan],[nan],Back Matter.,0,0,0,0,0,2010,05,01
78,1,2010-01-01,ECONLIT None Found,[nan],[nan],[nan],ANNOUNCEMENTS: 2010 WORLD CONGRESS OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2010,01,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],ACCEPTED MANUSCRIPTS.,0,0,0,0,0,1992,11,01
60,3,1992-05-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,1992,05,01
60,3,1992-05-01,ECONLIT None Found,[nan],[nan],[nan],THE 1993 FAR EASTERN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,05,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],SECTION 11. THE CONSTITUTION OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],1993 NORTH AMERICAN WINTER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],THE 1992 INDIA AND SOUTHEAST ASIA MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,"['Stokey, Nancy L.', 'Lucas, Robert E., Jr.']","['Money and Interest Rates: General', 'General Aggregative Models: Neoclassical']","['E40', 'E13']",Money and Interest in a Cash-in-Advance Economy: Reply,0,0,0,0,0,1992,03,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"EUROPEAN MEETING OF THE ECONOMETRIC SOCIETY BRUSSELS, BELGIUM, 1992.",0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],NORTH AMERICAN SUMMER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,01,01
63,1,1995-01-01,ECONLIT None Found,"['Govindan, Srihari']",['Noncooperative Games'],['C72'],Every Stable Set Contains a Fully Stable Set,0,0,0,0,0,1995,01,01
77,3,2009-05-01,ECONLIT None Found,[nan],[nan],[nan],Forthcoming Papers.,0,0,0,0,0,2009,05,01
77,3,2009-05-01,ECONLIT None Found,[nan],[nan],[nan],Front Matter.,0,0,0,0,0,2009,05,01
77,3,2009-05-01,ECONLIT None Found,[nan],[nan],[nan],Back Matter.,0,0,0,0,0,2009,05,01
77,2,2009-03-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2009,03,01
77,2,2009-03-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2009,03,01
62,3,1994-05-01,ECONLIT None Found,"['Wakker, Peter', 'Sarin, Rakesh']","['Criteria for Decision-Making under Risk and Uncertainty', 'Consumer Economics: Theory']","['D81', 'D11']",A General Result for Quantifying Beliefs,0,0,0,0,0,1994,05,01
76,6,2008-11-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2008,11,01
76,6,2008-11-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2008,11,01
76,6,2008-11-01,ECONLIT None Found,"['Chamberlain, Gary']","['Single Equation Models; Single Variables: General', 'Multiple or Simultaneous Equation Models; Multiple Variables: General']","['C20', 'C30']",Comment on 'Decision Theory Applied to an Instrumental Variables Model',0,0,0,0,0,2008,11,01
76,5,2008-09-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2008,09,01
76,5,2008-09-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2008,09,01
76,4,2008-07-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2008,07,01
76,3,2008-05-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2008,05,01
76,3,2008-05-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2008,05,01
76,2,2008-03-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2008,03,01
76,1,2008-01-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2008,01,01
76,1,2008-01-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2008,01,01
78,5,2010-09-01,ECONLIT None Found,[nan],['Pictures and Maps'],['Y91'],Roger B. Myerson,0,0,0,0,0,2010,09,01
75,6,2007-11-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2007,11,01
75,6,2007-11-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2007,11,01
75,5,2007-09-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2007,09,01
75,5,2007-09-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2007,09,01
75,4,2007-07-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2007,07,01
75,3,2007-05-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2007,05,01
75,3,2007-05-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2007,05,01
75,2,2007-03-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2007,03,01
75,2,2007-03-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2007,03,01
74,5,2006-09-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2006,09,01
74,4,2006-07-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2006,07,01
74,3,2006-05-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2006,05,01
74,2,2006-03-01,ECONLIT None Found,[nan],[nan],[nan],FORTHCOMING PAPERS.,0,0,0,0,0,2006,03,01
77,6,2009-11-01,ECONLIT None Found,[nan],['Pictures and Maps'],['Y91'],Torsten Persson,0,0,0,0,0,2009,11,01
59,2,1991-03-01,ECONLIT None Found,"['Howe, Eric C.']",['Input-Output Models'],['C67'],A More Powerful Method for Triangularizing Input-Output Matrices: A Comment,0,0,0,0,0,1991,03,01
59,1,1991-01-01,ECONLIT None Found,"['Smith, Gregor W.']","['Asset Pricing; Trading Volume; Bond Interest Rates', 'Foreign Exchange']","[nan, 'F31']",Solution to a Problem of Stochastic Process Switching,0,0,0,0,0,1991,01,01
58,5,1990-09-01,ECONLIT None Found,"['Calvo, Guillermo A.', 'Obstfeld, Maurice']",[nan],[nan],Time Consistency of Fiscal and Monetary Policy: A Comment,0,0,0,0,0,1990,09,01
58,5,1990-09-01,ECONLIT None Found,"['Brandenburger, Adam', 'Bergin, James']",[nan],[nan],A Simple Characterization of Stochastically Monotone Functions,0,0,0,0,0,1990,09,01
71,4,2003-07-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2003,07,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],NEWS NOTES.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],XXI LATIN AMERICAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],2003 EUROPEAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],2003 AUSTRALASIAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],2003 FAR EASTERN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],2003 NORTH AMERICAN SUMMER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,2003,05,01
71,3,2003-05-01,ECONLIT None Found,[nan],[nan],[nan],Table of Contents.,0,0,0,0,0,2003,05,01
70,6,2002-11-01,ECONLIT None Found,[nan],[nan],[nan],Table of Contents.,0,0,0,0,0,2002,11,01
70,5,2002-09-01,ECONLIT None Found,[nan],[nan],[nan],Table of Contents.,0,0,0,0,0,2002,09,01
70,4,2002-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2002,07,01
70,2,2002-03-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,2002,03,01
70,1,2002-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2002,01,01
69,6,2001-11-01,ECONLIT None Found,[nan],[nan],[nan],"Index to Volume 69, 2001.",0,0,0,0,0,2001,11,01
69,6,2001-11-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts To Econometrica.,0,0,0,0,0,2001,11,01
69,5,2001-09-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts To Econometrica.,0,0,0,0,0,2001,09,01
69,4,2001-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts To Econometrica.,0,0,0,0,0,2001,07,01
69,4,2001-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2001,07,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2001,05,01
69,3,2001-05-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,2001,05,01
69,2,2001-03-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts To Econometrica.,0,0,0,0,0,2001,03,01
69,1,2001-01-01,ECONLIT None Found,[nan],[nan],[nan],TABLE OF CONTENTS.,0,0,0,0,0,2001,01,01
68,6,2000-11-01,ECONLIT None Found,[nan],[nan],[nan],Index.,0,0,0,0,0,2000,11,01
68,5,2000-09-01,ECONLIT None Found,[nan],[nan],[nan],Erratum.,0,0,0,0,0,2000,09,01
68,5,2000-09-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,09,01
68,5,2000-09-01,ECONLIT None Found,"['Palm, Franz C.', 'Zellner, Arnold']",['Multiple or Simultaneous Equation Models: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes; State Space Models'],['C32'],Correction: Cointegration and Dynamic Simultaneous Equations Model,0,0,0,0,0,2000,09,01
68,4,2000-07-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,07,01
68,4,2000-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2000,07,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],News Notes.,0,0,0,0,0,2000,05,01
68,3,2000-05-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,2000,05,01
68,2,2000-03-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,2000,03,01
68,1,2000-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,2000,01,01
67,6,1999-11-01,ECONLIT None Found,[nan],[nan],[nan],"Index to Volume 67, 1999.",0,0,0,0,0,1999,11,01
67,5,1999-09-01,ECONLIT None Found,[nan],[nan],[nan],Erratum.,0,0,0,0,0,1999,09,01
67,5,1999-09-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,1999,09,01
67,4,1999-07-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,1999,07,01
67,3,1999-05-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,1999,05,01
67,2,1999-03-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,1999,03,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to Econometrica.,0,0,0,0,0,1999,01,01
67,1,1999-01-01,ECONLIT None Found,[nan],[nan],[nan],Submission of Manuscripts to the Econometric Society Monograph Series.,0,0,0,0,0,1999,01,01
60,6,1992-11-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,1992,11,01
60,6,1992-11-01,"The feasibility of Bertrand undercutting with nonuniform prices is established and properties are derived for Bertrand equilibrium in nonuniform price strategies. With free entry, equilibrium entails zero-profit minimum average cost production. If there is more than one producing firm, all prices collapse to a minimum average cost uniform price. An existence condition is compared to conditions from uniform price theory. Without free entry equilibrium, prices may not collapse to a uniform price. Positive profit may occur but all firms earn equal profit and incur equal marginal cost, while consumers pay average outlay no greater than marginal cost.","['Mandy, David M.']","['Market Structure, Pricing, and Design: Oligopoly and Other Forms of Market Imperfection', 'Oligopoly and Other Imperfect Markets']","['D43', 'L13']",Nonuniform Bertrand Competition,1,0,1,0,0,1992,11,01
60,3,1992-05-01,ECONLIT None Found,[nan],[nan],[nan],ACCEPTED MANUSCRIPTS.,0,0,0,0,0,1992,05,01
60,3,1992-05-01,ECONLIT None Found,[nan],[nan],[nan],THE 1992 INDIA AND SOUTHEAST ASIA MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,05,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],ACCEPTED MANUSCRIPTS.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],THE 1993 FAR EASTERN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],"EUROPEAN MEETING OF THE ECONOMETRIC SOCIETY BRUSSELS, BELGIUM, 1992.",0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],"NOMINATION OF FELLOWS, 1992.",0,0,0,0,0,1992,03,01
60,2,1992-03-01,ECONLIT None Found,[nan],[nan],[nan],CONTENTS.,0,0,0,0,0,1992,03,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],ACCEPTED MANUSCRIPTS.,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],1993 NORTH AMERICAN WINTER MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],THE 1992 INDIA AND SOUTHEAST ASIA MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],1992 AUSTRALASIAN MEETING OF THE ECONOMETRIC SOCIETY.,0,0,0,0,0,1992,01,01
60,1,1992-01-01,ECONLIT None Found,[nan],[nan],[nan],"NOMINATION OF FELLOWS, 1992.",0,0,0,0,0,1992,01,01
73,3,2005-05-01,ECONLIT None Found,"['King, Ian', 'Tang, Xueli']","['Fiscal Policy', 'Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies', 'Personal Income and Other Nonbusiness Taxes and Subsidies; includes inheritance and gift taxes', 'Educational Finance; Financial Aid', 'One, Two, and Multisector Growth Models']","['E62', 'H23', 'H24', 'I22', 'O41']",A Comment on Roland Benabou's 'Tax and Education Policy in a Heterogeneous-Agent Economy: What Levels of Redistribution Maximize Growth and Efficiency?',0,0,0,0,0,2005,05,01
65,5,1997-09-01,ECONLIT None Found,"['Chakravarty, Satya R.']",['Measurement and Analysis of Poverty'],['I32'],On Shorrocks' Reinvestigation of the Sen Poverty Index,0,0,0,0,0,1997,09,01
64,5,1996-09-01,ECONLIT None Found,"['Hanson, Robin']",['Search; Learning; Information and Knowledge; Communication; Belief; Unawareness'],['D83'],"Correction to McKelvey and Page, 'Public and Private Information: An Experimental Study of Information Pooling'",0,0,0,0,0,1996,09,01
61,1,1993-01-01,ECONLIT None Found,"['Perron, P.']","['Single Equation Models; Single Variables: Time-Series Models; Dynamic Quantile Regressions; Dynamic Treatment Effect Models; Diffusion Processes', 'Business Fluctuations; Cycles']","['C22', 'E32']","Erratum [The Great Crash, the Oil Price Shock and the Unit Root Hypothesis].",0,0,0,0,0,1993,01,01
64,6,1996-11-01,ECONLIT None Found,"['Gallant, A. Ronald', 'Fenton, Victor M.']",['Estimation: General'],['C13'],Erratum [Convergence Rates of SNP Density Estimators].,0,0,0,0,0,1996,11,01
58,2,1990-03-01,ECONLIT None Found,"['Forges, Francoise']",['Game Theory and Bargaining Theory'],[nan],Correlated Equilibrium in Two-Person Zero-Sum Games,0,0,0,0,0,1990,03,01
