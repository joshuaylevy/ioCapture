# README

## About
This folder is dedicated to data collection, cleaning, and matching.

## Files and Folders

### Folders
- econ_lit_xml
    - This folder contains the .xml files that are generated by the EconLit batch citation tool.
    - Procedure: After running an exclusive year-appropriate (1990-2021), ISSN-based Boolean search, all of the article meta-data can be downloaded by clicking "Share" and then "E-mail a link to download exported results ()". An email will then be sent to the designated address with a download link for the .xml file.
    - Submit these queries and download these downloads at the journal-level.
    - The format for the .xml filename should be "[PUBCODE]_[Start YY]-[End YY].xml"
    - These are raw data files; they should **NOT** be edited.
- econlit_scopus_matching_out
    - This folder contains the .csv files that underlie the papers dataset(s). There are 4 types of .csv files:
    1. '[PUBCODE]_author_abstract_funding.csv'
        - This .csv contains article-author-level observations from the [Scopus Abstract Retrieval API](https://dev.elsevier.com/documentation/AbstractRetrievalAPI.wadl). Each article-level observation contains doi, volume, issue, date, publication name, title, page-range,  
        - This .csv file is generated by `scopus_read.ipynb` in the `abstract_references_collect()` function.
        - These are effectively raw data files; they should **NOT** be edited. 
    2. '[PUBCODE]_cites.csv'
        - This .csv file contains article-citation-level observations from the [Scopus Abstract Retrieval API](). Each article-citation-level contains xxxxxxxxxxxxxxxxxxxxxxxxxx.
        - This .csv file is generated by `scopus_read.ipynb` in the `abstract_references_collect()` function.
        - These are effectively raw data files; the should **NOT** be edited.
    3. '[PUBCODE]_scopus_core.csv'
        - This .csv contains article-level observations from the [Scopus Search API](https://dev.elsevier.com/documentation/SCOPUSSearchAPI.wadl). Each article-level observation contains doi, title, publication name, volume, issue, page-range, date, and open-access status information. Additionally, columns for the article's corresponding abstract retrieval API endpoint and the API endpoint that was used to generate the observation of interest are made available.
        - This .csv file is generated by `scopus_read.ipynb` in the `publication_collect()` function.
        - These are raw data files; they should **NOT** be edited.
    4. '[pubcode]_econlit.csv' 
        - This .csv file contains article-level observations from EconLit. It is generated by `jel_scopus_matching.ipynb` which reads in the .xml files in the folder "00_Scraping/econ_lit_xml/". The article-level observations contains volume, issue, date, author, abstract, JEL code/description, title and some other extraneous data.
- nber_scholars
  - This folder contains several output .csvs with scholar-level data for scholars who are *currently* affiliated with the NBER.
- nber_working_papers
  - This folder contains .PDF files of NBER working papers. These are collected by STEP 3 in `nber_scholars_papers_links.ipynb`

### Scripts
- `author_abstract_analysis.ipynb`
  - This is mostly a scratchpad script for generating statistic of interest for the 04-21 and 05-16 reports (see '.../adhoc_material/Reports'). This can be further refined when we have a better idea of how exactly we want to subset/identify data.
- `scopus_read.ipynb`
  - This is the primary Scopus collection script.
- `nber_pdf_to_text.ipynb`
  - This is an in-progress script for converting .PDF files to strings (looking for both NBER working paper JEL codes and the first-footnote/thanks section). This is going to take considerable work because a lot of documents are going to require OCR.
- `nber_scholar_scraper.ipynb`
  - This script identifies scholars who are *currently* affiliated with NBER programs of interest by using the NBER's exposed APIs. Scholar-level results are stored in `nber_scholars/nber_affiliated_scholars.csv`.
- `nber_scholars_papers_links.ipynb`
  - This script uses the scholar-level data identified by `nber_scholar_scraper.ipynb` and stored in `nber_affiliated_scholars.csv` to identify those scholars NBER working papers (and associated abstracts, disclosures etc.). Paper-level results are stored in `nber_scholars/nber_affiliated_scholar_paper.csv` and the papers themselves are downloaded and stored in the `nber_papers` folder as .PDF files.
- `jel_scopus_matching.ipynb`
  - This is an in-progress script that reads in EconLit .xml files (to convert them to .csv files) and Scopus .csv files and matches them to each other and with JEL codes. So far the EconLit-JEL matching is done but the EconLit-Scopus matching has yet to be completed.


### Misc.
- `aea_jel_codes.xml`
  - This is effectively a table of JEL codes and their descriptions exactly the way the AEA writes them. We use this for matching codes to descriptions. This file has been collected from the AEA's [website](https://www.aeaweb.org/econlit/jelCodes.php).
    - The codes and descriptions can be accessed in Python scripts using the following code
    ```python
        df = pd.read_xml('aea_jel_codes.xml', xpath='classification)
    ```
- `env_keys.json`
  - This contains API keys for SCOPUS. VERY IMPORTANT TO NOT UPLOAD THIS TO GITHUB. ENSURE THAT IT IS IN YOUR `.gitignore` FILE.
- `proxies.txt`
  - John is subscribed to a proxy-hosting service. We use these proxies to route our traffic when web-scraping so that our IPs are masked. Note that the proxy addresses in this .txt file are scrambled. To actually use them, split each line on colons (':') and then rearrange in order [2,3,0,1]. VERY IMPORTANT TO NOT UPLOAD THIS TO GITHUB. ENSURE THAT IT IS IN YOUR `.gitignore` FILE.
- `test.json`
  - There are a bunch of API calls that get made throughout many of these files. I usually format the response as JSON objects. I often copy-paste those objects into a separate .json file so that there is nice formatting when I am writing code/figuring out how to extract the actual data of interest. This is that .json file 
- `authors_of_interest.md`
  - We are briefly interested in looking at how (well) published certain IO, finance, and labor economists are. This is just a list of names with their Scopus author IDs.
